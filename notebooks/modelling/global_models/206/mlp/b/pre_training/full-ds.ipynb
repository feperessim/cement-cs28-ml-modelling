{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 12:33:28.896949: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-11 12:33:28.899971: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-11 12:33:28.961578: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-11 12:33:28.962710: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-11 12:33:29.916646: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/206/mlp/b/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 1\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 1\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 1\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"206\\\",\\n    \\\"Plant\\\": \\\"B\\\",\\n    \\\"Features\\\": \\\"Chemical + Physical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"206\\\",\\n    \\\"Plant\\\": \\\"B\\\",\\n    \\\"Features\\\": \\\"Chemical + Physical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"206\",\n",
    "    \"Plant\": \"B\",\n",
    "    \"Features\": \"Chemical + Physical\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/206/global_b.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/206/global_b.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/206/global_b.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7f76b_row0_col0 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7f76b_row1_col0, #T_7f76b_row2_col0, #T_7f76b_row3_col0, #T_7f76b_row4_col0, #T_7f76b_row5_col0, #T_7f76b_row6_col0, #T_7f76b_row7_col0, #T_7f76b_row8_col0, #T_7f76b_row9_col0, #T_7f76b_row10_col0, #T_7f76b_row11_col0, #T_7f76b_row12_col0 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7f76b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7f76b_level0_col0\" class=\"col_heading level0 col0\" >Zero (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7f76b_level0_row0\" class=\"row_heading level0 row0\" >#200</th>\n",
       "      <td id=\"T_7f76b_row0_col0\" class=\"data row0 col0\" >13.998534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f76b_level0_row1\" class=\"row_heading level0 row1\" >MgO</th>\n",
       "      <td id=\"T_7f76b_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f76b_level0_row2\" class=\"row_heading level0 row2\" >SO3</th>\n",
       "      <td id=\"T_7f76b_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f76b_level0_row3\" class=\"row_heading level0 row3\" >Loss on Ignition</th>\n",
       "      <td id=\"T_7f76b_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f76b_level0_row4\" class=\"row_heading level0 row4\" >Insoluble Residue</th>\n",
       "      <td id=\"T_7f76b_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f76b_level0_row5\" class=\"row_heading level0 row5\" >Blaine</th>\n",
       "      <td id=\"T_7f76b_row5_col0\" class=\"data row5 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f76b_level0_row6\" class=\"row_heading level0 row6\" >#325</th>\n",
       "      <td id=\"T_7f76b_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f76b_level0_row7\" class=\"row_heading level0 row7\" >Initial setting time</th>\n",
       "      <td id=\"T_7f76b_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f76b_level0_row8\" class=\"row_heading level0 row8\" >Final setting time</th>\n",
       "      <td id=\"T_7f76b_row8_col0\" class=\"data row8 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f76b_level0_row9\" class=\"row_heading level0 row9\" >CS1</th>\n",
       "      <td id=\"T_7f76b_row9_col0\" class=\"data row9 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f76b_level0_row10\" class=\"row_heading level0 row10\" >CS3</th>\n",
       "      <td id=\"T_7f76b_row10_col0\" class=\"data row10 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f76b_level0_row11\" class=\"row_heading level0 row11\" >CS7</th>\n",
       "      <td id=\"T_7f76b_row11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f76b_level0_row12\" class=\"row_heading level0 row12\" >CS28</th>\n",
       "      <td id=\"T_7f76b_row12_col0\" class=\"data row12 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ba7aa703ca0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_formatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_values = {}\n",
    "for col in df.select_dtypes(include=\"number\").columns:\n",
    "    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\n",
    "    zero_values[col] = zero_percentages\n",
    "\n",
    "zero_percentages = pd.Series(zero_values, name=f\"Zero (%)\")\n",
    "zero_percentages = zero_percentages.sort_values(ascending=False)\n",
    "zero_percentages = zero_percentages.to_frame(name=f\"Zero (%)\")\n",
    "zero_percentages.style.background_gradient(cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop([\\\"Cement_Type\\\", \\\"Factory_Plant\\\"], axis=1)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop([\\\"Cement_Type\\\", \\\"Factory_Plant\\\"], axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop([\"Cement_Type\", \"Factory_Plant\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 12:33:34.903286: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  9.254107344150544\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.414 (0.000)\n",
      "MAE: 1.070 (0.000)\n",
      "MAPE: 0.024 (0.000)\n",
      "R2: 0.958 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.627 (0.000)\n",
      "MAE: 1.233 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.927 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  10.27252864042918\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.450 (0.000)\n",
      "MAE: 1.093 (0.000)\n",
      "MAPE: 0.025 (0.000)\n",
      "R2: 0.955 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.652 (0.000)\n",
      "MAE: 1.257 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.925 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  13.734217087427774\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.413 (0.000)\n",
      "MAE: 1.095 (0.000)\n",
      "MAPE: 0.025 (0.000)\n",
      "R2: 0.958 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.665 (0.000)\n",
      "MAE: 1.285 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.923 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  18.14204713900884\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.494 (0.000)\n",
      "MAE: 1.158 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.953 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.736 (0.000)\n",
      "MAE: 1.344 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.917 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  19.627054599920907\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.314 (0.000)\n",
      "MAE: 0.998 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.963 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.604 (0.000)\n",
      "MAE: 1.201 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.929 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  30.080585956573486\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.331 (0.000)\n",
      "MAE: 1.000 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.962 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.571 (0.000)\n",
      "MAE: 1.167 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.932 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  28.11012737751007\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.282 (0.000)\n",
      "MAE: 0.977 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.965 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.590 (0.000)\n",
      "MAE: 1.195 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.930 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  18.66994342406591\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.348 (0.000)\n",
      "MAE: 1.046 (0.000)\n",
      "MAPE: 0.024 (0.000)\n",
      "R2: 0.961 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.694 (0.000)\n",
      "MAE: 1.296 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.921 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  27.402089393138887\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.636 (0.000)\n",
      "MAE: 1.281 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.943 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.027 (0.000)\n",
      "MAE: 1.578 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.887 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  28.063943537076316\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.290 (0.000)\n",
      "MAE: 0.979 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.965 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.582 (0.000)\n",
      "MAE: 1.168 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.931 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.900498394171397\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.326 (0.000)\n",
      "MAE: 1.000 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.963 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.543 (0.000)\n",
      "MAE: 1.153 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.934 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.536941993236542\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.433 (0.000)\n",
      "MAE: 1.080 (0.000)\n",
      "MAPE: 0.024 (0.000)\n",
      "R2: 0.957 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.599 (0.000)\n",
      "MAE: 1.207 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.929 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.38301369746526\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.665 (0.000)\n",
      "MAE: 1.266 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.941 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.662 (0.000)\n",
      "MAE: 1.254 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.924 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/206/b/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/206/b/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/206/b/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>206</td>\n",
       "      <td>B</td>\n",
       "      <td>Chemical + Physical</td>\n",
       "      <td>(64121, 12)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_11</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>1.325525</td>\n",
       "      <td>0.999631</td>\n",
       "      <td>0.022437</td>\n",
       "      <td>0.962785</td>\n",
       "      <td>1.542577</td>\n",
       "      <td>1.152931</td>\n",
       "      <td>0.026871</td>\n",
       "      <td>0.934304</td>\n",
       "      <td>-3.765867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category Company Plant             Features   Data Shape Timesteps  \\\n",
       "10  Global Model     206     B  Chemical + Physical  (64121, 12)      None   \n",
       "\n",
       "     Model Model Params           Scaler Scaler Params  ...  \\\n",
       "10  MLP_11         None  Standard Scaler          None  ...   \n",
       "\n",
       "                  Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "10  {\"train_size\": 0.8, \"test_size\": 0.2}   1.325525  0.999631   0.022437   \n",
       "\n",
       "    R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "10  0.962785   1.542577  1.152931   0.026871  0.934304 -3.765867  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  31.222840782006582\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.293 (0.000)\n",
      "MAE: 0.977 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.963 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.293 (0.000)\n",
      "MAE: 0.977 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.963 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\nmodel_name = \\\"mlp_full_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\nmodel_name = \\\"mlp_full_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/206/mlp/b/pre_training/\"\n",
    "model_name = \"mlp_full_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ba7a7916aa0>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ba5367a3af0>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ba51cca2920>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ba614f3dd20>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 256)               3328      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 16)                64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49089 (191.75 KB)\n",
      "Trainable params: 48097 (187.88 KB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
