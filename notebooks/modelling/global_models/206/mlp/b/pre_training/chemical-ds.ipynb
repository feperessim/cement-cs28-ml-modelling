{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 12:33:03.794130: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-11 12:33:03.796649: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-11 12:33:03.843099: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-11 12:33:03.844243: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-11 12:33:04.594151: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/206/mlp/b/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 2\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 2\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 2\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"206\\\",\\n    \\\"Plant\\\": \\\"B\\\",\\n    \\\"Features\\\": \\\"Chemical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"206\\\",\\n    \\\"Plant\\\": \\\"B\\\",\\n    \\\"Features\\\": \\\"Chemical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"206\",\n",
    "    \"Plant\": \"B\",\n",
    "    \"Features\": \"Chemical\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/206/global_b.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/206/global_b.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/206/global_b.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Cement_Type\\\",\\n        \\\"Factory_Plant\\\",\\n        \\\"Blaine\\\",\\n        \\\"#200\\\",\\n        \\\"#325\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Cement_Type\\\",\\n        \\\"Factory_Plant\\\",\\n        \\\"Blaine\\\",\\n        \\\"#200\\\",\\n        \\\"#325\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop(\n",
    "    [\n",
    "        \"Cement_Type\",\n",
    "        \"Factory_Plant\",\n",
    "        \"Blaine\",\n",
    "        \"#200\",\n",
    "        \"#325\",\n",
    "        \"Final setting time\",\n",
    "        \"Initial setting time\",\n",
    "        \"CS1\",\n",
    "        \"CS3\",\n",
    "        \"CS7\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 12:33:08.309593: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  9.571970121065776\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 3.117 (0.000)\n",
      "MAE: 2.288 (0.000)\n",
      "MAPE: 0.052 (0.000)\n",
      "R2: 0.794 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.382 (0.000)\n",
      "MAE: 2.504 (0.000)\n",
      "MAPE: 0.059 (0.000)\n",
      "R2: 0.684 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  10.382642424106598\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 3.152 (0.000)\n",
      "MAE: 2.325 (0.000)\n",
      "MAPE: 0.053 (0.000)\n",
      "R2: 0.790 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.441 (0.000)\n",
      "MAE: 2.525 (0.000)\n",
      "MAPE: 0.060 (0.000)\n",
      "R2: 0.673 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  13.865054949124653\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.855 (0.000)\n",
      "MAE: 2.103 (0.000)\n",
      "MAPE: 0.048 (0.000)\n",
      "R2: 0.827 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.373 (0.000)\n",
      "MAE: 2.496 (0.000)\n",
      "MAPE: 0.060 (0.000)\n",
      "R2: 0.686 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  17.67194552818934\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.681 (0.000)\n",
      "MAE: 1.932 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.848 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.285 (0.000)\n",
      "MAE: 2.377 (0.000)\n",
      "MAPE: 0.056 (0.000)\n",
      "R2: 0.702 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  21.387825946013134\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.793 (0.000)\n",
      "MAE: 2.005 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.835 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.370 (0.000)\n",
      "MAE: 2.425 (0.000)\n",
      "MAPE: 0.057 (0.000)\n",
      "R2: 0.686 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  30.544779960314433\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.831 (0.000)\n",
      "MAE: 2.030 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.830 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.251 (0.000)\n",
      "MAE: 2.339 (0.000)\n",
      "MAPE: 0.055 (0.000)\n",
      "R2: 0.708 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  28.719509466489157\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.709 (0.000)\n",
      "MAE: 1.935 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.845 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.265 (0.000)\n",
      "MAE: 2.359 (0.000)\n",
      "MAPE: 0.056 (0.000)\n",
      "R2: 0.706 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  18.389114971955618\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.741 (0.000)\n",
      "MAE: 1.973 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.841 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.328 (0.000)\n",
      "MAE: 2.365 (0.000)\n",
      "MAPE: 0.056 (0.000)\n",
      "R2: 0.694 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  27.2508927265803\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.763 (0.000)\n",
      "MAE: 2.055 (0.000)\n",
      "MAPE: 0.047 (0.000)\n",
      "R2: 0.838 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.367 (0.000)\n",
      "MAE: 2.508 (0.000)\n",
      "MAPE: 0.060 (0.000)\n",
      "R2: 0.687 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  27.984473061561584\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.737 (0.000)\n",
      "MAE: 1.964 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.841 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.251 (0.000)\n",
      "MAE: 2.325 (0.000)\n",
      "MAPE: 0.055 (0.000)\n",
      "R2: 0.708 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.09398892323176\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.818 (0.000)\n",
      "MAE: 2.019 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.832 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.226 (0.000)\n",
      "MAE: 2.325 (0.000)\n",
      "MAPE: 0.055 (0.000)\n",
      "R2: 0.713 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.483843350410462\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 3.004 (0.000)\n",
      "MAE: 2.189 (0.000)\n",
      "MAPE: 0.050 (0.000)\n",
      "R2: 0.809 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.230 (0.000)\n",
      "MAE: 2.333 (0.000)\n",
      "MAPE: 0.055 (0.000)\n",
      "R2: 0.712 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.476867604255677\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 3.489 (0.000)\n",
      "MAE: 2.649 (0.000)\n",
      "MAPE: 0.059 (0.000)\n",
      "R2: 0.742 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.360 (0.000)\n",
      "MAE: 2.533 (0.000)\n",
      "MAPE: 0.060 (0.000)\n",
      "R2: 0.688 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/206/b/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/206/b/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/206/b/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>206</td>\n",
       "      <td>B</td>\n",
       "      <td>Chemical</td>\n",
       "      <td>(64121, 4)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_11</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>2.817743</td>\n",
       "      <td>2.019496</td>\n",
       "      <td>0.045798</td>\n",
       "      <td>0.83183</td>\n",
       "      <td>3.225938</td>\n",
       "      <td>2.32504</td>\n",
       "      <td>0.054846</td>\n",
       "      <td>0.712684</td>\n",
       "      <td>-4.955771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category Company Plant  Features  Data Shape Timesteps   Model  \\\n",
       "10  Global Model     206     B  Chemical  (64121, 4)      None  MLP_11   \n",
       "\n",
       "   Model Params           Scaler Scaler Params  ...  \\\n",
       "10         None  Standard Scaler          None  ...   \n",
       "\n",
       "                  Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "10  {\"train_size\": 0.8, \"test_size\": 0.2}   2.817743  2.019496   0.045798   \n",
       "\n",
       "    R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "10   0.83183   3.225938   2.32504   0.054846  0.712684 -4.955771  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R²\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  32.41312770446142\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.817 (0.000)\n",
      "MAE: 2.024 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.825 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.817 (0.000)\n",
      "MAE: 2.024 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.825 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/206/mlp/b/pre_training/\"\n",
    "model_name = \"mlp_chemical_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7816e6033940>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7816e5f1f940>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7816e5fa9f60>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7816e5e1fee0>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 256)               1280      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 16)                64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47041 (183.75 KB)\n",
      "Trainable params: 46049 (179.88 KB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
