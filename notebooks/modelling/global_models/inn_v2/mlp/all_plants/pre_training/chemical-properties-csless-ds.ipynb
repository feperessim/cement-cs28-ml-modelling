{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 11:50:41.146737: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-04 11:50:41.149061: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-04 11:50:41.195774: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-04 11:50:41.196857: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-04 11:50:41.936303: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/206/mlp/b/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 10\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 10\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 10\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"INN\\\",\\n    \\\"Plant\\\": \\\"INN\\\",\\n    \\\"Features\\\": \\\"Chemical + Properties CS Less\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"INN\\\",\\n    \\\"Plant\\\": \\\"INN\\\",\\n    \\\"Features\\\": \\\"Chemical + Properties CS Less\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"INN\",\n",
    "    \"Plant\": \"INN\",\n",
    "    \"Features\": \"Chemical + Properties CS Less\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/inn/global_dataset_inn_v2.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/inn/global_dataset_inn_v2.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/inn/global_dataset_inn_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_eba8b_row0_col0, #T_eba8b_row1_col0, #T_eba8b_row2_col0, #T_eba8b_row3_col0, #T_eba8b_row4_col0, #T_eba8b_row5_col0, #T_eba8b_row6_col0, #T_eba8b_row7_col0, #T_eba8b_row8_col0, #T_eba8b_row9_col0, #T_eba8b_row10_col0, #T_eba8b_row11_col0, #T_eba8b_row12_col0, #T_eba8b_row13_col0, #T_eba8b_row14_col0, #T_eba8b_row15_col0, #T_eba8b_row16_col0, #T_eba8b_row17_col0, #T_eba8b_row18_col0, #T_eba8b_row19_col0 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_eba8b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_eba8b_level0_col0\" class=\"col_heading level0 col0\" >Zero (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_eba8b_level0_row0\" class=\"row_heading level0 row0\" >Blaine</th>\n",
       "      <td id=\"T_eba8b_row0_col0\" class=\"data row0 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eba8b_level0_row1\" class=\"row_heading level0 row1\" >C3A</th>\n",
       "      <td id=\"T_eba8b_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eba8b_level0_row2\" class=\"row_heading level0 row2\" >Initial setting time</th>\n",
       "      <td id=\"T_eba8b_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eba8b_level0_row3\" class=\"row_heading level0 row3\" >Total C3S</th>\n",
       "      <td id=\"T_eba8b_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eba8b_level0_row4\" class=\"row_heading level0 row4\" >Na2O</th>\n",
       "      <td id=\"T_eba8b_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eba8b_level0_row5\" class=\"row_heading level0 row5\" >K2O</th>\n",
       "      <td id=\"T_eba8b_row5_col0\" class=\"data row5 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eba8b_level0_row6\" class=\"row_heading level0 row6\" >MgO</th>\n",
       "      <td id=\"T_eba8b_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eba8b_level0_row7\" class=\"row_heading level0 row7\" >Fe2O3</th>\n",
       "      <td id=\"T_eba8b_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eba8b_level0_row8\" class=\"row_heading level0 row8\" >Al2O3</th>\n",
       "      <td id=\"T_eba8b_row8_col0\" class=\"data row8 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eba8b_level0_row9\" class=\"row_heading level0 row9\" >SiO2</th>\n",
       "      <td id=\"T_eba8b_row9_col0\" class=\"data row9 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eba8b_level0_row10\" class=\"row_heading level0 row10\" >Free CaO</th>\n",
       "      <td id=\"T_eba8b_row10_col0\" class=\"data row10 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eba8b_level0_row11\" class=\"row_heading level0 row11\" >CaO</th>\n",
       "      <td id=\"T_eba8b_row11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eba8b_level0_row12\" class=\"row_heading level0 row12\" >C4AF</th>\n",
       "      <td id=\"T_eba8b_row12_col0\" class=\"data row12 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eba8b_level0_row13\" class=\"row_heading level0 row13\" >SO3</th>\n",
       "      <td id=\"T_eba8b_row13_col0\" class=\"data row13 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eba8b_level0_row14\" class=\"row_heading level0 row14\" >#325</th>\n",
       "      <td id=\"T_eba8b_row14_col0\" class=\"data row14 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eba8b_level0_row15\" class=\"row_heading level0 row15\" >CS28</th>\n",
       "      <td id=\"T_eba8b_row15_col0\" class=\"data row15 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eba8b_level0_row16\" class=\"row_heading level0 row16\" >CS3</th>\n",
       "      <td id=\"T_eba8b_row16_col0\" class=\"data row16 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eba8b_level0_row17\" class=\"row_heading level0 row17\" >CS1</th>\n",
       "      <td id=\"T_eba8b_row17_col0\" class=\"data row17 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eba8b_level0_row18\" class=\"row_heading level0 row18\" >Loss on Ignition</th>\n",
       "      <td id=\"T_eba8b_row18_col0\" class=\"data row18 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eba8b_level0_row19\" class=\"row_heading level0 row19\" >CS7</th>\n",
       "      <td id=\"T_eba8b_row19_col0\" class=\"data row19 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x70b7939c7040>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_formatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_values = {}\n",
    "for col in df.select_dtypes(include=\"number\").columns:\n",
    "    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\n",
    "    zero_values[col] = zero_percentages\n",
    "\n",
    "zero_percentages = pd.Series(zero_values, name=f\"Zero (%)\")\n",
    "zero_percentages = zero_percentages.sort_values(ascending=False)\n",
    "zero_percentages = zero_percentages.to_frame(name=f\"Zero (%)\")\n",
    "zero_percentages.style.background_gradient(cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Factory_Plant\\\",\\n        \\\"Cement_Type\\\",\\n        \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Factory_Plant\\\",\\n        \\\"Cement_Type\\\",\\n        \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop(\n",
    "    [\n",
    "        \"Factory_Plant\",\n",
    "        \"Cement_Type\",\n",
    "        \"CS1\",\n",
    "        \"CS3\",\n",
    "        \"CS7\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 11:50:46.669173: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.4209365963935852\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.177 (0.000)\n",
      "MAE: 1.617 (0.000)\n",
      "MAPE: 0.036 (0.000)\n",
      "R2: 0.840 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.397 (0.000)\n",
      "MAE: 2.681 (0.000)\n",
      "MAPE: 0.057 (0.000)\n",
      "R2: 0.732 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.4267141898473104\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.241 (0.000)\n",
      "MAE: 1.667 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.830 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.476 (0.000)\n",
      "MAE: 2.783 (0.000)\n",
      "MAPE: 0.059 (0.000)\n",
      "R2: 0.719 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.5184265812238057\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.219 (0.000)\n",
      "MAE: 1.654 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.833 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.598 (0.000)\n",
      "MAE: 2.840 (0.000)\n",
      "MAPE: 0.059 (0.000)\n",
      "R2: 0.699 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.5949118137359619\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 5.557 (0.000)\n",
      "MAE: 4.980 (0.000)\n",
      "MAPE: 0.109 (0.000)\n",
      "R2: -0.044 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 7.092 (0.000)\n",
      "MAE: 6.333 (0.000)\n",
      "MAPE: 0.130 (0.000)\n",
      "R2: -0.170 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.6245603481928508\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.044 (0.000)\n",
      "MAE: 1.478 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.859 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.387 (0.000)\n",
      "MAE: 2.581 (0.000)\n",
      "MAPE: 0.054 (0.000)\n",
      "R2: 0.733 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.9418090979258219\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.970 (0.000)\n",
      "MAE: 1.435 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.869 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.344 (0.000)\n",
      "MAE: 2.537 (0.000)\n",
      "MAPE: 0.053 (0.000)\n",
      "R2: 0.740 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.904841939608256\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.742 (0.000)\n",
      "MAE: 1.279 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.897 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.329 (0.000)\n",
      "MAE: 2.498 (0.000)\n",
      "MAPE: 0.053 (0.000)\n",
      "R2: 0.742 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.5899747014045715\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.111 (0.000)\n",
      "MAE: 1.559 (0.000)\n",
      "MAPE: 0.034 (0.000)\n",
      "R2: 0.849 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.770 (0.000)\n",
      "MAE: 2.914 (0.000)\n",
      "MAPE: 0.061 (0.000)\n",
      "R2: 0.669 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.8305942972501119\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 6.029 (0.000)\n",
      "MAE: 5.633 (0.000)\n",
      "MAPE: 0.124 (0.000)\n",
      "R2: -0.230 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 7.813 (0.000)\n",
      "MAE: 7.130 (0.000)\n",
      "MAPE: 0.148 (0.000)\n",
      "R2: -0.420 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.8603607217470804\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.044 (0.000)\n",
      "MAE: 1.544 (0.000)\n",
      "MAPE: 0.034 (0.000)\n",
      "R2: 0.859 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.741 (0.000)\n",
      "MAE: 2.987 (0.000)\n",
      "MAPE: 0.063 (0.000)\n",
      "R2: 0.674 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.9109929998715719\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.920 (0.000)\n",
      "MAE: 1.401 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.875 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.338 (0.000)\n",
      "MAE: 2.546 (0.000)\n",
      "MAPE: 0.054 (0.000)\n",
      "R2: 0.741 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.5950914939244588\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.238 (0.000)\n",
      "MAE: 1.669 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.831 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.643 (0.000)\n",
      "MAE: 2.845 (0.000)\n",
      "MAPE: 0.060 (0.000)\n",
      "R2: 0.691 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.5773919820785522\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.039 (0.000)\n",
      "MAE: 1.470 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.859 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.466 (0.000)\n",
      "MAE: 2.616 (0.000)\n",
      "MAPE: 0.054 (0.000)\n",
      "R2: 0.721 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/inn_v2/all_cements/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/inn_v2/all_cements/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/inn_v2/all_cements/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>INN</td>\n",
       "      <td>INN</td>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>(2226, 16)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_7</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>1.74168</td>\n",
       "      <td>1.279226</td>\n",
       "      <td>0.028323</td>\n",
       "      <td>0.897394</td>\n",
       "      <td>3.329241</td>\n",
       "      <td>2.497709</td>\n",
       "      <td>0.052801</td>\n",
       "      <td>0.74216</td>\n",
       "      <td>-2.163137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category Company Plant                       Features  Data Shape  \\\n",
       "6  Global Model     INN   INN  Chemical + Properties CS Less  (2226, 16)   \n",
       "\n",
       "  Timesteps  Model Model Params           Scaler Scaler Params  ...  \\\n",
       "6      None  MLP_7         None  Standard Scaler          None  ...   \n",
       "\n",
       "                 Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "6  {\"train_size\": 0.8, \"test_size\": 0.2}    1.74168  1.279226   0.028323   \n",
       "\n",
       "   R2 Train  RMSE Test  MAE Test  MAPE Test  R2 Test      SCPM  \n",
       "6  0.897394   3.329241  2.497709   0.052801  0.74216 -2.163137  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R²\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  1.1009176095326743\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.800 (0.000)\n",
      "MAE: 1.316 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.903 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.800 (0.000)\n",
      "MAE: 1.316 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.903 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 63;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/inn/mlp/inn/pre_training\\\"\\nmodel_name = \\\"mlp_chemical_properties_csless_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/inn/mlp/inn/pre_training\\\"\\nmodel_name = \\\"mlp_chemical_properties_csless_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/inn/mlp/inn/pre_training\"\n",
    "model_name = \"mlp_chemical_properties_csless_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 64;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 65;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x70b6247279d0>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x70b624664b20>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x70b6ac6afee0>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x70b624a20820>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 256)               4352      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 16)                64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50113 (195.75 KB)\n",
      "Trainable params: 49121 (191.88 KB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
