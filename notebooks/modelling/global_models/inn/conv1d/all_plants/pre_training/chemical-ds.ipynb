{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-01T19:37:38.021523Z",
     "iopub.status.busy": "2022-10-01T19:37:38.021092Z",
     "iopub.status.idle": "2022-10-01T19:37:42.654282Z",
     "shell.execute_reply": "2022-10-01T19:37:42.653296Z",
     "shell.execute_reply.started": "2022-10-01T19:37:38.021438Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 23:59:58.339819: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-15 23:59:58.343041: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-15 23:59:58.425860: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-15 23:59:58.427944: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-15 23:59:59.844995: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Plotting\\nimport matplotlib.pyplot as plt\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.model_selection import TimeSeriesSplit\\nfrom sklearn.model_selection import RepeatedKFold\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.model_selection import cross_validate\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.preprocessing import RobustScaler\\n\\n# Metrics\\nfrom sklearn.metrics import mean_squared_error\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.metrics import mean_absolute_percentage_error\\nfrom sklearn.metrics import r2_score\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import BaseEstimator, RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\n# Converting Times Series Data to 3D format\\nfrom src.utils.split_sequences import split_sequences\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Plotting\\nimport matplotlib.pyplot as plt\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.model_selection import TimeSeriesSplit\\nfrom sklearn.model_selection import RepeatedKFold\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.model_selection import cross_validate\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.preprocessing import RobustScaler\\n\\n# Metrics\\nfrom sklearn.metrics import mean_squared_error\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.metrics import mean_absolute_percentage_error\\nfrom sklearn.metrics import r2_score\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import BaseEstimator, RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\n# Converting Times Series Data to 3D format\\nfrom src.utils.split_sequences import split_sequences\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "# Converting Times Series Data to 3D format\n",
    "from src.utils.split_sequences import split_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert train/test data to 3D format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def generate_sequences_helper(\\n    dataset, cement_types, dates=None, timesteps=None, split_by_cement_type=False\\n):\\n    index_train = dataset[\\\"y_train\\\"].index\\n    index_test = dataset[\\\"y_test\\\"].index\\n\\n    dataset[\\\"y_train\\\"] = dataset[\\\"y_train\\\"].reset_index(drop=True)\\n    dataset[\\\"y_test\\\"] = dataset[\\\"y_test\\\"].reset_index(drop=True)\\n\\n    if dates is not None:\\n        dataset[\\\"dates_train\\\"] = dates[index_train].reset_index(drop=True)\\n        dataset[\\\"dates_test\\\"] = dates[index_test].reset_index(drop=True)\\n\\n    dataset[\\\"cement_types_train\\\"] = cement_types.loc[index_train].reset_index(drop=True)\\n    dataset[\\\"cement_types_test\\\"] = cement_types.loc[index_test].reset_index(drop=True)\\n\\n    dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\\n\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def generate_sequences_helper(\\n    dataset, cement_types, dates=None, timesteps=None, split_by_cement_type=False\\n):\\n    index_train = dataset[\\\"y_train\\\"].index\\n    index_test = dataset[\\\"y_test\\\"].index\\n\\n    dataset[\\\"y_train\\\"] = dataset[\\\"y_train\\\"].reset_index(drop=True)\\n    dataset[\\\"y_test\\\"] = dataset[\\\"y_test\\\"].reset_index(drop=True)\\n\\n    if dates is not None:\\n        dataset[\\\"dates_train\\\"] = dates[index_train].reset_index(drop=True)\\n        dataset[\\\"dates_test\\\"] = dates[index_test].reset_index(drop=True)\\n\\n    dataset[\\\"cement_types_train\\\"] = cement_types.loc[index_train].reset_index(drop=True)\\n    dataset[\\\"cement_types_test\\\"] = cement_types.loc[index_test].reset_index(drop=True)\\n\\n    dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\\n\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_sequences_helper(\n",
    "    dataset, cement_types, dates=None, timesteps=None, split_by_cement_type=False\n",
    "):\n",
    "    index_train = dataset[\"y_train\"].index\n",
    "    index_test = dataset[\"y_test\"].index\n",
    "\n",
    "    dataset[\"y_train\"] = dataset[\"y_train\"].reset_index(drop=True)\n",
    "    dataset[\"y_test\"] = dataset[\"y_test\"].reset_index(drop=True)\n",
    "\n",
    "    if dates is not None:\n",
    "        dataset[\"dates_train\"] = dates[index_train].reset_index(drop=True)\n",
    "        dataset[\"dates_test\"] = dates[index_test].reset_index(drop=True)\n",
    "\n",
    "    dataset[\"cement_types_train\"] = cement_types.loc[index_train].reset_index(drop=True)\n",
    "    dataset[\"cement_types_test\"] = cement_types.loc[index_test].reset_index(drop=True)\n",
    "\n",
    "    dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"def generate_sequences(\\n    dataset,\\n    timesteps,\\n    split_by_cement_type=False,\\n    train_columns=[],\\n    test_columns=[],\\n):\\n    if split_by_cement_type:\\n        dataset[\\\"x_train\\\"], dataset[\\\"y_train\\\"] = split_sequences_per_cement_type(\\n            pd.concat(\\n                [\\n                    dataset[\\\"dates_train\\\"],\\n                    pd.DataFrame(dataset[\\\"x_train\\\"], columns=train_columns),\\n                    dataset[\\\"cement_types_train\\\"],\\n                    dataset[\\\"y_train\\\"],\\n                ],\\n                axis=1,\\n            ),\\n            timesteps,\\n        )\\n\\n        dataset[\\\"x_test\\\"], dataset[\\\"y_test\\\"] = split_sequences_per_cement_type(\\n            pd.concat(\\n                [\\n                    dataset[\\\"dates_test\\\"],\\n                    pd.DataFrame(dataset[\\\"x_test\\\"], columns=test_columns),\\n                    dataset[\\\"cement_types_test\\\"],\\n                    dataset[\\\"y_test\\\"],\\n                ],\\n                axis=1,\\n            ),\\n            timesteps,\\n        )\\n    else:\\n        dataset[\\\"x_train\\\"], dataset[\\\"y_train\\\"] = split_sequences(\\n            pd.concat(\\n                [\\n                    pd.DataFrame(dataset[\\\"x_train\\\"], columns=train_columns),\\n                    dataset[\\\"y_train\\\"],\\n                ],\\n                axis=1,\\n            ).values,\\n            timesteps,\\n        )\\n\\n        dataset[\\\"x_test\\\"], dataset[\\\"y_test\\\"] = split_sequences(\\n            pd.concat(\\n                [\\n                    pd.DataFrame(dataset[\\\"x_test\\\"], columns=test_columns),\\n                    dataset[\\\"y_test\\\"],\\n                ],\\n                axis=1,\\n            ).values,\\n            timesteps,\\n        )\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def generate_sequences(\\n    dataset,\\n    timesteps,\\n    split_by_cement_type=False,\\n    train_columns=[],\\n    test_columns=[],\\n):\\n    if split_by_cement_type:\\n        dataset[\\\"x_train\\\"], dataset[\\\"y_train\\\"] = split_sequences_per_cement_type(\\n            pd.concat(\\n                [\\n                    dataset[\\\"dates_train\\\"],\\n                    pd.DataFrame(dataset[\\\"x_train\\\"], columns=train_columns),\\n                    dataset[\\\"cement_types_train\\\"],\\n                    dataset[\\\"y_train\\\"],\\n                ],\\n                axis=1,\\n            ),\\n            timesteps,\\n        )\\n\\n        dataset[\\\"x_test\\\"], dataset[\\\"y_test\\\"] = split_sequences_per_cement_type(\\n            pd.concat(\\n                [\\n                    dataset[\\\"dates_test\\\"],\\n                    pd.DataFrame(dataset[\\\"x_test\\\"], columns=test_columns),\\n                    dataset[\\\"cement_types_test\\\"],\\n                    dataset[\\\"y_test\\\"],\\n                ],\\n                axis=1,\\n            ),\\n            timesteps,\\n        )\\n    else:\\n        dataset[\\\"x_train\\\"], dataset[\\\"y_train\\\"] = split_sequences(\\n            pd.concat(\\n                [\\n                    pd.DataFrame(dataset[\\\"x_train\\\"], columns=train_columns),\\n                    dataset[\\\"y_train\\\"],\\n                ],\\n                axis=1,\\n            ).values,\\n            timesteps,\\n        )\\n\\n        dataset[\\\"x_test\\\"], dataset[\\\"y_test\\\"] = split_sequences(\\n            pd.concat(\\n                [\\n                    pd.DataFrame(dataset[\\\"x_test\\\"], columns=test_columns),\\n                    dataset[\\\"y_test\\\"],\\n                ],\\n                axis=1,\\n            ).values,\\n            timesteps,\\n        )\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_sequences(\n",
    "    dataset,\n",
    "    timesteps,\n",
    "    split_by_cement_type=False,\n",
    "    train_columns=[],\n",
    "    test_columns=[],\n",
    "):\n",
    "    if split_by_cement_type:\n",
    "        dataset[\"x_train\"], dataset[\"y_train\"] = split_sequences_per_cement_type(\n",
    "            pd.concat(\n",
    "                [\n",
    "                    dataset[\"dates_train\"],\n",
    "                    pd.DataFrame(dataset[\"x_train\"], columns=train_columns),\n",
    "                    dataset[\"cement_types_train\"],\n",
    "                    dataset[\"y_train\"],\n",
    "                ],\n",
    "                axis=1,\n",
    "            ),\n",
    "            timesteps,\n",
    "        )\n",
    "\n",
    "        dataset[\"x_test\"], dataset[\"y_test\"] = split_sequences_per_cement_type(\n",
    "            pd.concat(\n",
    "                [\n",
    "                    dataset[\"dates_test\"],\n",
    "                    pd.DataFrame(dataset[\"x_test\"], columns=test_columns),\n",
    "                    dataset[\"cement_types_test\"],\n",
    "                    dataset[\"y_test\"],\n",
    "                ],\n",
    "                axis=1,\n",
    "            ),\n",
    "            timesteps,\n",
    "        )\n",
    "    else:\n",
    "        dataset[\"x_train\"], dataset[\"y_train\"] = split_sequences(\n",
    "            pd.concat(\n",
    "                [\n",
    "                    pd.DataFrame(dataset[\"x_train\"], columns=train_columns),\n",
    "                    dataset[\"y_train\"],\n",
    "                ],\n",
    "                axis=1,\n",
    "            ).values,\n",
    "            timesteps,\n",
    "        )\n",
    "\n",
    "        dataset[\"x_test\"], dataset[\"y_test\"] = split_sequences(\n",
    "            pd.concat(\n",
    "                [\n",
    "                    pd.DataFrame(dataset[\"x_test\"], columns=test_columns),\n",
    "                    dataset[\"y_test\"],\n",
    "                ],\n",
    "                axis=1,\n",
    "            ).values,\n",
    "            timesteps,\n",
    "        )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"def impute_data(dataset, imputer=None, imputer_params=None):\\n    x_train = dataset[\\\"x_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n\\n    # Apply imputation to the data\\n    if imputer is not None:\\n        imputer = imputer() if imputer_params is None else imputer(**imputer_params)\\n        x_train = imputer.fit_transform(x_train)\\n        x_test = imputer.transform(x_test)\\n\\n    dataset[\\\"x_train\\\"] = x_train\\n    dataset[\\\"x_test\\\"] = x_test\\n\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def impute_data(dataset, imputer=None, imputer_params=None):\\n    x_train = dataset[\\\"x_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n\\n    # Apply imputation to the data\\n    if imputer is not None:\\n        imputer = imputer() if imputer_params is None else imputer(**imputer_params)\\n        x_train = imputer.fit_transform(x_train)\\n        x_test = imputer.transform(x_test)\\n\\n    dataset[\\\"x_train\\\"] = x_train\\n    dataset[\\\"x_test\\\"] = x_test\\n\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def impute_data(dataset, imputer=None, imputer_params=None):\n",
    "    x_train = dataset[\"x_train\"]\n",
    "    x_test = dataset[\"x_test\"]\n",
    "\n",
    "    # Apply imputation to the data\n",
    "    if imputer is not None:\n",
    "        imputer = imputer() if imputer_params is None else imputer(**imputer_params)\n",
    "        x_train = imputer.fit_transform(x_train)\n",
    "        x_test = imputer.transform(x_test)\n",
    "\n",
    "    dataset[\"x_train\"] = x_train\n",
    "    dataset[\"x_test\"] = x_test\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"def transform_data(dataset, transformer=None):\\n    x_train = dataset[\\\"x_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n\\n    # Apply data normalization/standardization to the data\\n    if transformer is not None:\\n        scaler = transformer()\\n        x_train = scaler.fit_transform(x_train)\\n        x_test = scaler.transform(x_test)\\n\\n    dataset[\\\"x_train\\\"] = x_train\\n    dataset[\\\"x_test\\\"] = x_test\\n\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def transform_data(dataset, transformer=None):\\n    x_train = dataset[\\\"x_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n\\n    # Apply data normalization/standardization to the data\\n    if transformer is not None:\\n        scaler = transformer()\\n        x_train = scaler.fit_transform(x_train)\\n        x_test = scaler.transform(x_test)\\n\\n    dataset[\\\"x_train\\\"] = x_train\\n    dataset[\\\"x_test\\\"] = x_test\\n\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def transform_data(dataset, transformer=None):\n",
    "    x_train = dataset[\"x_train\"]\n",
    "    x_test = dataset[\"x_test\"]\n",
    "\n",
    "    # Apply data normalization/standardization to the data\n",
    "    if transformer is not None:\n",
    "        scaler = transformer()\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "    dataset[\"x_train\"] = x_train\n",
    "    dataset[\"x_test\"] = x_test\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"def preprocess_data(dataset, transformer=None, imputer=None, imputer_params=None):\\n    dataset = impute_data(dataset, imputer, imputer_params)\\n    dataset = transform_data(dataset, transformer)\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def preprocess_data(dataset, transformer=None, imputer=None, imputer_params=None):\\n    dataset = impute_data(dataset, imputer, imputer_params)\\n    dataset = transform_data(dataset, transformer)\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_data(dataset, transformer=None, imputer=None, imputer_params=None):\n",
    "    dataset = impute_data(dataset, imputer, imputer_params)\n",
    "    dataset = transform_data(dataset, transformer)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"def train_and_evaluate_model(Estimator, dataset, estimator_params=None):\\n    \\\"\\\"\\\"\\n    Purpose: Helper function to be used in conjunction with\\n    blocked time_series cross validation function\\n    \\\"\\\"\\\"\\n    x_train = dataset[\\\"x_train\\\"]\\n    y_train = dataset[\\\"y_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n    y_test = dataset[\\\"y_test\\\"]\\n\\n    # Instantiate the model\\n    model = Estimator() if estimator_params is None else Estimator(estimator_params)\\n\\n    # Fitting the model\\n    model.fit(x_train, y_train)\\n\\n    # Making predictions on train/test sets\\n    y_train_pred = model.predict(x_train)\\n    y_test_pred = model.predict(x_test)\\n\\n    # Return regression metrics\\n    return model, score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"def train_and_evaluate_model(Estimator, dataset, estimator_params=None):\\n    \\\"\\\"\\\"\\n    Purpose: Helper function to be used in conjunction with\\n    blocked time_series cross validation function\\n    \\\"\\\"\\\"\\n    x_train = dataset[\\\"x_train\\\"]\\n    y_train = dataset[\\\"y_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n    y_test = dataset[\\\"y_test\\\"]\\n\\n    # Instantiate the model\\n    model = Estimator() if estimator_params is None else Estimator(estimator_params)\\n\\n    # Fitting the model\\n    model.fit(x_train, y_train)\\n\\n    # Making predictions on train/test sets\\n    y_train_pred = model.predict(x_train)\\n    y_test_pred = model.predict(x_test)\\n\\n    # Return regression metrics\\n    return model, score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_and_evaluate_model(Estimator, dataset, estimator_params=None):\n",
    "    \"\"\"\n",
    "    Purpose: Helper function to be used in conjunction with\n",
    "    blocked time_series cross validation function\n",
    "    \"\"\"\n",
    "    x_train = dataset[\"x_train\"]\n",
    "    y_train = dataset[\"y_train\"]\n",
    "    x_test = dataset[\"x_test\"]\n",
    "    y_test = dataset[\"y_test\"]\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = Estimator() if estimator_params is None else Estimator(estimator_params)\n",
    "\n",
    "    # Fitting the model\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Making predictions on train/test sets\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "\n",
    "    # Return regression metrics\n",
    "    return model, score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"def evaluate_model(model, dataset):\\n    \\\"\\\"\\\"\\n    Purpose: Helper function to be used in conjunction with\\n    blocked time_series cross validation function\\n    \\\"\\\"\\\"\\n    x_train = dataset[\\\"x_train\\\"]\\n    y_train = dataset[\\\"y_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n    y_test = dataset[\\\"y_test\\\"]\\n\\n    # Making predictions on train/test sets\\n    y_train_pred = model.predict(x_train)\\n    y_test_pred = model.predict(x_test)\\n\\n    # Return regression metrics\\n    return score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"def evaluate_model(model, dataset):\\n    \\\"\\\"\\\"\\n    Purpose: Helper function to be used in conjunction with\\n    blocked time_series cross validation function\\n    \\\"\\\"\\\"\\n    x_train = dataset[\\\"x_train\\\"]\\n    y_train = dataset[\\\"y_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n    y_test = dataset[\\\"y_test\\\"]\\n\\n    # Making predictions on train/test sets\\n    y_train_pred = model.predict(x_train)\\n    y_test_pred = model.predict(x_test)\\n\\n    # Return regression metrics\\n    return score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_model(model, dataset):\n",
    "    \"\"\"\n",
    "    Purpose: Helper function to be used in conjunction with\n",
    "    blocked time_series cross validation function\n",
    "    \"\"\"\n",
    "    x_train = dataset[\"x_train\"]\n",
    "    y_train = dataset[\"y_train\"]\n",
    "    x_test = dataset[\"x_test\"]\n",
    "    y_test = dataset[\"y_test\"]\n",
    "\n",
    "    # Making predictions on train/test sets\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "\n",
    "    # Return regression metrics\n",
    "    return score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Cross Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"def custom_cross_validate(\\n    Estimator,\\n    Imputer,\\n    Transform,\\n    x,\\n    y,\\n    cv,\\n    timesteps,\\n    dates=None,\\n    cement_types=None,\\n    estimator_params=None,\\n    imputer_params=None,\\n    split_by_cement_type=True,\\n):\\n    results = []\\n    scores = []\\n\\n    for train_index, test_index in cv.split(x):\\n        dataset = {\\n            \\\"dates_train\\\": dates[train_index].reset_index(drop=True),\\n            \\\"cement_types_train\\\": cement_types.loc[train_index].reset_index(drop=True),\\n            \\\"x_train\\\": x.loc[train_index].reset_index(drop=True),\\n            \\\"y_train\\\": y[train_index].reset_index(drop=True),\\n            \\\"dates_test\\\": dates[test_index].reset_index(drop=True),\\n            \\\"cement_types_test\\\": cement_types.loc[test_index].reset_index(drop=True),\\n            \\\"x_test\\\": x.loc[test_index].reset_index(drop=True),\\n            \\\"y_test\\\": y[test_index].reset_index(drop=True),\\n        }\\n\\n        # Preprocess the dataset\\n        dataset = preprocess_data(dataset, Transform, Imputer, imputer_params)\\n\\n        # generate sequences (3D format)\\n        dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\\n\\n        # Train and Evaluate the model\\n        score = train_and_evaluate_model(Estimator, dataset, estimator_params)\\n        scores.append(score)\\n\\n    # After every iteration metrics results are appended together\\n    scores_final = {key: [] for key, _ in scores[0].items()}\\n    for scores_dict in scores:\\n        for key, value in scores_dict.items():\\n            scores_final[key] += [value]\\n    results.append(scores_final)\\n    return results\";\n",
       "                var nbb_formatted_code = \"def custom_cross_validate(\\n    Estimator,\\n    Imputer,\\n    Transform,\\n    x,\\n    y,\\n    cv,\\n    timesteps,\\n    dates=None,\\n    cement_types=None,\\n    estimator_params=None,\\n    imputer_params=None,\\n    split_by_cement_type=True,\\n):\\n    results = []\\n    scores = []\\n\\n    for train_index, test_index in cv.split(x):\\n        dataset = {\\n            \\\"dates_train\\\": dates[train_index].reset_index(drop=True),\\n            \\\"cement_types_train\\\": cement_types.loc[train_index].reset_index(drop=True),\\n            \\\"x_train\\\": x.loc[train_index].reset_index(drop=True),\\n            \\\"y_train\\\": y[train_index].reset_index(drop=True),\\n            \\\"dates_test\\\": dates[test_index].reset_index(drop=True),\\n            \\\"cement_types_test\\\": cement_types.loc[test_index].reset_index(drop=True),\\n            \\\"x_test\\\": x.loc[test_index].reset_index(drop=True),\\n            \\\"y_test\\\": y[test_index].reset_index(drop=True),\\n        }\\n\\n        # Preprocess the dataset\\n        dataset = preprocess_data(dataset, Transform, Imputer, imputer_params)\\n\\n        # generate sequences (3D format)\\n        dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\\n\\n        # Train and Evaluate the model\\n        score = train_and_evaluate_model(Estimator, dataset, estimator_params)\\n        scores.append(score)\\n\\n    # After every iteration metrics results are appended together\\n    scores_final = {key: [] for key, _ in scores[0].items()}\\n    for scores_dict in scores:\\n        for key, value in scores_dict.items():\\n            scores_final[key] += [value]\\n    results.append(scores_final)\\n    return results\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def custom_cross_validate(\n",
    "    Estimator,\n",
    "    Imputer,\n",
    "    Transform,\n",
    "    x,\n",
    "    y,\n",
    "    cv,\n",
    "    timesteps,\n",
    "    dates=None,\n",
    "    cement_types=None,\n",
    "    estimator_params=None,\n",
    "    imputer_params=None,\n",
    "    split_by_cement_type=True,\n",
    "):\n",
    "    results = []\n",
    "    scores = []\n",
    "\n",
    "    for train_index, test_index in cv.split(x):\n",
    "        dataset = {\n",
    "            \"dates_train\": dates[train_index].reset_index(drop=True),\n",
    "            \"cement_types_train\": cement_types.loc[train_index].reset_index(drop=True),\n",
    "            \"x_train\": x.loc[train_index].reset_index(drop=True),\n",
    "            \"y_train\": y[train_index].reset_index(drop=True),\n",
    "            \"dates_test\": dates[test_index].reset_index(drop=True),\n",
    "            \"cement_types_test\": cement_types.loc[test_index].reset_index(drop=True),\n",
    "            \"x_test\": x.loc[test_index].reset_index(drop=True),\n",
    "            \"y_test\": y[test_index].reset_index(drop=True),\n",
    "        }\n",
    "\n",
    "        # Preprocess the dataset\n",
    "        dataset = preprocess_data(dataset, Transform, Imputer, imputer_params)\n",
    "\n",
    "        # generate sequences (3D format)\n",
    "        dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\n",
    "\n",
    "        # Train and Evaluate the model\n",
    "        score = train_and_evaluate_model(Estimator, dataset, estimator_params)\n",
    "        scores.append(score)\n",
    "\n",
    "    # After every iteration metrics results are appended together\n",
    "    scores_final = {key: [] for key, _ in scores[0].items()}\n",
    "    for scores_dict in scores:\n",
    "        for key, value in scores_dict.items():\n",
    "            scores_final[key] += [value]\n",
    "    results.append(scores_final)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class Conv1D_1(BaseEstimator, RegressorMixin):\\n    def __init__(self, params):\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = params.get(\\\"verbose\\\", 0)\\n        self.callbacks = params.get(\\\"callbacks\\\", None)\\n        self.validation_split = params.get(\\\"validation_split\\\", None)\\n        self.kernel_size = params.get(\\\"kernel_size\\\", 1)\\n        self.activation = params.get(\\\"activation\\\", \\\"relu\\\")\\n        self.padding = params.get(\\\"padding\\\", \\\"causal\\\")\\n        self.strides = params.get(\\\"strides\\\", 1)\\n        self.pool_size = params.get(\\\"pool_size\\\", 1)\\n        self.model = self.get_model()\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(\\n            tf.keras.layers.Conv1D(\\n                filters=64,\\n                kernel_size=self.kernel_size,\\n                activation=self.activation,\\n                padding=self.padding,\\n                strides=self.strides,\\n            )\\n        )\\n        model.add(tf.keras.layers.MaxPooling1D(pool_size=self.pool_size))\\n        model.add(tf.keras.layers.Flatten())\\n        model.add(tf.keras.layers.Dense(32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class Conv1D_1(BaseEstimator, RegressorMixin):\\n    def __init__(self, params):\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = params.get(\\\"verbose\\\", 0)\\n        self.callbacks = params.get(\\\"callbacks\\\", None)\\n        self.validation_split = params.get(\\\"validation_split\\\", None)\\n        self.kernel_size = params.get(\\\"kernel_size\\\", 1)\\n        self.activation = params.get(\\\"activation\\\", \\\"relu\\\")\\n        self.padding = params.get(\\\"padding\\\", \\\"causal\\\")\\n        self.strides = params.get(\\\"strides\\\", 1)\\n        self.pool_size = params.get(\\\"pool_size\\\", 1)\\n        self.model = self.get_model()\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(\\n            tf.keras.layers.Conv1D(\\n                filters=64,\\n                kernel_size=self.kernel_size,\\n                activation=self.activation,\\n                padding=self.padding,\\n                strides=self.strides,\\n            )\\n        )\\n        model.add(tf.keras.layers.MaxPooling1D(pool_size=self.pool_size))\\n        model.add(tf.keras.layers.Flatten())\\n        model.add(tf.keras.layers.Dense(32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Conv1D_1(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, params):\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = params.get(\"verbose\", 0)\n",
    "        self.callbacks = params.get(\"callbacks\", None)\n",
    "        self.validation_split = params.get(\"validation_split\", None)\n",
    "        self.kernel_size = params.get(\"kernel_size\", 1)\n",
    "        self.activation = params.get(\"activation\", \"relu\")\n",
    "        self.padding = params.get(\"padding\", \"causal\")\n",
    "        self.strides = params.get(\"strides\", 1)\n",
    "        self.pool_size = params.get(\"pool_size\", 1)\n",
    "        self.model = self.get_model()\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(\n",
    "            tf.keras.layers.Conv1D(\n",
    "                filters=64,\n",
    "                kernel_size=self.kernel_size,\n",
    "                activation=self.activation,\n",
    "                padding=self.padding,\n",
    "                strides=self.strides,\n",
    "            )\n",
    "        )\n",
    "        model.add(tf.keras.layers.MaxPooling1D(pool_size=self.pool_size))\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class Conv1D_2(BaseEstimator, RegressorMixin):\\n    def __init__(self, params):\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = params.get(\\\"verbose\\\", 0)\\n        self.callbacks = params.get(\\\"callbacks\\\", None)\\n        self.validation_split = params.get(\\\"validation_split\\\", None)\\n        self.kernel_size = params.get(\\\"kernel_size\\\", 1)\\n        self.activation = params.get(\\\"activation\\\", \\\"relu\\\")\\n        self.padding = params.get(\\\"padding\\\", \\\"causal\\\")\\n        self.strides = params.get(\\\"strides\\\", 1)\\n        self.pool_size = params.get(\\\"pool_size\\\", 1)\\n        self.model = self.get_model()\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(\\n            tf.keras.layers.Conv1D(\\n                filters=64,\\n                kernel_size=self.kernel_size,\\n                activation=self.activation,\\n                padding=self.padding,\\n                strides=self.strides,\\n            )\\n        )\\n        model.add(tf.keras.layers.AveragePooling1D(pool_size=self.pool_size))\\n        model.add(tf.keras.layers.Flatten())\\n        model.add(tf.keras.layers.Dense(32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class Conv1D_2(BaseEstimator, RegressorMixin):\\n    def __init__(self, params):\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = params.get(\\\"verbose\\\", 0)\\n        self.callbacks = params.get(\\\"callbacks\\\", None)\\n        self.validation_split = params.get(\\\"validation_split\\\", None)\\n        self.kernel_size = params.get(\\\"kernel_size\\\", 1)\\n        self.activation = params.get(\\\"activation\\\", \\\"relu\\\")\\n        self.padding = params.get(\\\"padding\\\", \\\"causal\\\")\\n        self.strides = params.get(\\\"strides\\\", 1)\\n        self.pool_size = params.get(\\\"pool_size\\\", 1)\\n        self.model = self.get_model()\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(\\n            tf.keras.layers.Conv1D(\\n                filters=64,\\n                kernel_size=self.kernel_size,\\n                activation=self.activation,\\n                padding=self.padding,\\n                strides=self.strides,\\n            )\\n        )\\n        model.add(tf.keras.layers.AveragePooling1D(pool_size=self.pool_size))\\n        model.add(tf.keras.layers.Flatten())\\n        model.add(tf.keras.layers.Dense(32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Conv1D_2(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, params):\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = params.get(\"verbose\", 0)\n",
    "        self.callbacks = params.get(\"callbacks\", None)\n",
    "        self.validation_split = params.get(\"validation_split\", None)\n",
    "        self.kernel_size = params.get(\"kernel_size\", 1)\n",
    "        self.activation = params.get(\"activation\", \"relu\")\n",
    "        self.padding = params.get(\"padding\", \"causal\")\n",
    "        self.strides = params.get(\"strides\", 1)\n",
    "        self.pool_size = params.get(\"pool_size\", 1)\n",
    "        self.model = self.get_model()\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(\n",
    "            tf.keras.layers.Conv1D(\n",
    "                filters=64,\n",
    "                kernel_size=self.kernel_size,\n",
    "                activation=self.activation,\n",
    "                padding=self.padding,\n",
    "                strides=self.strides,\n",
    "            )\n",
    "        )\n",
    "        model.add(tf.keras.layers.AveragePooling1D(pool_size=self.pool_size))\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class Conv1D_3(BaseEstimator, RegressorMixin):\\n    def __init__(self, params):\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = params.get(\\\"verbose\\\", 0)\\n        self.callbacks = params.get(\\\"callbacks\\\", None)\\n        self.validation_split = params.get(\\\"validation_split\\\", None)\\n        self.kernel_size = params.get(\\\"kernel_size\\\", 1)\\n        self.activation = params.get(\\\"activation\\\", \\\"relu\\\")\\n        self.padding = params.get(\\\"padding\\\", \\\"causal\\\")\\n        self.strides = params.get(\\\"strides\\\", 1)\\n        self.pool_size = params.get(\\\"pool_size\\\", 1)\\n        self.model = self.get_model()\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(\\n            tf.keras.layers.Conv1D(\\n                filters=128,\\n                kernel_size=self.kernel_size,\\n                activation=self.activation,\\n                padding=self.padding,\\n                strides=self.strides,\\n            )\\n        )\\n        model.add(tf.keras.layers.MaxPooling1D(pool_size=self.pool_size))\\n        model.add(tf.keras.layers.Flatten())\\n        model.add(tf.keras.layers.Dense(32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class Conv1D_3(BaseEstimator, RegressorMixin):\\n    def __init__(self, params):\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = params.get(\\\"verbose\\\", 0)\\n        self.callbacks = params.get(\\\"callbacks\\\", None)\\n        self.validation_split = params.get(\\\"validation_split\\\", None)\\n        self.kernel_size = params.get(\\\"kernel_size\\\", 1)\\n        self.activation = params.get(\\\"activation\\\", \\\"relu\\\")\\n        self.padding = params.get(\\\"padding\\\", \\\"causal\\\")\\n        self.strides = params.get(\\\"strides\\\", 1)\\n        self.pool_size = params.get(\\\"pool_size\\\", 1)\\n        self.model = self.get_model()\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(\\n            tf.keras.layers.Conv1D(\\n                filters=128,\\n                kernel_size=self.kernel_size,\\n                activation=self.activation,\\n                padding=self.padding,\\n                strides=self.strides,\\n            )\\n        )\\n        model.add(tf.keras.layers.MaxPooling1D(pool_size=self.pool_size))\\n        model.add(tf.keras.layers.Flatten())\\n        model.add(tf.keras.layers.Dense(32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Conv1D_3(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, params):\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = params.get(\"verbose\", 0)\n",
    "        self.callbacks = params.get(\"callbacks\", None)\n",
    "        self.validation_split = params.get(\"validation_split\", None)\n",
    "        self.kernel_size = params.get(\"kernel_size\", 1)\n",
    "        self.activation = params.get(\"activation\", \"relu\")\n",
    "        self.padding = params.get(\"padding\", \"causal\")\n",
    "        self.strides = params.get(\"strides\", 1)\n",
    "        self.pool_size = params.get(\"pool_size\", 1)\n",
    "        self.model = self.get_model()\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(\n",
    "            tf.keras.layers.Conv1D(\n",
    "                filters=128,\n",
    "                kernel_size=self.kernel_size,\n",
    "                activation=self.activation,\n",
    "                padding=self.padding,\n",
    "                strides=self.strides,\n",
    "            )\n",
    "        )\n",
    "        model.add(tf.keras.layers.MaxPooling1D(pool_size=self.pool_size))\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class Conv1D_4(BaseEstimator, RegressorMixin):\\n    def __init__(self, params):\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = params.get(\\\"verbose\\\", 0)\\n        self.callbacks = params.get(\\\"callbacks\\\", None)\\n        self.validation_split = params.get(\\\"validation_split\\\", None)\\n        self.kernel_size = params.get(\\\"kernel_size\\\", 1)\\n        self.activation = params.get(\\\"activation\\\", \\\"relu\\\")\\n        self.padding = params.get(\\\"padding\\\", \\\"causal\\\")\\n        self.strides = params.get(\\\"strides\\\", 1)\\n        self.pool_size = params.get(\\\"pool_size\\\", 1)\\n        self.model = self.get_model()\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(\\n            tf.keras.layers.Conv1D(\\n                filters=128,\\n                kernel_size=self.kernel_size,\\n                activation=self.activation,\\n                padding=self.padding,\\n                strides=self.strides,\\n            )\\n        )\\n        model.add(tf.keras.layers.AveragePooling1D(pool_size=self.pool_size))\\n        model.add(tf.keras.layers.Flatten())\\n        model.add(tf.keras.layers.Dense(32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class Conv1D_4(BaseEstimator, RegressorMixin):\\n    def __init__(self, params):\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = params.get(\\\"verbose\\\", 0)\\n        self.callbacks = params.get(\\\"callbacks\\\", None)\\n        self.validation_split = params.get(\\\"validation_split\\\", None)\\n        self.kernel_size = params.get(\\\"kernel_size\\\", 1)\\n        self.activation = params.get(\\\"activation\\\", \\\"relu\\\")\\n        self.padding = params.get(\\\"padding\\\", \\\"causal\\\")\\n        self.strides = params.get(\\\"strides\\\", 1)\\n        self.pool_size = params.get(\\\"pool_size\\\", 1)\\n        self.model = self.get_model()\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(\\n            tf.keras.layers.Conv1D(\\n                filters=128,\\n                kernel_size=self.kernel_size,\\n                activation=self.activation,\\n                padding=self.padding,\\n                strides=self.strides,\\n            )\\n        )\\n        model.add(tf.keras.layers.AveragePooling1D(pool_size=self.pool_size))\\n        model.add(tf.keras.layers.Flatten())\\n        model.add(tf.keras.layers.Dense(32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Conv1D_4(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, params):\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = params.get(\"verbose\", 0)\n",
    "        self.callbacks = params.get(\"callbacks\", None)\n",
    "        self.validation_split = params.get(\"validation_split\", None)\n",
    "        self.kernel_size = params.get(\"kernel_size\", 1)\n",
    "        self.activation = params.get(\"activation\", \"relu\")\n",
    "        self.padding = params.get(\"padding\", \"causal\")\n",
    "        self.strides = params.get(\"strides\", 1)\n",
    "        self.pool_size = params.get(\"pool_size\", 1)\n",
    "        self.model = self.get_model()\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(\n",
    "            tf.keras.layers.Conv1D(\n",
    "                filters=128,\n",
    "                kernel_size=self.kernel_size,\n",
    "                activation=self.activation,\n",
    "                padding=self.padding,\n",
    "                strides=self.strides,\n",
    "            )\n",
    "        )\n",
    "        model.add(tf.keras.layers.AveragePooling1D(pool_size=self.pool_size))\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class Conv1D_5(BaseEstimator, RegressorMixin):\\n    def __init__(self, params):\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = params.get(\\\"verbose\\\", 0)\\n        self.callbacks = params.get(\\\"callbacks\\\", None)\\n        self.validation_split = params.get(\\\"validation_split\\\", None)\\n        self.kernel_size = params.get(\\\"kernel_size\\\", 1)\\n        self.activation = params.get(\\\"activation\\\", \\\"relu\\\")\\n        self.padding = params.get(\\\"padding\\\", \\\"causal\\\")\\n        self.strides = params.get(\\\"strides\\\", 1)\\n        self.pool_size = params.get(\\\"pool_size\\\", 1)\\n        self.model = self.get_model()\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(\\n            tf.keras.layers.Conv1D(\\n                filters=64,\\n                kernel_size=self.kernel_size,\\n                activation=self.activation,\\n                padding=self.padding,\\n                strides=self.strides,\\n            )\\n        )\\n        model.add(\\n            tf.keras.layers.Conv1D(\\n                filters=32,\\n                kernel_size=self.kernel_size,\\n                activation=self.activation,\\n                padding=self.padding,\\n                strides=self.strides,\\n            )\\n        )\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.AveragePooling1D(pool_size=self.pool_size))\\n        model.add(tf.keras.layers.Flatten())\\n        model.add(tf.keras.layers.Dense(32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class Conv1D_5(BaseEstimator, RegressorMixin):\\n    def __init__(self, params):\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = params.get(\\\"verbose\\\", 0)\\n        self.callbacks = params.get(\\\"callbacks\\\", None)\\n        self.validation_split = params.get(\\\"validation_split\\\", None)\\n        self.kernel_size = params.get(\\\"kernel_size\\\", 1)\\n        self.activation = params.get(\\\"activation\\\", \\\"relu\\\")\\n        self.padding = params.get(\\\"padding\\\", \\\"causal\\\")\\n        self.strides = params.get(\\\"strides\\\", 1)\\n        self.pool_size = params.get(\\\"pool_size\\\", 1)\\n        self.model = self.get_model()\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(\\n            tf.keras.layers.Conv1D(\\n                filters=64,\\n                kernel_size=self.kernel_size,\\n                activation=self.activation,\\n                padding=self.padding,\\n                strides=self.strides,\\n            )\\n        )\\n        model.add(\\n            tf.keras.layers.Conv1D(\\n                filters=32,\\n                kernel_size=self.kernel_size,\\n                activation=self.activation,\\n                padding=self.padding,\\n                strides=self.strides,\\n            )\\n        )\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.AveragePooling1D(pool_size=self.pool_size))\\n        model.add(tf.keras.layers.Flatten())\\n        model.add(tf.keras.layers.Dense(32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Conv1D_5(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, params):\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = params.get(\"verbose\", 0)\n",
    "        self.callbacks = params.get(\"callbacks\", None)\n",
    "        self.validation_split = params.get(\"validation_split\", None)\n",
    "        self.kernel_size = params.get(\"kernel_size\", 1)\n",
    "        self.activation = params.get(\"activation\", \"relu\")\n",
    "        self.padding = params.get(\"padding\", \"causal\")\n",
    "        self.strides = params.get(\"strides\", 1)\n",
    "        self.pool_size = params.get(\"pool_size\", 1)\n",
    "        self.model = self.get_model()\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(\n",
    "            tf.keras.layers.Conv1D(\n",
    "                filters=64,\n",
    "                kernel_size=self.kernel_size,\n",
    "                activation=self.activation,\n",
    "                padding=self.padding,\n",
    "                strides=self.strides,\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "            tf.keras.layers.Conv1D(\n",
    "                filters=32,\n",
    "                kernel_size=self.kernel_size,\n",
    "                activation=self.activation,\n",
    "                padding=self.padding,\n",
    "                strides=self.strides,\n",
    "            )\n",
    "        )\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.AveragePooling1D(pool_size=self.pool_size))\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"def pad_time_series(dataframe, timesteps):\\n    \\\"\\\"\\\"\\n    Pad timeseries with zeros\\n    \\\"\\\"\\\"\\n    df_tmp = pd.DataFrame(\\n        dict(\\n            zip(\\n                dataframe.columns,\\n                [[0 for _ in range(timesteps - 1)] for _ in range(dataframe.shape[1])],\\n            )\\n        )\\n    )\\n    df_tmp[DATE] = dataframe[DATE].iloc[0]\\n    return pd.concat([df_tmp, dataframe], axis=0).reset_index(drop=True)\";\n",
       "                var nbb_formatted_code = \"def pad_time_series(dataframe, timesteps):\\n    \\\"\\\"\\\"\\n    Pad timeseries with zeros\\n    \\\"\\\"\\\"\\n    df_tmp = pd.DataFrame(\\n        dict(\\n            zip(\\n                dataframe.columns,\\n                [[0 for _ in range(timesteps - 1)] for _ in range(dataframe.shape[1])],\\n            )\\n        )\\n    )\\n    df_tmp[DATE] = dataframe[DATE].iloc[0]\\n    return pd.concat([df_tmp, dataframe], axis=0).reset_index(drop=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pad_time_series(dataframe, timesteps):\n",
    "    \"\"\"\n",
    "    Pad timeseries with zeros\n",
    "    \"\"\"\n",
    "    df_tmp = pd.DataFrame(\n",
    "        dict(\n",
    "            zip(\n",
    "                dataframe.columns,\n",
    "                [[0 for _ in range(timesteps - 1)] for _ in range(dataframe.shape[1])],\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    df_tmp[DATE] = dataframe[DATE].iloc[0]\n",
    "    return pd.concat([df_tmp, dataframe], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def split_sequences_per_cement_type(dataframe, timesteps, pad=False):\\n    \\\"\\\"\\\"\\n    Create sequences per cement time\\n    to avoid having parts of the sequence\\n    of different types of cement.\\n    \\\"\\\"\\\"\\n    if timesteps == 1:\\n        return split_sequences(\\n            dataframe.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps\\n        )\\n\\n    dates = dataframe[DATE][timesteps - 1 :]\\n    data = []\\n    dataframes = []\\n\\n    for cement_type in CEMENT_TYPES:\\n        data.append(dataframe[dataframe[cement_type] == 1])\\n    data.append(dataframe[(dataframe[CEMENT_TYPES] == 0).all(axis=1)])\\n\\n    for df in data:\\n        if pad:\\n            dates = df[DATE].reset_index(drop=True)\\n            df = pad_time_series(df, timesteps).reset_index(drop=True)\\n        else:\\n            dates = df[DATE][timesteps - 1 :].reset_index(drop=True)\\n        x, y = split_sequences(df.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps)\\n        x = pd.DataFrame({\\\"Sequences\\\": [sample.tolist() for sample in x]})\\n        y = pd.DataFrame({\\\"Target\\\": y})\\n        dataframes.append(pd.concat([dates, x, y], axis=1))\\n\\n    data = pd.concat(dataframes, axis=0)\\n    data[DATE] = pd.to_datetime(data[DATE])\\n    data = data.sort_values(by=DATE).reset_index(drop=True)\\n    x = data[\\\"Sequences\\\"]\\n    y = data[\\\"Target\\\"].values\\n    x = np.array(x.tolist())\\n\\n    return x, y\";\n",
       "                var nbb_formatted_code = \"def split_sequences_per_cement_type(dataframe, timesteps, pad=False):\\n    \\\"\\\"\\\"\\n    Create sequences per cement time\\n    to avoid having parts of the sequence\\n    of different types of cement.\\n    \\\"\\\"\\\"\\n    if timesteps == 1:\\n        return split_sequences(\\n            dataframe.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps\\n        )\\n\\n    dates = dataframe[DATE][timesteps - 1 :]\\n    data = []\\n    dataframes = []\\n\\n    for cement_type in CEMENT_TYPES:\\n        data.append(dataframe[dataframe[cement_type] == 1])\\n    data.append(dataframe[(dataframe[CEMENT_TYPES] == 0).all(axis=1)])\\n\\n    for df in data:\\n        if pad:\\n            dates = df[DATE].reset_index(drop=True)\\n            df = pad_time_series(df, timesteps).reset_index(drop=True)\\n        else:\\n            dates = df[DATE][timesteps - 1 :].reset_index(drop=True)\\n        x, y = split_sequences(df.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps)\\n        x = pd.DataFrame({\\\"Sequences\\\": [sample.tolist() for sample in x]})\\n        y = pd.DataFrame({\\\"Target\\\": y})\\n        dataframes.append(pd.concat([dates, x, y], axis=1))\\n\\n    data = pd.concat(dataframes, axis=0)\\n    data[DATE] = pd.to_datetime(data[DATE])\\n    data = data.sort_values(by=DATE).reset_index(drop=True)\\n    x = data[\\\"Sequences\\\"]\\n    y = data[\\\"Target\\\"].values\\n    x = np.array(x.tolist())\\n\\n    return x, y\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def split_sequences_per_cement_type(dataframe, timesteps, pad=False):\n",
    "    \"\"\"\n",
    "    Create sequences per cement time\n",
    "    to avoid having parts of the sequence\n",
    "    of different types of cement.\n",
    "    \"\"\"\n",
    "    if timesteps == 1:\n",
    "        return split_sequences(\n",
    "            dataframe.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps\n",
    "        )\n",
    "\n",
    "    dates = dataframe[DATE][timesteps - 1 :]\n",
    "    data = []\n",
    "    dataframes = []\n",
    "\n",
    "    for cement_type in CEMENT_TYPES:\n",
    "        data.append(dataframe[dataframe[cement_type] == 1])\n",
    "    data.append(dataframe[(dataframe[CEMENT_TYPES] == 0).all(axis=1)])\n",
    "\n",
    "    for df in data:\n",
    "        if pad:\n",
    "            dates = df[DATE].reset_index(drop=True)\n",
    "            df = pad_time_series(df, timesteps).reset_index(drop=True)\n",
    "        else:\n",
    "            dates = df[DATE][timesteps - 1 :].reset_index(drop=True)\n",
    "        x, y = split_sequences(df.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps)\n",
    "        x = pd.DataFrame({\"Sequences\": [sample.tolist() for sample in x]})\n",
    "        y = pd.DataFrame({\"Target\": y})\n",
    "        dataframes.append(pd.concat([dates, x, y], axis=1))\n",
    "\n",
    "    data = pd.concat(dataframes, axis=0)\n",
    "    data[DATE] = pd.to_datetime(data[DATE])\n",
    "    data = data.sort_values(by=DATE).reset_index(drop=True)\n",
    "    x = data[\"Sequences\"]\n",
    "    y = data[\"Target\"].values\n",
    "    x = np.array(x.tolist())\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-01T19:37:42.775919Z",
     "iopub.status.busy": "2022-10-01T19:37:42.775308Z",
     "iopub.status.idle": "2022-10-01T19:37:42.788396Z",
     "shell.execute_reply": "2022-10-01T19:37:42.787455Z",
     "shell.execute_reply.started": "2022-10-01T19:37:42.775885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-01T19:37:42.791965Z",
     "iopub.status.busy": "2022-10-01T19:37:42.791690Z",
     "iopub.status.idle": "2022-10-01T19:37:42.798718Z",
     "shell.execute_reply": "2022-10-01T19:37:42.797787Z",
     "shell.execute_reply.started": "2022-10-01T19:37:42.791920Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"def set_global_determinism():\\n    set_seeds()\\n\\n    os.environ[\\\"TF_DETERMINISTIC_OPS\\\"] = \\\"1\\\"\\n    os.environ[\\\"TF_CUDNN_DETERMINISTIC\\\"] = \\\"1\\\"\\n\\n    tf.config.threading.set_inter_op_parallelism_threads(1)\\n    tf.config.threading.set_intra_op_parallelism_threads(1)\";\n",
       "                var nbb_formatted_code = \"def set_global_determinism():\\n    set_seeds()\\n\\n    os.environ[\\\"TF_DETERMINISTIC_OPS\\\"] = \\\"1\\\"\\n    os.environ[\\\"TF_CUDNN_DETERMINISTIC\\\"] = \\\"1\\\"\\n\\n    tf.config.threading.set_inter_op_parallelism_threads(1)\\n    tf.config.threading.set_intra_op_parallelism_threads(1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_global_determinism():\n",
    "    set_seeds()\n",
    "\n",
    "    os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "    os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"index_to_save = 2\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 2\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 2\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-01T19:37:42.801733Z",
     "iopub.status.busy": "2022-10-01T19:37:42.799988Z",
     "iopub.status.idle": "2022-10-01T19:37:42.809646Z",
     "shell.execute_reply": "2022-10-01T19:37:42.808739Z",
     "shell.execute_reply.started": "2022-10-01T19:37:42.801698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\\nDATE = \\\"Date\\\"\\nCEMENT_TYPES = [\\n    \\\"Cement_Type_CEM B\\\",\\n    \\\"Cement_Type_CEM C\\\",\\n    \\\"Cement_Type_CP II-F-32\\\",\\n    \\\"Cement_Type_CP II-F-40\\\",\\n    \\\"Cement_Type_CP V-ARI\\\",\\n    \\\"Cement_Type_Type I-II\\\",\\n    \\\"Cement_Type_Type III\\\",\\n    \\\"Cement_Type_Type IL\\\",\\n]\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\\nDATE = \\\"Date\\\"\\nCEMENT_TYPES = [\\n    \\\"Cement_Type_CEM B\\\",\\n    \\\"Cement_Type_CEM C\\\",\\n    \\\"Cement_Type_CP II-F-32\\\",\\n    \\\"Cement_Type_CP II-F-40\\\",\\n    \\\"Cement_Type_CP V-ARI\\\",\\n    \\\"Cement_Type_Type I-II\\\",\\n    \\\"Cement_Type_Type III\\\",\\n    \\\"Cement_Type_Type IL\\\",\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}\n",
    "DATE = \"Date\"\n",
    "CEMENT_TYPES = [\n",
    "    \"Cement_Type_CEM B\",\n",
    "    \"Cement_Type_CEM C\",\n",
    "    \"Cement_Type_CP II-F-32\",\n",
    "    \"Cement_Type_CP II-F-40\",\n",
    "    \"Cement_Type_CP V-ARI\",\n",
    "    \"Cement_Type_Type I-II\",\n",
    "    \"Cement_Type_Type III\",\n",
    "    \"Cement_Type_Type IL\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"INN\\\",\\n    \\\"Plant\\\": \\\"INN\\\",\\n    \\\"Features\\\": \\\"Chemical + Mineralogical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"Conv1D\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"INN\\\",\\n    \\\"Plant\\\": \\\"INN\\\",\\n    \\\"Features\\\": \\\"Chemical + Mineralogical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"Conv1D\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"INN\",\n",
    "    \"Plant\": \"INN\",\n",
    "    \"Features\": \"Chemical + Mineralogical\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"Conv1D\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-01T19:37:42.811541Z",
     "iopub.status.busy": "2022-10-01T19:37:42.811169Z",
     "iopub.status.idle": "2022-10-01T19:37:42.855721Z",
     "shell.execute_reply": "2022-10-01T19:37:42.854882Z",
     "shell.execute_reply.started": "2022-10-01T19:37:42.811509Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/inn/global_dataset_inn.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/inn/global_dataset_inn.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/inn/global_dataset_inn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy()\\ndf_copy = pd.get_dummies(data=df_copy, columns=[\\\"Cement_Type\\\"], drop_first=True)\\n\\ndf_copy = df_copy.drop(\\n    [\\n        # \\\"Cement_Type\\\",\\n        # \\\"Factory_Plant\\\",\\n        \\\"Blaine\\\",\\n        # \\\"#200\\\",\\n        \\\"#325\\\",\\n        # \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n        # \\\"Factory_Plant\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy()\\ndf_copy = pd.get_dummies(data=df_copy, columns=[\\\"Cement_Type\\\"], drop_first=True)\\n\\ndf_copy = df_copy.drop(\\n    [\\n        # \\\"Cement_Type\\\",\\n        # \\\"Factory_Plant\\\",\\n        \\\"Blaine\\\",\\n        # \\\"#200\\\",\\n        \\\"#325\\\",\\n        # \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n        # \\\"Factory_Plant\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy()\n",
    "df_copy = pd.get_dummies(data=df_copy, columns=[\"Cement_Type\"], drop_first=True)\n",
    "\n",
    "df_copy = df_copy.drop(\n",
    "    [\n",
    "        # \"Cement_Type\",\n",
    "        # \"Factory_Plant\",\n",
    "        \"Blaine\",\n",
    "        # \"#200\",\n",
    "        \"#325\",\n",
    "        # \"Final setting time\",\n",
    "        \"Initial setting time\",\n",
    "        \"CS1\",\n",
    "        \"CS3\",\n",
    "        \"CS7\",\n",
    "        # \"Factory_Plant\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"df_copy[CEMENT_TYPES] = df_copy[CEMENT_TYPES].astype(int)\\ndates = df[\\\"Date\\\"].copy()\\nx = df_copy.drop([\\\"Date\\\", \\\"CS28\\\", \\\"Factory_Plant\\\"] + CEMENT_TYPES, axis=1)\\ny = df_copy[\\\"CS28\\\"]\\ntrain_columns = x.columns\";\n",
       "                var nbb_formatted_code = \"df_copy[CEMENT_TYPES] = df_copy[CEMENT_TYPES].astype(int)\\ndates = df[\\\"Date\\\"].copy()\\nx = df_copy.drop([\\\"Date\\\", \\\"CS28\\\", \\\"Factory_Plant\\\"] + CEMENT_TYPES, axis=1)\\ny = df_copy[\\\"CS28\\\"]\\ntrain_columns = x.columns\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy[CEMENT_TYPES] = df_copy[CEMENT_TYPES].astype(int)\n",
    "dates = df[\"Date\"].copy()\n",
    "x = df_copy.drop([\"Date\", \"CS28\", \"Factory_Plant\"] + CEMENT_TYPES, axis=1)\n",
    "y = df_copy[\"CS28\"]\n",
    "train_columns = x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"def prepare_dataset(\\n    dataframe_original=df,\\n    dataframe_copy=df_copy,\\n    train_size=0.8,\\n    test_size=0.2,\\n    ignore_test_set=False,\\n    timesteps=1,\\n    split_by_cement_type=True,\\n):\\n    dataframe_original = df.copy()\\n    dataframe_copy = df_copy.copy()\\n    dataframe_copy[CEMENT_TYPES] = dataframe_copy[CEMENT_TYPES].astype(int).copy()\\n    dates = dataframe_original[\\\"Date\\\"].copy()\\n    x = dataframe_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1)\\n    y = dataframe_copy[\\\"CS28\\\"]\\n    cement_types = dataframe_copy[CEMENT_TYPES].copy()\\n\\n    # Split the dataframe by plant\\n    plants = dataframe_original[\\\"Factory_Plant\\\"].unique()\\n    train_indexes = []\\n    test_indexes = []\\n    plants_test_indexes = {}\\n\\n    for plant in plants:\\n        plant_df = dataframe_original[dataframe_original[\\\"Factory_Plant\\\"] == plant]\\n        plant_df = plant_df.sort_values(by=\\\"Date\\\")\\n        plant_indices = plant_df.index\\n        train_end_index = int(len(plant_indices) * train_size)\\n        # plants_indexes[]\\n\\n        if not ignore_test_set:\\n            train_indexes.extend(plant_indices[:train_end_index])\\n            test_indexes.extend(plant_indices[train_end_index:])\\n            plants_test_indexes[plant] = plant_indices[train_end_index:]\\n\\n        else:\\n            train_indexes.extend(plant_indices[:train_end_index])\\n            test_indexes.extend(plant_indices[train_end_index:])\\n            plants_test_indexes[plant] = plant_indices[train_end_index:]\\n\\n    train_index = dataframe_original.loc[train_indexes].sort_values(by=\\\"Date\\\").index\\n    test_index = dataframe_original.loc[test_indexes].sort_values(by=\\\"Date\\\").index\\n\\n    plant_id_series = x[\\\"Factory_Plant\\\"].copy()\\n    x = x.drop([\\\"Factory_Plant\\\"], axis=1)\\n\\n    dataset = {\\n        \\\"dates_train\\\": dates[train_index].reset_index(drop=True).copy(),\\n        \\\"cement_types_train\\\": cement_types.loc[train_index]\\n        .reset_index(drop=True)\\n        .copy(),\\n        \\\"x_train\\\": x.loc[train_index].reset_index(drop=True).copy(),\\n        \\\"y_train\\\": y[train_index].reset_index(drop=True).copy(),\\n        \\\"dates_test\\\": dates[test_index].reset_index(drop=True).copy(),\\n        \\\"cement_types_test\\\": cement_types.loc[test_index].reset_index(drop=True).copy(),\\n        \\\"x_test\\\": x.loc[test_index].reset_index(drop=True).copy(),\\n        \\\"y_test\\\": y[test_index].reset_index(drop=True).copy(),\\n    }\\n\\n    # Preprocess the dataset\\n    dataset = preprocess_data(dataset, None, SimpleImputer, {\\\"strategy\\\": \\\"median\\\"})\\n    # return dataset, plant_id_series.loc[test_index].reset_index(drop=True).copy()\\n    dataset[\\\"x_test\\\"] = np.concatenate(\\n        [\\n            dataset[\\\"x_test\\\"],\\n            plant_id_series.loc[test_index]\\n            .reset_index(drop=True)\\n            .copy()\\n            .values.reshape(-1, 1),\\n        ],\\n        axis=1,\\n    )\\n    index_list = x.columns.tolist()\\n    index_list.append(\\\"Factory_Plant\\\")\\n    test_columns = pd.Index(index_list)\\n\\n    # generate sequences (3D format)\\n    dataset = generate_sequences(\\n        dataset,\\n        timesteps=timesteps,\\n        split_by_cement_type=split_by_cement_type,\\n        train_columns=train_columns,\\n        test_columns=test_columns,\\n    )\\n\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def prepare_dataset(\\n    dataframe_original=df,\\n    dataframe_copy=df_copy,\\n    train_size=0.8,\\n    test_size=0.2,\\n    ignore_test_set=False,\\n    timesteps=1,\\n    split_by_cement_type=True,\\n):\\n    dataframe_original = df.copy()\\n    dataframe_copy = df_copy.copy()\\n    dataframe_copy[CEMENT_TYPES] = dataframe_copy[CEMENT_TYPES].astype(int).copy()\\n    dates = dataframe_original[\\\"Date\\\"].copy()\\n    x = dataframe_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1)\\n    y = dataframe_copy[\\\"CS28\\\"]\\n    cement_types = dataframe_copy[CEMENT_TYPES].copy()\\n\\n    # Split the dataframe by plant\\n    plants = dataframe_original[\\\"Factory_Plant\\\"].unique()\\n    train_indexes = []\\n    test_indexes = []\\n    plants_test_indexes = {}\\n\\n    for plant in plants:\\n        plant_df = dataframe_original[dataframe_original[\\\"Factory_Plant\\\"] == plant]\\n        plant_df = plant_df.sort_values(by=\\\"Date\\\")\\n        plant_indices = plant_df.index\\n        train_end_index = int(len(plant_indices) * train_size)\\n        # plants_indexes[]\\n\\n        if not ignore_test_set:\\n            train_indexes.extend(plant_indices[:train_end_index])\\n            test_indexes.extend(plant_indices[train_end_index:])\\n            plants_test_indexes[plant] = plant_indices[train_end_index:]\\n\\n        else:\\n            train_indexes.extend(plant_indices[:train_end_index])\\n            test_indexes.extend(plant_indices[train_end_index:])\\n            plants_test_indexes[plant] = plant_indices[train_end_index:]\\n\\n    train_index = dataframe_original.loc[train_indexes].sort_values(by=\\\"Date\\\").index\\n    test_index = dataframe_original.loc[test_indexes].sort_values(by=\\\"Date\\\").index\\n\\n    plant_id_series = x[\\\"Factory_Plant\\\"].copy()\\n    x = x.drop([\\\"Factory_Plant\\\"], axis=1)\\n\\n    dataset = {\\n        \\\"dates_train\\\": dates[train_index].reset_index(drop=True).copy(),\\n        \\\"cement_types_train\\\": cement_types.loc[train_index]\\n        .reset_index(drop=True)\\n        .copy(),\\n        \\\"x_train\\\": x.loc[train_index].reset_index(drop=True).copy(),\\n        \\\"y_train\\\": y[train_index].reset_index(drop=True).copy(),\\n        \\\"dates_test\\\": dates[test_index].reset_index(drop=True).copy(),\\n        \\\"cement_types_test\\\": cement_types.loc[test_index].reset_index(drop=True).copy(),\\n        \\\"x_test\\\": x.loc[test_index].reset_index(drop=True).copy(),\\n        \\\"y_test\\\": y[test_index].reset_index(drop=True).copy(),\\n    }\\n\\n    # Preprocess the dataset\\n    dataset = preprocess_data(dataset, None, SimpleImputer, {\\\"strategy\\\": \\\"median\\\"})\\n    # return dataset, plant_id_series.loc[test_index].reset_index(drop=True).copy()\\n    dataset[\\\"x_test\\\"] = np.concatenate(\\n        [\\n            dataset[\\\"x_test\\\"],\\n            plant_id_series.loc[test_index]\\n            .reset_index(drop=True)\\n            .copy()\\n            .values.reshape(-1, 1),\\n        ],\\n        axis=1,\\n    )\\n    index_list = x.columns.tolist()\\n    index_list.append(\\\"Factory_Plant\\\")\\n    test_columns = pd.Index(index_list)\\n\\n    # generate sequences (3D format)\\n    dataset = generate_sequences(\\n        dataset,\\n        timesteps=timesteps,\\n        split_by_cement_type=split_by_cement_type,\\n        train_columns=train_columns,\\n        test_columns=test_columns,\\n    )\\n\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_dataset(\n",
    "    dataframe_original=df,\n",
    "    dataframe_copy=df_copy,\n",
    "    train_size=0.8,\n",
    "    test_size=0.2,\n",
    "    ignore_test_set=False,\n",
    "    timesteps=1,\n",
    "    split_by_cement_type=True,\n",
    "):\n",
    "    dataframe_original = df.copy()\n",
    "    dataframe_copy = df_copy.copy()\n",
    "    dataframe_copy[CEMENT_TYPES] = dataframe_copy[CEMENT_TYPES].astype(int).copy()\n",
    "    dates = dataframe_original[\"Date\"].copy()\n",
    "    x = dataframe_copy.drop([\"Date\", \"CS28\"] + CEMENT_TYPES, axis=1)\n",
    "    y = dataframe_copy[\"CS28\"]\n",
    "    cement_types = dataframe_copy[CEMENT_TYPES].copy()\n",
    "\n",
    "    # Split the dataframe by plant\n",
    "    plants = dataframe_original[\"Factory_Plant\"].unique()\n",
    "    train_indexes = []\n",
    "    test_indexes = []\n",
    "    plants_test_indexes = {}\n",
    "\n",
    "    for plant in plants:\n",
    "        plant_df = dataframe_original[dataframe_original[\"Factory_Plant\"] == plant]\n",
    "        plant_df = plant_df.sort_values(by=\"Date\")\n",
    "        plant_indices = plant_df.index\n",
    "        train_end_index = int(len(plant_indices) * train_size)\n",
    "        # plants_indexes[]\n",
    "\n",
    "        if not ignore_test_set:\n",
    "            train_indexes.extend(plant_indices[:train_end_index])\n",
    "            test_indexes.extend(plant_indices[train_end_index:])\n",
    "            plants_test_indexes[plant] = plant_indices[train_end_index:]\n",
    "\n",
    "        else:\n",
    "            train_indexes.extend(plant_indices[:train_end_index])\n",
    "            test_indexes.extend(plant_indices[train_end_index:])\n",
    "            plants_test_indexes[plant] = plant_indices[train_end_index:]\n",
    "\n",
    "    train_index = dataframe_original.loc[train_indexes].sort_values(by=\"Date\").index\n",
    "    test_index = dataframe_original.loc[test_indexes].sort_values(by=\"Date\").index\n",
    "\n",
    "    plant_id_series = x[\"Factory_Plant\"].copy()\n",
    "    x = x.drop([\"Factory_Plant\"], axis=1)\n",
    "\n",
    "    dataset = {\n",
    "        \"dates_train\": dates[train_index].reset_index(drop=True).copy(),\n",
    "        \"cement_types_train\": cement_types.loc[train_index]\n",
    "        .reset_index(drop=True)\n",
    "        .copy(),\n",
    "        \"x_train\": x.loc[train_index].reset_index(drop=True).copy(),\n",
    "        \"y_train\": y[train_index].reset_index(drop=True).copy(),\n",
    "        \"dates_test\": dates[test_index].reset_index(drop=True).copy(),\n",
    "        \"cement_types_test\": cement_types.loc[test_index].reset_index(drop=True).copy(),\n",
    "        \"x_test\": x.loc[test_index].reset_index(drop=True).copy(),\n",
    "        \"y_test\": y[test_index].reset_index(drop=True).copy(),\n",
    "    }\n",
    "\n",
    "    # Preprocess the dataset\n",
    "    dataset = preprocess_data(dataset, None, SimpleImputer, {\"strategy\": \"median\"})\n",
    "    # return dataset, plant_id_series.loc[test_index].reset_index(drop=True).copy()\n",
    "    dataset[\"x_test\"] = np.concatenate(\n",
    "        [\n",
    "            dataset[\"x_test\"],\n",
    "            plant_id_series.loc[test_index]\n",
    "            .reset_index(drop=True)\n",
    "            .copy()\n",
    "            .values.reshape(-1, 1),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    index_list = x.columns.tolist()\n",
    "    index_list.append(\"Factory_Plant\")\n",
    "    test_columns = pd.Index(index_list)\n",
    "\n",
    "    # generate sequences (3D format)\n",
    "    dataset = generate_sequences(\n",
    "        dataset,\n",
    "        timesteps=timesteps,\n",
    "        split_by_cement_type=split_by_cement_type,\n",
    "        train_columns=train_columns,\n",
    "        test_columns=test_columns,\n",
    "    )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"def prepare_dataset_helper(timesteps):\\n    dataset = prepare_dataset(timesteps=timesteps)\\n    # Remove the last column (plant identification) for overall evaluation\\n    x_test_overall = np.delete(dataset[\\\"x_test\\\"], -1, axis=2)\\n\\n    # Initialize dictionaries to hold plant-specific datasets\\n    plant_specific_x_test = {}\\n    plant_specific_y_test = {}\\n\\n    # Get unique plant identifiers\\n    unique_plants = np.unique(dataset[\\\"x_test\\\"][:, 0, -1])\\n\\n    for plant in unique_plants:\\n        # Create a mask for the current plant\\n        plant_mask = dataset[\\\"x_test\\\"][:, 0, -1] == plant\\n        # Filter x_test and y_test using the mask\\n        x_test_plant = dataset[\\\"x_test\\\"][plant_mask]\\n        y_test_plant = dataset[\\\"y_test\\\"][plant_mask]\\n\\n        # Remove the last column (plant identification) from x_test_plant\\n        x_test_plant = np.delete(x_test_plant, -1, axis=2)\\n\\n        # Store the filtered arrays in the dictionaries\\n        plant_specific_x_test[plant] = x_test_plant\\n        plant_specific_y_test[plant] = y_test_plant\\n\\n    # Output the shapes to verify\\n    # print(\\\"Overall x_test shape:\\\", x_test_overall.shape)\\n    # for plant in plant_specific_x_test:\\n    #    print(f\\\"Plant {plant} x_test shape:\\\", plant_specific_x_test[plant].shape)\\n    #    print(f\\\"Plant {plant} y_test shape:\\\", plant_specific_y_test[plant].shape)\\n\\n    plant_specific = {\\\"x_test\\\": plant_specific_x_test, \\\"y_test\\\": plant_specific_y_test}\\n    x_test_overall = x_test_overall.astype(float)\\n    dataset[\\\"x_test\\\"] = x_test_overall\\n    return dataset, plant_specific\";\n",
       "                var nbb_formatted_code = \"def prepare_dataset_helper(timesteps):\\n    dataset = prepare_dataset(timesteps=timesteps)\\n    # Remove the last column (plant identification) for overall evaluation\\n    x_test_overall = np.delete(dataset[\\\"x_test\\\"], -1, axis=2)\\n\\n    # Initialize dictionaries to hold plant-specific datasets\\n    plant_specific_x_test = {}\\n    plant_specific_y_test = {}\\n\\n    # Get unique plant identifiers\\n    unique_plants = np.unique(dataset[\\\"x_test\\\"][:, 0, -1])\\n\\n    for plant in unique_plants:\\n        # Create a mask for the current plant\\n        plant_mask = dataset[\\\"x_test\\\"][:, 0, -1] == plant\\n        # Filter x_test and y_test using the mask\\n        x_test_plant = dataset[\\\"x_test\\\"][plant_mask]\\n        y_test_plant = dataset[\\\"y_test\\\"][plant_mask]\\n\\n        # Remove the last column (plant identification) from x_test_plant\\n        x_test_plant = np.delete(x_test_plant, -1, axis=2)\\n\\n        # Store the filtered arrays in the dictionaries\\n        plant_specific_x_test[plant] = x_test_plant\\n        plant_specific_y_test[plant] = y_test_plant\\n\\n    # Output the shapes to verify\\n    # print(\\\"Overall x_test shape:\\\", x_test_overall.shape)\\n    # for plant in plant_specific_x_test:\\n    #    print(f\\\"Plant {plant} x_test shape:\\\", plant_specific_x_test[plant].shape)\\n    #    print(f\\\"Plant {plant} y_test shape:\\\", plant_specific_y_test[plant].shape)\\n\\n    plant_specific = {\\\"x_test\\\": plant_specific_x_test, \\\"y_test\\\": plant_specific_y_test}\\n    x_test_overall = x_test_overall.astype(float)\\n    dataset[\\\"x_test\\\"] = x_test_overall\\n    return dataset, plant_specific\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_dataset_helper(timesteps):\n",
    "    dataset = prepare_dataset(timesteps=timesteps)\n",
    "    # Remove the last column (plant identification) for overall evaluation\n",
    "    x_test_overall = np.delete(dataset[\"x_test\"], -1, axis=2)\n",
    "\n",
    "    # Initialize dictionaries to hold plant-specific datasets\n",
    "    plant_specific_x_test = {}\n",
    "    plant_specific_y_test = {}\n",
    "\n",
    "    # Get unique plant identifiers\n",
    "    unique_plants = np.unique(dataset[\"x_test\"][:, 0, -1])\n",
    "\n",
    "    for plant in unique_plants:\n",
    "        # Create a mask for the current plant\n",
    "        plant_mask = dataset[\"x_test\"][:, 0, -1] == plant\n",
    "        # Filter x_test and y_test using the mask\n",
    "        x_test_plant = dataset[\"x_test\"][plant_mask]\n",
    "        y_test_plant = dataset[\"y_test\"][plant_mask]\n",
    "\n",
    "        # Remove the last column (plant identification) from x_test_plant\n",
    "        x_test_plant = np.delete(x_test_plant, -1, axis=2)\n",
    "\n",
    "        # Store the filtered arrays in the dictionaries\n",
    "        plant_specific_x_test[plant] = x_test_plant\n",
    "        plant_specific_y_test[plant] = y_test_plant\n",
    "\n",
    "    # Output the shapes to verify\n",
    "    # print(\"Overall x_test shape:\", x_test_overall.shape)\n",
    "    # for plant in plant_specific_x_test:\n",
    "    #    print(f\"Plant {plant} x_test shape:\", plant_specific_x_test[plant].shape)\n",
    "    #    print(f\"Plant {plant} y_test shape:\", plant_specific_y_test[plant].shape)\n",
    "\n",
    "    plant_specific = {\"x_test\": plant_specific_x_test, \"y_test\": plant_specific_y_test}\n",
    "    x_test_overall = x_test_overall.astype(float)\n",
    "    dataset[\"x_test\"] = x_test_overall\n",
    "    return dataset, plant_specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"def print_scores_2(scores, METRICS, METRICS_DICT):\\n    for phase in [\\\"test\\\"]:\\n        print(\\\"******\\\")\\n        print(f\\\"[{phase.upper()}]\\\")\\n        print(\\\"******\\\")\\n        for metric in METRICS:\\n            name = METRICS_DICT[metric]\\n            print(\\n                f\\\"{name}: %.3f (%.3f)\\\"\\n                % (\\n                    np.mean(scores[f\\\"{phase}_\\\" + metric]),\\n                    np.std(scores[f\\\"{phase}_\\\" + metric]),\\n                )\\n            )\\n        print(\\\"\\\\n======================\\\\n\\\")\";\n",
       "                var nbb_formatted_code = \"def print_scores_2(scores, METRICS, METRICS_DICT):\\n    for phase in [\\\"test\\\"]:\\n        print(\\\"******\\\")\\n        print(f\\\"[{phase.upper()}]\\\")\\n        print(\\\"******\\\")\\n        for metric in METRICS:\\n            name = METRICS_DICT[metric]\\n            print(\\n                f\\\"{name}: %.3f (%.3f)\\\"\\n                % (\\n                    np.mean(scores[f\\\"{phase}_\\\" + metric]),\\n                    np.std(scores[f\\\"{phase}_\\\" + metric]),\\n                )\\n            )\\n        print(\\\"\\\\n======================\\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_scores_2(scores, METRICS, METRICS_DICT):\n",
    "    for phase in [\"test\"]:\n",
    "        print(\"******\")\n",
    "        print(f\"[{phase.upper()}]\")\n",
    "        print(\"******\")\n",
    "        for metric in METRICS:\n",
    "            name = METRICS_DICT[metric]\n",
    "            print(\n",
    "                f\"{name}: %.3f (%.3f)\"\n",
    "                % (\n",
    "                    np.mean(scores[f\"{phase}_\" + metric]),\n",
    "                    np.std(scores[f\"{phase}_\" + metric]),\n",
    "                )\n",
    "            )\n",
    "        print(\"\\n======================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"def append_results(scores_dict):\\n    for plant, scores in scores_dict.items():\\n        results_dict_copy = results_dict.copy()\\n        results_dict_copy[\\\"Plant\\\"] = plant\\n        results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n        results_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\n        results_dict_copy[\\n            \\\"Cross Validation Params\\\"\\n        ] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\n        results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n        results_dict_copy[\\\"Model\\\"] = f\\\"Conv1D_{model_index}\\\"\\n        scores = {key: [value] for key, value in scores.items()}\\n        df_results = fill_results_dict(results_dict_copy, scores)\\n        results_to_save.append(df_results)\";\n",
       "                var nbb_formatted_code = \"def append_results(scores_dict):\\n    for plant, scores in scores_dict.items():\\n        results_dict_copy = results_dict.copy()\\n        results_dict_copy[\\\"Plant\\\"] = plant\\n        results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n        results_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\n        results_dict_copy[\\n            \\\"Cross Validation Params\\\"\\n        ] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\n        results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n        results_dict_copy[\\\"Model\\\"] = f\\\"Conv1D_{model_index}\\\"\\n        scores = {key: [value] for key, value in scores.items()}\\n        df_results = fill_results_dict(results_dict_copy, scores)\\n        results_to_save.append(df_results)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def append_results(scores_dict):\n",
    "    for plant, scores in scores_dict.items():\n",
    "        results_dict_copy = results_dict.copy()\n",
    "        results_dict_copy[\"Plant\"] = plant\n",
    "        results_dict_copy[\"Timesteps\"] = timesteps\n",
    "        results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "        results_dict_copy[\n",
    "            \"Cross Validation Params\"\n",
    "        ] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "        results_dict_copy[\"Data Shape\"] = x.shape\n",
    "        results_dict_copy[\"Model\"] = f\"Conv1D_{model_index}\"\n",
    "        scores = {key: [value] for key, value in scores.items()}\n",
    "        df_results = fill_results_dict(results_dict_copy, scores)\n",
    "        results_to_save.append(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"def print_results_and_get_scores_dict(scores, plant_specific):\\n    print(\\\"=======================\\\")\\n    print(\\\"Overall Score\\\")\\n    print(\\\"=======================\\\\n\\\")\\n\\n    print_scores(scores, METRICS, METRICS_DICT)\\n\\n    print(\\\"=======================\\\")\\n    print(\\\"Scores per plant\\\")\\n    print(\\\"=======================\\\\n\\\")\\n\\n    scores_dict = {\\\"INN\\\": scores}\\n\\n    for plant in df_copy[\\\"Factory_Plant\\\"].unique():\\n        x_test = plant_specific[\\\"x_test\\\"][plant].astype(float)\\n        y_test = plant_specific[\\\"y_test\\\"][plant].astype(float)\\n        dataset[\\\"x_test\\\"] = x_test\\n        dataset[\\\"y_test\\\"] = y_test\\n        print(\\\"=======================\\\")\\n        print(\\n            \\\"Plant\\\",\\n            plant,\\n        )\\n        print(\\\"=======================\\\\n\\\")\\n        scores_plant = evaluate_model(model, dataset)\\n        scores_dict[plant] = scores_plant\\n        print_scores_2(scores_plant, METRICS, METRICS_DICT)\\n    return scores_dict\";\n",
       "                var nbb_formatted_code = \"def print_results_and_get_scores_dict(scores, plant_specific):\\n    print(\\\"=======================\\\")\\n    print(\\\"Overall Score\\\")\\n    print(\\\"=======================\\\\n\\\")\\n\\n    print_scores(scores, METRICS, METRICS_DICT)\\n\\n    print(\\\"=======================\\\")\\n    print(\\\"Scores per plant\\\")\\n    print(\\\"=======================\\\\n\\\")\\n\\n    scores_dict = {\\\"INN\\\": scores}\\n\\n    for plant in df_copy[\\\"Factory_Plant\\\"].unique():\\n        x_test = plant_specific[\\\"x_test\\\"][plant].astype(float)\\n        y_test = plant_specific[\\\"y_test\\\"][plant].astype(float)\\n        dataset[\\\"x_test\\\"] = x_test\\n        dataset[\\\"y_test\\\"] = y_test\\n        print(\\\"=======================\\\")\\n        print(\\n            \\\"Plant\\\",\\n            plant,\\n        )\\n        print(\\\"=======================\\\\n\\\")\\n        scores_plant = evaluate_model(model, dataset)\\n        scores_dict[plant] = scores_plant\\n        print_scores_2(scores_plant, METRICS, METRICS_DICT)\\n    return scores_dict\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_results_and_get_scores_dict(scores, plant_specific):\n",
    "    print(\"=======================\")\n",
    "    print(\"Overall Score\")\n",
    "    print(\"=======================\\n\")\n",
    "\n",
    "    print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "    print(\"=======================\")\n",
    "    print(\"Scores per plant\")\n",
    "    print(\"=======================\\n\")\n",
    "\n",
    "    scores_dict = {\"INN\": scores}\n",
    "\n",
    "    for plant in df_copy[\"Factory_Plant\"].unique():\n",
    "        x_test = plant_specific[\"x_test\"][plant].astype(float)\n",
    "        y_test = plant_specific[\"y_test\"][plant].astype(float)\n",
    "        dataset[\"x_test\"] = x_test\n",
    "        dataset[\"y_test\"] = y_test\n",
    "        print(\"=======================\")\n",
    "        print(\n",
    "            \"Plant\",\n",
    "            plant,\n",
    "        )\n",
    "        print(\"=======================\\n\")\n",
    "        scores_plant = evaluate_model(model, dataset)\n",
    "        scores_dict[plant] = scores_plant\n",
    "        print_scores_2(scores_plant, METRICS, METRICS_DICT)\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"def get_conv1d_params(\\n    timesteps=1,\\n    activation=\\\"relu\\\",\\n    padding=\\\"causal\\\",\\n    kernel_size=1,\\n    pool_size=1,\\n    strides=1,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n):\\n    params = {}\\n    params[\\\"verbose\\\"] = verbose\\n    params[\\\"callbacks\\\"] = callbacks\\n    params[\\\"validation_split\\\"] = validation_split\\n    params[\\\"activation\\\"] = activation\\n    params[\\\"padding\\\"] = padding\\n    params[\\\"kernel_size\\\"] = kernel_size\\n    params[\\\"strides\\\"] = strides\\n    params[\\\"pool_size\\\"] = pool_size\\n\\n    return params\";\n",
       "                var nbb_formatted_code = \"def get_conv1d_params(\\n    timesteps=1,\\n    activation=\\\"relu\\\",\\n    padding=\\\"causal\\\",\\n    kernel_size=1,\\n    pool_size=1,\\n    strides=1,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n):\\n    params = {}\\n    params[\\\"verbose\\\"] = verbose\\n    params[\\\"callbacks\\\"] = callbacks\\n    params[\\\"validation_split\\\"] = validation_split\\n    params[\\\"activation\\\"] = activation\\n    params[\\\"padding\\\"] = padding\\n    params[\\\"kernel_size\\\"] = kernel_size\\n    params[\\\"strides\\\"] = strides\\n    params[\\\"pool_size\\\"] = pool_size\\n\\n    return params\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_conv1d_params(\n",
    "    timesteps=1,\n",
    "    activation=\"relu\",\n",
    "    padding=\"causal\",\n",
    "    kernel_size=1,\n",
    "    pool_size=1,\n",
    "    strides=1,\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    verbose=0,\n",
    "):\n",
    "    params = {}\n",
    "    params[\"verbose\"] = verbose\n",
    "    params[\"callbacks\"] = callbacks\n",
    "    params[\"validation_split\"] = validation_split\n",
    "    params[\"activation\"] = activation\n",
    "    params[\"padding\"] = padding\n",
    "    params[\"kernel_size\"] = kernel_size\n",
    "    params[\"strides\"] = strides\n",
    "    params[\"pool_size\"] = pool_size\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv1D 1\n",
    "\n",
    "1. TIMESTEPS: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 00:00:10.024315: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-07-16 00:00:10.024366: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: inspirada\n",
      "2024-07-16 00:00:10.024377: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: inspirada\n",
      "2024-07-16 00:00:10.024549: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 535.183.1\n",
      "2024-07-16 00:00:10.024582: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.183.1\n",
      "2024-07-16 00:00:10.024588: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 535.183.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.4313455104827881\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 1\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=1,\\n    pool_size=1,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_1, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 1\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=1,\\n    pool_size=1,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_1, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "set_global_determinism()\n",
    "timesteps = 1\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "dataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\n",
    "x_train = dataset[\"x_train\"]\n",
    "y_train = dataset[\"y_train\"]\n",
    "x_test = dataset[\"x_test\"]\n",
    "y_test = dataset[\"y_test\"]\n",
    "\n",
    "params = get_conv1d_params(\n",
    "    timesteps=timesteps,\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    verbose=0,\n",
    "    kernel_size=1,\n",
    "    pool_size=1,\n",
    ")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "model, scores = train_and_evaluate_model(Conv1D_1, dataset, estimator_params=params)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Overall Score\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 3.722 (0.000)\n",
      "MAE: 2.917 (0.000)\n",
      "MAPE: 0.065 (0.000)\n",
      "R2: 0.578 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.925 (0.000)\n",
      "MAE: 3.149 (0.000)\n",
      "MAPE: 0.072 (0.000)\n",
      "R2: 0.554 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Scores per plant\n",
      "=======================\n",
      "\n",
      "=======================\n",
      "Plant partner_iv\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 4.465 (0.000)\n",
      "MAE: 3.324 (0.000)\n",
      "MAPE: 0.068 (0.000)\n",
      "R2: 0.471 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_ii\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.042 (0.000)\n",
      "MAE: 2.456 (0.000)\n",
      "MAPE: 0.064 (0.000)\n",
      "R2: -0.159 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_i\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 4.165 (0.000)\n",
      "MAE: 3.617 (0.000)\n",
      "MAPE: 0.081 (0.000)\n",
      "R2: 0.301 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\n",
    "append_results(scores_dict)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv1D 1\n",
    "\n",
    "1. TIMESTEPS: 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.5343658367792765\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 7\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_1, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 7\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_1, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "set_global_determinism()\n",
    "timesteps = 7\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "dataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\n",
    "x_train = dataset[\"x_train\"]\n",
    "y_train = dataset[\"y_train\"]\n",
    "x_test = dataset[\"x_test\"]\n",
    "y_test = dataset[\"y_test\"]\n",
    "\n",
    "params = get_conv1d_params(\n",
    "    timesteps=timesteps,\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    verbose=0,\n",
    "    kernel_size=timesteps,\n",
    "    pool_size=timesteps,\n",
    ")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "model, scores = train_and_evaluate_model(Conv1D_1, dataset, estimator_params=params)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Overall Score\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.808 (0.000)\n",
      "MAE: 2.240 (0.000)\n",
      "MAPE: 0.049 (0.000)\n",
      "R2: 0.760 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.129 (0.000)\n",
      "MAE: 2.590 (0.000)\n",
      "MAPE: 0.059 (0.000)\n",
      "R2: 0.715 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Scores per plant\n",
      "=======================\n",
      "\n",
      "=======================\n",
      "Plant partner_iv\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.245 (0.000)\n",
      "MAE: 2.623 (0.000)\n",
      "MAPE: 0.054 (0.000)\n",
      "R2: 0.704 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_ii\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.823 (0.000)\n",
      "MAE: 2.285 (0.000)\n",
      "MAPE: 0.059 (0.000)\n",
      "R2: -0.066 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_i\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.288 (0.000)\n",
      "MAE: 2.826 (0.000)\n",
      "MAPE: 0.063 (0.000)\n",
      "R2: 0.559 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\n",
    "append_results(scores_dict)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv1D 1\n",
    "\n",
    "1. TIMESTEPS: 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.6941122452418009\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 14\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_1, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 14\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_1, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "set_global_determinism()\n",
    "timesteps = 14\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "dataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\n",
    "x_train = dataset[\"x_train\"]\n",
    "y_train = dataset[\"y_train\"]\n",
    "x_test = dataset[\"x_test\"]\n",
    "y_test = dataset[\"y_test\"]\n",
    "\n",
    "params = get_conv1d_params(\n",
    "    timesteps=timesteps,\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    verbose=0,\n",
    "    kernel_size=timesteps,\n",
    "    pool_size=timesteps,\n",
    ")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "model, scores = train_and_evaluate_model(Conv1D_1, dataset, estimator_params=params)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Overall Score\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.827 (0.000)\n",
      "MAE: 2.198 (0.000)\n",
      "MAPE: 0.047 (0.000)\n",
      "R2: 0.756 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.138 (0.000)\n",
      "MAE: 2.567 (0.000)\n",
      "MAPE: 0.058 (0.000)\n",
      "R2: 0.710 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Scores per plant\n",
      "=======================\n",
      "\n",
      "=======================\n",
      "Plant partner_iv\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.832 (0.000)\n",
      "MAE: 3.141 (0.000)\n",
      "MAPE: 0.065 (0.000)\n",
      "R2: 0.590 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_ii\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.557 (0.000)\n",
      "MAE: 2.007 (0.000)\n",
      "MAPE: 0.052 (0.000)\n",
      "R2: 0.091 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_i\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.042 (0.000)\n",
      "MAE: 2.635 (0.000)\n",
      "MAPE: 0.059 (0.000)\n",
      "R2: 0.619 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\n",
    "append_results(scores_dict)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv1D 2\n",
    "\n",
    "1. TIMESTEPS: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.45091569821039834\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 1\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_2, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 1\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_2, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "set_global_determinism()\n",
    "timesteps = 1\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "dataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\n",
    "x_train = dataset[\"x_train\"]\n",
    "y_train = dataset[\"y_train\"]\n",
    "x_test = dataset[\"x_test\"]\n",
    "y_test = dataset[\"y_test\"]\n",
    "\n",
    "params = get_conv1d_params(\n",
    "    timesteps=timesteps,\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    verbose=0,\n",
    "    kernel_size=timesteps,\n",
    "    pool_size=timesteps,\n",
    ")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "model, scores = train_and_evaluate_model(Conv1D_2, dataset, estimator_params=params)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Overall Score\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 3.722 (0.000)\n",
      "MAE: 2.917 (0.000)\n",
      "MAPE: 0.065 (0.000)\n",
      "R2: 0.578 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.925 (0.000)\n",
      "MAE: 3.149 (0.000)\n",
      "MAPE: 0.072 (0.000)\n",
      "R2: 0.554 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Scores per plant\n",
      "=======================\n",
      "\n",
      "=======================\n",
      "Plant partner_iv\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 4.465 (0.000)\n",
      "MAE: 3.324 (0.000)\n",
      "MAPE: 0.068 (0.000)\n",
      "R2: 0.471 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_ii\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.042 (0.000)\n",
      "MAE: 2.456 (0.000)\n",
      "MAPE: 0.064 (0.000)\n",
      "R2: -0.159 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_i\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 4.165 (0.000)\n",
      "MAE: 3.617 (0.000)\n",
      "MAPE: 0.081 (0.000)\n",
      "R2: 0.301 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\n",
    "append_results(scores_dict)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv1D 2\n",
    "\n",
    "1. TIMESTEPS: 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.5438487092653911\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 7\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_2, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 7\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_2, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "set_global_determinism()\n",
    "timesteps = 7\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "dataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\n",
    "x_train = dataset[\"x_train\"]\n",
    "y_train = dataset[\"y_train\"]\n",
    "x_test = dataset[\"x_test\"]\n",
    "y_test = dataset[\"y_test\"]\n",
    "\n",
    "params = get_conv1d_params(\n",
    "    timesteps=timesteps,\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    verbose=0,\n",
    "    kernel_size=timesteps,\n",
    "    pool_size=timesteps,\n",
    ")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "model, scores = train_and_evaluate_model(Conv1D_2, dataset, estimator_params=params)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Overall Score\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.792 (0.000)\n",
      "MAE: 2.226 (0.000)\n",
      "MAPE: 0.049 (0.000)\n",
      "R2: 0.763 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.078 (0.000)\n",
      "MAE: 2.533 (0.000)\n",
      "MAPE: 0.058 (0.000)\n",
      "R2: 0.724 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Scores per plant\n",
      "=======================\n",
      "\n",
      "=======================\n",
      "Plant partner_iv\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.319 (0.000)\n",
      "MAE: 2.699 (0.000)\n",
      "MAPE: 0.055 (0.000)\n",
      "R2: 0.690 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_ii\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.882 (0.000)\n",
      "MAE: 2.332 (0.000)\n",
      "MAPE: 0.061 (0.000)\n",
      "R2: -0.111 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_i\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.058 (0.000)\n",
      "MAE: 2.584 (0.000)\n",
      "MAPE: 0.058 (0.000)\n",
      "R2: 0.618 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\n",
    "append_results(scores_dict)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv1D 2\n",
    "\n",
    "1. TIMESTEPS: 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.6970356424649556\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 14\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_2, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 14\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_2, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "set_global_determinism()\n",
    "timesteps = 14\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "dataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\n",
    "x_train = dataset[\"x_train\"]\n",
    "y_train = dataset[\"y_train\"]\n",
    "x_test = dataset[\"x_test\"]\n",
    "y_test = dataset[\"y_test\"]\n",
    "\n",
    "params = get_conv1d_params(\n",
    "    timesteps=timesteps,\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    verbose=0,\n",
    "    kernel_size=timesteps,\n",
    "    pool_size=timesteps,\n",
    ")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "model, scores = train_and_evaluate_model(Conv1D_2, dataset, estimator_params=params)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Overall Score\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.866 (0.000)\n",
      "MAE: 2.217 (0.000)\n",
      "MAPE: 0.048 (0.000)\n",
      "R2: 0.749 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.975 (0.000)\n",
      "MAE: 2.417 (0.000)\n",
      "MAPE: 0.056 (0.000)\n",
      "R2: 0.739 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Scores per plant\n",
      "=======================\n",
      "\n",
      "=======================\n",
      "Plant partner_iv\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.540 (0.000)\n",
      "MAE: 2.852 (0.000)\n",
      "MAPE: 0.057 (0.000)\n",
      "R2: 0.651 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_ii\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.110 (0.000)\n",
      "MAE: 2.557 (0.000)\n",
      "MAPE: 0.067 (0.000)\n",
      "R2: -0.344 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_i\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.369 (0.000)\n",
      "MAE: 1.999 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.769 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\n",
    "append_results(scores_dict)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv1D 3\n",
    "\n",
    "1. TIMESTEPS: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.48037752707799275\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 1\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_3, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 1\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_3, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "set_global_determinism()\n",
    "timesteps = 1\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "dataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\n",
    "x_train = dataset[\"x_train\"]\n",
    "y_train = dataset[\"y_train\"]\n",
    "x_test = dataset[\"x_test\"]\n",
    "y_test = dataset[\"y_test\"]\n",
    "\n",
    "params = get_conv1d_params(\n",
    "    timesteps=timesteps,\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    verbose=0,\n",
    "    kernel_size=timesteps,\n",
    "    pool_size=timesteps,\n",
    ")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "model, scores = train_and_evaluate_model(Conv1D_3, dataset, estimator_params=params)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Overall Score\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 3.532 (0.000)\n",
      "MAE: 2.758 (0.000)\n",
      "MAPE: 0.062 (0.000)\n",
      "R2: 0.621 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.839 (0.000)\n",
      "MAE: 3.117 (0.000)\n",
      "MAPE: 0.072 (0.000)\n",
      "R2: 0.573 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Scores per plant\n",
      "=======================\n",
      "\n",
      "=======================\n",
      "Plant partner_iv\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.944 (0.000)\n",
      "MAE: 2.935 (0.000)\n",
      "MAPE: 0.060 (0.000)\n",
      "R2: 0.587 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_ii\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.656 (0.000)\n",
      "MAE: 3.066 (0.000)\n",
      "MAPE: 0.080 (0.000)\n",
      "R2: -0.674 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_i\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.912 (0.000)\n",
      "MAE: 3.297 (0.000)\n",
      "MAPE: 0.075 (0.000)\n",
      "R2: 0.384 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\n",
    "append_results(scores_dict)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv1D 3\n",
    "\n",
    "1. TIMESTEPS: 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.6723046183586121\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 7\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_3, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 7\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_3, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "set_global_determinism()\n",
    "timesteps = 7\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "dataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\n",
    "x_train = dataset[\"x_train\"]\n",
    "y_train = dataset[\"y_train\"]\n",
    "x_test = dataset[\"x_test\"]\n",
    "y_test = dataset[\"y_test\"]\n",
    "\n",
    "params = get_conv1d_params(\n",
    "    timesteps=timesteps,\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    verbose=0,\n",
    "    kernel_size=timesteps,\n",
    "    pool_size=timesteps,\n",
    ")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "model, scores = train_and_evaluate_model(Conv1D_3, dataset, estimator_params=params)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Overall Score\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 3.145 (0.000)\n",
      "MAE: 2.531 (0.000)\n",
      "MAPE: 0.055 (0.000)\n",
      "R2: 0.699 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.355 (0.000)\n",
      "MAE: 2.795 (0.000)\n",
      "MAPE: 0.063 (0.000)\n",
      "R2: 0.672 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Scores per plant\n",
      "=======================\n",
      "\n",
      "=======================\n",
      "Plant partner_iv\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.712 (0.000)\n",
      "MAE: 3.097 (0.000)\n",
      "MAPE: 0.063 (0.000)\n",
      "R2: 0.613 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_ii\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.387 (0.000)\n",
      "MAE: 1.922 (0.000)\n",
      "MAPE: 0.050 (0.000)\n",
      "R2: 0.238 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_i\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.763 (0.000)\n",
      "MAE: 3.319 (0.000)\n",
      "MAPE: 0.074 (0.000)\n",
      "R2: 0.422 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\n",
    "append_results(scores_dict)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv1D 3\n",
    "\n",
    "1. TIMESTEPS: 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.9803036411603292\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 14\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_3, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 14\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_3, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "set_global_determinism()\n",
    "timesteps = 14\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "dataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\n",
    "x_train = dataset[\"x_train\"]\n",
    "y_train = dataset[\"y_train\"]\n",
    "x_test = dataset[\"x_test\"]\n",
    "y_test = dataset[\"y_test\"]\n",
    "\n",
    "params = get_conv1d_params(\n",
    "    timesteps=timesteps,\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    verbose=0,\n",
    "    kernel_size=timesteps,\n",
    "    pool_size=timesteps,\n",
    ")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "model, scores = train_and_evaluate_model(Conv1D_3, dataset, estimator_params=params)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Overall Score\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.524 (0.000)\n",
      "MAE: 1.972 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.806 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.401 (0.000)\n",
      "MAE: 2.706 (0.000)\n",
      "MAPE: 0.064 (0.000)\n",
      "R2: 0.659 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Scores per plant\n",
      "=======================\n",
      "\n",
      "=======================\n",
      "Plant partner_iv\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.976 (0.000)\n",
      "MAE: 3.193 (0.000)\n",
      "MAPE: 0.065 (0.000)\n",
      "R2: 0.559 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_ii\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 4.147 (0.000)\n",
      "MAE: 3.599 (0.000)\n",
      "MAPE: 0.094 (0.000)\n",
      "R2: -1.390 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_i\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.979 (0.000)\n",
      "MAE: 1.622 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.839 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\n",
    "append_results(scores_dict)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv1D 4\n",
    "\n",
    "1. TIMESTEPS: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.5122621496518452\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 1\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_4, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 1\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_4, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "set_global_determinism()\n",
    "timesteps = 1\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "dataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\n",
    "x_train = dataset[\"x_train\"]\n",
    "y_train = dataset[\"y_train\"]\n",
    "x_test = dataset[\"x_test\"]\n",
    "y_test = dataset[\"y_test\"]\n",
    "\n",
    "params = get_conv1d_params(\n",
    "    timesteps=timesteps,\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    verbose=0,\n",
    "    kernel_size=timesteps,\n",
    "    pool_size=timesteps,\n",
    ")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "model, scores = train_and_evaluate_model(Conv1D_4, dataset, estimator_params=params)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Overall Score\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 3.532 (0.000)\n",
      "MAE: 2.758 (0.000)\n",
      "MAPE: 0.062 (0.000)\n",
      "R2: 0.621 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.839 (0.000)\n",
      "MAE: 3.117 (0.000)\n",
      "MAPE: 0.072 (0.000)\n",
      "R2: 0.573 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Scores per plant\n",
      "=======================\n",
      "\n",
      "=======================\n",
      "Plant partner_iv\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.944 (0.000)\n",
      "MAE: 2.935 (0.000)\n",
      "MAPE: 0.060 (0.000)\n",
      "R2: 0.587 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_ii\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.656 (0.000)\n",
      "MAE: 3.066 (0.000)\n",
      "MAPE: 0.080 (0.000)\n",
      "R2: -0.674 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_i\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.912 (0.000)\n",
      "MAE: 3.297 (0.000)\n",
      "MAPE: 0.075 (0.000)\n",
      "R2: 0.384 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\n",
    "append_results(scores_dict)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv1D 4\n",
    "\n",
    "1. TIMESTEPS: 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.6593296488126119\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 7\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_4, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 7\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_4, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "set_global_determinism()\n",
    "timesteps = 7\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "dataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\n",
    "x_train = dataset[\"x_train\"]\n",
    "y_train = dataset[\"y_train\"]\n",
    "x_test = dataset[\"x_test\"]\n",
    "y_test = dataset[\"y_test\"]\n",
    "\n",
    "params = get_conv1d_params(\n",
    "    timesteps=timesteps,\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    verbose=0,\n",
    "    kernel_size=timesteps,\n",
    "    pool_size=timesteps,\n",
    ")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "model, scores = train_and_evaluate_model(Conv1D_4, dataset, estimator_params=params)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Overall Score\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.995 (0.000)\n",
      "MAE: 2.379 (0.000)\n",
      "MAPE: 0.052 (0.000)\n",
      "R2: 0.727 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.095 (0.000)\n",
      "MAE: 2.517 (0.000)\n",
      "MAPE: 0.057 (0.000)\n",
      "R2: 0.721 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Scores per plant\n",
      "=======================\n",
      "\n",
      "=======================\n",
      "Plant partner_iv\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.556 (0.000)\n",
      "MAE: 2.839 (0.000)\n",
      "MAPE: 0.057 (0.000)\n",
      "R2: 0.645 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_ii\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.606 (0.000)\n",
      "MAE: 2.130 (0.000)\n",
      "MAPE: 0.055 (0.000)\n",
      "R2: 0.091 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_i\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.121 (0.000)\n",
      "MAE: 2.614 (0.000)\n",
      "MAPE: 0.058 (0.000)\n",
      "R2: 0.602 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\n",
    "append_results(scores_dict)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv1D 4\n",
    "\n",
    "1. TIMESTEPS: 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  1.0341217239697775\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 14\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_4, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 14\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_4, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "set_global_determinism()\n",
    "timesteps = 14\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "dataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\n",
    "x_train = dataset[\"x_train\"]\n",
    "y_train = dataset[\"y_train\"]\n",
    "x_test = dataset[\"x_test\"]\n",
    "y_test = dataset[\"y_test\"]\n",
    "\n",
    "params = get_conv1d_params(\n",
    "    timesteps=timesteps,\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    verbose=0,\n",
    "    kernel_size=timesteps,\n",
    "    pool_size=timesteps,\n",
    ")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "model, scores = train_and_evaluate_model(Conv1D_4, dataset, estimator_params=params)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Overall Score\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 3.003 (0.000)\n",
      "MAE: 2.326 (0.000)\n",
      "MAPE: 0.050 (0.000)\n",
      "R2: 0.725 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.165 (0.000)\n",
      "MAE: 2.532 (0.000)\n",
      "MAPE: 0.058 (0.000)\n",
      "R2: 0.705 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Scores per plant\n",
      "=======================\n",
      "\n",
      "=======================\n",
      "Plant partner_iv\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 4.125 (0.000)\n",
      "MAE: 3.236 (0.000)\n",
      "MAPE: 0.064 (0.000)\n",
      "R2: 0.526 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_ii\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.063 (0.000)\n",
      "MAE: 2.526 (0.000)\n",
      "MAPE: 0.066 (0.000)\n",
      "R2: -0.304 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_i\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.384 (0.000)\n",
      "MAE: 2.047 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.766 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\n",
    "append_results(scores_dict)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv1D 5\n",
    "\n",
    "1. TIMESTEPS: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.6650588393211365\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 1\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_5, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 1\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_5, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "set_global_determinism()\n",
    "timesteps = 1\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "dataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\n",
    "x_train = dataset[\"x_train\"]\n",
    "y_train = dataset[\"y_train\"]\n",
    "x_test = dataset[\"x_test\"]\n",
    "y_test = dataset[\"y_test\"]\n",
    "\n",
    "params = get_conv1d_params(\n",
    "    timesteps=timesteps,\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    verbose=0,\n",
    "    kernel_size=timesteps,\n",
    "    pool_size=timesteps,\n",
    ")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "model, scores = train_and_evaluate_model(Conv1D_5, dataset, estimator_params=params)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Overall Score\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 4.903 (0.000)\n",
      "MAE: 3.987 (0.000)\n",
      "MAPE: 0.085 (0.000)\n",
      "R2: 0.269 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 4.937 (0.000)\n",
      "MAE: 3.858 (0.000)\n",
      "MAPE: 0.084 (0.000)\n",
      "R2: 0.294 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Scores per plant\n",
      "=======================\n",
      "\n",
      "=======================\n",
      "Plant partner_iv\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 6.210 (0.000)\n",
      "MAE: 4.934 (0.000)\n",
      "MAPE: 0.099 (0.000)\n",
      "R2: -0.023 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_ii\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.405 (0.000)\n",
      "MAE: 1.928 (0.000)\n",
      "MAPE: 0.048 (0.000)\n",
      "R2: 0.276 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_i\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 5.463 (0.000)\n",
      "MAE: 4.720 (0.000)\n",
      "MAPE: 0.103 (0.000)\n",
      "R2: -0.202 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\n",
    "append_results(scores_dict)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv1D 5\n",
    "\n",
    "1. TIMESTEPS: 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  0.9982159813245137\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 7\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_5, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 7\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_5, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "set_global_determinism()\n",
    "timesteps = 7\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "dataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\n",
    "x_train = dataset[\"x_train\"]\n",
    "y_train = dataset[\"y_train\"]\n",
    "x_test = dataset[\"x_test\"]\n",
    "y_test = dataset[\"y_test\"]\n",
    "\n",
    "params = get_conv1d_params(\n",
    "    timesteps=timesteps,\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    verbose=0,\n",
    "    kernel_size=timesteps,\n",
    "    pool_size=timesteps,\n",
    ")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "model, scores = train_and_evaluate_model(Conv1D_5, dataset, estimator_params=params)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Overall Score\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.624 (0.000)\n",
      "MAE: 2.080 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.790 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.395 (0.000)\n",
      "MAE: 2.776 (0.000)\n",
      "MAPE: 0.065 (0.000)\n",
      "R2: 0.664 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Scores per plant\n",
      "=======================\n",
      "\n",
      "=======================\n",
      "Plant partner_iv\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.513 (0.000)\n",
      "MAE: 2.757 (0.000)\n",
      "MAPE: 0.056 (0.000)\n",
      "R2: 0.653 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_ii\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.808 (0.000)\n",
      "MAE: 3.247 (0.000)\n",
      "MAPE: 0.084 (0.000)\n",
      "R2: -0.940 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_i\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.899 (0.000)\n",
      "MAE: 2.389 (0.000)\n",
      "MAPE: 0.054 (0.000)\n",
      "R2: 0.657 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\n",
    "append_results(scores_dict)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv1D 5\n",
    "\n",
    "1. TIMESTEPS: 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  1.9040929317474364\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 14\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_5, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nset_global_determinism()\\ntimesteps = 14\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ndataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\\nx_train = dataset[\\\"x_train\\\"]\\ny_train = dataset[\\\"y_train\\\"]\\nx_test = dataset[\\\"x_test\\\"]\\ny_test = dataset[\\\"y_test\\\"]\\n\\nparams = get_conv1d_params(\\n    timesteps=timesteps,\\n    callbacks=None,\\n    validation_split=0.0,\\n    verbose=0,\\n    kernel_size=timesteps,\\n    pool_size=timesteps,\\n)\\n\\n\\nstart = time.time()\\nmodel, scores = train_and_evaluate_model(Conv1D_5, dataset, estimator_params=params)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "set_global_determinism()\n",
    "timesteps = 14\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "dataset, plant_specific = prepare_dataset_helper(timesteps=timesteps)\n",
    "x_train = dataset[\"x_train\"]\n",
    "y_train = dataset[\"y_train\"]\n",
    "x_test = dataset[\"x_test\"]\n",
    "y_test = dataset[\"y_test\"]\n",
    "\n",
    "params = get_conv1d_params(\n",
    "    timesteps=timesteps,\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    verbose=0,\n",
    "    kernel_size=timesteps,\n",
    "    pool_size=timesteps,\n",
    ")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "model, scores = train_and_evaluate_model(Conv1D_5, dataset, estimator_params=params)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Overall Score\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 3.123 (0.000)\n",
      "MAE: 2.502 (0.000)\n",
      "MAPE: 0.054 (0.000)\n",
      "R2: 0.702 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.441 (0.000)\n",
      "MAE: 2.790 (0.000)\n",
      "MAPE: 0.062 (0.000)\n",
      "R2: 0.651 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Scores per plant\n",
      "=======================\n",
      "\n",
      "=======================\n",
      "Plant partner_iv\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.814 (0.000)\n",
      "MAE: 3.006 (0.000)\n",
      "MAPE: 0.061 (0.000)\n",
      "R2: 0.594 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_ii\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.445 (0.000)\n",
      "MAE: 1.934 (0.000)\n",
      "MAPE: 0.050 (0.000)\n",
      "R2: 0.169 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "=======================\n",
      "Plant partner_i\n",
      "=======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.854 (0.000)\n",
      "MAE: 3.356 (0.000)\n",
      "MAPE: 0.074 (0.000)\n",
      "R2: 0.388 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\\nappend_results(scores_dict)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_dict = print_results_and_get_scores_dict(scores, plant_specific)\n",
    "append_results(scores_dict)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/inn/all_cements/pre_training/full/\\\"\\nfilename = f\\\"conv1d_results_full_{index_to_save}.csv\\\"\\n\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/inn/all_cements/pre_training/full/\\\"\\nfilename = f\\\"conv1d_results_full_{index_to_save}.csv\\\"\\n\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/inn/all_cements/pre_training/full/\"\n",
    "filename = f\"conv1d_results_full_{index_to_save}.csv\"\n",
    "\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 63;\n",
       "                var nbb_unformatted_code = \"from sklearn.preprocessing import StandardScaler\";\n",
       "                var nbb_formatted_code = \"from sklearn.preprocessing import StandardScaler\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 64;\n",
       "                var nbb_unformatted_code = \"columns_to_standardize = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\";\n",
       "                var nbb_formatted_code = \"columns_to_standardize = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns_to_standardize = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>INN</td>\n",
       "      <td>INN</td>\n",
       "      <td>Chemical + Mineralogical</td>\n",
       "      <td>(3180, 13)</td>\n",
       "      <td>14</td>\n",
       "      <td>Conv1D_6</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Out of time</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>2.866132</td>\n",
       "      <td>2.217415</td>\n",
       "      <td>0.048178</td>\n",
       "      <td>0.749472</td>\n",
       "      <td>2.974922</td>\n",
       "      <td>2.417211</td>\n",
       "      <td>0.055525</td>\n",
       "      <td>0.739126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>INN</td>\n",
       "      <td>partner_iv</td>\n",
       "      <td>Chemical + Mineralogical</td>\n",
       "      <td>(3180, 13)</td>\n",
       "      <td>14</td>\n",
       "      <td>Conv1D_6</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Out of time</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>2.866132</td>\n",
       "      <td>2.217415</td>\n",
       "      <td>0.048178</td>\n",
       "      <td>0.749472</td>\n",
       "      <td>3.539505</td>\n",
       "      <td>2.851517</td>\n",
       "      <td>0.057414</td>\n",
       "      <td>0.650590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>INN</td>\n",
       "      <td>partner_ii</td>\n",
       "      <td>Chemical + Mineralogical</td>\n",
       "      <td>(3180, 13)</td>\n",
       "      <td>14</td>\n",
       "      <td>Conv1D_6</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Out of time</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>2.866132</td>\n",
       "      <td>2.217415</td>\n",
       "      <td>0.048178</td>\n",
       "      <td>0.749472</td>\n",
       "      <td>3.109730</td>\n",
       "      <td>2.557178</td>\n",
       "      <td>0.066983</td>\n",
       "      <td>-0.344170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>INN</td>\n",
       "      <td>partner_i</td>\n",
       "      <td>Chemical + Mineralogical</td>\n",
       "      <td>(3180, 13)</td>\n",
       "      <td>14</td>\n",
       "      <td>Conv1D_6</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Out of time</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>2.866132</td>\n",
       "      <td>2.217415</td>\n",
       "      <td>0.048178</td>\n",
       "      <td>0.749472</td>\n",
       "      <td>2.368999</td>\n",
       "      <td>1.998861</td>\n",
       "      <td>0.044647</td>\n",
       "      <td>0.768679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category Company       Plant                  Features  Data Shape  \\\n",
       "0  Global Model     INN         INN  Chemical + Mineralogical  (3180, 13)   \n",
       "1  Global Model     INN       partner_iv  Chemical + Mineralogical  (3180, 13)   \n",
       "2  Global Model     INN  partner_ii  Chemical + Mineralogical  (3180, 13)   \n",
       "3  Global Model     INN  partner_i  Chemical + Mineralogical  (3180, 13)   \n",
       "\n",
       "   Timesteps     Model Model Params           Scaler Scaler Params  ...  \\\n",
       "0         14  Conv1D_6         None  Standard Scaler          None  ...   \n",
       "1         14  Conv1D_6         None  Standard Scaler          None  ...   \n",
       "2         14  Conv1D_6         None  Standard Scaler          None  ...   \n",
       "3         14  Conv1D_6         None  Standard Scaler          None  ...   \n",
       "\n",
       "  Cross Validation                Cross Validation Params RMSE Train  \\\n",
       "0      Out of time  {\"train_size\": 0.8, \"test_size\": 0.2}   2.866132   \n",
       "1      Out of time  {\"train_size\": 0.8, \"test_size\": 0.2}   2.866132   \n",
       "2      Out of time  {\"train_size\": 0.8, \"test_size\": 0.2}   2.866132   \n",
       "3      Out of time  {\"train_size\": 0.8, \"test_size\": 0.2}   2.866132   \n",
       "\n",
       "  MAE Train  MAPE Train  R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test  \n",
       "0  2.217415    0.048178  0.749472   2.974922  2.417211   0.055525  0.739126  \n",
       "1  2.217415    0.048178  0.749472   3.539505  2.851517   0.057414  0.650590  \n",
       "2  2.217415    0.048178  0.749472   3.109730  2.557178   0.066983 -0.344170  \n",
       "3  2.217415    0.048178  0.749472   2.368999  1.998861   0.044647  0.768679  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 65;\n",
       "                var nbb_unformatted_code = \"ddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\nddf_copy = ddf_copy[ddf_copy[\\\"Plant\\\"].eq(\\\"INN\\\")]\\nscaler = StandardScaler()\\ndddf_copy = ddf_copy.copy()\\ndddf_copy[columns_to_standardize] = scaler.fit_transform(\\n    ddf_copy[columns_to_standardize]\\n).copy()\\n\\nddf_copy[\\\"SCPM\\\"] = (\\n    dddf_copy[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\"]].sum(axis=1) - dddf_copy[\\\"R2 Test\\\"]\\n)\\nmin_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\nddf.merge(min_row[[\\\"Timesteps\\\", \\\"Model\\\"]], on=(\\\"Timesteps\\\", \\\"Model\\\"), how=\\\"inner\\\")\";\n",
       "                var nbb_formatted_code = \"ddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\nddf_copy = ddf_copy[ddf_copy[\\\"Plant\\\"].eq(\\\"INN\\\")]\\nscaler = StandardScaler()\\ndddf_copy = ddf_copy.copy()\\ndddf_copy[columns_to_standardize] = scaler.fit_transform(\\n    ddf_copy[columns_to_standardize]\\n).copy()\\n\\nddf_copy[\\\"SCPM\\\"] = (\\n    dddf_copy[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\"]].sum(axis=1) - dddf_copy[\\\"R2 Test\\\"]\\n)\\nmin_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\nddf.merge(min_row[[\\\"Timesteps\\\", \\\"Model\\\"]], on=(\\\"Timesteps\\\", \\\"Model\\\"), how=\\\"inner\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "ddf_copy = ddf_copy[ddf_copy[\"Plant\"].eq(\"INN\")]\n",
    "scaler = StandardScaler()\n",
    "dddf_copy = ddf_copy.copy()\n",
    "dddf_copy[columns_to_standardize] = scaler.fit_transform(\n",
    "    ddf_copy[columns_to_standardize]\n",
    ").copy()\n",
    "\n",
    "ddf_copy[\"SCPM\"] = (\n",
    "    dddf_copy[[\"RMSE Test\", \"MAE Test\", \"MAPE Test\"]].sum(axis=1) - dddf_copy[\"R2 Test\"]\n",
    ")\n",
    "min_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "ddf.merge(min_row[[\"Timesteps\", \"Model\"]], on=(\"Timesteps\", \"Model\"), how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
