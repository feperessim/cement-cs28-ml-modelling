{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 00:39:55.352741: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-19 00:39:55.355440: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-19 00:39:55.410391: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-19 00:39:55.411871: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-19 00:39:56.514545: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/206/mlp/b/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 1\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 1\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 1\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"L\\\",\\n    \\\"Features\\\": \\\"Chemical + Physical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"L\\\",\\n    \\\"Features\\\": \\\"Chemical + Physical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"209\",\n",
    "    \"Plant\": \"L\",\n",
    "    \"Features\": \"Chemical + Physical\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/209/global_l.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/209/global_l.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/209/global_l.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f014d_row0_col0, #T_f014d_row1_col0, #T_f014d_row2_col0, #T_f014d_row3_col0, #T_f014d_row4_col0, #T_f014d_row5_col0, #T_f014d_row6_col0, #T_f014d_row7_col0, #T_f014d_row8_col0, #T_f014d_row9_col0, #T_f014d_row10_col0, #T_f014d_row11_col0, #T_f014d_row12_col0, #T_f014d_row13_col0, #T_f014d_row14_col0, #T_f014d_row15_col0 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f014d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f014d_level0_col0\" class=\"col_heading level0 col0\" >Zero (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f014d_level0_row0\" class=\"row_heading level0 row0\" >CaO</th>\n",
       "      <td id=\"T_f014d_row0_col0\" class=\"data row0 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f014d_level0_row1\" class=\"row_heading level0 row1\" >MgO</th>\n",
       "      <td id=\"T_f014d_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f014d_level0_row2\" class=\"row_heading level0 row2\" >Na2O</th>\n",
       "      <td id=\"T_f014d_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f014d_level0_row3\" class=\"row_heading level0 row3\" >Al2O3</th>\n",
       "      <td id=\"T_f014d_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f014d_level0_row4\" class=\"row_heading level0 row4\" >SiO2</th>\n",
       "      <td id=\"T_f014d_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f014d_level0_row5\" class=\"row_heading level0 row5\" >SO3</th>\n",
       "      <td id=\"T_f014d_row5_col0\" class=\"data row5 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f014d_level0_row6\" class=\"row_heading level0 row6\" >K2O</th>\n",
       "      <td id=\"T_f014d_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f014d_level0_row7\" class=\"row_heading level0 row7\" >Fe2O3</th>\n",
       "      <td id=\"T_f014d_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f014d_level0_row8\" class=\"row_heading level0 row8\" >Loss on Ignition</th>\n",
       "      <td id=\"T_f014d_row8_col0\" class=\"data row8 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f014d_level0_row9\" class=\"row_heading level0 row9\" >Insoluble Residue</th>\n",
       "      <td id=\"T_f014d_row9_col0\" class=\"data row9 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f014d_level0_row10\" class=\"row_heading level0 row10\" >Blaine</th>\n",
       "      <td id=\"T_f014d_row10_col0\" class=\"data row10 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f014d_level0_row11\" class=\"row_heading level0 row11\" >Initial setting time</th>\n",
       "      <td id=\"T_f014d_row11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f014d_level0_row12\" class=\"row_heading level0 row12\" >Final setting time</th>\n",
       "      <td id=\"T_f014d_row12_col0\" class=\"data row12 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f014d_level0_row13\" class=\"row_heading level0 row13\" >CS3</th>\n",
       "      <td id=\"T_f014d_row13_col0\" class=\"data row13 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f014d_level0_row14\" class=\"row_heading level0 row14\" >CS7</th>\n",
       "      <td id=\"T_f014d_row14_col0\" class=\"data row14 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f014d_level0_row15\" class=\"row_heading level0 row15\" >CS28</th>\n",
       "      <td id=\"T_f014d_row15_col0\" class=\"data row15 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7a4f05646710>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_formatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_values = {}\n",
    "for col in df.select_dtypes(include=\"number\").columns:\n",
    "    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\n",
    "    zero_values[col] = zero_percentages\n",
    "\n",
    "zero_percentages = pd.Series(zero_values, name=f\"Zero (%)\")\n",
    "zero_percentages = zero_percentages.sort_values(ascending=False)\n",
    "zero_percentages = zero_percentages.to_frame(name=f\"Zero (%)\")\n",
    "zero_percentages.style.background_gradient(cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop([\\\"Cement_Type\\\", \\\"Factory_Plant\\\"], axis=1)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop([\\\"Cement_Type\\\", \\\"Factory_Plant\\\"], axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop([\"Cement_Type\", \"Factory_Plant\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 00:53:00.151883: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  12.475866321722666\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.354 (0.000)\n",
      "MAE: 1.025 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.961 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.564 (0.000)\n",
      "MAE: 1.174 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.931 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  12.096067571640015\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.368 (0.000)\n",
      "MAE: 1.034 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.960 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.518 (0.000)\n",
      "MAE: 1.138 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.935 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.413262800375621\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.379 (0.000)\n",
      "MAE: 1.061 (0.000)\n",
      "MAPE: 0.025 (0.000)\n",
      "R2: 0.959 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.601 (0.000)\n",
      "MAE: 1.207 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.928 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  22.055553309122722\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.378 (0.000)\n",
      "MAE: 1.072 (0.000)\n",
      "MAPE: 0.025 (0.000)\n",
      "R2: 0.959 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.651 (0.000)\n",
      "MAE: 1.254 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.923 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  20.911839771270753\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.335 (0.000)\n",
      "MAE: 1.021 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.962 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.532 (0.000)\n",
      "MAE: 1.137 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.934 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  32.79024651447932\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.288 (0.000)\n",
      "MAE: 0.977 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.964 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.476 (0.000)\n",
      "MAE: 1.100 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.939 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  24.08537832895915\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.246 (0.000)\n",
      "MAE: 0.938 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.967 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.478 (0.000)\n",
      "MAE: 1.082 (0.000)\n",
      "MAPE: 0.025 (0.000)\n",
      "R2: 0.938 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.781197893619538\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.295 (0.000)\n",
      "MAE: 0.986 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.964 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.558 (0.000)\n",
      "MAE: 1.155 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.932 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  23.532057146231335\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.540 (0.000)\n",
      "MAE: 1.206 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.949 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.886 (0.000)\n",
      "MAE: 1.451 (0.000)\n",
      "MAPE: 0.035 (0.000)\n",
      "R2: 0.900 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  23.68996619383494\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.300 (0.000)\n",
      "MAE: 0.988 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.964 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.528 (0.000)\n",
      "MAE: 1.124 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.934 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.230201923847197\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.302 (0.000)\n",
      "MAE: 0.988 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.964 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.497 (0.000)\n",
      "MAE: 1.104 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.937 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.419299085934957\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.424 (0.000)\n",
      "MAE: 1.079 (0.000)\n",
      "MAPE: 0.024 (0.000)\n",
      "R2: 0.956 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.516 (0.000)\n",
      "MAE: 1.126 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.935 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.908419541517894\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.675 (0.000)\n",
      "MAE: 1.312 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.940 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.765 (0.000)\n",
      "MAE: 1.350 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.912 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/209/l/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/209/l/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/209/l/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>209</td>\n",
       "      <td>L</td>\n",
       "      <td>Chemical + Physical</td>\n",
       "      <td>(63072, 15)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_7</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>1.246254</td>\n",
       "      <td>0.937778</td>\n",
       "      <td>0.021064</td>\n",
       "      <td>0.96665</td>\n",
       "      <td>1.478337</td>\n",
       "      <td>1.082472</td>\n",
       "      <td>0.025432</td>\n",
       "      <td>0.938496</td>\n",
       "      <td>-3.690706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category Company Plant             Features   Data Shape Timesteps  \\\n",
       "6  Global Model     209     L  Chemical + Physical  (63072, 15)      None   \n",
       "\n",
       "   Model Model Params           Scaler Scaler Params  ...  \\\n",
       "6  MLP_7         None  Standard Scaler          None  ...   \n",
       "\n",
       "                 Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "6  {\"train_size\": 0.8, \"test_size\": 0.2}   1.246254  0.937778   0.021064   \n",
       "\n",
       "   R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "6   0.96665   1.478337  1.082472   0.025432  0.938496 -3.690706  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 00:42:09.917272: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  60.531282718976335\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.235 (0.000)\n",
      "MAE: 0.937 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.966 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.235 (0.000)\n",
      "MAE: 0.937 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.966 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/209/mlp/l/pre_training/\\\"\\nmodel_name = \\\"mlp_full_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/209/mlp/l/pre_training/\\\"\\nmodel_name = \\\"mlp_full_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/209/mlp/l/pre_training/\"\n",
    "model_name = \"mlp_full_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7a4d58618f40>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7a4d90f41ed0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7a4d90fdc0d0>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7a4d90e32ce0>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               4096      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 256)               1024      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 16)                64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49857 (194.75 KB)\n",
      "Trainable params: 48865 (190.88 KB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
