{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 00:39:24.956916: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-19 00:39:24.959781: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-19 00:39:25.015796: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-19 00:39:25.017144: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-19 00:39:26.097840: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/206/mlp/b/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 2\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 2\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 2\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"L\\\",\\n    \\\"Features\\\": \\\"Chemical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"L\\\",\\n    \\\"Features\\\": \\\"Chemical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"209\",\n",
    "    \"Plant\": \"L\",\n",
    "    \"Features\": \"Chemical\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/209/global_l.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/209/global_l.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/209/global_l.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Cement_Type\\\",\\n        \\\"Factory_Plant\\\",\\n        \\\"Blaine\\\",\\n        # \\\"#200\\\",\\n        # \\\"#325\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        # \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Cement_Type\\\",\\n        \\\"Factory_Plant\\\",\\n        \\\"Blaine\\\",\\n        # \\\"#200\\\",\\n        # \\\"#325\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        # \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop(\n",
    "    [\n",
    "        \"Cement_Type\",\n",
    "        \"Factory_Plant\",\n",
    "        \"Blaine\",\n",
    "        # \"#200\",\n",
    "        # \"#325\",\n",
    "        \"Final setting time\",\n",
    "        \"Initial setting time\",\n",
    "        # \"CS1\",\n",
    "        \"CS3\",\n",
    "        \"CS7\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 00:53:25.723369: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  11.743509729703268\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.226 (0.000)\n",
      "MAE: 1.638 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.894 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.857 (0.000)\n",
      "MAE: 2.081 (0.000)\n",
      "MAPE: 0.050 (0.000)\n",
      "R2: 0.770 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  11.084346270561218\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.233 (0.000)\n",
      "MAE: 1.644 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.893 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.745 (0.000)\n",
      "MAE: 1.988 (0.000)\n",
      "MAPE: 0.047 (0.000)\n",
      "R2: 0.788 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.493727127710978\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.036 (0.000)\n",
      "MAE: 1.509 (0.000)\n",
      "MAPE: 0.034 (0.000)\n",
      "R2: 0.911 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.818 (0.000)\n",
      "MAE: 2.001 (0.000)\n",
      "MAPE: 0.048 (0.000)\n",
      "R2: 0.776 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  23.425037173430123\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.903 (0.000)\n",
      "MAE: 1.402 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.922 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.804 (0.000)\n",
      "MAE: 1.968 (0.000)\n",
      "MAPE: 0.047 (0.000)\n",
      "R2: 0.779 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  21.89776169459025\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.970 (0.000)\n",
      "MAE: 1.448 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.917 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.867 (0.000)\n",
      "MAE: 2.007 (0.000)\n",
      "MAPE: 0.048 (0.000)\n",
      "R2: 0.769 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  34.774257278442384\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.002 (0.000)\n",
      "MAE: 1.455 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.914 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.661 (0.000)\n",
      "MAE: 1.868 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.801 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  22.928101778030396\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.917 (0.000)\n",
      "MAE: 1.401 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.921 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.768 (0.000)\n",
      "MAE: 1.937 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.784 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.345850400129954\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.930 (0.000)\n",
      "MAE: 1.416 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.920 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.779 (0.000)\n",
      "MAE: 1.941 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.783 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  24.121434930960337\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.824 (0.000)\n",
      "MAE: 1.364 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.929 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.014 (0.000)\n",
      "MAE: 2.116 (0.000)\n",
      "MAPE: 0.051 (0.000)\n",
      "R2: 0.744 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.00847680568695\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.880 (0.000)\n",
      "MAE: 1.390 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.924 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.801 (0.000)\n",
      "MAE: 1.956 (0.000)\n",
      "MAPE: 0.047 (0.000)\n",
      "R2: 0.779 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  26.62583978573481\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.983 (0.000)\n",
      "MAE: 1.443 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.916 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.701 (0.000)\n",
      "MAE: 1.914 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.795 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.534422679742176\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.164 (0.000)\n",
      "MAE: 1.588 (0.000)\n",
      "MAPE: 0.036 (0.000)\n",
      "R2: 0.899 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.651 (0.000)\n",
      "MAE: 1.883 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.802 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.183462917804718\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.355 (0.000)\n",
      "MAE: 1.745 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.881 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.755 (0.000)\n",
      "MAE: 1.961 (0.000)\n",
      "MAPE: 0.047 (0.000)\n",
      "R2: 0.786 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/209/l/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/209/l/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/209/l/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>209</td>\n",
       "      <td>L</td>\n",
       "      <td>Chemical</td>\n",
       "      <td>(63072, 10)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_6</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>2.002205</td>\n",
       "      <td>1.454547</td>\n",
       "      <td>0.032916</td>\n",
       "      <td>0.91392</td>\n",
       "      <td>2.661388</td>\n",
       "      <td>1.86777</td>\n",
       "      <td>0.044436</td>\n",
       "      <td>0.800671</td>\n",
       "      <td>-5.658337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category Company Plant  Features   Data Shape Timesteps  Model  \\\n",
       "5  Global Model     209     L  Chemical  (63072, 10)      None  MLP_6   \n",
       "\n",
       "  Model Params           Scaler Scaler Params  ...  \\\n",
       "5         None  Standard Scaler          None  ...   \n",
       "\n",
       "                 Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "5  {\"train_size\": 0.8, \"test_size\": 0.2}   2.002205  1.454547   0.032916   \n",
       "\n",
       "   R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "5   0.91392   2.661388   1.86777   0.044436  0.800671 -5.658337  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 00:41:42.577409: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  61.40693540175756\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.005 (0.000)\n",
      "MAE: 1.470 (0.000)\n",
      "MAPE: 0.034 (0.000)\n",
      "R2: 0.910 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.005 (0.000)\n",
      "MAE: 1.470 (0.000)\n",
      "MAPE: 0.034 (0.000)\n",
      "R2: 0.910 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/209/mlp/l/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/209/mlp/l/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/209/mlp/l/pre_training/\"\n",
    "model_name = \"mlp_chemical_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7c5e9dc31720>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7c5e9db154e0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7c5e9db7fac0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7c5e9da099c0>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               2816      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 256)               1024      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 16)                64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48577 (189.75 KB)\n",
      "Trainable params: 47585 (185.88 KB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
