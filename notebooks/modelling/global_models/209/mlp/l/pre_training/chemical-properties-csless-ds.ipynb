{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 00:39:39.726598: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-19 00:39:39.729449: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-19 00:39:39.786749: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-19 00:39:39.787943: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-19 00:39:40.885251: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/206/mlp/b/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 10\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 10\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 10\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"L\\\",\\n    \\\"Features\\\": \\\"Chemical + Properties CS Less\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"L\\\",\\n    \\\"Features\\\": \\\"Chemical + Properties CS Less\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"209\",\n",
    "    \"Plant\": \"L\",\n",
    "    \"Features\": \"Chemical + Properties CS Less\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/209/global_l.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/209/global_l.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/209/global_l.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e07b8_row0_col0, #T_e07b8_row1_col0, #T_e07b8_row2_col0, #T_e07b8_row3_col0, #T_e07b8_row4_col0, #T_e07b8_row5_col0, #T_e07b8_row6_col0, #T_e07b8_row7_col0, #T_e07b8_row8_col0, #T_e07b8_row9_col0, #T_e07b8_row10_col0, #T_e07b8_row11_col0, #T_e07b8_row12_col0, #T_e07b8_row13_col0, #T_e07b8_row14_col0, #T_e07b8_row15_col0 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e07b8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e07b8_level0_col0\" class=\"col_heading level0 col0\" >Zero (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e07b8_level0_row0\" class=\"row_heading level0 row0\" >CaO</th>\n",
       "      <td id=\"T_e07b8_row0_col0\" class=\"data row0 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e07b8_level0_row1\" class=\"row_heading level0 row1\" >MgO</th>\n",
       "      <td id=\"T_e07b8_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e07b8_level0_row2\" class=\"row_heading level0 row2\" >Na2O</th>\n",
       "      <td id=\"T_e07b8_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e07b8_level0_row3\" class=\"row_heading level0 row3\" >Al2O3</th>\n",
       "      <td id=\"T_e07b8_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e07b8_level0_row4\" class=\"row_heading level0 row4\" >SiO2</th>\n",
       "      <td id=\"T_e07b8_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e07b8_level0_row5\" class=\"row_heading level0 row5\" >SO3</th>\n",
       "      <td id=\"T_e07b8_row5_col0\" class=\"data row5 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e07b8_level0_row6\" class=\"row_heading level0 row6\" >K2O</th>\n",
       "      <td id=\"T_e07b8_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e07b8_level0_row7\" class=\"row_heading level0 row7\" >Fe2O3</th>\n",
       "      <td id=\"T_e07b8_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e07b8_level0_row8\" class=\"row_heading level0 row8\" >Loss on Ignition</th>\n",
       "      <td id=\"T_e07b8_row8_col0\" class=\"data row8 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e07b8_level0_row9\" class=\"row_heading level0 row9\" >Insoluble Residue</th>\n",
       "      <td id=\"T_e07b8_row9_col0\" class=\"data row9 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e07b8_level0_row10\" class=\"row_heading level0 row10\" >Blaine</th>\n",
       "      <td id=\"T_e07b8_row10_col0\" class=\"data row10 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e07b8_level0_row11\" class=\"row_heading level0 row11\" >Initial setting time</th>\n",
       "      <td id=\"T_e07b8_row11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e07b8_level0_row12\" class=\"row_heading level0 row12\" >Final setting time</th>\n",
       "      <td id=\"T_e07b8_row12_col0\" class=\"data row12 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e07b8_level0_row13\" class=\"row_heading level0 row13\" >CS3</th>\n",
       "      <td id=\"T_e07b8_row13_col0\" class=\"data row13 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e07b8_level0_row14\" class=\"row_heading level0 row14\" >CS7</th>\n",
       "      <td id=\"T_e07b8_row14_col0\" class=\"data row14 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e07b8_level0_row15\" class=\"row_heading level0 row15\" >CS28</th>\n",
       "      <td id=\"T_e07b8_row15_col0\" class=\"data row15 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7592f80f4f10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_formatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_values = {}\n",
    "for col in df.select_dtypes(include=\"number\").columns:\n",
    "    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\n",
    "    zero_values[col] = zero_percentages\n",
    "\n",
    "zero_percentages = pd.Series(zero_values, name=f\"Zero (%)\")\n",
    "zero_percentages = zero_percentages.sort_values(ascending=False)\n",
    "zero_percentages = zero_percentages.to_frame(name=f\"Zero (%)\")\n",
    "zero_percentages.style.background_gradient(cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Factory_Plant\\\",\\n        \\\"Cement_Type\\\",\\n        # \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Factory_Plant\\\",\\n        \\\"Cement_Type\\\",\\n        # \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop(\n",
    "    [\n",
    "        \"Factory_Plant\",\n",
    "        \"Cement_Type\",\n",
    "        # \"CS1\",\n",
    "        \"CS3\",\n",
    "        \"CS7\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 00:53:13.419934: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  12.460435803731283\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.965 (0.000)\n",
      "MAE: 1.473 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.917 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.392 (0.000)\n",
      "MAE: 1.787 (0.000)\n",
      "MAPE: 0.042 (0.000)\n",
      "R2: 0.839 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  11.846016681194305\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.991 (0.000)\n",
      "MAE: 1.481 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.915 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.410 (0.000)\n",
      "MAE: 1.777 (0.000)\n",
      "MAPE: 0.042 (0.000)\n",
      "R2: 0.837 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.357746024926504\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.824 (0.000)\n",
      "MAE: 1.389 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.929 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.240 (0.000)\n",
      "MAE: 1.662 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.859 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  21.751183565457662\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.635 (0.000)\n",
      "MAE: 1.225 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.943 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.297 (0.000)\n",
      "MAE: 1.596 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.852 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  21.426981397469838\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.710 (0.000)\n",
      "MAE: 1.296 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.937 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.355 (0.000)\n",
      "MAE: 1.672 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.844 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  34.42441202799479\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.769 (0.000)\n",
      "MAE: 1.328 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.933 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.257 (0.000)\n",
      "MAE: 1.651 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.857 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  22.869029279549917\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.676 (0.000)\n",
      "MAE: 1.251 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.940 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.156 (0.000)\n",
      "MAE: 1.562 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.869 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.077162063121795\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.677 (0.000)\n",
      "MAE: 1.265 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.940 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.282 (0.000)\n",
      "MAE: 1.632 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.853 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  23.45977076689402\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.659 (0.000)\n",
      "MAE: 1.285 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.941 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.470 (0.000)\n",
      "MAE: 1.831 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.828 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  24.345930596192677\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.652 (0.000)\n",
      "MAE: 1.241 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.941 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.233 (0.000)\n",
      "MAE: 1.615 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.860 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  26.65424839258194\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.731 (0.000)\n",
      "MAE: 1.288 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.936 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.190 (0.000)\n",
      "MAE: 1.589 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.865 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.501733307043711\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.946 (0.000)\n",
      "MAE: 1.434 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.919 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.146 (0.000)\n",
      "MAE: 1.558 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.870 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.384940576553344\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.165 (0.000)\n",
      "MAE: 1.602 (0.000)\n",
      "MAPE: 0.036 (0.000)\n",
      "R2: 0.899 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.318 (0.000)\n",
      "MAE: 1.675 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.849 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/209/l/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/209/l/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/209/l/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>209</td>\n",
       "      <td>L</td>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>(63072, 13)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_12</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>1.946462</td>\n",
       "      <td>1.434389</td>\n",
       "      <td>0.032326</td>\n",
       "      <td>0.918646</td>\n",
       "      <td>2.146154</td>\n",
       "      <td>1.558399</td>\n",
       "      <td>0.036894</td>\n",
       "      <td>0.870379</td>\n",
       "      <td>-5.388531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category Company Plant                       Features   Data Shape  \\\n",
       "11  Global Model     209     L  Chemical + Properties CS Less  (63072, 13)   \n",
       "\n",
       "   Timesteps   Model Model Params           Scaler Scaler Params  ...  \\\n",
       "11      None  MLP_12         None  Standard Scaler          None  ...   \n",
       "\n",
       "                  Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "11  {\"train_size\": 0.8, \"test_size\": 0.2}   1.946462  1.434389   0.032326   \n",
       "\n",
       "    R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "11  0.918646   2.146154  1.558399   0.036894  0.870379 -5.388531  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R²\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 00:41:56.923441: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  35.41834760109584\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.868 (0.000)\n",
      "MAE: 1.393 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.922 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.868 (0.000)\n",
      "MAE: 1.393 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.922 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/209/mlp/l/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_properties_csless_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/209/mlp/l/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_properties_csless_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/209/mlp/l/pre_training/\"\n",
    "model_name = \"mlp_chemical_properties_csless_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x759194632530>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x75919444a590>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7591944e6650>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEdklEQVR4nO3dd3hUVf4G8PdOTZ1Jb6QQagglIB2VIghkERC7omJZWFasuKi4C5afLoq7rg1hdV2xrVhBUEGREnoJEDohCYGEhPQyqVPP748kI4FQApO5Se77eZ55ZO69M/Od4wzzcu4550pCCAEiIiIiN1HJXQAREREpC8MHERERuRXDBxEREbkVwwcRERG5FcMHERERuRXDBxEREbkVwwcRERG5FcMHERERuZVG7gLO5XA4kJubC19fX0iSJHc5REREdBmEEKioqEBERARUqov3bbS68JGbm4uoqCi5yyAiIqIrkJ2djcjIyIse0+rCh6+vL4C64g0Gg8zVEBER0eUwmUyIiopy/o5fTKsLHw2nWgwGA8MHERFRG3M5QyY44JSIiIjciuGDiIiI3Irhg4iIiNyK4YOIiIjciuGDiIiI3Irhg4iIiNyK4YOIiIjciuGDiIiI3Irhg4iIiNyK4YOIiIjciuGDiIiI3Irhg4iIiNyq1V1YrqWYbXYsXJMKq92Bv02Ih07D3EVERCQHRf0Cf7QlE59uP4Vam13uUoiIiBRLMeFDq/r9rVptDhkrISIiUjbFhA+VSoJWLQEALHaGDyIiIrkoJnwAgFZd93atNiFzJURERMqlqPDRMMjUYueYDyIiIrkoKnw09HxY2PNBREQkG0WFD11D+OCYDyIiItkoK3zUn3axMnwQERHJRlnhw3naheGDiIhILooKH1oNp9oSERHJTVHhgz0fRERE8lNU+HCu88GeDyIiItkoKnw41/lgzwcREZFslBU+2PNBREQkO2WFD+cKp1xkjIiISC6KCh9aDjglIiKSnaLCBxcZIyIikl+zw8emTZswceJEREREQJIkrFixotH+yspKPProo4iMjISnpyfi4+OxZMkSV9V7VdjzQUREJL9mh4+qqiokJCRg0aJFTe6fPXs21qxZg88//xxHjx7Fk08+iUcffRQrV6686mKvlp49H0RERLLTNPcBiYmJSExMvOD+bdu2Ydq0aRg5ciQAYMaMGfj3v/+NXbt2YdKkSVdcqCto1fUrnLLng4iISDYuH/MxbNgwrFy5Ejk5ORBCYMOGDTh+/DjGjh3b5PFmsxkmk6nRraX8PtuF4YOIiEguLg8f7777LuLj4xEZGQmdTofx48dj0aJFGD58eJPHL1iwAEaj0XmLiopydUlOHPNBREQkvxYJHzt27MDKlSuxZ88e/POf/8SsWbPw22+/NXn83LlzUV5e7rxlZ2e7uiQnLq9OREQkv2aP+biYmpoaPP/881i+fDkmTJgAAOjTpw9SUlLwj3/8A2PGjDnvMXq9Hnq93pVlXJCey6sTERHJzqU9H1arFVarFSpV46dVq9VwOOT/wf+954MrnBIREcml2T0flZWVSE9Pd97PzMxESkoKAgICEB0djREjRmDOnDnw9PRETEwMkpKS8Omnn+LNN990aeFXomHAqZk9H0RERLJpdvhITk7GqFGjnPdnz54NAJg2bRqWLl2KZcuWYe7cuZg6dSpKSkoQExODV199FTNnznRd1VeIYz6IiIjk1+zwMXLkSAhx4dMWYWFh+Pjjj6+qqJai45gPIiIi2Snr2i71i4yx54OIiEg+ygofXGSMiIhIdooKH1xkjIiISH6KCh86NXs+iIiI5Kao8KHlVW2JiIhkp6jwoeNpFyIiItkpK3xouMIpERGR3JQVPtjzQUREJDtFhQ8tp9oSERHJTlHh4+yej4ut0kpEREQtR5HhAwBsDoYPIiIiOSgrfGh+f7ucbktERCQPRYUPbf21XQAOOiUiIpKLosKHRq2Cqj5/cNApERGRPBQVPgBe34WIiEhuigsfDYNOudAYERGRPJQXPjTs+SAiIpKT4sKHVs2LyxEREclJceGjoefDzJ4PIiIiWSgufDRMt2XPBxERkTwUFz50GjUAjvkgIiKSi/LCB3s+iIiIZKW88MHZLkRERLJSXPhwLjLGng8iIiJZKC58sOeDiIhIXooLH1qucEpERCQrxYWP33s+7DJXQkREpEzKCx/s+SAiIpKVYsMHB5wSERHJQ3HhQ6upW+eDA06JiIjkobjwoVPXr3DKng8iIiJZKC58NPR8WNnzQUREJAvFhQ+9mle1JSIikpPiwoeHru60S62VU22JiIjkoLjw4amtCx81DB9ERESyUGz4YM8HERGRPJodPjZt2oSJEyciIiICkiRhxYoV5x1z9OhRTJo0CUajEd7e3hg4cCCysrJcUe9V89Sx54OIiEhOzQ4fVVVVSEhIwKJFi5rcn5GRgeuuuw5xcXHYuHEjDhw4gHnz5sHDw+Oqi3UFj4bTLhaGDyIiIjlomvuAxMREJCYmXnD/X//6V/zhD3/AwoULnds6d+58ZdW1gN/HfHC2CxERkRxcOubD4XDgp59+Qrdu3TBu3DiEhIRg8ODBTZ6aaWA2m2EymRrdWpInZ7sQERHJyqXho6CgAJWVlXjttdcwfvx4/Prrr5gyZQpuueUWJCUlNfmYBQsWwGg0Om9RUVGuLOk8HHBKREQkL5f3fADA5MmT8dRTT6Fv37547rnncNNNN2HJkiVNPmbu3LkoLy933rKzs11Z0nk8tHVvmQNOiYiI5NHsMR8XExQUBI1Gg/j4+Ebbe/TogS1btjT5GL1eD71e78oyLooDTomIiOTl0p4PnU6HgQMHIjU1tdH248ePIyYmxpUvdcUaTruYbQ44HELmaoiIiJSn2T0flZWVSE9Pd97PzMxESkoKAgICEB0djTlz5uDOO+/E8OHDMWrUKKxZswarVq3Cxo0bXVn3FWsYcAoAtTY7vHQu7fwhIiKiS2j2L29ycjJGjRrlvD979mwAwLRp07B06VJMmTIFS5YswYIFC/D444+je/fu+O6773Dddde5ruqr4KH5PXzUWBg+iIiI3K3Zv7wjR46EEBc/XfHQQw/hoYceuuKiWpJKJUGvUcFsc3DQKRERkQwUd20XgGt9EBERyUmZ4cM544WrnBIREbmbosNHrY09H0RERO6myPCh51ofREREslFk+PDkKqdERESyUWb44IBTIiIi2SgzfPC0CxERkWwUGT6c13dhzwcREZHbKTJ8eDJ8EBERyUaZ4aNhzAdPuxAREbmdMsMHez6IiIhko8jwwTEfRERE8lF0+Ki1cnl1IiIid1Nk+OAiY0RERPJRZvjggFMiIiLZKDJ8cMwHERGRfBQZPjjbhYiISD7KDB86Lq9OREQkF2WGDy0vLEdERCQXRYYPjvkgIiKSjyLDB0+7EBERyUeR4cO5yJiNi4wRERG5myLDR8OYD4vNAbtDyFwNERGRsig6fAAcdEpERORuigwfes3vb7ua4z6IiIjcSpHhQ6WS4KPXAACqzDaZqyEiIlIWRYYPAM7wUcnwQURE5FbKDR8edeGjopbhg4iIyJ2UGz7Y80FERCQLxYYPX4+G8GGVuRIiIiJlUWz48NbVhw+ediEiInIrxYYP55gPnnYhIiJyK+WGD061JSIikoViw4dzzAdPuxAREbmVYsNHQ88HT7sQERG5l3LDB3s+iIiIZNHs8LFp0yZMnDgRERERkCQJK1asuOCxM2fOhCRJeOutt66ixJbBdT6IiIjk0ezwUVVVhYSEBCxatOiixy1fvhw7duxARETEFRfXkn5f54Phg4iIyJ00zX1AYmIiEhMTL3pMTk4OHnvsMfzyyy+YMGHCFRfXknz0WgA87UJERORuLh/z4XA4cN9992HOnDno2bOnq5/eZTjglIiISB7N7vm4lNdffx0ajQaPP/74ZR1vNpthNpud900mk6tLalLDaReu80FEROReLu352LNnD95++20sXboUkiRd1mMWLFgAo9HovEVFRbmypAvyru/5qLbYYXcIt7wmERERuTh8bN68GQUFBYiOjoZGo4FGo8GpU6fw9NNPo2PHjk0+Zu7cuSgvL3fesrOzXVnSBXnr1c4/c9ApERGR+7j0tMt9992HMWPGNNo2btw43HfffXjwwQebfIxer4der3dlGZdFr1FDp1HBYnOg0myD0VPr9hqIiIiUqNnho7KyEunp6c77mZmZSElJQUBAAKKjoxEYGNjoeK1Wi7CwMHTv3v3qq3UxX70GxTYLZ7wQERG5UbPDR3JyMkaNGuW8P3v2bADAtGnTsHTpUpcV5g4+HhoUV1lQabbKXQoREZFiNDt8jBw5EkJc/gDNkydPNvcl3MY53ZY9H0RERG6j2Gu7AFxinYiISA6KDh++vLgcERGR2yk6fLDng4iIyP2UHT54cTkiIiK3U3b44MXliIiI3E7R4cPgWdfzUVrNqbZERETuoujwEW70AACcKa+RuRIiIiLlUHj48AQAnCmvlbkSIiIi5VB0+OjgVxc+cstqmrVwGhEREV05RYePUIMHJAkw2xwoqbLIXQ4REZEiKDp86DQqBPvUXVGXp16IiIjcQ9HhAwDC60+95JRx0CkREZE7KD58dPCrn/HC8EFEROQWig8fDTNecnnahYiIyC0YPurX+shlzwcREZFbKD58nD3dloiIiFqe4sNHw4BTznYhIiJyD8WHj4j6Aaf5plrY7A6ZqyEiImr/FB8+grz10KolOASQX2GWuxwiIqJ2T/HhQ6WSfp/xwnEfRERELU7x4QPgjBciIiJ3YvjA2TNeOOiUiIiopTF8AAhvWOW0nD0fRERELY3hA2etcsqeDyIiohbH8AEuNEZERORODB/gaRciIiJ3YvgAEFHf81FabUWNxS5zNURERO0bwwcAg4cWPnoNACCXvR9EREQtiuGjXsMy6xz3QURE1LIYPuo1zHg5wxkvRERELYrho15Dz0cOez6IiIhaFMNHvYj6ng+GDyIiopbF8FGvU7APACC9oFLmSoiIiNo3ho963UJ/Dx9CCJmrISIiar8YPup1DPKGVi2h0mxDbjkHnRIREbUUho96WrUKsUHeAIDj+RUyV0NERNR+MXycpWuoLwAgjeGDiIioxTQ7fGzatAkTJ05EREQEJEnCihUrnPusViueffZZ9O7dG97e3oiIiMD999+P3NxcV9bcYrqF1IWP4/kcdEpERNRSmh0+qqqqkJCQgEWLFp23r7q6Gnv37sW8efOwd+9efP/990hNTcWkSZNcUmxL61o/6JQ9H0RERC1H09wHJCYmIjExscl9RqMRa9eubbTtvffew6BBg5CVlYXo6Ogrq9JNGma8pBVUwuEQUKkkmSsiIiJqf5odPpqrvLwckiTBz8+vyf1msxlms9l532QytXRJFxQT6A2dWoVqix3ZpdWICfSWrRYiIqL2qkUHnNbW1uLZZ5/F3XffDYPB0OQxCxYsgNFodN6ioqJasqSL0qpV6NWhrs7dJ0tlq4OIiKg9a7HwYbVacccdd0AIgcWLF1/wuLlz56K8vNx5y87ObqmSLsug2EAAwK7MYlnrICIiaq9aJHw0BI9Tp05h7dq1F+z1AAC9Xg+DwdDoJqfBsQEA2PNBRETUUlwePhqCR1paGn777TcEBga6+iVa1DUx/pAkILOoCgUmrnRKRETkas0OH5WVlUhJSUFKSgoAIDMzEykpKcjKyoLVasVtt92G5ORkfPHFF7Db7cjLy0NeXh4sFoura28RRk8teoTV9b7sOlkiczVERETtT7PDR3JyMvr164d+/foBAGbPno1+/fph/vz5yMnJwcqVK3H69Gn07dsX4eHhztu2bdtcXnxLGVR/6uW3I/kyV0JERNT+NHuq7ciRIy961df2cEXYiQnhWLrtJFak5OKWayIxvFuw3CURERG1G7y2SxP6xwRg2tAYAMCz3x1AjcUuc0VERETtB8PHBTybGIdwowfOlNdiU1qh3OUQERG1GwwfF+Cl02BczzAAwIZjBTJXQ0RE1H4wfFzEqLgQAMCG1IJ2MZaFiIioNWD4uIjBsQHw1KqRbzLjcK5815whIiJqTxg+LsJDq8a1XYIA8NQLERGRqzB8XMIN9adeNqcVyVwJERFR+8DwcQnDOtctD5+SXcYpt0RERC7A8HEJMYFeCDN4wGJ3YF8WLzZHRER0tRg+LkGSJAzpVLfc+o4TxTJXQ0RE1PYxfFyGIZ3qTr3sOMELzREREV0tho/L0BA+9maV4p4Pd2BjKme+EBERXalmX1hOiWICvRAT6IVTxdXYllGMSrMNI7uHyF0WERFRm8Sej8sgSRI+e2gwXrm5FwDgUE45KmqtMldFRETUNjF8XKboQC/cOyQGMYFecAgg+SRnvhAREV0Jho9mGhLbMPiUM1+IiIiuBMNHMw1umHabyZkvREREV4Lho5kG18984bgPIiKiK8Pw0Uwd/DwRE+gFu0NgQ2qh3OUQERG1OQwfV2BSQgQA4Ls9p2WuhIiIqO1h+LgCt14TCQDYnFaIvPJamashIiJqWxg+rkDHIG8M7OgPhwD+/vNRHD1jkrskIiKiNoPh4wrdPiAKALByfy4mvrsFe05x3Q8iIqLLwfBxhW69JhILbumNvlF+sDkE3lmXJndJREREbQLDxxVSqyTcPSgab9/VFyoJSDpeiIOny+Uui4iIqNVj+LhKMYHeztkvS5IyZK6GiIio9WP4cIEZwzsDAH49kofiSrPM1RAREbVuDB8uEB9hQJ9II6x2gRUpuXKXQ0RE1KoxfLjI7f3r1v74JjkbQgiZqyEiImq9GD5cZFJCB+g0KhzLq8Duk5x2S0REdCEMHy5i9NI6Vz59ceVh2B3s/SAiImoKw4cL/WVsNxg8NDhyxoQvdp6SuxwiIqJWieHDhQJ99JgzrjsAYMnGDDjY+0FERHQehg8Xu31AFHw9NMgtr8WOzGK5yyEiImp1GD5czEOrxk19wgEAy/fmyFwNERFR68Pw0QKm9KsbeLr6UB5qLHaZqyEiImpdmh0+Nm3ahIkTJyIiIgKSJGHFihWN9gshMH/+fISHh8PT0xNjxoxBWpqyLro2IMYfUQGeqDTb8OuRPLnLISIialWaHT6qqqqQkJCARYsWNbl/4cKFeOedd7BkyRLs3LkT3t7eGDduHGpra6+62LZCpZIwpW8HAMDyfTz1QkREdDZNcx+QmJiIxMTEJvcJIfDWW2/hb3/7GyZPngwA+PTTTxEaGooVK1bgrrvuurpq25Ap10TinfXp2JxWhIKKWoT4eshdEhERUavg0jEfmZmZyMvLw5gxY5zbjEYjBg8ejO3btzf5GLPZDJPJ1OjWHsQGeaNftB/sDoE31qTi54NnuOw6ERERXBw+8vLqxjeEhoY22h4aGurcd64FCxbAaDQ6b1FRUa4sSVa39Ks79fLNntN45Iu9+GhLpswVERERyU/22S5z585FeXm585adnS13SS5zW/8o3N4/EoNiAwAA//g1FSeLqmSuioiISF4uDR9hYWEAgPz8/Ebb8/PznfvOpdfrYTAYGt3aC0+dGm/cnoCvZgzBtV0CUWt1YPbXKbDYHHKXRkREJBuXho/Y2FiEhYVh3bp1zm0mkwk7d+7E0KFDXflSbYokSXjtlj7w9dBgb1YZXv7xsNwlERERyabZ4aOyshIpKSlISUkBUDfINCUlBVlZWZAkCU8++SReeeUVrFy5EgcPHsT999+PiIgI3HzzzS4uvW2JCvDC23f1hSQBn+/Iwm9H8i/9ICIionao2eEjOTkZ/fr1Q79+/QAAs2fPRr9+/TB//nwAwDPPPIPHHnsMM2bMwMCBA1FZWYk1a9bAw4NTTW+IC8X06zsBAN5ad5yzX4iISJEk0cp+AU0mE4xGI8rLy9vV+I8GJVUWXPf6elRb7Pj4gYEYFRcid0lERERXrTm/37LPdlGaAG8d7h0SAwB4c+1xOBytKvsRERG1OIYPGUy/vhN89BoczCnHf7dm4oNNGdiaXiR3WURERG7B8CGDYF89nrqxGwDglZ+O4u8/H8P0T5NRXmOVuTIiIqKWx/Ahk2lDYxAX5uu8X22x46vdWTJWRERE5B4MHzLRqFX47OHBeOvOvnhxYjwA4JNtp2CzcwEyIiJq3xg+ZBTsq8fN/TrgrkHRCPDWIaesBvNXHkat1S53aURERC2G4aMV8NCq8Zex3QEA/9uZhemfJnMNECIiarcYPlqJewZH4+MHBkKnUWFzWhF2ZpbIXRIREVGLYPhoRUbFheC2/pEAgA82nZC5GiIiopbB8NHKTL++EyQJWH+sAMfyTHKXQ0RE5HIMH61MbJA3xvcMAwA8/fV+1FrtsHMVVCIiakc0chdA53thYk/szCzB4VwTBrzyGyw2B+4ZHI2/jOsOHz3/lxERUdvGno9WKMzogbfu7AtJAirNNljsDizddhK3Ld4Gi43rgBARUdvGf0a3UsO7BWPVo9eh2mJHtcWG2V/vx7G8Cny1Owv3De0od3lERERXjD0frVivDkYMig3AyO4heHJMVwDA2+vSUW2xyVwZERHRlWP4aCPuGhiN6AAvFFWa8f6GDLnLISIiumIMH22ETqPC83+IAwAsScrgNFwiImqzGD7akHE9wzA2PhQ2h8Ccbw6gxsJrwBARUdvD8NGGSJKE/7u5FwweGhzMKcej/9sLK6+CS0REbQzDRxsTavDAf6YNhF6jwrpjBXh99TG5SyIiImoWho82aFBsAN6+qy8A4D9bMrHpeKG8BRERETUDw0cbNb5XOO4bEgMAeHzZPmxNL5K5IiIiosvD8NGG/XVCDyRE+aGs2or7PtqJ5747gKziarnLIiIiuiiGjzbMQ6vGVzOG4Pb+kXAIYNnubEx4ZzOO51fIXRoREdEFMXy0cR5aNd64PQHfzhyKPpFGVJht+OMnycg31cpdGhERUZMYPtqJAR0DsPTBQYj090RWSTWuX7gBr60+BiGE3KURERE1wvDRjgR467D0wUHoG+UHi82BJUkZ+Gp3ttxlERERNSKJVvZPY5PJBKPRiPLychgMBrnLaZOEEFiclIGFa1LhrVOjf8cABPvo8dqtvaFVM28SEZHrNef3m79E7ZAkSfjT8M4Y2NEfVRY7Nh0vxHd7T2Pp1pNyl0ZERMTw0V6pVRLeu+caPHxdLO4eFA0A+Ndvx5FTViNzZUREpHQauQuglhNq8MC8m+LhcAik5Vcg+VQp7vtoJxJ7hWHl/lxMv74T7h/aUe4yiYhIYdjzoQAqlYSFt/VBuNEDJwqrsGhDBrJLajD/h8P4ISVH7vKIiEhhGD4UolOwD3549Fpc2yUQXUN88IfeYQCAp75KwYsrD6PSbJO5QiIiUgrOdlEoh0Pg+eUHsax+Km6XEB/85/4B6BjkLXNlRETUFnG2C12SSiXhtVv74LOHByHM4IH0gkrc/P5WpGSXyV0aERG1cwwfCnd912CsfPRaJEQaUVZtxdQPd+Dr3dmosdjlLo2IiNophg9CiMED/5s+BMM6B6LKYscz3x3AiDc2ILuEV8glIiLXc3n4sNvtmDdvHmJjY+Hp6YnOnTvj//7v/3iNkVbOW6/Bfx8YiGfHxyHC6IGCCjNmf52Cr3dn44NNGbA7+P+PiIhcw+XrfLz++utYvHgxPvnkE/Ts2RPJycl48MEHYTQa8fjjj7v65ciFPLRq/HlkZ9zUJxzj39qE3SdLsftkKQAg2FePKf0iZa6QiIjaA5f3fGzbtg2TJ0/GhAkT0LFjR9x2220YO3Ysdu3a5eqXohYSFeCFlyb3AgDo6q8F8+GmTPZeERGRS7g8fAwbNgzr1q3D8ePHAQD79+/Hli1bkJiY2OTxZrMZJpOp0Y3kd1v/SGx+ZhQ2PTMKnlo1jpwxYXtGsdxlERFRO+Dy0y7PPfccTCYT4uLioFarYbfb8eqrr2Lq1KlNHr9gwQK89NJLri6DXCAqwAtAXRD5bMcpTPt4F4Z0CsTAjgEY3SMEPSOMMldIRERtkcsXGVu2bBnmzJmDN954Az179kRKSgqefPJJvPnmm5g2bdp5x5vNZpjNZud9k8mEqKgoLjLWiuSbavHHT5JxMKe80fYuIT7oGuKDuwdFY3i3YJmqIyKi1qA5i4y5PHxERUXhueeew6xZs5zbXnnlFXz++ec4duzYJR/PFU5br/SCCmxNL8a2jCKsP1YAq73uo6NWSXjzjgRM7ttB5gqJiEguzfn9dvlpl+rqaqhUjYeSqNVqOBwOV78UuVmXEF90CfHFtGEdUVplwd6sUvyQkouV+3Px1FcpCPH1wNDOgXKXSURErZzLw8fEiRPx6quvIjo6Gj179sS+ffvw5ptv4qGHHnL1S5GM/L11GN0jFKO6h0AlAStScjH3+wNY8+RweGjVcpdHREStmMtPu1RUVGDevHlYvnw5CgoKEBERgbvvvhvz58+HTqe75ON52qXtMdVaMfbNTcgz1eLBazvihYk95S6JiIjcTNYxH1eL4aNtWnskH9M/TQYAzL6xGx4f3RUOh0BJtQVBPnqZqyMiopYm65gPUqYb40MxNzEOC1Yfw5trj+N0aTUO5phwPL8C70+9BjUWO5btzsIbtyU4p/ASEZEyseeDXOrDTSfw99VHcfanKtBbB1OtFVa7wITe4Vg09Rr5CiQiohbBng+SzfThndAlxAfPfHcAcWG+OF1ag8yiKuf+nw6eQe+kDOSW1WDWqC4INXjIWC0REcmBPR/UIoQQkCQJ29KLMPWjnYgweqJbqA82pBY6j+kRbsDXfxoCXw+tjJUSEZErcMAptSqpeRUI9NGhrNqKSe9tgVqSoFFLKK22oncHI+aM684VUomI2jiGD2q1CivM8NSpcaKwEnd/sANVFjsAYN5N8Xj4uliZqyMioivF8EFtwpnyGry7Ph3/25kFjUrC3YOikZpfgb9N6IE+kX5yl0dERM3A8EFthhACs/63Fz8fzHNuC/HV444BUdiQWoB5N8VjSCcu2U5E1NoxfFCbYqq1YuZneyBJQF55LTIKf58dE+Sjx+onrkeQjw6SJMlYJRERXQzDB7VZJ4uqcNuS7QAAH70aJ4ur4aGtu1DhfUNicOfAKGSX1uC6LkHQqlUXeyoiInIjhg9q02osdmjVEjKLqjB50VZU1w9KPdsDwzrixUm8hgwRUWvRnN9v/tORWh1PnRoatQpdQ33x2+wR+PGx67Dk3v4INeihVdedevl8xymcPGvxsqTjhbjrg+1IOl54oaclIqJWgj0f1GYIIWC1C8z4LBkbUwtxU59wvHfPNVi1PxdPfZUCm0PA4KHBmieHI8LPU+5yiYgUhT0f1C5JkgSdRoVnxsVBkoAfD5zBP35JdQYPL50aplob/vLNfjgcrSpTExHRWRg+qM2JjzDgj/ULkr23IR02h8CEPuFY9dh18NSqsS2jGF8lZ8tcJRERXQjDB7VJc8bFISHKDwDQJcQHC2/tg87BPnh6bDcAwN9/PortGcUor7HKWCURETWFYz6ozSqsMOPbPadxc78IhBvrxnjYHQJT3t+KA6fLAQBeOjVeubkXxvUMg4dWDbWKa4UQEbUETrUlRTtZVIUXVx3G0TMm5JvMzu1hBg+8d08/DOgYIGN1RETtE8MHEep6Qd5dn4b3N2TAYncAAHQaFe4ZFI0R3YIxsnswV00lInIRhg+is5htdtRY7Jjz7QGsPZLv3D4gxh/zbopHQpQfSqss8PXQQMNVU4mIrgjDB1ET7A6BtUfysCW9CN/tyUGNtW7l1JhAL5wqrkaYwQMPXNsR06/vxLEhRETNxPBBdAl55bVY+MsxfL8357x9T4zuiqdu7CZDVUREbRfDB9FlOnrGhFPFVbgmxh8/7MvFqz8fhSQB9wyKRpCPHj3CDejVwYBgXz1ySmsQ4ecJD61a7rKJiFqd5vx+a9xUE1Gr1CPcgB7hdV+S6cM74WRxFb7YmYUvdmY1efyAGH8smzGEY0OIiK4CwwfRWV6Y2BM9I4zILq1GUYUZh3NNSCuogNVe10GYfKoUr/58FEZPLTQqCf1jAjC0c6DMVRMRtS087UJ0CWabHaYaG7akF+Kpr/aft/+lST0xbVhH9xdGRNSK8MJyRC6k16gR7KvHzX074Lb+kdCoJNwYH4ob40MB1C3lfjy/AkIIbM8oRlZxtcwVExG1buz5IGoGIQQcAlCrJAgh8MDHu5F0vBC+eg06+HviWF4FPLQq/HlEF5wurUZ8hAEPDOvIxcyIqN3jbBciNymoqMV9/9mF1PwKAIBKAhznfKMeujYW827qwQBCRO0aZ7sQuUmIrwdWP3E9NqUV4mRRFRJ7h2P5vhz8dOAMOgV744eUXPx3ayYqzVYsuKUPFy8jIgJ7Poha1Ld7TuOZb/fDIYAxPULx2q29EeSjR3mNFal5FfDRa9Ap2JtrhxBRm8eeD6JW4rb+kfDRq/HYl/vw29F8jHqjGMG+epwqqYa9/vxMqEGP96f2R/8Yf5mrJSJyD852IWph43uFY/kj1yIuzBcVZhtOFFXB7hCIMHrA10ODfJMZd32wHQt+Poqcshqc2xlZUmVBpdkmU/VE8qgy27Bg9VEcOF0mdynUAnjahchNrHYHDuWUw2xzoIOfJ6ICvFBptuEvX+/HmsN5zuO8dGp4atXQqCXYHQJFlRaE+Orx61PDYfDQwuYQ0Gn47wZq335IycETy1JwQ1wI/vvAQLnLocvA0y5ErZBWrUK/6ManVnz0Giy+9xqsP1aARRvSkZJdhmqLHdUWe6PjCirMeH1NKvaeKkWN1Y5vZw5FiMHDneUTuVV5jbXRf6l9YfggkpkkSRjdIxSje4TCbLMjp7QGFrsDtvol3TMKK/HEshR8uev3683M/f4g/jNtwCWn7645lIe0/Ao8MqoLZ9pQm1Jlttf/l6cc26MW6bvNycnBvffei8DAQHh6eqJ3795ITk5uiZcialf0GjU6BfsgLsyAXh2M6NXBiEkJEegb5QcA8NapoVOrsO5YAWZ8tgdLt2ZiQ2oBzDb7ec+VWVSFx77ci3+uPY4fD+S6+Z0QXZ1qS13oqLGe/9mmts/lPR+lpaW49tprMWrUKKxevRrBwcFIS0uDvz9H8hNdCUmS8MrNvfDKT0cwa1QXpOZV4JWfjmLtkXysPZIPAOjVwYAP7x+AcKOn83EvrzrsvCDeh5tPYFJCBBc6ozaj4dRjQw8ItS8uDx+vv/46oqKi8PHHHzu3xcbGuvpliBSlVwcjls0YCgC4vmswBnQMwIZjBTiWZ8LOzBIcyjFh/Fubcc/gaET6e2LT8UJsSC2EVi1BJUk4lGPC9hPFGNY5CEIIhhBq9Rp6Phr+S+2Ly8PHypUrMW7cONx+++1ISkpChw4d8Mgjj2D69OlNHm82m2E2m533TSaTq0sianf6Rvk5T8Vkl1Rjxmd7cPSMCYs3ZjQ6bvaN3ZFbVoPPdpzCvBWHMHVwDN7fmIF7h0TjyTHdZKic6PI09HjUWO1wOARUHLPUrrg8fJw4cQKLFy/G7Nmz8fzzz2P37t14/PHHodPpMG3atPOOX7BgAV566SVXl0GkGFEBXlj16LX47Wg+Vu0/A4u9birvPYOj0S3UF3nltVh7JB8ZhVV4+ccjAIB316djUkIEOgX7yFw9UdMaTrsIAdTa7PDScX5Ee+LydT50Oh0GDBiAbdu2Obc9/vjj2L17N7Zv337e8U31fERFRXGdDyIXyiquxt0f7kBueQ0i/T2RXVKDG+JCMKF3OBKi/NAlxAe1VjvWHMpDTlkNHr4uFh5aNWx2BzRqrilC7nfPhzuwLaMYALD7r2MQ7KuXuSK6FFnX+QgPD0d8fHyjbT169MB3333X5PF6vR56PT9URC0pOtALa2cPR0mVBRW1Nvzhnc1Yf6wA648VQJLqTuOkF1Siorbu/HpqXgVqrHZsSSvC83+Iw71DYjhOhNyq6qy1bmosHHTa3rg8fFx77bVITU1ttO348eOIiYlx9UsRUTN46TTOrutHRnbGyv25CPDWY392GfZllQEAwgweKKw0Y+X+36fmzvvhMA6cLsfssd2w4Odj6BjohVk3dIFew4vhUcupPmt9jyoOOm13XB4+nnrqKQwbNgx///vfcccdd2DXrl344IMP8MEHH7j6pYjoCs0ZF4c54+IAAEdyTThyxoTuob7oEe6Lz3acwkurjsDPS4s7BkThoy2Z+GbPafyQkguL3QEA+PlQHkbHhSCxd7hz4OvZNqcV4oNNJ/DXCT0QF8bTp9R8Z6/ye+6Kv9T2tci1XX788UfMnTsXaWlpiI2NxezZsy842+VcvLYLkbyEENhzqhTRgV4I8fXA2iP5mPW/vbDYHIgJ9EJlrQ3FVRYAgEoC/jyyM2ICvREfXrcwWoGpFmPf2oSyaitiAr2w6rHrYPDQyvyuqK3p9/KvKK2uW1r9s4cH4fquwTJXRJfSnN9vXliOiC5pb1YpklIL8cCwjnAIgTWH87D5eFGjC+IBwA1xISisMONgTrlz243xoVh0zzVXdDG8ilorPth0AncMiEJUgNdVvw9qO7r9bTUstrqetiX39sf4XmEyV0SX0pzfbw5jJ6JLuibaH0/d2A3+3joE+ugxdXAMltzXH/+6MwHXdw3CkE4BkCRg/bECHMwph06jwsJb+0CjkrD2SD4e+HgXThZVYXtGMd5Zl4aDp8ubfJ0ai73RUvH/TjqBd9en45WfjrjrrVIrYLM7nMEDAGqsHPPR3nDiNBFdsSn9IjGlXySAuhkya4/kweYQGNIpEEM6BSLYoMesL/ZiW0YxRv5jo/Nxb649jokJEXj91t7OQbDVFhtuencLSqos+GjaQPSP8UfS8UIAwJa0ItTWz74Z1CmAp3HauepzrufCJdbbH4YPInKJ7mG+6B7m22jbqO4h+HbmMLy25hg2pxVCp1ZhQEd/bMsoxqr9ucgsqsTg2EDEhxuQX1GLE4VVAID7P9qJt+/qh0O5dT0kVRY7/vhJMrakF2Fy3wi8fVc/t78/cp/qc8IGl1hvfxg+iKhFxUcY8OlDg1BaZYFGLcHXQ4s9p0rwx0+ScSjHhEM5dZdUaFg9OyqgbhG0R77Yi7NHpG1JLwIA/HzwDF6Y2BMB3jp3vxVyk3PDBme7tD8c80FEbuHvrYNv/emS/jEB+GHWdZg5ojPuGRwNtUqCQwBdQ3yw6tHrEOCtc07rjQ3ybvQ8VrvA8n05AICk44X4enc2HI7fU4rN7sC5HA6BpOOFKKo0n7fvagkhUMvLvrvUuWGD4aP9YfggIllEB3rhucQ4/H1Kb3w0bQBGdQ/GG7cnwM9Lh9k3/n7RuznjukNT3y1yfdcgAMDSbZn402fJmPbfXXjmuwN45rsDsDsEfjyQiz4v/Yr7PtqJ7JJqAEBZtQUPf7Ib0/67C7e8vw0VtVaXvo9Ptp1E3Lw12Jha4NLnVbIq87k9Hzzt0t7wtAsRyW5k9xCM7B7ivH/3oGj8djQf5TVW3BAXgtdu7YPcshrcPzQGg/++DtklNcguqYFaJUEIgW/3nMaeU6XIKqmG3SGwOa0Io99MwrDOgdhzqtS5bHxWSTXm/3AY/7qzr0vqFkLgk+2nAAA/HjjT6D3QlTuv54MDTtsdhg8ianXUKglLHxzkvH9b/0jnn9+75xpsTC2At16DiX0icLq0GrO/3o/MorrBqhMTIlBgqsXOzBJsTK2bLdMlxAcPXRuLeT8cwvJ9ORjeLQhj48OQVVKNuDBfSJKE3LIapGSXITrAC706GC+rzvSCSufr7s8uc9G7p3PDB5dXb38YPoioTbkxPhQ3xoc67/eONOK6rkH47Wg+qi123DUwGioJOJxrwqa0QnQL8cUNcSFQqSQUVZrx5trj+NvyQ1i4JhVnymvRMdALNofA6dIa53MOiPHHi5N6OkOI3SGgkgBJklBptkGrlqDXqPHrkXznY9ILK1FRa4WvhxZWuwOl1RZ46TTw0fOv2eY6N2xwzEf7w28FEbV5vh5a53ojDXp1MJ7XgzFrVBdsSS/CrswS51VTTxbXjQ1RqyR0DfFBRmElkk+VYsr7WzE6LhS1Nju2ZRRjcGwAFt7WB+Pf2owAbx3+N30wfjlrhVchgAOny9Ev2g9j/7XJGWZendILUwfzwprN0XBROa1agtUuGD7aIYYPIlIMtUrC23f1xZxvDqB7mC9mjuiMXZkl8PHQoH+MP3z0GhSYajH/h8NYcziv0fLxm9OKMPPzvSivsaK8xorR/0xCtcUOSQIGxwZgx4kSpGSXIbOoqlEvysurjqB3ByN89Bp0DPSGqmFOMV1QwyJjQT56nCmvPW8AKrV9DB9EpCjhRk98/sfBzvsT+oQ32h9i8MDie6/B1vRiZBRWwu4QOJxrwnd7TzvHdRg9tSivsUKnVmH22G7QqCTsOFGCfVllOFVcNwZk3k3xSDpeiE3HCzHpva0AgE7B3nhidFdM7tvBPW+2jWoYYNoQPmo4lbndYfggIjqHJEm4rmsQrquf2ltgqsWqA7mw2BzoGWHAR9MGYu3RfIyND0WowQO7T5YAADakFsDuEPDWqXH7gEjc1CccE97ZgqJKM9QqCScKq/DEshQcyinHs+Pj8NvRAny24yTCDJ4Y1jkQQzoHItRXj4zCKuw4UYyxPUMRbvQEAOSV16KwwozekZc3GLYtaxjzEeRTt5Acl1dvfxg+iIguIcTggT8N74T3N2ZgzrjuCDN64L4hv4/j6N3BiJhAL5yqHz9yW/9IGDy0MHhoseEvI1BjscNLr8GSjRl4b0M6PtyciS93ZaPyrNMJ3+09fd7rfrQlE8tmDMEvh/OwcE0qaqx2jOkRink39UBMoPd5x7cXDT0fwb76uvuc7dLuSEKcvYCx/JpzSV4iInepW8nUAU+dusn9FpsDOzOLcTy/EncNjIL3BWa5/JCSgxdXHkZptRWSBDw4LBZ6rQrbM4px4HQZHALQqVXw0qtRVt30gmg6tQoPXtsRk/pGwGoXqKy1ITbYGz56DSQJkFDXe6NTq6BVS1i5PxeHcsrx6KiuMHppcbq0Gq+vSUXfKD88fF2sq5rIZR77ch9W7c/FrFGdsWhDBiQJyHj1Dxwv08o15/ebPR9ERJdBkqQLBg8A0GlUuL5rMK7vGnzR55nctwNu6hOBI7kmGDw1jXowLDYHqi026DVqnCmvwS2Lt6Gs2oowgwdm3dAFg2MD8PKqI9iSXoR/bzqBf286cdHXUqskBPvokWeqBQAknyrF7f2jsPCXYyirtmLV/lwYPDS4fUCU8zGlVRZ4aNUXfK8Ni7r5emgxvleYc3uV2Yb0gkrsOFGM1LwKPDKqC7qE+Fy0vgtpmO0S5KOvf01gcVIGbowPRbdQ34s9lNoI9nwQEbVSZ8prkFtWi75RflDX/6tfCIHfjhZg2a4sbEkvgq+HFgZPDbKKq2FzNP3XuadWDY1acq70CtT9sDeMReng54mBHQPQOcQbb/2WBi+dGjOGd8LAjgE4nl+BjIIqTEwIR59IP7yw8hA+35EFAPjvAwNwQ1woPtiUgTd+SYXV/vvrD+0UiC9nDLmi933XB9ux40QJ3r6rL55YluLcHhXgiXWzR0Kn4ZVBWiP2fBARtQPhRk/ngNMGkiQ5F1oTQkCS6kKJ3SFgczicVwIWAiittiC9oBJxYb7ILa/Fw0t3w+ilxR0DovDAsI545tsDWLk/F1kl1ciqvxYOUNcDs3BNaqPX/e/WTOg0Klhsv1+47+mv92NEt2CsSMkFUBdoenUwYEtaEbafqDuN1CfSz3m8ze7AumMFqKy1YWzPUFSZ7XW9M/VjOxrU1K/r4euhgUYlOUNVdkkNvk7Oxr1Dzl83pbTKgr/9cAi9IoyYOaITCivN8NVrL9pb5QolVRZeYfkKsOeDiEghzg4rDfdPFVfjdGkNPt6aieRTpXhyTFf46DVYkZKDk0XVCPLVI9LfE6sPnoFD1AWCeTfF49PtJ3Eox+R8rjnjumPWqC4AgKe+SsHyfTkY1jkQN8aHYvWhPOSW1cBsc6Cwou7Kwg2hQiUBkxIiUF5jRZXZjlFxIfjv1kwUVpjx5fQhuPvDHY3eQ6hBj7WzR8BQf4XksmoLfPQaPPPdAXy/t+5qx/HhBhw5Y8KgjgH46k9DGr1nV/p6dzae+e4A5ibG4U8jOrfIa7Qlzfn9ZvggIiIA54eTsxVU1KLabEdUgBfU9UvV/29nFqrMNvSP8cfYnr+P/zh6xoTEtzc3+TwB3jr4eWlxorAKKgm4wJkiAMC6p0dg9D+TAAC3XhOJHSeKkVNWg+6hvnh+Qg9syyjCfzZnItBbh4IKMxpKP/tXbcm9/XEktxxdQn3xh15h+GJnFjy0KkzoE3He0vcVtVacKKyCVq1CdKAXfPQaCCEgBM4b7GqzOzDijY3IKauBj16Dzc+Mgn8L9IAcyilHlL8XjF5alz+3qzF8EBGRrJZuzcSW9CLYHALDOgeif4w/LDaBvlF+8NCqkFlUhRCDB1LzKvD93tOI9PeCl06NzWmFCPbVY0S3YIzvFY7v957GjhPFeHFST5worMJDS3ejoL735FzThsbg+q7BWHcsHxW1Nvx44Eyj0zZxYb44llcBAJAkQCVJCPHVo3OwD/JMtThRWOkMQ946NW7oEYot9fX894GBWHMoD1VmO8b3CsOxPFOj8SgzR3TGc4lxTdZVa7UjLb8SOzOLcSinHKN7hGJiQoRzv83ugEZ9/jiWZbuy8Nz3BzEgxh/fzBx6XjD8Ojkb3+45jbsGRmFy3w7OcUFyYfggIqJ2KbesBn//+ShS8yqgVavw+OiuKKmy4FRJFR6/oatzinNeeS2GL9wAi90BtUqCvT5V6DQqRPp54kT91YjPFeyrh90hUFJlabS94Toz5xoUG4BdmSXQqiX8aXhnGD21qLHaEWrQQ6dRYXNaEX7cfwYWu6PR4yb0CceUvh3w5trjSM2vwIAYf/SL9kfvDkaM6xmK1PwK3PL+Npjrx9j8b/pgDOscBJvdgWqrHSeLqnDL+9ucwWpAjD8+mjZQ1h4Shg8iIlK8N345hk+3ncK/7uyLrJJqrNyfi7mJcRgUG4DCSjMcDuBkcRWyiqsRZvRAt1BfhBk9IITA+mMF2J5RjF4djPjHr6k4XVoD3/prAG1LL4bF7oDBQ4MNfxmJ+SsP46cDZy5ai7+XFr06GBEV4IWvdmc7w1BTOvh5oqCiFla7gIdWhVqrAwmRRoQZPbAtvRgVZhs8tWrUWO3o3cGIk0VVqDDbEBfmi3/cnoCt6UXYkFqALiE+uKlPBDoH++CFlYdwKMcEi82B/h39MbJbMG7qE+HSAbkMH0RERAAcDnHVi5Pllddi1f5c/KFPODr4ecJicyCtoAIB3jqEGz0hhMBPB8/gy11Z8PPUwUevQX5FLWx2gTCjB+4dEoOESKPztMnB0+VYkpSBXw7nYWT3YDwxuhtSskuRml+Bnw/mOXtdhnQKwNzEHrhl8bYmw0qIrx6/PDkceaZa3PfRLhRVNn06ylevQcU5F+fTqiXsmz/2vHEvV4Phg4iIqJWz2h3QnjPWo6LWivXHChAV4IVrov0BAAtWH8V3e3IwKSECU/p1QKhRjz0nS509KQBwurQaC1Yfw08HzsDPS4s/j+iME4VV+HbvadgdAp2CvPHy5F7QqCVsTS9CeY0VL0/u5dL3w/BBRESkQNkl1TB4amH0rBv7kZpXga3pRbj1msgWHw/CRcaIiIgUqKEnpEH3MF90D2t9S9JzjVoiIiJyK4YPIiIiciuGDyIiInIrhg8iIiJyK4YPIiIiciuGDyIiInIrhg8iIiJyK4YPIiIiciuGDyIiInKrFg8fr732GiRJwpNPPtnSL0VERERtQIuGj927d+Pf//43+vTp05IvQ0RERG1Ii4WPyspKTJ06FR9++CH8/f1b6mWIiIiojWmx8DFr1ixMmDABY8aMuehxZrMZJpOp0Y2IiIjarxa5qu2yZcuwd+9e7N69+5LHLliwAC+99NJ52xlCiIiI2o6G320hxCWPlcTlHNUM2dnZGDBgANauXesc6zFy5Ej07dsXb7311nnHm81mmM1m5/2cnBzEx8e7siQiIiJyk+zsbERGRl70GJeHjxUrVmDKlClQq9XObXa7HZIkQaVSwWw2N9p3LofDgdzcXPj6+kKSJFeWBpPJhKioKGRnZ8NgMLj0udsjttflY1s1D9uredhel49t1TyubC8hBCoqKhAREQGV6uKjOlx+2mX06NE4ePBgo20PPvgg4uLi8Oyzz140eACASqW6ZGK6WgaDgR/KZmB7XT62VfOwvZqH7XX52FbN46r2MhqNl3Wcy8OHr68vevXq1Wibt7c3AgMDz9tOREREysMVTomIiMitWmS2y7k2btzojpe5JL1ejxdeeAF6vV7uUtoEttflY1s1D9uredhel49t1TxytZfLB5wSERERXQxPuxAREZFbMXwQERGRWzF8EBERkVsxfBAREZFbKSp8LFq0CB07doSHhwcGDx6MXbt2yV2S7F588UVIktToFhcX59xfW1uLWbNmITAwED4+Prj11luRn58vY8XutWnTJkycOBERERGQJAkrVqxotF8Igfnz5yM8PByenp4YM2YM0tLSGh1TUlKCqVOnwmAwwM/PDw8//DAqKyvd+C7c41Jt9cADD5z3WRs/fnyjY5TSVkDdda0GDhwIX19fhISE4Oabb0ZqamqjYy7n+5eVlYUJEybAy8sLISEhmDNnDmw2mzvfSou7nLYaOXLkeZ+vmTNnNjpGCW0FAIsXL0afPn2cC4cNHToUq1evdu5vDZ8rxYSPr776CrNnz8YLL7yAvXv3IiEhAePGjUNBQYHcpcmuZ8+eOHPmjPO2ZcsW576nnnoKq1atwjfffIOkpCTk5ubilltukbFa96qqqkJCQgIWLVrU5P6FCxfinXfewZIlS7Bz5054e3tj3LhxqK2tdR4zdepUHD58GGvXrsWPP/6ITZs2YcaMGe56C25zqbYCgPHjxzf6rH355ZeN9iulrQAgKSkJs2bNwo4dO7B27VpYrVaMHTsWVVVVzmMu9f2z2+2YMGECLBYLtm3bhk8++QRLly7F/Pnz5XhLLeZy2goApk+f3ujztXDhQuc+pbQVAERGRuK1117Dnj17kJycjBtuuAGTJ0/G4cOHAbSSz5VQiEGDBolZs2Y579vtdhERESEWLFggY1Xye+GFF0RCQkKT+8rKyoRWqxXffPONc9vRo0cFALF9+3Y3Vdh6ABDLly933nc4HCIsLEy88cYbzm1lZWVCr9eLL7/8UgghxJEjRwQAsXv3bucxq1evFpIkiZycHLfV7m7ntpUQQkybNk1Mnjz5go9Rals1KCgoEABEUlKSEOLyvn8///yzUKlUIi8vz3nM4sWLhcFgEGaz2b1vwI3ObSshhBgxYoR44oknLvgYpbZVA39/f/Gf//yn1XyuFNHzYbFYsGfPHowZM8a5TaVSYcyYMdi+fbuMlbUOaWlpiIiIQKdOnTB16lRkZWUBAPbs2QOr1dqo3eLi4hAdHc12A5CZmYm8vLxG7WM0GjF48GBn+2zfvh1+fn4YMGCA85gxY8ZApVJh586dbq9Zbhs3bkRISAi6d++OP//5zyguLnbuU3pblZeXAwACAgIAXN73b/v27ejduzdCQ0Odx4wbNw4mk8n5r9z26Ny2avDFF18gKCgIvXr1wty5c1FdXe3cp9S2stvtWLZsGaqqqjB06NBW87lyywqncisqKoLdbm/UkAAQGhqKY8eOyVRV6zB48GAsXboU3bt3x5kzZ/DSSy/h+uuvx6FDh5CXlwedTgc/P79GjwkNDUVeXp48BbciDW3Q1OeqYV9eXh5CQkIa7ddoNAgICFBcG44fPx633HILYmNjkZGRgeeffx6JiYnYvn071Gq1otvK4XDgySefxLXXXuu8BtblfP/y8vKa/Pw17GuPmmorALjnnnsQExODiIgIHDhwAM8++yxSU1Px/fffA1BeWx08eBBDhw5FbW0tfHx8sHz5csTHxyMlJaVVfK4UET7owhITE51/7tOnDwYPHoyYmBh8/fXX8PT0lLEyam/uuusu55979+6NPn36oHPnzti4cSNGjx4tY2XymzVrFg4dOtRovBU17UJtdfbYoN69eyM8PByjR49GRkYGOnfu7O4yZde9e3ekpKSgvLwc3377LaZNm4akpCS5y3JSxGmXoKAgqNXq80bz5ufnIywsTKaqWic/Pz9069YN6enpCAsLg8ViQVlZWaNj2G51GtrgYp+rsLCw8wY122w2lJSUKL4NO3XqhKCgIKSnpwNQbls9+uij+PHHH7FhwwZERkY6t1/O9y8sLKzJz1/DvvbmQm3VlMGDBwNAo8+XktpKp9OhS5cu6N+/PxYsWICEhAS8/fbbreZzpYjwodPp0L9/f6xbt865zeFwYN26dRg6dKiMlbU+lZWVyMjIQHh4OPr37w+tVtuo3VJTU5GVlcV2AxAbG4uwsLBG7WMymbBz505n+wwdOhRlZWXYs2eP85j169fD4XA4/3JUqtOnT6O4uBjh4eEAlNdWQgg8+uijWL58OdavX4/Y2NhG+y/n+zd06FAcPHiwUWhbu3YtDAYD4uPj3fNG3OBSbdWUlJQUAGj0+VJCW12Iw+GA2WxuPZ8rlwxbbQOWLVsm9Hq9WLp0qThy5IiYMWOG8PPzazSaV4mefvppsXHjRpGZmSm2bt0qxowZI4KCgkRBQYEQQoiZM2eK6OhosX79epGcnCyGDh0qhg4dKnPV7lNRUSH27dsn9u3bJwCIN998U+zbt0+cOnVKCCHEa6+9Jvz8/MQPP/wgDhw4ICZPnixiY2NFTU2N8znGjx8v+vXrJ3bu3Cm2bNkiunbtKu6++2653lKLuVhbVVRUiL/85S9i+/btIjMzU/z222/immuuEV27dhW1tbXO51BKWwkhxJ///GdhNBrFxo0bxZkzZ5y36upq5zGX+v7ZbDbRq1cvMXbsWJGSkiLWrFkjgoODxdy5c+V4Sy3mUm2Vnp4uXn75ZZGcnCwyMzPFDz/8IDp16iSGDx/ufA6ltJUQQjz33HMiKSlJZGZmigMHDojnnntOSJIkfv31VyFE6/hcKSZ8CCHEu+++K6Kjo4VOpxODBg0SO3bskLsk2d15550iPDxc6HQ60aFDB3HnnXeK9PR05/6amhrxyCOPCH9/f+Hl5SWmTJkizpw5I2PF7rVhwwYB4LzbtGnThBB1023nzZsnQkNDhV6vF6NHjxapqamNnqO4uFjcfffdwsfHRxgMBvHggw+KiooKGd5Ny7pYW1VXV4uxY8eK4OBgodVqRUxMjJg+ffp54V8pbSWEaLKtAIiPP/7YeczlfP9OnjwpEhMThaenpwgKChJPP/20sFqtbn43LetSbZWVlSWGDx8uAgIChF6vF126dBFz5swR5eXljZ5HCW0lhBAPPfSQiImJETqdTgQHB4vRo0c7g4cQreNzJQkhhGv6UIiIiIguTRFjPoiIiKj1YPggIiIit2L4ICIiIrdi+CAiIiK3YvggIiIit2L4ICIiIrdi+CAiIiK3YvggIiIit2L4ICIiIrdi+CAiIiK3YvggIiIit2L4ICIiIrf6fy8GzD80VOthAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7591943711e0>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               3584      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44801 (175.00 KB)\n",
      "Trainable params: 44801 (175.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
