{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 01:29:48.997004: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-19 01:29:48.999297: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-19 01:29:49.046759: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-19 01:29:49.048151: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-19 01:29:49.857205: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/206/mlp/b/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 2\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 2\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 2\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"S\\\",\\n    \\\"Features\\\": \\\"Chemical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"S\\\",\\n    \\\"Features\\\": \\\"Chemical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"209\",\n",
    "    \"Plant\": \"S\",\n",
    "    \"Features\": \"Chemical\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/ecics/global_s.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/ecics/global_s.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/209/global_s.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Cement_Type\\\",\\n        \\\"Factory_Plant\\\",\\n        \\\"Blaine\\\",\\n        \\\"#400\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Cement_Type\\\",\\n        \\\"Factory_Plant\\\",\\n        \\\"Blaine\\\",\\n        \\\"#400\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop(\n",
    "    [\n",
    "        \"Cement_Type\",\n",
    "        \"Factory_Plant\",\n",
    "        \"Blaine\",\n",
    "        \"#400\",\n",
    "        \"Final setting time\",\n",
    "        \"Initial setting time\",\n",
    "        \"CS3\",\n",
    "        \"CS7\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 14:20:50.703002: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  9.038261771202087\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.196 (0.000)\n",
      "MAE: 1.618 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.897 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.881 (0.000)\n",
      "MAE: 2.068 (0.000)\n",
      "MAPE: 0.049 (0.000)\n",
      "R2: 0.770 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  9.526654867331187\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.230 (0.000)\n",
      "MAE: 1.634 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.894 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.758 (0.000)\n",
      "MAE: 1.999 (0.000)\n",
      "MAPE: 0.048 (0.000)\n",
      "R2: 0.789 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  12.736843085289001\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.000 (0.000)\n",
      "MAE: 1.473 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.914 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.732 (0.000)\n",
      "MAE: 1.948 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.793 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.95374292532603\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.903 (0.000)\n",
      "MAE: 1.404 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.922 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.719 (0.000)\n",
      "MAE: 1.933 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.795 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.627599263191223\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.961 (0.000)\n",
      "MAE: 1.444 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.918 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.782 (0.000)\n",
      "MAE: 1.971 (0.000)\n",
      "MAPE: 0.047 (0.000)\n",
      "R2: 0.785 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  24.341933306058248\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.995 (0.000)\n",
      "MAE: 1.451 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.915 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.670 (0.000)\n",
      "MAE: 1.898 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.802 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  23.617925842603047\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.907 (0.000)\n",
      "MAE: 1.402 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.922 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.707 (0.000)\n",
      "MAE: 1.936 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.797 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.225973308086395\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.920 (0.000)\n",
      "MAE: 1.417 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.921 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.795 (0.000)\n",
      "MAE: 2.012 (0.000)\n",
      "MAPE: 0.048 (0.000)\n",
      "R2: 0.783 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  21.780122148990632\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.827 (0.000)\n",
      "MAE: 1.377 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.929 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.953 (0.000)\n",
      "MAE: 2.110 (0.000)\n",
      "MAPE: 0.051 (0.000)\n",
      "R2: 0.758 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  22.153793462117513\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.877 (0.000)\n",
      "MAE: 1.378 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.925 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.783 (0.000)\n",
      "MAE: 1.959 (0.000)\n",
      "MAPE: 0.047 (0.000)\n",
      "R2: 0.785 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  23.04273739258448\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.977 (0.000)\n",
      "MAE: 1.437 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.916 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.607 (0.000)\n",
      "MAE: 1.862 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.811 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.088286765416463\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.149 (0.000)\n",
      "MAE: 1.565 (0.000)\n",
      "MAPE: 0.036 (0.000)\n",
      "R2: 0.901 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.764 (0.000)\n",
      "MAE: 1.969 (0.000)\n",
      "MAPE: 0.047 (0.000)\n",
      "R2: 0.788 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.323395029703777\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.392 (0.000)\n",
      "MAE: 1.742 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.877 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.764 (0.000)\n",
      "MAE: 1.951 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.788 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/ecics/209_s/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = (\\n    f\\\"../../../../../../../reports/results/global_models/ecics/209_s/pre_training/full/\\\"\\n)\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = (\n",
    "    f\"../../../../../../../reports/results/global_models/209/s/pre_training/full/\"\n",
    ")\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>209</td>\n",
       "      <td>S</td>\n",
       "      <td>Chemical</td>\n",
       "      <td>(61946, 11)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_11</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>1.976558</td>\n",
       "      <td>1.437021</td>\n",
       "      <td>0.032604</td>\n",
       "      <td>0.916336</td>\n",
       "      <td>2.60744</td>\n",
       "      <td>1.862365</td>\n",
       "      <td>0.044299</td>\n",
       "      <td>0.811351</td>\n",
       "      <td>-6.922071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category Company Plant  Features   Data Shape Timesteps   Model  \\\n",
       "10  Global Model     209     S  Chemical  (61946, 11)      None  MLP_11   \n",
       "\n",
       "   Model Params           Scaler Scaler Params  ...  \\\n",
       "10         None  Standard Scaler          None  ...   \n",
       "\n",
       "                  Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "10  {\"train_size\": 0.8, \"test_size\": 0.2}   1.976558  1.437021   0.032604   \n",
       "\n",
       "    R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "10  0.916336    2.60744  1.862365   0.044299  0.811351 -6.922071  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R²\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 01:30:00.404170: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  30.749831267197926\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.956 (0.000)\n",
      "MAE: 1.423 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.915 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.956 (0.000)\n",
      "MAE: 1.423 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.915 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/ecics/mlp/209_s/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/ecics/mlp/209_s/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/209/mlp/s/pre_training/\"\n",
    "model_name = \"mlp_chemical_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7821500194e0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7821500f1600>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x78213ff5b8b0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA4nUlEQVR4nO3deXyU5b3///fMZGayzmTfIAlhB1kqqBBRazUVrcejhbZq6a9arVaLnrp1ob9TrT1t8djT2tqDelwK9rRIS0+p1dZaCxJEA0KUsilrIIFkskEmySSZTGbu7x8hg1FAAsncgfv1fDzmEXLf9wyfuZyYN9f9ua/bZhiGIQAAgBixm10AAACwFsIHAACIKcIHAACIKcIHAACIKcIHAACIKcIHAACIKcIHAACIKcIHAACIqTizC/iwSCSimpoapaSkyGazmV0OAAA4CYZhqLW1Vfn5+bLbTzy3MeTCR01NjQoKCswuAwAAnILq6moNHz78hMcMufCRkpIiqad4j8djcjUAAOBktLS0qKCgIPp7/ESGXPjoPdXi8XgIHwAAnGFOpmWChlMAABBThA8AABBThA8AABBThA8AABBThA8AABBThA8AABBThA8AABBThA8AABBThA8AABBThA8AABBThA8AABBThA8AABBTQ+7GcoOloTWoRa/vVoLLoW9fOd7scgAAsCzLzHy0dIa05K19Wrq+yuxSAACwNMuED/uRW/xGDMPkSgAAsDYLhY+er2QPAADMZZnwYRMzHwAADAXWCR/MfAAAMCRYJnzY7cx8AAAwFFgnfDDzAQDAkGCZ8EHPBwAAQ4Nlwkd05sPcMgAAsDzLhA8b63wAADAkWCZ8fLDnwyCAAABgGsuEj96ZD4mmUwAAzGSZ8GE/mj3o+wAAwESWCR8fnPmg7wMAAPNYJnx8cOaD8AEAgHksEz7o+QAAYGiwTPjo0/NB+AAAwDQWCh/0fAAAMBRYJnzY6PkAAGBIsE740AdnPkwsBAAAi7NM+PhgzwcLfQAAYB4LhQ96PgAAGAosEz7o+QAAYGiwUPig5wMAgKHAMuFD+sCdbWn6AADANBYLHz3pg7MuAACYx1Lho/fMCz0fAACYp9/h4+DBg/rSl76kjIwMJSQkaPLkydq4cWN0v2EYevDBB5WXl6eEhASVlpZq165dA1r0qert+6DnAwAA8/QrfBw+fFizZs2S0+nUK6+8ou3bt+unP/2p0tLSosc8+uijevzxx/XUU09p/fr1SkpK0uzZs9XZ2TngxfdXtOeDmQ8AAEwT15+D//M//1MFBQVavHhxdFtxcXH0z4Zh6Oc//7n+/d//Xddee60k6de//rVycnL0pz/9STfccMMAlX1q6PkAAMB8/Zr5+POf/6zzzjtPn//855Wdna1zzz1XzzzzTHR/ZWWlfD6fSktLo9u8Xq9mzJih8vLyY75mMBhUS0tLn8dg6b3Ylp4PAADM06/wsXfvXj355JMaM2aMXn31Vd155536t3/7Nz3//POSJJ/PJ0nKycnp87ycnJzovg9buHChvF5v9FFQUHAq7+OkMPMBAID5+hU+IpGIpk2bph//+Mc699xzdfvtt+u2227TU089dcoFLFiwQH6/P/qorq4+5df6OFztAgCA+foVPvLy8jRx4sQ+2yZMmKCqqipJUm5uriSprq6uzzF1dXXRfR/mdrvl8Xj6PAaL3c7VLgAAmK1f4WPWrFnasWNHn207d+5UUVGRpJ7m09zcXK1cuTK6v6WlRevXr1dJSckAlHt6ens+uNoFAADz9Otql3vvvVcXXnihfvzjH+sLX/iC3n77bT399NN6+umnJfWso3HPPffohz/8ocaMGaPi4mJ973vfU35+vq677rrBqL9foj0fJtcBAICV9St8nH/++VqxYoUWLFigH/zgByouLtbPf/5zzZs3L3rMt771LQUCAd1+++1qbm7WRRddpL/97W+Kj48f8OL76+giY8QPAADMYjOG2DmIlpYWeb1e+f3+Ae//uOBH/1B9a1B//beLNTF/8HpLAACwmv78/ubeLgAAIKYsFT56ez4AAIB5LBk+mPkAAMA8lgofR0+7mFsHAABWZtHwQfoAAMAslgof3NsFAADzWTR8kD4AADCLpcIHPR8AAJjPWuHjyFd6PgAAMI+lwgc9HwAAmM+i4YP0AQCAWSwVPuj5AADAfBYLH6xwCgCA2SwVPuxHZj6IHgAAmMdi4YOZDwAAzGap8NHb80HDKQAA5rFY+Dgy8xExuRAAACzMUuGDng8AAMxnsfBBzwcAAGazVPjoXV6dng8AAMxjqfBxdObD5EIAALAwS4WPo1e7mFsHAABWZqnwQc8HAADms1T4OHpvF8IHAABmsVT46J35AAAA5rFU+GDmAwAA81kqfNhZ4RQAANNZKnww8wEAgPksFT56Zz6IHgAAmMdi4aPnKyucAgBgHkuFDxsrnAIAYDprhY8jX+n5AADAPJYKH9GeD7IHAACmsVb4OPJu6fkAAMA8lgof9HwAAGA+a4WPI1/p+QAAwDyWCh/0fAAAYD6LhY+er8x8AABgHouFD2Y+AAAwm6XCh5j5AADAdJYKH9zbBQAA81ksfPR8ZeYDAADzWCp82ETPBwAAZrNU+Ohd4TTCKmMAAJjGUuHDRs8HAACm61f4+P73vy+bzdbnMX78+Oj+zs5OzZ8/XxkZGUpOTtbcuXNVV1c34EWfKno+AAAwX79nPs455xzV1tZGH2vXro3uu/fee/XSSy9p+fLlKisrU01NjebMmTOgBZ+O3p4PzroAAGCeuH4/IS5Oubm5H9nu9/v13HPPaenSpbrsssskSYsXL9aECRO0bt06zZw58/SrPU29Mx/c1RYAAPP0e+Zj165dys/P18iRIzVv3jxVVVVJkioqKhQKhVRaWho9dvz48SosLFR5efnAVXwabKxwCgCA6fo18zFjxgwtWbJE48aNU21trR5++GFdfPHF2rp1q3w+n1wul1JTU/s8JycnRz6f77ivGQwGFQwGo9+3tLT07x30Q+8iY/R8AABgnn6Fj6uuuir65ylTpmjGjBkqKirS73//eyUkJJxSAQsXLtTDDz98Ss/tL1u04TQmfx0AADiG07rUNjU1VWPHjtXu3buVm5urrq4uNTc39zmmrq7umD0ivRYsWCC/3x99VFdXn05JJxTt+eBiWwAATHNa4aOtrU179uxRXl6epk+fLqfTqZUrV0b379ixQ1VVVSopKTnua7jdbnk8nj6PwcJdbQEAMF+/Trs88MADuuaaa1RUVKSamho99NBDcjgcuvHGG+X1enXrrbfqvvvuU3p6ujwej+6++26VlJQMiStdpKMNp6xwCgCAefoVPg4cOKAbb7xRTU1NysrK0kUXXaR169YpKytLkvTYY4/Jbrdr7ty5CgaDmj17tp544olBKfxU0PMBAID5+hU+li1bdsL98fHxWrRokRYtWnRaRQ0Wej4AADCfpe7tQs8HAADms1T4sLHOBwAAprNW+DjylfABAIB5LBU+OO0CAID5LBY+er5ytQsAAOaxVviw9858kD4AADCLpcJHL3o+AAAwj6XCBz0fAACYz2Lho+crPR8AAJjHYuGDng8AAMxmqfBx9N4uhA8AAMxisfBxZObD5DoAALAyS4UPej4AADCfpcIHy6sDAGA+S4UPFhkDAMB8lgofNtb5AADAdJYKH3audgEAwHSWCh+2I10fNJwCAGAeS4WP3pkPej4AADCPxcIHPR8AAJjNUuGDFU4BADCfxcIHPR8AAJjNUuGDq10AADCfxcKH7eMPAgAAg8pS4YOeDwAAzGex8HGk5yNiciEAAFiYpcJHdJ0PMfMBAIBZLBY+uNoFAACzWSx89HxlhVMAAMxjqfAh7u0CAIDpLBU+mPkAAMB8FgsfzHwAAGA2a4WPI++WmQ8AAMxjqfBho+cDAADTWSt8sM4HAACms1T4sLPCKQAAprNm+KDnAwAA01gqfERPu5A9AAAwjTXDBz0fAACYxlLhg3U+AAAwn6XCx5GJD3o+AAAwkaXCh/3I+upkDwAAzGOt8MG9XQAAMJ2lwoeNng8AAExnrfBx5Cs9HwAAmMdS4aP3aheyBwAA5jmt8PHII4/IZrPpnnvuiW7r7OzU/PnzlZGRoeTkZM2dO1d1dXWnW+eAOBo+SB8AAJjllMPHhg0b9D//8z+aMmVKn+333nuvXnrpJS1fvlxlZWWqqanRnDlzTrvQgdC7yBg9HwAAmOeUwkdbW5vmzZunZ555RmlpadHtfr9fzz33nH72s5/psssu0/Tp07V48WK99dZbWrdu3YAVfaqOhg/SBwAAZjml8DF//nxdffXVKi0t7bO9oqJCoVCoz/bx48ersLBQ5eXlx3ytYDColpaWPo/BwgqnAACYL66/T1i2bJneeecdbdiw4SP7fD6fXC6XUlNT+2zPycmRz+c75ustXLhQDz/8cH/LOCW94UPc2wUAANP0a+ajurpa3/jGN/Tb3/5W8fHxA1LAggUL5Pf7o4/q6uoBed1jsdPzAQCA6foVPioqKlRfX69p06YpLi5OcXFxKisr0+OPP664uDjl5OSoq6tLzc3NfZ5XV1en3NzcY76m2+2Wx+Pp8xgs9HwAAGC+fp12ufzyy7Vly5Y+277yla9o/Pjx+va3v62CggI5nU6tXLlSc+fOlSTt2LFDVVVVKikpGbiqT5GNdT4AADBdv8JHSkqKJk2a1GdbUlKSMjIyottvvfVW3XfffUpPT5fH49Hdd9+tkpISzZw5c+CqPkVHG05JHwAAmKXfDacf57HHHpPdbtfcuXMVDAY1e/ZsPfHEEwP915ySozeWM7cOAACs7LTDx+rVq/t8Hx8fr0WLFmnRokWn+9IDziZmPgAAMJul7u1iY+YDAADTWSp82O3MfAAAYDZrhQ9mPgAAMJ2lwgc9HwAAmM9S4SM682FuGQAAWJqlwoeNdT4AADCdpcLHB3s+DAIIAACmsFT4sEXvakvTKQAAZrFU+LAfzR70fQAAYBJLhY8PznzQ9wEAgDksFj6O/pnwAQCAOSwVPuz0fAAAYDqLhY+jfyZ8AABgDouFD3o+AAAwm6XCxwcRPgAAMIelwkffmQ8TCwEAwMIsFj4+8A3hAwAAU1gsfNDzAQCA2SwVPljnAwAA81ksfNDzAQCA2SwVPqQP3NmWpg8AAExhwfDRkz446wIAgDksFz56z7zQ8wEAgDksGD560gc9HwAAmMNy4SPa88HMBwAAprBg+KDnAwAAM1kufPRebEvPBwAA5rBc+GDmAwAAc1kufHC1CwAA5rJc+LDbudoFAAAzWS589PZ8cLULAADmsFz4iPZ8mFwHAABWZbnwcXSRMeIHAABmsFz46F1kLBIxtw4AAKzKcuGDq10AADCX5cJHb88HAAAwh2XDBzMfAACYw3Lh4+hpF3PrAADAqiwcPkgfAACYwXLhg3u7AABgLguHD9IHAABmsFz46L3WhZ4PAADMYb3wQc8HAACmslz4oOcDAABzWTh8kD4AADBDv8LHk08+qSlTpsjj8cjj8aikpESvvPJKdH9nZ6fmz5+vjIwMJScna+7cuaqrqxvwok8H63wAAGCufoWP4cOH65FHHlFFRYU2btyoyy67TNdee622bdsmSbr33nv10ksvafny5SorK1NNTY3mzJkzKIWfKu5qCwCAueL6c/A111zT5/sf/ehHevLJJ7Vu3ToNHz5czz33nJYuXarLLrtMkrR48WJNmDBB69at08yZMweu6tPQe1dbogcAAOY45Z6PcDisZcuWKRAIqKSkRBUVFQqFQiotLY0eM378eBUWFqq8vPy4rxMMBtXS0tLnMZi4twsAAObqd/jYsmWLkpOT5Xa7dccdd2jFihWaOHGifD6fXC6XUlNT+xyfk5Mjn8933NdbuHChvF5v9FFQUNDvN9EfvT0fNJwCAGCOfoePcePGadOmTVq/fr3uvPNO3XTTTdq+ffspF7BgwQL5/f7oo7q6+pRf62REez4ig/rXAACA4+hXz4ckuVwujR49WpI0ffp0bdiwQb/4xS90/fXXq6urS83NzX1mP+rq6pSbm3vc13O73XK73f2v/BTR8wEAgLlOe52PSCSiYDCo6dOny+l0auXKldF9O3bsUFVVlUpKSk73rxkw9HwAAGCufs18LFiwQFdddZUKCwvV2tqqpUuXavXq1Xr11Vfl9Xp166236r777lN6ero8Ho/uvvtulZSUDJkrXaSj93ah5wMAAHP0K3zU19fry1/+smpra+X1ejVlyhS9+uqr+vSnPy1Jeuyxx2S32zV37lwFg0HNnj1bTzzxxKAUfqqOznyYXAgAABbVr/Dx3HPPnXB/fHy8Fi1apEWLFp1WUYPp6NUu5tYBAIBVWfbeLvR8AABgDsuFj6P3diF8AABgBsuFj96ZDwAAYA7LhQ9mPgAAMJflwoedFU4BADCV5cIHMx8AAJjLcuGjd+aD6AEAgDksGD56vrLCKQAA5rBc+LCxwikAAKayXvg48pWeDwAAzGG58BHt+SB7AABgCuuFjyPvmJ4PAADMYbnwYRM9HwAAmMl64YN1PgAAMJXlwgc9HwAAmMuC4aPna5jzLgAAmMJy4SMz2S1JqvF3mFwJAADWZLnwMTYnRZK0u77N5EoAALAmy4WP0TnJkqSdda0mVwIAgDVZL3xk94SPupag/B0hk6sBAMB6LBc+PPFO5XnjJUm765n9AAAg1iwXPqSjsx+76uj7AAAg1iwZPnqbTncSPgAAiDlLho8xvTMfnHYBACDmrBk+ojMfrdxgDgCAGLNk+BifmyJXnF11LUFOvQAAEGOWDB9J7jhdMiZTkvTK1lqTqwEAwFosGT4k6cpJeZKkv231mVwJAADWYtnw8ekJOYqz2/S+r1WVjQGzywEAwDIsGz68iU6VjMqQJP3p3YMmVwMAgHVYNnxI0ufPK5Ak/Xb9fnWGwiZXAwCANVg6fFw1KVd53ng1tnXpz/+sMbscAAAswdLhw+mw6+YLR0iSnirbo0Cw29yCAACwAEuHD0m64YJCpSU6tbchoK/9b4WC3Zx+AQBgMFk+fHgTnPrVzecr0eXQ2t2N+uXK3WaXBADAWc3y4UOSzi1M008+N1WStOStfToc6DK5IgAAzl6EjyM+MzlXE/M8agt267m1lWaXAwDAWYvwcYTNZtM3SsdIYvYDAIDBRPj4gCsm5jD7AQDAICN8fIDNZtM9R2Y/Fr9ZqR2+VoUjhslVAQBwdiF8fMinj8x+BLrCmv3zNbpu0Ztq72L9DwAABgrh40NsNpv+47pzNGmYR644u7Yc9OsXK3eZXRYAAGcNwscxTC9K18t3X6wn502TJD33RqXKdjbIMDgFAwDA6SJ8nMDlE3L06Yk56o4YuulXb+vmxRvUHY6YXRYAAGc0wsfH+K/PT9W8GYVyxdlVtrNBK949aHZJAACc0QgfH8Ob4NSPPjtZD1wxVpL0y1W7FWL2AwCAU9av8LFw4UKdf/75SklJUXZ2tq677jrt2LGjzzGdnZ2aP3++MjIylJycrLlz56qurm5AizbDl2YWKTPZpapD7Xr4pW1q7QyZXRIAAGekfoWPsrIyzZ8/X+vWrdNrr72mUCikK664QoFAIHrMvffeq5deeknLly9XWVmZampqNGfOnAEvPNYSXXG6p7Rn9uM366p05c/fYBVUAABOgc04jUs4GhoalJ2drbKyMl1yySXy+/3KysrS0qVL9bnPfU6S9P7772vChAkqLy/XzJkzP/Y1W1pa5PV65ff75fF4TrW0QWEYhla9X68HX9ymg80dmjNtmH72hU+YXRYAAKbrz+/vuNP5i/x+vyQpPT1dklRRUaFQKKTS0tLoMePHj1dhYeFxw0cwGFQwGOxT/FBls9l0+YQcpSa69Lmn3tIf3zkof3tI04rS9PVLR8lms5ldIgAAQ94pN5xGIhHdc889mjVrliZNmiRJ8vl8crlcSk1N7XNsTk6OfD7fMV9n4cKF8nq90UdBQcGplhQz04vSdPOFIyRJK9+v109e3aE3dzeZWxQAAGeIUw4f8+fP19atW7Vs2bLTKmDBggXy+/3RR3V19Wm9Xqx89zMTtOiL01Q6IUeS9Ks3uREdAAAn45ROu9x11116+eWXtWbNGg0fPjy6PTc3V11dXWpubu4z+1FXV6fc3Nxjvpbb7Zbb7T6VMkzldNh19ZQ8Tcz3aOX7dVr1fr32NLRpVFay2aUBADCk9WvmwzAM3XXXXVqxYoVWrVql4uLiPvunT58up9OplStXRrft2LFDVVVVKikpGZiKh5jizCRdPj5bkvTN5f9UQ2vwY54BAIC19St8zJ8/X7/5zW+0dOlSpaSkyOfzyefzqaOjQ5Lk9Xp166236r777tPrr7+uiooKfeUrX1FJSclJXelyprr302OV4o7TO1XN+szjb+g36/arMxQ2uywAAIakfl1qe7yrORYvXqybb75ZUs8iY/fff79eeOEFBYNBzZ49W0888cRxT7t82FC+1PZE9jS06fZfb9Sehp41TxJdDpVOyNGtFxVrakGqucUBADDI+vP7+7TW+RgMZ2r4kKRgd1jL3q7W02v26mBzR3T7zJHpmv+p0bp4TJaJ1QEAMHgIHyYzDEP/PODXr8v36c+batQd6Rnimy8coe9+ZoJccdxSBwBwdiF8DCE1zR16qmyPfl2+X5L0mcm5WvTFaSxIBgA4q/Tn9zf/BB9k+akJ+sG1k/TMl8+T02HTX7f49NzaStW1dJpdGgAApiB8xMinJ+boO1dNkCT98C/vacaPV2r+0ncUjgypiScAAAbdad3bBf1zy6wR2nKgWX/ZUqtQ2NBfNtcq2RWnT43P0syRGUpNdJldIgAAg46eD5O8vLlGdy19N/p9jsetZ798viYP95pYFQAApyZmd7XFqfuXKfnq6o7oDxUHtL+pXQebOzT3qbf0+enDdeelozQ8LdHsEgEAGBTMfAwBLZ0h3bNsk1a9Xy9J8sTH6Wdf+IRKJ+aYXBkAACeHq13OMJ54p5676Tz97vaZ+kRBqlo6u/XVX2/Ub9fvN7s0AAAGHOFjiLDZbJoxMkO//1qJ5s0olCT9/yu26n/L95lbGAAAA4yejyHGFWfXD6+bpASnQ8+urdT3Xtymg82d+tz0YRqZmSy7ncXJAABnNno+hijDMPTzf+zSL1buim47ryhNz3z5PKUlcUkuAGBoYXn1s8iKdw9oyZv79L6vVcHuiArTEzWtMFVzpw/nRnUAgCGD8HEW2lnXqv/vufWqawlKkuLsNv3uazM1vSjd5MoAACB8nLUa24Ja+V6d/rrFp7KdDcpMdumC4nRdMCJd82YWyemgfxgAYA7Cx1muLdita/97rfY0BKLbJuR5tOiL52pkVrKJlQEArIrwYQH+9pBe2VqrpkCXnnljr5rbQ0pPcummkhEKhSO69aJiGlMBADFD+LCYhtagbn1+gzYf8Ee3TR7m1dLbZigl3mliZQAAqyB8WFAg2K1frtqtupZOle1s0KFAl7wJTo3JTtaCz4ynMRUAMKgIHxa39aBfX/7V2zoU6JLUs3DZv189Qf8yJV/pnIoBAAwCwgfU3tWtvQ0B/WLlLr22vU5Sz+W537pynG67eKRsNlZKBQAMHMIHosIRQ8++sVcr3j2o932tkqQZxenK88brmqn5SnA6tG5vk66/oFDDUhNMrhYAcKYifOCYnn1jr3701/d0rP/iuZ54/earF2h0dkrsCwMAnPEIHziuLQf82lrj1576Ni3bUC1J8iY4dbC5Q4kuh26+cITuuHSUPFwlAwDoB8IHTkp3OCJDUltnt27/343asO+wJCnfG6//uG6SLh2XLQd30QUAnATCB/rNMAy9tr1OP/zLe6o61C5Jykx268slRfrKrBGsFwIAOCHCB05ZINitn/59p/7vnQPyd4QkSVkpbj31pWmsFQIAOC7CB05bKBzRK1t9euy1napsDMjpsOmWi4r1pRlFKkhPNLs8AMAQQ/jAgAkEu/XA8n/qla2+6LZxOSn61PhsXT05T5OHe/WXzbWqbGzT7ZeMkiuOO+sCgBURPjCgDMPQP96r1/Nv7dNbexoV+cAn5tMTc6KLmH1mcq4ev+FcxTkIIABgNYQPDJrDgS6t2dWgv26p1avb6qLbbTbJMKTZ5+Top1/4hBKdDtm5UgYALIPwgZj4Q8UBPfbaTn3+vOGakOfRXUvfUShsKMHpUCgc0dVT8rRwzmQluuLMLhUAMMgIHzBFxf7DuvM3FapvDUa3TRrm0bNfPl+53ngTKwMADDbCB0zT0RVWZWNATYGgvrFskw4FupSd4taIzCT520O6ZGymSkZlKCs5XtWH2/WJglTlc08ZADjjET4wJFQfatetz2/Qzrq24x6TmezW7742U6OykmNYGQBgoBE+MGS0doa0+M19ykh2yZvg1Kr367X1oF+HAl2SbGpsCyrH49bjN5yrScO8CgS7le3hFA0AnGkIHzgjNLUFdeMz66IzI3abFDGkWaMzdPslo3TJmEzZbFwxAwBnAsIHzhj+jpAeeeV9vfB21Uf2jc5O1pThXtU2d6opENQXzivQl2YWKd7pMKFSAMCJED5wxvH5O2WzSV3dEf3qzUr9bkO12rvCHzluVFaSHv3cVO2sa1UwFNaEPI8uKE5nhgQATEb4wBnP3x7S2t2NqmxsU1qSS4YhPb5yV5/LeHt99aJi/fu/TDShSgBAr/78/mb1JwxJ3kSnrp6S12fblZNydffSd1W+t0kT8jwalpqgf7xXp2fXViol3ql5MwvljrMrwelgiXcAGMKY+cAZJRIxVN8ajC5a9t+rdum//r6zzzHuOLsmDfPq6sl5+uy5w5SW5DKjVACwFE67wDIMw9Dzb+3T7zYe0Hu1LR/Z73LYNXtSrr52yUhNGuaVJDW0BuWw25ROKAGAAUP4gCUFgt1y2G2qae7QG7sa9bsN1dr+gUAyeZhXNpu0+YBfKfFx+vUtF+jcwjQTKwaAswfhAzhi60G/nn1jr178Z40+/ElPiY/TpeOyVZyRqC/NLGJxMwA4DYMaPtasWaOf/OQnqqioUG1trVasWKHrrrsuut8wDD300EN65pln1NzcrFmzZunJJ5/UmDFjBrx44GTtbwrofV+rurojOiffo+/83xa9ve9QdL/TYVOeN0FTC1L18L+eo8PtXdpV16aMZJc+UZAqJw2sAHBCg3q1SyAQ0NSpU3XLLbdozpw5H9n/6KOP6vHHH9fzzz+v4uJife9739Ps2bO1fft2xcfzL0uYoygjSUUZSdHvn7/lAv1tW62a2rr0t60+bdx/WFWH2lV1qF1rdzWouSMUnSmZOtyrH1w7SbX+TuWnxmt8rkeuOMIIAJyq0zrtYrPZ+sx8GIah/Px83X///XrggQckSX6/Xzk5OVqyZIluuOGGj31NZj5ghupD7drbGNCDL27V/qZ2SdKkYR7tb2xXa7C7z7G9V9PccH6B5k4brsa2oFITXQQSAJZm2joflZWV8vl8Ki0tjW7zer2aMWOGysvLjxk+gsGggsGjC0e1tHz0igVgsBWkJ6ogPVEvzp+lP75zUCWjMjQhz6Oqpnbd/cI72l7botHZKapp7pC/I6SK/YdVsf+wvv/nbQp0hZXkcuhT47P18L+eo/Qkl9q7wkpys4wOABzLgP7f0efzSZJycnL6bM/JyYnu+7CFCxfq4YcfHsgygFOWmujSLRcVR78vzEjUi3ddpHDEkMNuk2EYqmwM6NVtdfrvVbsUOLIEfKArrJc312rzAb8cdpsqGwNKiY/T+NwUXVCcrptKRtDQCgBHmP5PswULFui+++6Lft/S0qKCggITKwI+ymHvuXeMzWbTyKxk3Xlpsm44v0DVh9s1JjtF22v9+sayTao61B59TmtntzbsO6wN+w7r2TcqddOFI3T7JSPliXdyigaApQ1o+MjNzZUk1dXVKS/v6NLYdXV1+sQnPnHM57jdbrnd7oEsA4iJtCRXdPXU6UXp+uPXL9Qv/rFLo7OT9a9T89XY1qV/HmjW7zZUq2L/YT29Zq+eXrNXklScmaRZozMUDEV0ydgsXTM1X4ZhqHxvk96tatYN5xcoI5mfCwBnpwENH8XFxcrNzdXKlSujYaOlpUXr16/XnXfeOZB/FTDkZKfE60efnRz9PiPZrXG5Kfr89OFavaNB//X3HdpW09PTVNkYUGVjQJK0vOKA/rbVp72Ngegqrc+trdSCq8brs+cO4z41AM46/Q4fbW1t2r17d/T7yspKbdq0Senp6SosLNQ999yjH/7whxozZkz0Utv8/Pw+a4EAVmKz2fSp8dm6dFyWWjq6FYpE9NaeJm2vaVFbMKTfrKvSX7bUSpLinXbleOK1v6ld3/zDZv3stZ0amZWktESX7Dabttb4NSorWf9x7aTo/W0A4EzT70ttV69erU996lMf2X7TTTdpyZIl0UXGnn76aTU3N+uiiy7SE088obFjx57U63OpLazm1W0+vby5VheOytDsc3KV7I7Tc2sr9cwbe3Uo0HXM56QmOjVrdKYOHO7QTl+rLh6TqZkjMxQxDM0anSlPglNbD/o1eZhX+akJMX5HAKyI5dWBs0BHV1gb9h3SoUCXDgW61BEKqzgzSb9ctfuYN9E7novHZOq/Pj9VToddEcNQJr0kAAYB4QM4iwW7w3pzd6P21AfkSYjTmJwU/WVzrXz+TnWGwnpjV6O6IxEVZyZpb2NAhtFzH5v2rrCcDpu+f805stttemVLrdZXHtJtF4/UvZ8eq/qWThZLA3DKCB+AhQWC3YoYhlLindrb0KY7flOhnXVtJ3zOhDyP3qttkTfBqVFZSdrf1K4LR2dqzrRh2lPfpon5HpWMzJDN1nPJcSgcUWNbUNkp8dHLkAFYG+EDQFQg2K3XttdpynCv/rSpRote362xOSn6zKRcdXaHtej1PSf1OnneeGV74nUoEFRNc6fCEUMjMhL1rSvH69JxWUp0xam1M6TtNS1KT3JpVFay7AQTwDIIHwCOKxSORO/SaxiGfvXmPlU2tumrF43UweYO1bd2Kis5Xs+u3avd9W0anZ2stysPqf3Iaq7H4rDbFB9nV3soHL0hX2ayS3d8cpQmD/OqIxRWyagMueMcsXiLAExA+AAwoNqC3dpe06LD7V1KS3SpKCNRiS6Hnly9R39696Bq/J3RY/O98TrU3qXOUKTPa2Qmu5SW6NKBwx2SJE9CnArSEvWZyXm67txhSk9yqTMUVntXWMnuOHpPgDMM4QNATNW3dKozFFGi26HMZLdC4YhWvHNQ/7Nmj7ojhjq6wqpvDR73+U6HTZOGebXtYIu6whG5HHbdenGxvnhBoWqaO1R1qF1twW51hMLa6WtVrjdBd35ylLyJzhi+SwAnQvgAMKSEwhGt3d0oSSrOSJLDbtPh9i69W9Ws5RXV2nqw/3ezTk9yadboTI3KStKIjCQZ6vlfmcvh0KH2LoW6I8pMceuTY7PkTSCkAION8AHgjLKtxq8tB/w6b0SaRmQk6R/v1ev7f96mxraghqUlqDA9UZ4Ep5x2m0ZkJunlzbXaXX/iK3h6pSY6ddm4bNX4OzQuJ0WXjs/WuQWp+vv2OlU1tWtMTrLG5aYoJyVeLZ0h5XkT+pzyMQxD71Y3qyg9kfvtACdA+ABwxjMMQ+GIccx723R1R/Tm7kbtrGvVnoY2VR/qiF7yG+wOR9crea+mRXuP3EPnZCW743TeiDRlJbs1IjNJG/cd0us7GpTsjtOXZhYpwelQrtetKcNTNT43RcHuiHz+ThWkJ3LZMSyN8AEAkrrDEf35nzXa1xjQ8LREbTrQrNXv16vG36lhqQmaNTpDexsC2uFrVWuwWy6HXV3hyMe/8BEjM5PU0BpUa7BbSS6H4hx2dXVHNGt0ptISnfJ3hDQiM0mZyS457HY5bFJzR0jN7SEVpidqTE6yhqclqrm9Zxn91ESXusMRpcQ7leNxR9dVAc4EhA8AOA7DMNTQGlR6kis6q2IYhkJhQ3F2mzYf9Gt7TYua2oLaVd8mm02a/6nR2nrQr7f2NMnpsKnqULs27jusYHdPUImz29QdGdj/lXri4zQ2J0Vup12HAiFdMCJNo7KT5fN3KiPZrYK0hOh9e4LdEXV1RxTsDqurO6JQ2JArzq5cT7wm5nuYkUFMED4AYJC1dIa0ZmeDslPiNa0wVXsbA7KpJwiU7WxQJGIoJT5OlY0BtQa71R021B2JyBPvlDfRqf2N7dpV36qDzR3Ruxb7O0KKc9jU2tmt8ACFmZT4OKUlupTsjtPYnGTta2pXQ2tQed545acmaFhagvK98WoLhtUdjmh8nkdrdjZoX1NA375yvILdYW2vadElY7MU73SooTWokVlJMgypqa1LCS6HMpJcLCgHwgcAnMmC3WHtbQhoZ12rusOGElwOrXq/Xs3tXcrzJqgpENSBwx2q9XfKbpNccXa54xxyOexyO+1yOuwKhsLa2xhQa2f3KdfhsNuOGYJsNumDvznSk1y6aHSmLhmbpY5QWHvq2zQqO1m1zR3asO+Q6lqCcthtyvXE64pzcjStME2tnd1q6QwpK8WtaYVp2tcU6AkzTofinXZlpbjlTXDqfV+rDgW6VJSRqGGpCZyKGsIIHwAAdYcj2lnXps7usBpag9pV16rhaYkqSE+Qzx/UweZ2HTwSYpLdcQobhrYe9Gt0drLCEUP/eK9eDrtNk4d59c8DzbJJ8iY4dbg9JEmKd9o/spjcqTher40nPk4tHwhPWSk9p5sOBbrUeGTWpXRCjjzxcXLYbcpLTdC6vU1qbA1qxsgMRSKGOkNhjcxKVtgwdOBwu3bXtcmT4FSS26EdvlZle+J1flGaCjMS1RYMq62zW8WZScpPjVdGslvJ7jhJUiRiqK2rW4nOnt6ew4Eu7WsKqDMU0Xkj0qKrBvcKdoflbw/Jk+BUvNMaK/sSPgAAp8UwDL21p0kFaYkqzEiUvyMkl8OuBJdDjW1BOR12eROcCoUj2lTdrLIdDXprT6PinQ6Ny03R3oaAPAlOfXJslooyEhWJGNpe26I/vnNQDa1BeROcSomP0676tp7XjrMr3xuvYHdEHaGwmj8QcPK8CTpwuF2hcOx/XY3ISFTYMHTwcIcihpTocijPG689DUevohqW2nM5+O6GNqUmOBUIdkdX/U1wOnTxmEw1BbrU0RVWaqJTqYlOhcKGDge6NCYnRSMyEtUZiqizO6zUBKdGZSXr6Tf2qr6lU1dPydNFo7OU43GruSMkf3tIlY0BbTno16FAl1Li43T9+QW6oDhdgWBYm6oPyx3n0IjMJA1LTVBTW1B7GgJKS3SqKCNpUFcOJnwAAM4IoXBE+xoDKkhP7DND4O8IaX9TQGOyU5TgcqgzFNY/q5t1uL1LGcluZSS5VH24Q2t2NsgmqbM7rP1N7ZqY71FheqI27jusJLdDLodDexvb5I6zK8cTrzHZyWrp7FZrZ7fG5iSr+lCHthxsVk1zz+xPotuhvQ0BNbYFT3g/I6nnVgIdoXB0JmioyfPGq66lU71nzlLccZoxMl3ZnngNT0vQ1y8dPaB/H+EDAIDT1NzepW01LXI67CpMT1RqolP7m9pVfahdUwtSlZXiVmcorFe21ioYimhCnketnd2Kd9o1MitZqQlObTrQrPV7Dyk/NV6eBKdaOkI6HOiSw2GXJz5OWw/61dTWpXiXQ/FxDlU2tmlrTYsuHZuli8Zk6pUtPm2t8cvfHpI30am0RJdyPG5NHZ6qHG+8tte06P8qDqg12HN6anR2siRpX2MgegXWsNQEtXSEosdI0sisJK26/9IBHS/CBwAAFmEYhlo6eoJF7/2O2oLd2lzdrGFpCSrKSFIkYmjzQb82H2jWoUCXkt1x+urFIwe0DsIHAACIqf78/uae1QAAIKYIHwAAIKYIHwAAIKYIHwAAIKYIHwAAIKYIHwAAIKYIHwAAIKYIHwAAIKYIHwAAIKYIHwAAIKYIHwAAIKYIHwAAIKYIHwAAIKbizC7gw3pvstvS0mJyJQAA4GT1/t7u/T1+IkMufLS2tkqSCgoKTK4EAAD0V2trq7xe7wmPsRknE1FiKBKJqKamRikpKbLZbAP62i0tLSooKFB1dbU8Hs+AvvbZiPE6eYxV/zBe/cN4nTzGqn8GcrwMw1Bra6vy8/Nlt5+4q2PIzXzY7XYNHz58UP8Oj8fDh7IfGK+Tx1j1D+PVP4zXyWOs+megxuvjZjx60XAKAABiivABAABiylLhw+1266GHHpLb7Ta7lDMC43XyGKv+Ybz6h/E6eYxV/5g1XkOu4RQAAJzdLDXzAQAAzEf4AAAAMUX4AAAAMUX4AAAAMWWZ8LFo0SKNGDFC8fHxmjFjht5++22zSxoSvv/978tms/V5jB8/Prq/s7NT8+fPV0ZGhpKTkzV37lzV1dWZWHFsrVmzRtdcc43y8/Nls9n0pz/9qc9+wzD04IMPKi8vTwkJCSotLdWuXbv6HHPo0CHNmzdPHo9HqampuvXWW9XW1hbDdxEbHzdWN99880c+a1deeWWfY6wyVgsXLtT555+vlJQUZWdn67rrrtOOHTv6HHMyP3tVVVW6+uqrlZiYqOzsbH3zm99Ud3d3LN9KTJzMeF166aUf+XzdcccdfY6xyng9+eSTmjJlSnThsJKSEr3yyivR/UPhs2WJ8PG73/1O9913nx566CG98847mjp1qmbPnq36+nqzSxsSzjnnHNXW1kYfa9euje6799579dJLL2n58uUqKytTTU2N5syZY2K1sRUIBDR16lQtWrTomPsfffRRPf7443rqqae0fv16JSUlafbs2ers7IweM2/ePG3btk2vvfaaXn75Za1Zs0a33357rN5CzHzcWEnSlVde2eez9sILL/TZb5WxKisr0/z587Vu3Tq99tprCoVCuuKKKxQIBKLHfNzPXjgc1tVXX62uri699dZbev7557VkyRI9+OCDZrylQXUy4yVJt912W5/P16OPPhrdZ6XxGj58uB555BFVVFRo48aNuuyyy3Tttddq27ZtkobIZ8uwgAsuuMCYP39+9PtwOGzk5+cbCxcuNLGqoeGhhx4ypk6desx9zc3NhtPpNJYvXx7d9t577xmSjPLy8hhVOHRIMlasWBH9PhKJGLm5ucZPfvKT6Lbm5mbD7XYbL7zwgmEYhrF9+3ZDkrFhw4boMa+88ophs9mMgwcPxqz2WPvwWBmGYdx0003Gtddee9znWHWsDMMw6uvrDUlGWVmZYRgn97P317/+1bDb7YbP54se8+STTxoej8cIBoOxfQMx9uHxMgzD+OQnP2l84xvfOO5zrDxehmEYaWlpxrPPPjtkPltn/cxHV1eXKioqVFpaGt1mt9tVWlqq8vJyEysbOnbt2qX8/HyNHDlS8+bNU1VVlSSpoqJCoVCoz9iNHz9ehYWFjJ2kyspK+Xy+PuPj9Xo1Y8aM6PiUl5crNTVV5513XvSY0tJS2e12rV+/PuY1m2316tXKzs7WuHHjdOedd6qpqSm6z8pj5ff7JUnp6emSTu5nr7y8XJMnT1ZOTk70mNmzZ6ulpSX6L9yz1YfHq9dvf/tbZWZmatKkSVqwYIHa29uj+6w6XuFwWMuWLVMgEFBJScmQ+WwNuRvLDbTGxkaFw+E+gyhJOTk5ev/9902qauiYMWOGlixZonHjxqm2tlYPP/ywLr74Ym3dulU+n08ul0upqal9npOTkyOfz2dOwUNI7xgc67PVu8/n8yk7O7vP/ri4OKWnp1tuDK+88krNmTNHxcXF2rNnj7773e/qqquuUnl5uRwOh2XHKhKJ6J577tGsWbM0adIkSTqpnz2fz3fMz17vvrPVscZLkr74xS+qqKhI+fn52rx5s7797W9rx44d+uMf/yjJeuO1ZcsWlZSUqLOzU8nJyVqxYoUmTpyoTZs2DYnP1lkfPnBiV111VfTPU6ZM0YwZM1RUVKTf//73SkhIMLEynG1uuOGG6J8nT56sKVOmaNSoUVq9erUuv/xyEysz1/z587V169Y+vVY4vuON1wd7gyZPnqy8vDxdfvnl2rNnj0aNGhXrMk03btw4bdq0SX6/X3/4wx900003qayszOyyos760y6ZmZlyOBwf6eStq6tTbm6uSVUNXampqRo7dqx2796t3NxcdXV1qbm5uc8xjF2P3jE40WcrNzf3I43N3d3dOnTokOXHcOTIkcrMzNTu3bslWXOs7rrrLr388st6/fXXNXz48Oj2k/nZy83NPeZnr3ff2eh443UsM2bMkKQ+ny8rjZfL5dLo0aM1ffp0LVy4UFOnTtUvfvGLIfPZOuvDh8vl0vTp07Vy5crotkgkopUrV6qkpMTEyoamtrY27dmzR3l5eZo+fbqcTmefsduxY4eqqqoYO0nFxcXKzc3tMz4tLS1av359dHxKSkrU3NysioqK6DGrVq1SJBKJ/s/Rqg4cOKCmpibl5eVJstZYGYahu+66SytWrNCqVatUXFzcZ//J/OyVlJRoy5YtfQLba6+9Jo/Ho4kTJ8bmjcTIx43XsWzatEmS+ny+rDJexxKJRBQMBofOZ2tA2laHuGXLlhlut9tYsmSJsX37duP22283UlNT+3TyWtX9999vrF692qisrDTefPNNo7S01MjMzDTq6+sNwzCMO+64wygsLDRWrVplbNy40SgpKTFKSkpMrjp2WltbjXfffdd49913DUnGz372M+Pdd9819u/fbxiGYTzyyCNGamqq8eKLLxqbN282rr32WqO4uNjo6OiIvsaVV15pnHvuucb69euNtWvXGmPGjDFuvPFGs97SoDnRWLW2thoPPPCAUV5eblRWVhr/+Mc/jGnTphljxowxOjs7o69hlbG68847Da/Xa6xevdqora2NPtrb26PHfNzPXnd3tzFp0iTjiiuuMDZt2mT87W9/M7KysowFCxaY8ZYG1ceN1+7du40f/OAHxsaNG43KykrjxRdfNEaOHGlccskl0dew0nh95zvfMcrKyozKykpj8+bNxne+8x3DZrMZf//73w3DGBqfLUuED8MwjF/+8pdGYWGh4XK5jAsuuMBYt26d2SUNCddff72Rl5dnuFwuY9iwYcb1119v7N69O7q/o6PD+PrXv26kpaUZiYmJxmc/+1mjtrbWxIpj6/XXXzckfeRx0003GYbRc7nt9773PSMnJ8dwu93G5ZdfbuzYsaPPazQ1NRk33nijkZycbHg8HuMrX/mK0draasK7GVwnGqv29nbjiiuuMLKysgyn02kUFRUZt91220f+AWCVsTrWOEkyFi9eHD3mZH729u3bZ1x11VVGQkKCkZmZadx///1GKBSK8bsZfB83XlVVVcYll1xipKenG2632xg9erTxzW9+0/D7/X1exyrjdcsttxhFRUWGy+UysrKyjMsvvzwaPAxjaHy2bIZhGAMzhwIAAPDxzvqeDwAAMLQQPgAAQEwRPgAAQEwRPgAAQEwRPgAAQEwRPgAAQEwRPgAAQEwRPgAAQEwRPgAAQEwRPgAAQEwRPgAAQEwRPgAAQEz9PxkXv7Z3WTaQAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x78213ffe5cf0>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
