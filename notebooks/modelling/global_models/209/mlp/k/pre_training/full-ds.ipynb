{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-24 19:15:28.889008: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-24 19:15:28.891578: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-24 19:15:28.944946: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-24 19:15:28.946088: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-24 19:15:29.934206: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/206/mlp/b/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 1\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 1\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 1\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"K\\\",\\n    \\\"Features\\\": \\\"Chemical + Physical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"K\\\",\\n    \\\"Features\\\": \\\"Chemical + Physical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"209\",\n",
    "    \"Plant\": \"K\",\n",
    "    \"Features\": \"Chemical + Physical\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/209/global_k.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/209/global_k.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/209/global_k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_64f49_row0_col0, #T_64f49_row1_col0, #T_64f49_row2_col0, #T_64f49_row3_col0, #T_64f49_row4_col0, #T_64f49_row5_col0, #T_64f49_row6_col0, #T_64f49_row7_col0, #T_64f49_row8_col0, #T_64f49_row9_col0, #T_64f49_row10_col0, #T_64f49_row11_col0, #T_64f49_row12_col0, #T_64f49_row13_col0, #T_64f49_row14_col0, #T_64f49_row15_col0, #T_64f49_row16_col0 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_64f49\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_64f49_level0_col0\" class=\"col_heading level0 col0\" >Zero (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_64f49_level0_row0\" class=\"row_heading level0 row0\" >CaO</th>\n",
       "      <td id=\"T_64f49_row0_col0\" class=\"data row0 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64f49_level0_row1\" class=\"row_heading level0 row1\" >Insoluble Residue</th>\n",
       "      <td id=\"T_64f49_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64f49_level0_row2\" class=\"row_heading level0 row2\" >CS7</th>\n",
       "      <td id=\"T_64f49_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64f49_level0_row3\" class=\"row_heading level0 row3\" >CS3</th>\n",
       "      <td id=\"T_64f49_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64f49_level0_row4\" class=\"row_heading level0 row4\" >Final setting time</th>\n",
       "      <td id=\"T_64f49_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64f49_level0_row5\" class=\"row_heading level0 row5\" >Initial setting time</th>\n",
       "      <td id=\"T_64f49_row5_col0\" class=\"data row5 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64f49_level0_row6\" class=\"row_heading level0 row6\" >#325</th>\n",
       "      <td id=\"T_64f49_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64f49_level0_row7\" class=\"row_heading level0 row7\" >Blaine</th>\n",
       "      <td id=\"T_64f49_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64f49_level0_row8\" class=\"row_heading level0 row8\" >Loss on Ignition</th>\n",
       "      <td id=\"T_64f49_row8_col0\" class=\"data row8 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64f49_level0_row9\" class=\"row_heading level0 row9\" >MgO</th>\n",
       "      <td id=\"T_64f49_row9_col0\" class=\"data row9 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64f49_level0_row10\" class=\"row_heading level0 row10\" >Fe2O3</th>\n",
       "      <td id=\"T_64f49_row10_col0\" class=\"data row10 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64f49_level0_row11\" class=\"row_heading level0 row11\" >K2O</th>\n",
       "      <td id=\"T_64f49_row11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64f49_level0_row12\" class=\"row_heading level0 row12\" >SO3</th>\n",
       "      <td id=\"T_64f49_row12_col0\" class=\"data row12 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64f49_level0_row13\" class=\"row_heading level0 row13\" >SiO2</th>\n",
       "      <td id=\"T_64f49_row13_col0\" class=\"data row13 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64f49_level0_row14\" class=\"row_heading level0 row14\" >Al2O3</th>\n",
       "      <td id=\"T_64f49_row14_col0\" class=\"data row14 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64f49_level0_row15\" class=\"row_heading level0 row15\" >Na2O</th>\n",
       "      <td id=\"T_64f49_row15_col0\" class=\"data row15 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64f49_level0_row16\" class=\"row_heading level0 row16\" >CS28</th>\n",
       "      <td id=\"T_64f49_row16_col0\" class=\"data row16 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fab2a373850>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_formatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_values = {}\n",
    "for col in df.select_dtypes(include=\"number\").columns:\n",
    "    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\n",
    "    zero_values[col] = zero_percentages\n",
    "\n",
    "zero_percentages = pd.Series(zero_values, name=f\"Zero (%)\")\n",
    "zero_percentages = zero_percentages.sort_values(ascending=False)\n",
    "zero_percentages = zero_percentages.to_frame(name=f\"Zero (%)\")\n",
    "zero_percentages.style.background_gradient(cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop([\\\"Cement_Type\\\", \\\"Factory_Plant\\\"], axis=1)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop([\\\"Cement_Type\\\", \\\"Factory_Plant\\\"], axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop([\"Cement_Type\", \"Factory_Plant\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 16:37:08.958368: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  9.087880174318949\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.335 (0.000)\n",
      "MAE: 1.018 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.962 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.611 (0.000)\n",
      "MAE: 1.210 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.929 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  10.210788094997406\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.378 (0.000)\n",
      "MAE: 1.049 (0.000)\n",
      "MAPE: 0.024 (0.000)\n",
      "R2: 0.960 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.599 (0.000)\n",
      "MAE: 1.209 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.930 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  13.991438241799672\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.406 (0.000)\n",
      "MAE: 1.101 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.958 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.729 (0.000)\n",
      "MAE: 1.334 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.918 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  16.581532216072084\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.429 (0.000)\n",
      "MAE: 1.121 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.956 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.740 (0.000)\n",
      "MAE: 1.346 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.917 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  17.150179366270702\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.271 (0.000)\n",
      "MAE: 0.972 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.966 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.574 (0.000)\n",
      "MAE: 1.167 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.932 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  27.697538435459137\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.288 (0.000)\n",
      "MAE: 0.976 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.965 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.519 (0.000)\n",
      "MAE: 1.131 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.937 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.28221120039622\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.259 (0.000)\n",
      "MAE: 0.958 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.966 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.507 (0.000)\n",
      "MAE: 1.127 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.938 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.277058450380961\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.242 (0.000)\n",
      "MAE: 0.950 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.967 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.534 (0.000)\n",
      "MAE: 1.157 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.936 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  22.432614839076997\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.637 (0.000)\n",
      "MAE: 1.262 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.943 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.900 (0.000)\n",
      "MAE: 1.452 (0.000)\n",
      "MAPE: 0.035 (0.000)\n",
      "R2: 0.901 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  23.970387371381126\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.310 (0.000)\n",
      "MAE: 0.999 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.963 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.561 (0.000)\n",
      "MAE: 1.148 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.933 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.858534224828084\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.274 (0.000)\n",
      "MAE: 0.965 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.965 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.515 (0.000)\n",
      "MAE: 1.126 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.937 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  16.326599955558777\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.408 (0.000)\n",
      "MAE: 1.063 (0.000)\n",
      "MAPE: 0.024 (0.000)\n",
      "R2: 0.958 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.505 (0.000)\n",
      "MAE: 1.117 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.938 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.781423219045003\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.482 (0.000)\n",
      "MAE: 1.131 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.953 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.558 (0.000)\n",
      "MAE: 1.156 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.934 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/209/k/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/209/k/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/209/k/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>209</td>\n",
       "      <td>K</td>\n",
       "      <td>Chemical + Physical</td>\n",
       "      <td>(60916, 16)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_12</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>1.408376</td>\n",
       "      <td>1.063349</td>\n",
       "      <td>0.023811</td>\n",
       "      <td>0.957688</td>\n",
       "      <td>1.504705</td>\n",
       "      <td>1.11716</td>\n",
       "      <td>0.026249</td>\n",
       "      <td>0.938098</td>\n",
       "      <td>-3.473772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category Company Plant             Features   Data Shape Timesteps  \\\n",
       "11  Global Model     209     K  Chemical + Physical  (60916, 16)      None   \n",
       "\n",
       "     Model Model Params           Scaler Scaler Params  ...  \\\n",
       "11  MLP_12         None  Standard Scaler          None  ...   \n",
       "\n",
       "                  Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "11  {\"train_size\": 0.8, \"test_size\": 0.2}   1.408376  1.063349   0.023811   \n",
       "\n",
       "    R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "11  0.957688   1.504705   1.11716   0.026249  0.938098 -3.473772  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  19.14567002852758\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.354 (0.000)\n",
      "MAE: 1.019 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.959 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.354 (0.000)\n",
      "MAE: 1.019 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.959 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/209/mlp/k/pre_training/\\\"\\nmodel_name = \\\"mlp_full_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/209/mlp/k/pre_training/\\\"\\nmodel_name = \\\"mlp_full_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/209/mlp/k/pre_training/\"\n",
    "model_name = \"mlp_full_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7de90129db40>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7de90134d540>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7de9b7f855d0>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7de9bc1a46d0>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 256)               4352      \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45569 (178.00 KB)\n",
      "Trainable params: 45569 (178.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for global analysis results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-24 19:16:44.954388: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.975713614622752\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.408 (0.000)\n",
      "MAE: 1.063 (0.000)\n",
      "MAPE: 0.024 (0.000)\n",
      "R2: 0.958 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.505 (0.000)\n",
      "MAE: 1.117 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.938 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\\nweights_path = \\\"../../../../../../../models/global_models/209/mlp/k/pre_training/\\\"\\nmodel_name = \\\"mlp_k_chemical_properties_csless_vars_partial_ds_weights.h5\\\"\\n\\nfull_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\\nweights_path = \\\"../../../../../../../models/global_models/209/mlp/k/pre_training/\\\"\\nmodel_name = \\\"mlp_k_chemical_properties_csless_vars_partial_ds_weights.h5\\\"\\n\\nfull_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]\n",
    "weights_path = \"../../../../../../../models/global_models/209/mlp/k/pre_training/\"\n",
    "model_name = \"mlp_k_full_vars_weights_partial_ds_weights.h5\"\n",
    "\n",
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
