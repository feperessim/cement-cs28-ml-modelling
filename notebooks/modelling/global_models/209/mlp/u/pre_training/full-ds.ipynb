{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 01:22:18.386802: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-28 01:22:18.390685: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-28 01:22:18.478567: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-28 01:22:18.479845: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-28 01:22:19.992635: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/206/mlp/b/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 1\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 1\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 1\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"U\\\",\\n    \\\"Features\\\": \\\"Chemical + Physical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"U\\\",\\n    \\\"Features\\\": \\\"Chemical + Physical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"209\",\n",
    "    \"Plant\": \"U\",\n",
    "    \"Features\": \"Chemical + Physical\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/209/global_u.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/209/global_u.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/209/global_u.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4812d_row0_col0 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4812d_row1_col0, #T_4812d_row2_col0, #T_4812d_row3_col0, #T_4812d_row4_col0, #T_4812d_row5_col0, #T_4812d_row6_col0, #T_4812d_row7_col0, #T_4812d_row8_col0, #T_4812d_row9_col0, #T_4812d_row10_col0, #T_4812d_row11_col0, #T_4812d_row12_col0, #T_4812d_row13_col0, #T_4812d_row14_col0, #T_4812d_row15_col0, #T_4812d_row16_col0, #T_4812d_row17_col0 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4812d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4812d_level0_col0\" class=\"col_heading level0 col0\" >Zero (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4812d_level0_row0\" class=\"row_heading level0 row0\" >#200</th>\n",
       "      <td id=\"T_4812d_row0_col0\" class=\"data row0 col0\" >14.086090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4812d_level0_row1\" class=\"row_heading level0 row1\" >CaO</th>\n",
       "      <td id=\"T_4812d_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4812d_level0_row2\" class=\"row_heading level0 row2\" >MgO</th>\n",
       "      <td id=\"T_4812d_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4812d_level0_row3\" class=\"row_heading level0 row3\" >CS7</th>\n",
       "      <td id=\"T_4812d_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4812d_level0_row4\" class=\"row_heading level0 row4\" >CS3</th>\n",
       "      <td id=\"T_4812d_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4812d_level0_row5\" class=\"row_heading level0 row5\" >Final setting time</th>\n",
       "      <td id=\"T_4812d_row5_col0\" class=\"data row5 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4812d_level0_row6\" class=\"row_heading level0 row6\" >Initial setting time</th>\n",
       "      <td id=\"T_4812d_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4812d_level0_row7\" class=\"row_heading level0 row7\" >#325</th>\n",
       "      <td id=\"T_4812d_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4812d_level0_row8\" class=\"row_heading level0 row8\" >Blaine</th>\n",
       "      <td id=\"T_4812d_row8_col0\" class=\"data row8 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4812d_level0_row9\" class=\"row_heading level0 row9\" >Insoluble Residue</th>\n",
       "      <td id=\"T_4812d_row9_col0\" class=\"data row9 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4812d_level0_row10\" class=\"row_heading level0 row10\" >Loss on Ignition</th>\n",
       "      <td id=\"T_4812d_row10_col0\" class=\"data row10 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4812d_level0_row11\" class=\"row_heading level0 row11\" >Fe2O3</th>\n",
       "      <td id=\"T_4812d_row11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4812d_level0_row12\" class=\"row_heading level0 row12\" >K2O</th>\n",
       "      <td id=\"T_4812d_row12_col0\" class=\"data row12 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4812d_level0_row13\" class=\"row_heading level0 row13\" >SO3</th>\n",
       "      <td id=\"T_4812d_row13_col0\" class=\"data row13 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4812d_level0_row14\" class=\"row_heading level0 row14\" >SiO2</th>\n",
       "      <td id=\"T_4812d_row14_col0\" class=\"data row14 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4812d_level0_row15\" class=\"row_heading level0 row15\" >Al2O3</th>\n",
       "      <td id=\"T_4812d_row15_col0\" class=\"data row15 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4812d_level0_row16\" class=\"row_heading level0 row16\" >Na2O</th>\n",
       "      <td id=\"T_4812d_row16_col0\" class=\"data row16 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4812d_level0_row17\" class=\"row_heading level0 row17\" >CS28</th>\n",
       "      <td id=\"T_4812d_row17_col0\" class=\"data row17 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcc33a11c00>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_formatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_values = {}\n",
    "for col in df.select_dtypes(include=\"number\").columns:\n",
    "    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\n",
    "    zero_values[col] = zero_percentages\n",
    "\n",
    "zero_percentages = pd.Series(zero_values, name=f\"Zero (%)\")\n",
    "zero_percentages = zero_percentages.sort_values(ascending=False)\n",
    "zero_percentages = zero_percentages.to_frame(name=f\"Zero (%)\")\n",
    "zero_percentages.style.background_gradient(cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop([\\\"Cement_Type\\\", \\\"Factory_Plant\\\"], axis=1)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop([\\\"Cement_Type\\\", \\\"Factory_Plant\\\"], axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop([\"Cement_Type\", \"Factory_Plant\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 01:22:25.349594: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  8.888394089539846\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.318 (0.000)\n",
      "MAE: 1.006 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.963 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.554 (0.000)\n",
      "MAE: 1.179 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.934 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  8.647758229573567\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.332 (0.000)\n",
      "MAE: 1.006 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.962 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.519 (0.000)\n",
      "MAE: 1.132 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.937 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  12.171245896816254\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.379 (0.000)\n",
      "MAE: 1.077 (0.000)\n",
      "MAPE: 0.025 (0.000)\n",
      "R2: 0.959 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.745 (0.000)\n",
      "MAE: 1.361 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.917 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.154340275128682\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.306 (0.000)\n",
      "MAE: 1.006 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.964 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.656 (0.000)\n",
      "MAE: 1.265 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.925 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.564988271395366\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.274 (0.000)\n",
      "MAE: 0.980 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.965 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.603 (0.000)\n",
      "MAE: 1.218 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.930 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  24.40659085114797\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.274 (0.000)\n",
      "MAE: 0.964 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.965 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.525 (0.000)\n",
      "MAE: 1.133 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.936 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  23.99576956431071\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.218 (0.000)\n",
      "MAE: 0.923 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.968 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.513 (0.000)\n",
      "MAE: 1.126 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.937 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  13.12776673634847\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.254 (0.000)\n",
      "MAE: 0.965 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.966 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.598 (0.000)\n",
      "MAE: 1.192 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.930 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  19.29167176882426\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.617 (0.000)\n",
      "MAE: 1.274 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.944 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.008 (0.000)\n",
      "MAE: 1.555 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.890 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  19.384902107715607\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.223 (0.000)\n",
      "MAE: 0.937 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.968 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.600 (0.000)\n",
      "MAE: 1.194 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.930 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  23.5977170308431\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.253 (0.000)\n",
      "MAE: 0.945 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.967 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.532 (0.000)\n",
      "MAE: 1.128 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.936 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.954300796985626\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.374 (0.000)\n",
      "MAE: 1.041 (0.000)\n",
      "MAPE: 0.024 (0.000)\n",
      "R2: 0.960 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.556 (0.000)\n",
      "MAE: 1.168 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.934 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  12.766860580444336\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.909 (0.000)\n",
      "MAE: 1.467 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.922 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.772 (0.000)\n",
      "MAE: 1.334 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.914 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/209/u/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/209/u/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/209/u/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>209</td>\n",
       "      <td>U</td>\n",
       "      <td>Chemical + Physical</td>\n",
       "      <td>(63190, 17)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_7</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>1.218463</td>\n",
       "      <td>0.923335</td>\n",
       "      <td>0.020812</td>\n",
       "      <td>0.968346</td>\n",
       "      <td>1.513492</td>\n",
       "      <td>1.126432</td>\n",
       "      <td>0.026494</td>\n",
       "      <td>0.937305</td>\n",
       "      <td>-3.398653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category Company Plant             Features   Data Shape Timesteps  \\\n",
       "6  Global Model     209     U  Chemical + Physical  (63190, 17)      None   \n",
       "\n",
       "   Model Model Params           Scaler Scaler Params  ...  \\\n",
       "6  MLP_7         None  Standard Scaler          None  ...   \n",
       "\n",
       "                 Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "6  {\"train_size\": 0.8, \"test_size\": 0.2}   1.218463  0.923335   0.020812   \n",
       "\n",
       "   R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "6  0.968346   1.513492  1.126432   0.026494  0.937305 -3.398653  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R²\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.02690008083979\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.220 (0.000)\n",
      "MAE: 0.924 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.967 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.220 (0.000)\n",
      "MAE: 0.924 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.967 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/209/mlp/u/pre_training/\\\"\\nmodel_name = \\\"mlp_full_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/209/mlp/u/pre_training/\\\"\\nmodel_name = \\\"mlp_full_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/209/mlp/u/pre_training/\"\n",
    "model_name = \"mlp_full_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcab4f2ec20>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcb6c593880>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyg0lEQVR4nO3de5DU1Z3H/c+v73PpnmGYuwwIqKAi1i5ryFQSlggRSMrCyB+JWhXctbR00Vo1V1K54W4Ky63amGwRsk/FR7JPBd2YEi2tVdcbUG6ADawUXhIiiILCcBmY6Zme6ft5/uiZhpbbzDDTZ+S8X1VdPd2/3/ScPvQ4H8/5nvPzjDFGAAAAZeKz3QAAAOAWwgcAACgrwgcAACgrwgcAACgrwgcAACgrwgcAACgrwgcAACgrwgcAACirgO0GfFI+n9fBgwcVjUbleZ7t5gAAgCEwxqinp0etra3y+c49tjHuwsfBgwfV1tZmuxkAAGAEDhw4oEmTJp3znHEXPqLRqKRC42OxmOXWAACAoYjH42prayv+HT+XcRc+BqdaYrEY4QMAgE+ZoZRMUHAKAADKivABAADKaljhY+3atZo9e3ZxSqS9vV0vvPBC8fj8+fPleV7J7e677x71RgMAgE+vYdV8TJo0SQ8//LAuv/xyGWP0m9/8RkuXLtWbb76pq6++WpJ055136qGHHip+T2Vl5ei2GAAAfKoNK3zceOONJY9/+tOfau3atdq6dWsxfFRWVqq5uXn0WggAAC4qI675yOVyevLJJ5VIJNTe3l58/re//a3q6+s1a9YsrVy5Un19fed8nVQqpXg8XnIDAAAXr2EvtX3rrbfU3t6uZDKp6upqbdiwQVdddZUk6dZbb9WUKVPU2tqqXbt26bvf/a52796tp59++qyvt3r1aq1atWrk7wAAAHyqeMYYM5xvSKfT2r9/v7q7u/X73/9ev/71r7Vp06ZiADnVa6+9pgULFmjPnj2aPn36GV8vlUoplUoVHw9uUtLd3c0+HwAAfErE43HV1NQM6e/3sMPHJy1cuFDTp0/Xv//7v592LJFIqLq6Wi+++KIWLVo0pNcbTuMBAMD4MJy/3xe8z0c+ny8ZuTjVzp07JUktLS0X+mMAAMBFYlg1HytXrtSSJUs0efJk9fT0aP369dq4caNeeukl7d27V+vXr9eXv/xlTZw4Ubt27dIDDzygefPmafbs2WPVfgAA8CkzrPBx5MgRfeMb39ChQ4dUU1Oj2bNn66WXXtKXvvQlHThwQK+88ooeffRRJRIJtbW1admyZfrBD34wVm0HAACfQhdc8zHaxqrm42hPSmte36NI0K/vLZk5aq8LAADKXPPxaRFPZrTuDx9o/bYPbTcFAACnORM+Bi/wO77GeQAAcI874cMrxA+yBwAAdjkTPnwDQx/jrMQFAADnOBM+vIGJlzzZAwAAq9wJH4MjH0y8AABglXPhg5EPAADscih8FIc+AACARc6EDx/TLgAAjAvOhA8KTgEAGB+cCR8stQUAYHxwJnyIglMAAMYFZ8KHV9xgHQAA2ORM+PCdkj2YegEAwB5nwkdxqa2YegEAwCZnwgcjHwAAjA/OhI9Taz4Y+QAAwB5nwsep9aZsNAYAgD3OhI/SaRd77QAAwHXOhI9TC04JHwAA2ONM+PAx7QIAwLjgTPg4teCUkQ8AAOxxJ3ycMvKRJ30AAGCNk+GD6AEAgD3uhI9Tp13yFhsCAIDjnAkfFJwCADA+OBM+WGoLAMD44E74OOVrCk4BALDHnfBBwSkAAOOCQ+Hj1AvLET8AALDFmfAhnTL6QfYAAMAap8KHbyB9kD0AALDHqfAxOPDBtAsAAPY4FT6KIx9kDwAArHEqfAwOfTDyAQCAPU6Fj2K9KdkDAABrnAofvlM3+wAAAFY4FT48pl0AALDOqfBBwSkAAPY5FT5YagsAgH1OhY/B9EH0AADAnmGFj7Vr12r27NmKxWKKxWJqb2/XCy+8UDyeTCa1YsUKTZw4UdXV1Vq2bJkOHz486o0eKaZdAACwb1jhY9KkSXr44Ye1Y8cObd++Xddff72WLl2qd955R5L0wAMP6LnnntNTTz2lTZs26eDBg7r55pvHpOEjMVhwakgfAABYExjOyTfeeGPJ45/+9Kdau3attm7dqkmTJumxxx7T+vXrdf3110uSHn/8cV155ZXaunWrPvvZz45eq0eIa7sAAGDfiGs+crmcnnzySSUSCbW3t2vHjh3KZDJauHBh8ZyZM2dq8uTJ2rJly1lfJ5VKKR6Pl9zGCpuMAQBg37DDx1tvvaXq6mqFw2Hdfffd2rBhg6666ip1dHQoFAqptra25PympiZ1dHSc9fVWr16tmpqa4q2trW3Yb2Ko2OcDAAD7hh0+ZsyYoZ07d2rbtm265557tHz5cr377rsjbsDKlSvV3d1dvB04cGDEr3U+HgWnAABYN6yaD0kKhUK67LLLJElz5szRH//4R/385z/X1772NaXTaXV1dZWMfhw+fFjNzc1nfb1wOKxwODz8lo8A+3wAAGDfBe/zkc/nlUqlNGfOHAWDQb366qvFY7t379b+/fvV3t5+oT9mVHBtFwAA7BvWyMfKlSu1ZMkSTZ48WT09PVq/fr02btyol156STU1Nbrjjjv04IMPqq6uTrFYTPfdd5/a29vHxUoX6dSltnbbAQCAy4YVPo4cOaJvfOMbOnTokGpqajR79my99NJL+tKXviRJ+tnPfiafz6dly5YplUpp0aJF+uUvfzkmDR8Jpl0AALBvWOHjscceO+fxSCSiNWvWaM2aNRfUqLHisc8HAADWOXVtF5baAgBgn1Phg2u7AABgn1Ph4+RiF9IHAAC2uBU+Bu7zZA8AAKxxKnww7QIAgH1OhQ9RcAoAgHVOhQ9GPgAAsM+p8DFY82EoOAUAwBq3wgfbqwMAYJ1T4YNpFwAA7HMqfAyi4BQAAHucCh9c2wUAAPucCh++Ys0H8QMAAFucCh8UnAIAYJ9T4aNYcMrECwAA1jgVPor7fJA9AACwxqnwMTjvwoXlAACwx6nwQcEpAAD2ORU+BqddGPkAAMAep8LHYMEpO30AAGCPU+GDpbYAANjnVvgQBacAANjmVvgYHPlg2gUAAGucDB+MfAAAYI9T4aO4wylFHwAAWONU+CgudgEAANa4FT6KBaeMfAAAYItb4YOltgAAWOdY+GCpLQAAtjkVPri2CwAA9jkVPthcHQAA+9wKHyy1BQDAOqfCh4+CUwAArHMqfAxOvJA9AACwx6nw4Stur078AADAFqfCB/t8AABgn1vhQxScAgBgm1PhwzfwbokeAADY41T4ODnyYbkhAAA4zK3wQcEpAADWDSt8rF69Wtddd52i0agaGxt10003affu3SXnzJ8/X57nldzuvvvuUW30SJ3cZMxyQwAAcNiwwsemTZu0YsUKbd26VS+//LIymYxuuOEGJRKJkvPuvPNOHTp0qHh75JFHRrXRIzW4vTojHwAA2BMYzskvvvhiyeN169apsbFRO3bs0Lx584rPV1ZWqrm5eXRaOIoG9/kAAAD2XFDNR3d3tySprq6u5Pnf/va3qq+v16xZs7Ry5Ur19fWd9TVSqZTi8XjJbaww7QIAgH3DGvk4VT6f1/3336/Pfe5zmjVrVvH5W2+9VVOmTFFra6t27dql7373u9q9e7eefvrpM77O6tWrtWrVqpE2Y1iYdgEAwL4Rh48VK1bo7bff1htvvFHy/F133VX8+pprrlFLS4sWLFigvXv3avr06ae9zsqVK/Xggw8WH8fjcbW1tY20WedUHPkYk1cHAABDMaLwce+99+r555/X5s2bNWnSpHOeO3fuXEnSnj17zhg+wuGwwuHwSJoxbCy1BQDAvmGFD2OM7rvvPm3YsEEbN27U1KlTz/s9O3fulCS1tLSMqIGjyce1XQAAsG5Y4WPFihVav369nn32WUWjUXV0dEiSampqVFFRob1792r9+vX68pe/rIkTJ2rXrl164IEHNG/ePM2ePXtM3sBweGK5CwAAtg0rfKxdu1ZSYSOxUz3++OO6/fbbFQqF9Morr+jRRx9VIpFQW1ubli1bph/84Aej1uALUZx2yTP0AQCALcOedjmXtrY2bdq06YIaNJYoOAUAwD6u7QIAAMrKqfBBwSkAAPY5FT4GC07JHgAA2ONW+CiOfBA/AACwxanw4ePaLgAAWOdU+BhkmHgBAMAap8LH4MgH23wAAGCPU+HDY7ULAADWuRU+Bu4pOAUAwB6nwofPx1JbAABscyp8MPIBAIB9boUPCk4BALDOsfBRuGfgAwAAe9wKHwP3XFgOAAB7nAofg/t8AAAAe5wKH1zbBQAA+xwLHxScAgBgm1vhY+Cea7sAAGCPW+FjIH0w8gEAgD1OhY/BglNKPgAAsMep8HFyrQvpAwAAW5wKH4PXdsnnLTcEAACHORU+BlFwCgCAPU6FD7ZXBwDAPqfCh499PgAAsM6p8ME+HwAA2OdW+GDaBQAA65wKHyf3+SB9AABgi1PhYxDRAwAAe5wKHxScAgBgn1Ph42TNB+kDAABb3AofA/dkDwAA7HEqfAxur85SWwAA7HEqfDDyAQCAfW6Fj2LBKekDAABbHAsfhXuyBwAA9rgVPsRSWwAAbHMqfPgGiz4oOAUAwBqnwgfTLgAA2OdY+KDgFAAA29wKHwP3RA8AAOwZVvhYvXq1rrvuOkWjUTU2Nuqmm27S7t27S85JJpNasWKFJk6cqOrqai1btkyHDx8e1UaPlMe1XQAAsG5Y4WPTpk1asWKFtm7dqpdfflmZTEY33HCDEolE8ZwHHnhAzz33nJ566ilt2rRJBw8e1M033zzqDR8JH9d2AQDAusBwTn7xxRdLHq9bt06NjY3asWOH5s2bp+7ubj322GNav369rr/+eknS448/riuvvFJbt27VZz/72dFr+Qh43vnPAQAAY+uCaj66u7slSXV1dZKkHTt2KJPJaOHChcVzZs6cqcmTJ2vLli1nfI1UKqV4PF5yGys+Ck4BALBuxOEjn8/r/vvv1+c+9znNmjVLktTR0aFQKKTa2tqSc5uamtTR0XHG11m9erVqamqKt7a2tpE2acjIHgAA2DPi8LFixQq9/fbbevLJJy+oAStXrlR3d3fxduDAgQt6vXMZLDglfAAAYM+waj4G3XvvvXr++ee1efNmTZo0qfh8c3Oz0um0urq6SkY/Dh8+rObm5jO+VjgcVjgcHkkzhm2w4JRpFwAA7BnWyIcxRvfee682bNig1157TVOnTi05PmfOHAWDQb366qvF53bv3q39+/ervb19dFp8AQav7UL0AADAnmGNfKxYsULr16/Xs88+q2g0WqzjqKmpUUVFhWpqanTHHXfowQcfVF1dnWKxmO677z61t7dbX+kisdQWAIDxYFjhY+3atZKk+fPnlzz/+OOP6/bbb5ck/exnP5PP59OyZcuUSqW0aNEi/fKXvxyVxl4oru0CAIB9wwofQxkxiEQiWrNmjdasWTPiRo0dpl0AALDNqWu7UHAKAIB9ToUPltoCAGCfU+GDglMAAOxzKnwUC07tNgMAAKe5FT7EtAsAALa5FT4oOAUAwDrHwgcjHwAA2OZW+Bi4Z+QDAAB7nAofvsF5FwAAYI1T4YPt1QEAsM/J8MG0CwAA9rgVPri2CwAA1rkVPhj5AADAOqfCh48tTgEAsM6p8EH2AADAPqfCh49pFwAArHMqfIhruwAAYJ1T4ePktAvpAwAAW5wKH4MFp/m85YYAAOAwp8IHm6sDAGCfU+GjOPJB0QcAANY4FT64tgsAAPY5FT4GUXAKAIA9ToWPk9MulhsCAIDDnAofTLsAAGCfU+FjcOTDkD4AALDGqfDBtV0AALDPrfAxcM/IBwAA9rgVPig4BQDAOsfCR+GekQ8AAOxxKnycLDi13BAAABzmVPgo1nxYbQUAAG5zK3ww7QIAgHVOhQ92OAUAwD6nwscgru0CAIA9ToUPn4+CUwAAbHMqfJzcZMxqMwAAcJpb4aO4vTrpAwAAW5wKHxScAgBgn1Phg2u7AABg37DDx+bNm3XjjTeqtbVVnufpmWeeKTl+++23y/O8ktvixYtHq70XhqvaAgBg3bDDRyKR0LXXXqs1a9ac9ZzFixfr0KFDxdsTTzxxQY0cLWyvDgCAfYHhfsOSJUu0ZMmSc54TDofV3Nw84kaNFe+Ur40xxavcAgCA8hmTmo+NGzeqsbFRM2bM0D333KPOzs6x+DHD5jslbFB0CgCAHcMe+TifxYsX6+abb9bUqVO1d+9eff/739eSJUu0ZcsW+f3+085PpVJKpVLFx/F4fLSbVHTqQEeh6JSRDwAAym3Uw8fXv/714tfXXHONZs+erenTp2vjxo1asGDBaeevXr1aq1atGu1mnJF3Sthg4AMAADvGfKnttGnTVF9frz179pzx+MqVK9Xd3V28HThwYMza4p3ybvNUnQIAYMWoj3x80kcffaTOzk61tLSc8Xg4HFY4HB7rZkj6ZMFpWX4kAAD4hGGHj97e3pJRjH379mnnzp2qq6tTXV2dVq1apWXLlqm5uVl79+7Vd77zHV122WVatGjRqDZ8JE4tOCV8AABgx7DDx/bt2/XFL36x+PjBBx+UJC1fvlxr167Vrl279Jvf/EZdXV1qbW3VDTfcoH/6p38q2+jGuZQUnFL1AQCAFcMOH/Pnzz/n9uQvvfTSBTVoLJUUnJI9AACwwq1ru5wy8kHBKQAAdjgbPogeAADY4VT4KCk4zVtsCAAADnMqfJQstWXsAwAAK9wKHyy1BQDAOqfCh4+CUwAArHMqfJSMfFhsBwAALnMqfEgnV7ww8AEAgB3uhY+B+3NtlAYAAMaOe+FjYOiD6AEAgB3OhY/BolMKTgEAsMO58DF4fReyBwAAdrgXPgYLTu02AwAAZzkbPvJ54gcAADa4Fz5KNlkHAADl5lz4oOAUAAC7nAsfxaW2ZA8AAKxwMHwU7skeAADY4V74GLhn2gUAADvcCx9MuwAAYJVz4cNXvLAc6QMAABucCx9c2wUAALvcCx8D9wx8AABgh3vhY2Dkg4JTAADscDB8FO7JHgAA2OFc+GCHUwAA7HIufHBtFwAA7HIvfDDtAgCAVc6FDx8FpwAAWOVc+BhE9AAAwA7nwodv4B2zwykAAHY4Fz4GC07zZA8AAKxwL3wUF7uQPgAAsMG58HGy4NRyQwAAcJRz4YNruwAAYJd74aO4zwfpAwAAGxwMH0y7AABgk3vhY+DeUHAKAIAVzoWPwYJTZl0AALDDufDBtV0AALDLwfAxMPLBtAsAAFYMO3xs3rxZN954o1pbW+V5np555pmS48YY/ehHP1JLS4sqKiq0cOFCvffee6PV3gs2WPNBwSkAAHYMO3wkEglde+21WrNmzRmPP/LII/rFL36hX/3qV9q2bZuqqqq0aNEiJZPJC27saGCpLQAAdgWG+w1LlizRkiVLznjMGKNHH31UP/jBD7R06VJJ0n/8x3+oqalJzzzzjL7+9a9fWGtHAQWnAADYNao1H/v27VNHR4cWLlxYfK6mpkZz587Vli1bzvg9qVRK8Xi85DaWiiMf1HwAAGDFqIaPjo4OSVJTU1PJ801NTcVjn7R69WrV1NQUb21tbaPZpNN4jHwAAGCV9dUuK1euVHd3d/F24MCBMf15FJwCAGDXqIaP5uZmSdLhw4dLnj98+HDx2CeFw2HFYrGS21ii4BQAALtGNXxMnTpVzc3NevXVV4vPxeNxbdu2Te3t7aP5o0asWHBquR0AALhq2Ktdent7tWfPnuLjffv2aefOnaqrq9PkyZN1//3365//+Z91+eWXa+rUqfrhD3+o1tZW3XTTTaPZ7hErXtuFkQ8AAKwYdvjYvn27vvjFLxYfP/jgg5Kk5cuXa926dfrOd76jRCKhu+66S11dXfr85z+vF198UZFIZPRafQFYagsAgF3DDh/z588/56iB53l66KGH9NBDD11Qw8bMwNAHBacAANhhfbVLuRWnXaj6AADACufCB9MuAADY5Vz48IrTLqQPAABscDZ8AAAAO5wLH4PTLox8AABgh3PhYxDZAwAAO5wLHxScAgBgl3Phg4JTAADsci98DNwTPQAAsMO58HFy2oX4AQCADc6Fj8FpF7IHAAB2OBg+BkY+LLcDAABXuRc+Bu4pOAUAwA73wgfTLgAAWOVc+KDgFAAAu5wLH8WRD7vNAADAWQ6GD3Y4BQDAJvfCx8A9BacAANjhXvhg5AMAAKucCx8+ru0CAIBVzoWPSMAvSUpl85ZbAgCAm5wLH1XhgCSpN5W13BIAANzkYPgojHz0ET4AALDCufBRGRoc+chZbgkAAG5yLnxUD458pBn5AADABufCx8mRD8IHAAA2OBc+BgtO+9JMuwAAYIOD4aMw7ZJg5AMAACscDB+FkY8ENR8AAFjhXvgYqPlIsNoFAAAr3AsfTLsAAGCVe+FjYOQjlc0rm2OLdQAAys298DFQ8yFJCVa8AABQds6Fj1DAp6C/cGlbpl4AACg/58KHdOpeH4QPAADKzc3wwfVdAACwxs3wwZVtAQCwxsnwMXh9FwpOAQAoPyfDB3t9AABgj5vhI8QW6wAA2DLq4eMnP/mJPM8ruc2cOXO0f8wFKV7fhZEPAADKLnD+U4bv6quv1iuvvHLyhwTG5MeM2MlpF2o+AAAotzFJBYFAQM3NzWPx0qPi5MXlGPkAAKDcxqTm47333lNra6umTZum2267Tfv37x+LHzNixWkXVrsAAFB2oz7yMXfuXK1bt04zZszQoUOHtGrVKn3hC1/Q22+/rWg0etr5qVRKqVSq+Dgej492k05TGWK1CwAAtox6+FiyZEnx69mzZ2vu3LmaMmWKfve73+mOO+447fzVq1dr1apVo92Mc6pme3UAAKwZ86W2tbW1uuKKK7Rnz54zHl+5cqW6u7uLtwMHDox1k1QZHtxenfABAEC5jXn46O3t1d69e9XS0nLG4+FwWLFYrOQ21qoHt1en5gMAgLIb9fDxrW99S5s2bdIHH3ygP/zhD/rqV78qv9+vW265ZbR/1IhVhhj5AADAllGv+fjoo490yy23qLOzUw0NDfr85z+vrVu3qqGhYbR/1IgVaz7Y5wMAgLIb9fDx5JNPjvZLjrpopPC2j/WmtOPD45ozpc5yiwAAcIeT13aZXFepeVc0KJs3Wv7//lH/39YPlcwwCgIAQDl4xhhjuxGnisfjqqmpUXd395gWn/anc/r7dX/Ulvc7JUmxSEDXz2zUpAmV8vs8+TxPfzujQTObo0pl8qqpDI5ZWwAA+LQbzt9vZ8OHJKWyOT2xbb/+n83v62B38pznTmuo0hdnNOqLMxp13dQJCgf8Y9o2AAA+TQgfw5TLG23/4Li2vN+pE4m0snmjrv6MXvvTEfWfYTqmMuTXzOaoqiNBVYf9mjShUp+/rF6fmVqnSJBQAgBwD+FjlCQzOaWyeUnSH/Yc0+u7j+j13Ud1tCd1xvNDAZ+mN1SrMuTXpROrNKO5Wlc0RTWjOarmWESe55Wz+QAAlA3hYwzl80Z/6ojrwPF+JVJZ9SQzeudgXG/sOaZD55i6iUYCuryxWtFIUBOrQ5rVWqPqcECRkF+tNRG11FaoKRpWwO9kDTAA4FOO8GGBMUbvH0vooxP96klmtPdIQn853KPdh3u071hCufz5u7ky5NffXFqn9mkT9ZmpE3RlS6y4IRoAAOMZ4WOcSWVzev9oQu8fTag/k9NHJ/r0p0NxZXJGvcmsDnb363A8qUyu9J/C86RoOKBoJKhYRVDRSEAN1WFNra/StIYqTW+o1rSGKkUjrMQBANg1nL/f/G91GYQDfl3ZEtOVLWf/x8jljf5yuEdb9nZqy/ud2nmgS0d7Uoons4ons/q4q/+s39sQDau1JiK/z9M1l9Tos9MmyufzNLmuUpc3VjOVAwAYVxj5GMeOJ9I60ZdWvD+jeLJQX9LRndT7xxLae6RX7x9LnLX4dVAk6NNVA9M3Qb+nq1trFKsIyOd5aoiGNb2hWjOaowoSUAAAF4CRj4tEXVVIdVWhc54TT2a072hCR3pSSmZy2vyXo3rvSK+MpL1HetWbyur/9ncVz39999HTXiMU8OnK5qjCAb98Pmn+jEZd3RpTLBJUTUVQTbGIKkIsIQYAjA5GPi5i+bzRvs6E3jkYVz5v1JPK6t2D3Upl8krn8jrSk9KfD8UVT57/6r4N0bAm11Vqcl2lWmoiigT9mlAZVGttRfEWiwRYTgwAjmLkA5Ikn8/T9IZqTW+oPus5xhjtP96ndw7GZYx0PJHSq38+oo7upOL9GXX1Z9SXzuloT0pHe1La8eGJs75WVciv1toKXVpfpSuaqtUci6ghGlFjLKzGaFjRSFCRoI/dYQHAcYx84Ly6+zI6cKJP+48Xbh3dSaWyOR3tSetQd78OdvXrRF9myK9XXx3W5LrCaEkk6FdDNKwrW2K6qiWqplhEAZ9PkaCPURQA+BRh5AOjqqYyqJrKGs26pOas5/Snczo4EET2HOnV3qO9OhJP6cjAiMnRnpTSucJuscd6UzrWmyqpRfmkSNCn+uqw6qvDxdqXiVUhTRi4b4xF1FAdVkO0cNzvI6gAwKcFIx8oC2OMMjmjRCqrj07068CJPh0aGEH56ES//nQort0dPepLn34tnfPx+zxNrAqpIVoII43RsEIBn1KZvGY0R3XNJTVqiIZVHw0rGqYuBQDGAiMfGHc8z1Mo4CkUKIxeXDPp9FGUfN4oncsrmzc63pvW0YERkhOJtDoTaZ1IpHU8kdaxRHpgNCWpzkRaubzRkZ7CKMv5hAI+NVSHVV8dKo6s1EdDmlhVGEHpSWXl9wr7pTTXRFRTEVQowDJkABhNhA+MGz6fp4ivUIxaHQ5o8sTK835PNpdXZzGMpHSkJ6kj8ZQyeSO/52nngRPadyyhY71p9aaySmfz+rir/5ybtn1SJOhTJOhXVSiglpqImmsiaopFVFsRlOdJQb+vUKvi91QZ8mv2pFrVV4dH3A8AcLEjfOBTLTDwh78pFjnvuf3pXLHe5FhvunDfc/Lx8URa0UhA/Zmc3v64u1hEm8zklczk1dWXGXJoCQd8qqkInnaLDYykHE+k1VITKe6nUh0JKBzwK5PLq7YyqOZYRD7Pk49aFgAXIcIHnFER8qutrlJtdecfUZEKW973JrOKJzNKZXPq7s/qcDypQ91JHYkn1TUQTtK5vA7Hk4XpokRae470KpXND3kq6FwmVoU0ZWKl6qrCqq0MqjocUCaXV11VSG11lYpFgvJ5UjZvlMnlFQ74NbE6pMsaqjXhPBvUAYAthA/gLPw+b2Clz/Au3JdIZXU8kVZ3f+aMt3Q2r9qKoD7o7NPeo71KpLJKpLJKZvMK+j0dT6SLFxnsHKh3GYnGaFgtNRHtPZpQJOjT5Y1RpXN5VYb8mjShUtFIQBVBvypCflUEC6Flcl2lIkG/aiuDaqgOU5wLYEwQPoBRVhUOqCocUNsIvz+XN+ruzyhvjDq6k9p/vE9dfRmd6Esrkcoq4PfpWG9KH53oV28yIyMp6PMp4PeUzOR0pKdw7NSRl96UdKy3c1jtqAz5VRnyK+j3KRTwKegv3EJ+T5Fg4VghuARO+bqw8+0lEypVEfTL7/MU8HvyeZ4CPq/4OBYJqqXm5FQZIQdwC+EDGGf8Pq94TZ/66vA591c5m95UVn853KPD3UlNbahSXzqnD44lVBnyK95fuEpyfyan/nROfemc+jNZdXQn9XFXvzI5o66+tPoGjo2ViqBfuXxhhKe+OqRw0K9YRVBXNFarL5NTKpPTxKqw8sbI86S6qsIqpbqqkCZUhnQ8kVZ/Jqe2ukLQkQpLuo2kqlBAlzdVK+j3KZvPs6suMM6wzweA06SyOR3qSiqVzSudLVwLKDNwS2XyheAyEF76M4WQkszk1JfO6lhPWge7+5XO5pXLG+XyRtnifeG5rr6Msvmx/U+P3+cpb4yMKdTOBPye0tm8Mjmj6nBADdGwJlaH1JfKKZ7MqK4qVLz6c9DvU2M0rOaaiE70pZXO5uX3+VRfHVIk6JfnSdFIYToum8urIRou1AilsppYFdal9ZVqjkWKRcsTKoOM7uCixz4fAC5IOODXpfVVY/b6g0ueQwGfjDE61ptWJpfXkXhKe470qjoSUCToU2dvWn6fJ2NMof5lYFXS8URaE6qCigT8OnCiT5mckSdJA3/fTyTSJVv+f7JupjeVVUc8OWbvTyrsKZPOFnb1DfgKU08lPMnnqbCqyStMR7VNqFRtZVCp7Mmwl80ZVYQKS72rwv7CtF6oMLVXHfYrlc3rWG9K4YBf0Uhg4BZU0O9TLp9XfXVYkyYUwlBXf6FfUpmcQgGfKkMnp8wkqTeZVUtt5JwjRfm8GfIqrOGcC7cQPgCUXSjg09RTws2kCUNbgTRUxhgdjqfk93kK+j0d7Eoqb4zCA7UrPcmsjvYmdbQnpcpQQLGKoI4nUupP55XNF0Z7DnYldbQ3pbrKoCIhv9LZvI72pJTJ5WWMFE9m5KlQx3KkJym/z6fqsF+dvWl9eLyvGDwkDYzynH+kp6uve1T7YSRCfp/a6ioKK6gGRr1Ojn4VRrAmVAbVGI3IP1DHY2SUyRqFAoX6oGQmp4+7+tWTzKptQoXqq8MDYSlQcimEwatlhwI+fXSiTx+fKATSSNBfuA38ewX8PgUG6oWKX/sKI1SD/8YBn09+v6f+dE69yazqqkIKBXzKG6OmWKT47ze42u1oT0oN0bCMjI71pFUR8ikWCSoaCSoaCRRXrx1PpOTzPDVEwzqRyCidyykWCeqSCRXy5Onjrn75fV6heDvoVyTkkzGFpf2eVxiBC/h8Cgd8xSDWk8yoP53TxOqwMgOXnYgE3ZoaJHwAuOh4nqfmUwpaayvPtOx4+LU0Q5XM5NTRnVRzTUSeJ51IZGQ+ET6MUXFaKJc3SmZz2t/Zp0Q6q5DfX5j+Cfjk97yBqa2selM5JVJZ9aVOfh3we2qMRpTK5tSTzKonmVFPMjuw0Z6KBcjd/RmFA4VrJoWDhVGZkzU/hdqecMCnVDavvUcT53x/J/oyQ76Y5Aedffqgs29kHTnOeV7h33GoIsGT4feTaiuDCvl9JZ+SoM9TbWWoOKXXn8nJ53mqCPkUCRQCWiqb04edfZoysVKzJ9WqszeljnhKqUxOkycWluNncnl19qZlZBQJ+hUO+HRJbYVWLZ114Z0wQoQPABhlkWDptFVzzdD+r3Zm89jVuSUzOYUDZ75adD5fiEY+T/qws08Hu/uLo0SDK51CA1/7PE9He1LqTKSUHwhQUmHEJJXNKZ01Cgd9ao5FFKsIan9nn7r70+pJFpaUD6wilzFGB7uSOtjVr0wur8ZYRFMmViqXN0plckpm80pmcgPTT0bZgUsvZHOF2qHBrzODz+cL51SGClNTpy5Z7+juV9BfCF4HThSCUFMsoqM9KXme1FAdVrIY3rLFQuiqkF911SHlckZHe1OaUBlSOOhTVyKjnlRWxhR2Y/Yk9WVyxe87+79BYcNC6fTg0nWWMHewe2jTg3853Ku/HO4tee79Y2cPkdMbxm5adSgIHwDggHMN659al3FpfdV5630aokO/fMAltRVDPnc8MMYURxjO1WddfWnlTWkxcSZXKMYeDCWSCkEpZ4oF2qlsTo2xiKpChYAUDvqUH7g+VXYgLA3mw1Q2r66+tIJ+38DS90BxlCyZKdx8nqdJEyr17qG4PjyWUEM0rKaaiMIBnz7s7FNfOie/J9VHw/J5nlLZnJKZQkizidUuAADggg3n7zeX6wQAAGVF+AAAAGVF+AAAAGVF+AAAAGVF+AAAAGVF+AAAAGVF+AAAAGVF+AAAAGVF+AAAAGVF+AAAAGVF+AAAAGVF+AAAAGVF+AAAAGUVsN2ATxq8yG48HrfcEgAAMFSDf7cH/46fy7gLHz09PZKktrY2yy0BAADD1dPTo5qamnOe45mhRJQyyufzOnjwoKLRqDzPG9XXjsfjamtr04EDBxSLxUb1tS829NXw0F9DR18ND/01dPTV0I1FXxlj1NPTo9bWVvl8567qGHcjHz6fT5MmTRrTnxGLxfhgDhF9NTz019DRV8NDfw0dfTV0o91X5xvxGETBKQAAKCvCBwAAKCunwkc4HNaPf/xjhcNh200Z9+ir4aG/ho6+Gh76a+joq6Gz3VfjruAUAABc3Jwa+QAAAPYRPgAAQFkRPgAAQFkRPgAAQFk5Ez7WrFmjSy+9VJFIRHPnztX//u//2m7SuPCTn/xEnueV3GbOnFk8nkwmtWLFCk2cOFHV1dVatmyZDh8+bLHF5bN582bdeOONam1tled5euaZZ0qOG2P0ox/9SC0tLaqoqNDChQv13nvvlZxz/Phx3XbbbYrFYqqtrdUdd9yh3t7eMr6L8jhfX91+++2nfc4WL15cco4rfbV69Wpdd911ikajamxs1E033aTdu3eXnDOU37v9+/frK1/5iiorK9XY2Khvf/vbymaz5XwrZTGU/po/f/5pn6+777675BwX+mvt2rWaPXt2ceOw9vZ2vfDCC8Xj4+lz5UT4+M///E89+OCD+vGPf6z/+7//07XXXqtFixbpyJEjtps2Llx99dU6dOhQ8fbGG28Ujz3wwAN67rnn9NRTT2nTpk06ePCgbr75ZoutLZ9EIqFrr71Wa9asOePxRx55RL/4xS/0q1/9Stu2bVNVVZUWLVqkZDJZPOe2227TO++8o5dfflnPP/+8Nm/erLvuuqtcb6FsztdXkrR48eKSz9kTTzxRctyVvtq0aZNWrFihrVu36uWXX1Ymk9ENN9ygRCJRPOd8v3e5XE5f+cpXlE6n9Yc//EG/+c1vtG7dOv3oRz+y8ZbG1FD6S5LuvPPOks/XI488UjzmSn9NmjRJDz/8sHbs2KHt27fr+uuv19KlS/XOO+9IGmefK+OAz3zmM2bFihXFx7lczrS2tprVq1dbbNX48OMf/9hce+21ZzzW1dVlgsGgeeqpp4rP/elPfzKSzJYtW8rUwvFBktmwYUPxcT6fN83NzeZf/uVfis91dXWZcDhsnnjiCWOMMe+++66RZP74xz8Wz3nhhReM53nm448/Llvby+2TfWWMMcuXLzdLly496/e42lfGGHPkyBEjyWzatMkYM7Tfu//6r/8yPp/PdHR0FM9Zu3aticViJpVKlfcNlNkn+8sYY/72b//W/OM//uNZv8fl/powYYL59a9/Pe4+Vxf9yEc6ndaOHTu0cOHC4nM+n08LFy7Uli1bLLZs/HjvvffU2tqqadOm6bbbbtP+/fslSTt27FAmkynpu5kzZ2ry5MnO992+ffvU0dFR0jc1NTWaO3dusW+2bNmi2tpa/c3f/E3xnIULF8rn82nbtm1lb7NtGzduVGNjo2bMmKF77rlHnZ2dxWMu91V3d7ckqa6uTtLQfu+2bNmia665Rk1NTcVzFi1apHg8Xvy/3IvVJ/tr0G9/+1vV19dr1qxZWrlypfr6+orHXOyvXC6nJ598UolEQu3t7ePuczXuLiw32o4dO6ZcLlfSmZLU1NSkP//5z5ZaNX7MnTtX69at04wZM3To0CGtWrVKX/jCF/T222+ro6NDoVBItbW1Jd/T1NSkjo4OOw0eJwbf/5k+V4PHOjo61NjYWHI8EAiorq7Ouf5bvHixbr75Zk2dOlV79+7V97//fS1ZskRbtmyR3+93tq/y+bzuv/9+fe5zn9OsWbMkaUi/dx0dHWf87A0eu1idqb8k6dZbb9WUKVPU2tqqXbt26bvf/a52796tp59+WpJb/fXWW2+pvb1dyWRS1dXV2rBhg6666irt3LlzXH2uLvrwgXNbsmRJ8evZs2dr7ty5mjJlin73u9+poqLCYstwMfn6179e/Pqaa67R7NmzNX36dG3cuFELFiyw2DK7VqxYobfffrukzgpnd7b+OrU26JprrlFLS4sWLFigvXv3avr06eVuplUzZszQzp071d3drd///vdavny5Nm3aZLtZp7nop13q6+vl9/tPq+g9fPiwmpubLbVq/KqtrdUVV1yhPXv2qLm5Wel0Wl1dXSXn0Hcqvv9zfa6am5tPK2rOZrM6fvy48/03bdo01dfXa8+ePZLc7Kt7771Xzz//vF5//XVNmjSp+PxQfu+am5vP+NkbPHYxOlt/ncncuXMlqeTz5Up/hUIhXXbZZZozZ45Wr16ta6+9Vj//+c/H3efqog8foVBIc+bM0auvvlp8Lp/P69VXX1V7e7vFlo1Pvb292rt3r1paWjRnzhwFg8GSvtu9e7f279/vfN9NnTpVzc3NJX0Tj8e1bdu2Yt+0t7erq6tLO3bsKJ7z2muvKZ/PF//j6KqPPvpInZ2damlpkeRWXxljdO+992rDhg167bXXNHXq1JLjQ/m9a29v11tvvVUS2F5++WXFYjFdddVV5XkjZXK+/jqTnTt3SlLJ58uV/vqkfD6vVCo1/j5Xo1q+Ok49+eSTJhwOm3Xr1pl3333X3HXXXaa2trakotdV3/zmN83GjRvNvn37zP/8z/+YhQsXmvr6enPkyBFjjDF33323mTx5snnttdfM9u3bTXt7u2lvb7fc6vLo6ekxb775pnnzzTeNJPOv//qv5s033zQffvihMcaYhx9+2NTW1ppnn33W7Nq1yyxdutRMnTrV9Pf3F19j8eLF5q/+6q/Mtm3bzBtvvGEuv/xyc8stt9h6S2PmXH3V09NjvvWtb5ktW7aYffv2mVdeecX89V//tbn88stNMpksvoYrfXXPPfeYmpoas3HjRnPo0KHira+vr3jO+X7vstmsmTVrlrnhhhvMzp07zYsvvmgaGhrMypUrbbylMXW+/tqzZ4956KGHzPbt282+ffvMs88+a6ZNm2bmzZtXfA1X+ut73/ue2bRpk9m3b5/ZtWuX+d73vmc8zzP//d//bYwZX58rJ8KHMcb827/9m5k8ebIJhULmM5/5jNm6davtJo0LX/va10xLS4sJhULmkksuMV/72tfMnj17isf7+/vNP/zDP5gJEyaYyspK89WvftUcOnTIYovL5/XXXzeSTrstX77cGFNYbvvDH/7QNDU1mXA4bBYsWGB2795d8hqdnZ3mlltuMdXV1SYWi5m/+7u/Mz09PRbezdg6V1/19fWZG264wTQ0NJhgMGimTJli7rzzztPCvyt9daZ+kmQef/zx4jlD+b374IMPzJIlS0xFRYWpr6833/zmN00mkynzuxl75+uv/fv3m3nz5pm6ujoTDofNZZddZr797W+b7u7uktdxob/+/u//3kyZMsWEQiHT0NBgFixYUAwexoyvz5VnjDGjO5YCAABwdhd9zQcAABhfCB8AAKCsCB8AAKCsCB8AAKCsCB8AAKCsCB8AAKCsCB8AAKCsCB8AAKCsCB8AAKCsCB8AAKCsCB8AAKCsCB8AAKCs/n9V8D+q2mSWTwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc9f7660dc0>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc9c2a624a0>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 256)               4608      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 16)                64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50369 (196.75 KB)\n",
      "Trainable params: 49377 (192.88 KB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
