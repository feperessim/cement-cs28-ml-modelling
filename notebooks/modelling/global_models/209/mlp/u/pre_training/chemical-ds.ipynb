{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 01:21:53.081784: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-28 01:21:53.086591: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-28 01:21:53.180518: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-28 01:21:53.182425: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-28 01:21:54.669708: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/206/mlp/b/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 2\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 2\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 2\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"U\\\",\\n    \\\"Features\\\": \\\"Chemical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"U\\\",\\n    \\\"Features\\\": \\\"Chemical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"209\",\n",
    "    \"Plant\": \"U\",\n",
    "    \"Features\": \"Chemical\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/209/global_u.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/209/global_u.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/209/global_u.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Cement_Type\\\",\\n        \\\"Factory_Plant\\\",\\n        \\\"Blaine\\\",\\n        \\\"#200\\\",\\n        \\\"#325\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        #  \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Cement_Type\\\",\\n        \\\"Factory_Plant\\\",\\n        \\\"Blaine\\\",\\n        \\\"#200\\\",\\n        \\\"#325\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        #  \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop(\n",
    "    [\n",
    "        \"Cement_Type\",\n",
    "        \"Factory_Plant\",\n",
    "        \"Blaine\",\n",
    "        \"#200\",\n",
    "        \"#325\",\n",
    "        \"Final setting time\",\n",
    "        \"Initial setting time\",\n",
    "        #  \"CS1\",\n",
    "        \"CS3\",\n",
    "        \"CS7\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 01:21:59.067075: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  9.076904304822285\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.234 (0.000)\n",
      "MAE: 1.648 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.894 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.933 (0.000)\n",
      "MAE: 2.103 (0.000)\n",
      "MAPE: 0.050 (0.000)\n",
      "R2: 0.765 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  8.739706349372863\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.208 (0.000)\n",
      "MAE: 1.616 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.896 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.598 (0.000)\n",
      "MAE: 1.903 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.815 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  12.092082850138347\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.040 (0.000)\n",
      "MAE: 1.516 (0.000)\n",
      "MAPE: 0.035 (0.000)\n",
      "R2: 0.911 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.742 (0.000)\n",
      "MAE: 1.988 (0.000)\n",
      "MAPE: 0.048 (0.000)\n",
      "R2: 0.794 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.186359135309855\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.904 (0.000)\n",
      "MAE: 1.395 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.923 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.711 (0.000)\n",
      "MAE: 1.892 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.799 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  16.476569469769796\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.950 (0.000)\n",
      "MAE: 1.419 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.919 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.719 (0.000)\n",
      "MAE: 1.910 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.798 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.47410343885422\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.016 (0.000)\n",
      "MAE: 1.456 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.913 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.578 (0.000)\n",
      "MAE: 1.842 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.818 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  24.34307813247045\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.914 (0.000)\n",
      "MAE: 1.404 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.922 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.617 (0.000)\n",
      "MAE: 1.867 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.813 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  12.305491630236308\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.944 (0.000)\n",
      "MAE: 1.414 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.919 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.629 (0.000)\n",
      "MAE: 1.850 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.811 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  19.058830165863036\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.923 (0.000)\n",
      "MAE: 1.448 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.921 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.809 (0.000)\n",
      "MAE: 2.012 (0.000)\n",
      "MAPE: 0.049 (0.000)\n",
      "R2: 0.784 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  18.78923435608546\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.873 (0.000)\n",
      "MAE: 1.365 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.925 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.675 (0.000)\n",
      "MAE: 1.872 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.804 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  22.087166023254394\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.985 (0.000)\n",
      "MAE: 1.439 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.916 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.600 (0.000)\n",
      "MAE: 1.854 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.815 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.842435669898986\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.155 (0.000)\n",
      "MAE: 1.573 (0.000)\n",
      "MAPE: 0.036 (0.000)\n",
      "R2: 0.901 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.669 (0.000)\n",
      "MAE: 1.912 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.805 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  12.31801464955012\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.390 (0.000)\n",
      "MAE: 1.731 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.878 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.650 (0.000)\n",
      "MAE: 1.893 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.808 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/209/u/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/209/u/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/209/u/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>209</td>\n",
       "      <td>U</td>\n",
       "      <td>Chemical</td>\n",
       "      <td>(63190, 10)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_6</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>2.015673</td>\n",
       "      <td>1.456277</td>\n",
       "      <td>0.032893</td>\n",
       "      <td>0.913376</td>\n",
       "      <td>2.57767</td>\n",
       "      <td>1.8416</td>\n",
       "      <td>0.043598</td>\n",
       "      <td>0.818143</td>\n",
       "      <td>-4.331761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category Company Plant  Features   Data Shape Timesteps  Model  \\\n",
       "5  Global Model     209     U  Chemical  (63190, 10)      None  MLP_6   \n",
       "\n",
       "  Model Params           Scaler Scaler Params  ...  \\\n",
       "5         None  Standard Scaler          None  ...   \n",
       "\n",
       "                 Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "5  {\"train_size\": 0.8, \"test_size\": 0.2}   2.015673  1.456277   0.032893   \n",
       "\n",
       "   R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "5  0.913376    2.57767    1.8416   0.043598  0.818143 -4.331761  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  26.390289409955344\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.986 (0.000)\n",
      "MAE: 1.449 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.913 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.986 (0.000)\n",
      "MAE: 1.449 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.913 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/209/mlp/u/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/209/mlp/u/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/209/mlp/u/pre_training/\"\n",
    "model_name = \"mlp_chemical_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x73b68e7edfc0>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x73b68e6da080>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x73b68e570610>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x73b68e5d26b0>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 256)               2816      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 16)                64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48577 (189.75 KB)\n",
      "Trainable params: 47585 (185.88 KB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
