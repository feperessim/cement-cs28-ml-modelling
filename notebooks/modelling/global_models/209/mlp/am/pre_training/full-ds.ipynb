{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 23:59:24.479480: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-21 23:59:24.484265: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-21 23:59:24.585559: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-21 23:59:24.588525: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-21 23:59:26.524352: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/206/mlp/b/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 1\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 1\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 1\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"AM\\\",\\n    \\\"Features\\\": \\\"Chemical + Physical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"AM\\\",\\n    \\\"Features\\\": \\\"Chemical + Physical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"209\",\n",
    "    \"Plant\": \"AM\",\n",
    "    \"Features\": \"Chemical + Physical\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/209/global_am.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/209/global_am.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/209/global_am.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0e341_row0_col0, #T_0e341_row1_col0, #T_0e341_row2_col0, #T_0e341_row3_col0, #T_0e341_row4_col0, #T_0e341_row5_col0, #T_0e341_row6_col0, #T_0e341_row7_col0, #T_0e341_row8_col0, #T_0e341_row9_col0, #T_0e341_row10_col0, #T_0e341_row11_col0, #T_0e341_row12_col0, #T_0e341_row13_col0, #T_0e341_row14_col0, #T_0e341_row15_col0, #T_0e341_row16_col0 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0e341\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0e341_level0_col0\" class=\"col_heading level0 col0\" >Zero (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0e341_level0_row0\" class=\"row_heading level0 row0\" >CaO</th>\n",
       "      <td id=\"T_0e341_row0_col0\" class=\"data row0 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e341_level0_row1\" class=\"row_heading level0 row1\" >Insoluble Residue</th>\n",
       "      <td id=\"T_0e341_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e341_level0_row2\" class=\"row_heading level0 row2\" >CS7</th>\n",
       "      <td id=\"T_0e341_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e341_level0_row3\" class=\"row_heading level0 row3\" >CS3</th>\n",
       "      <td id=\"T_0e341_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e341_level0_row4\" class=\"row_heading level0 row4\" >Final setting time</th>\n",
       "      <td id=\"T_0e341_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e341_level0_row5\" class=\"row_heading level0 row5\" >Initial setting time</th>\n",
       "      <td id=\"T_0e341_row5_col0\" class=\"data row5 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e341_level0_row6\" class=\"row_heading level0 row6\" >#325</th>\n",
       "      <td id=\"T_0e341_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e341_level0_row7\" class=\"row_heading level0 row7\" >Blaine</th>\n",
       "      <td id=\"T_0e341_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e341_level0_row8\" class=\"row_heading level0 row8\" >Loss on Ignition</th>\n",
       "      <td id=\"T_0e341_row8_col0\" class=\"data row8 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e341_level0_row9\" class=\"row_heading level0 row9\" >MgO</th>\n",
       "      <td id=\"T_0e341_row9_col0\" class=\"data row9 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e341_level0_row10\" class=\"row_heading level0 row10\" >Fe2O3</th>\n",
       "      <td id=\"T_0e341_row10_col0\" class=\"data row10 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e341_level0_row11\" class=\"row_heading level0 row11\" >K2O</th>\n",
       "      <td id=\"T_0e341_row11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e341_level0_row12\" class=\"row_heading level0 row12\" >SO3</th>\n",
       "      <td id=\"T_0e341_row12_col0\" class=\"data row12 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e341_level0_row13\" class=\"row_heading level0 row13\" >SiO2</th>\n",
       "      <td id=\"T_0e341_row13_col0\" class=\"data row13 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e341_level0_row14\" class=\"row_heading level0 row14\" >Al2O3</th>\n",
       "      <td id=\"T_0e341_row14_col0\" class=\"data row14 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e341_level0_row15\" class=\"row_heading level0 row15\" >Na2O</th>\n",
       "      <td id=\"T_0e341_row15_col0\" class=\"data row15 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e341_level0_row16\" class=\"row_heading level0 row16\" >CS28</th>\n",
       "      <td id=\"T_0e341_row16_col0\" class=\"data row16 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x79c4ee710280>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_formatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_values = {}\n",
    "for col in df.select_dtypes(include=\"number\").columns:\n",
    "    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\n",
    "    zero_values[col] = zero_percentages\n",
    "\n",
    "zero_percentages = pd.Series(zero_values, name=f\"Zero (%)\")\n",
    "zero_percentages = zero_percentages.sort_values(ascending=False)\n",
    "zero_percentages = zero_percentages.to_frame(name=f\"Zero (%)\")\n",
    "zero_percentages.style.background_gradient(cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop([\\\"Cement_Type\\\", \\\"Factory_Plant\\\"], axis=1)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop([\\\"Cement_Type\\\", \\\"Factory_Plant\\\"], axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop([\"Cement_Type\", \"Factory_Plant\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 23:59:32.743392: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  11.223295795917512\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.327 (0.000)\n",
      "MAE: 1.010 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.962 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.647 (0.000)\n",
      "MAE: 1.247 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.924 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  11.555098783969878\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.368 (0.000)\n",
      "MAE: 1.037 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.960 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.583 (0.000)\n",
      "MAE: 1.186 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.930 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.90670379002889\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.408 (0.000)\n",
      "MAE: 1.101 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.958 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.743 (0.000)\n",
      "MAE: 1.340 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.915 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  19.323311789830527\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.326 (0.000)\n",
      "MAE: 1.021 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.962 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.672 (0.000)\n",
      "MAE: 1.264 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.922 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  21.395629107952118\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.298 (0.000)\n",
      "MAE: 0.988 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.964 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.557 (0.000)\n",
      "MAE: 1.161 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.932 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  29.433163114388783\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.285 (0.000)\n",
      "MAE: 0.975 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.965 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.535 (0.000)\n",
      "MAE: 1.136 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.934 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.979296203454336\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.253 (0.000)\n",
      "MAE: 0.948 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.966 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.523 (0.000)\n",
      "MAE: 1.136 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.935 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.278921798865001\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.259 (0.000)\n",
      "MAE: 0.959 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.966 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.575 (0.000)\n",
      "MAE: 1.180 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.931 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  22.128353289763133\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.547 (0.000)\n",
      "MAE: 1.208 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.949 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.936 (0.000)\n",
      "MAE: 1.508 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.895 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  22.065547859668733\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.309 (0.000)\n",
      "MAE: 0.998 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.963 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.569 (0.000)\n",
      "MAE: 1.175 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.931 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  22.761227413018545\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.276 (0.000)\n",
      "MAE: 0.971 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.965 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.498 (0.000)\n",
      "MAE: 1.117 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.937 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  13.795143735408782\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.394 (0.000)\n",
      "MAE: 1.055 (0.000)\n",
      "MAPE: 0.024 (0.000)\n",
      "R2: 0.958 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.554 (0.000)\n",
      "MAE: 1.155 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.933 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.183435984452565\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.501 (0.000)\n",
      "MAE: 1.132 (0.000)\n",
      "MAPE: 0.025 (0.000)\n",
      "R2: 0.952 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.563 (0.000)\n",
      "MAE: 1.166 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.932 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/209/am/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/209/am/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/209/am/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>209</td>\n",
       "      <td>AM</td>\n",
       "      <td>Chemical + Physical</td>\n",
       "      <td>(60402, 16)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_11</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>1.275554</td>\n",
       "      <td>0.970792</td>\n",
       "      <td>0.021864</td>\n",
       "      <td>0.965203</td>\n",
       "      <td>1.497813</td>\n",
       "      <td>1.116662</td>\n",
       "      <td>0.026283</td>\n",
       "      <td>0.937313</td>\n",
       "      <td>-3.720416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category Company Plant             Features   Data Shape Timesteps  \\\n",
       "10  Global Model     209    AM  Chemical + Physical  (60402, 16)      None   \n",
       "\n",
       "     Model Model Params           Scaler Scaler Params  ...  \\\n",
       "10  MLP_11         None  Standard Scaler          None  ...   \n",
       "\n",
       "                  Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "10  {\"train_size\": 0.8, \"test_size\": 0.2}   1.275554  0.970792   0.021864   \n",
       "\n",
       "    R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "10  0.965203   1.497813  1.116662   0.026283  0.937313 -3.720416  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  33.424264045556384\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.270 (0.000)\n",
      "MAE: 0.965 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.964 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.270 (0.000)\n",
      "MAE: 0.965 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.964 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/209/mlp/am/pre_training/\\\"\\nmodel_name = \\\"mlp_full_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/209/mlp/am/pre_training/\\\"\\nmodel_name = \\\"mlp_full_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/209/mlp/am/pre_training/\"\n",
    "model_name = \"mlp_full_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x79c29bf18820>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x79c266bc9c30>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyx0lEQVR4nO3de3DU133//9dnr7ruCkkISUZgboHYGNpSh+jrxnUM4ZKMB8fMNHE8E7v12F+72FObXMnkZrcZPO78EicdQvqbeEz6nRC3zgT7a39ru74EMWmAGmq++JIQINiAkQQWSCuttPfz/WOlBZmbVkh7ZM7zMdlZ7X4+2j37yRK9cs77nOMZY4wAAABKxGe7AQAAwC2EDwAAUFKEDwAAUFKEDwAAUFKEDwAAUFKEDwAAUFKEDwAAUFKEDwAAUFIB2w34oFwup2PHjqm6ulqe59luDgAAGAFjjHp7e9Xc3Cyf78J9GxMufBw7dkwtLS22mwEAAEbhyJEjmjp16gXPmXDho7q6WlK+8ZFIxHJrAADASMRiMbW0tBT+jl/IhAsfQ0MtkUiE8AEAwIfMSEomKDgFAAAlRfgAAAAlRfgAAAAlRfgAAAAlRfgAAAAlRfgAAAAlRfgAAAAlRfgAAAAlRfgAAAAlVVT42LhxoxYsWFBYfbS1tVXPP/984fgNN9wgz/OG3e65554xbzQAAPjwKmp59alTp+qRRx7RnDlzZIzRz372M61atUqvv/66rr76aknSXXfdpYcffrjwOxUVFWPbYgAA8KFWVPi46aabhj3+3ve+p40bN2rHjh2F8FFRUaHGxsaxayEAALisjLrmI5vN6sknn1Q8Hldra2vh+Z///Oeqr6/X/PnztW7dOvX391/wdZLJpGKx2LDbeDjRm9R3//dbeuT534/L6wMAgJEpelfbN954Q62trUokEqqqqtKWLVt01VVXSZK+8IUvaPr06WpubtbevXv1ta99Tfv27dOvfvWr877e+vXr9dBDD43+E4xQLJHWpt++o0hZQF9fOW/c3w8AAJybZ4wxxfxCKpXS4cOH1dPTo1/+8pf66U9/qra2tkIAOdOrr76qJUuW6MCBA5o1a9Y5Xy+ZTCqZTBYex2IxtbS0qKenR5FIpMiPc35/PNGnG/+/NlWHA3rjoeVj9roAACD/9zsajY7o73fRPR+hUEizZ8+WJC1atEivvfaafvjDH+qf//mfzzp38eLFknTB8BEOhxUOh4ttRtF8nidJKippAQCAMXfJ63zkcrlhPRdn2rNnjySpqanpUt/mkg1mD+WK6+gBAABjrKiej3Xr1mnlypWaNm2aent7tXnzZm3dulUvvviiDh48qM2bN+vTn/606urqtHfvXj344IO6/vrrtWDBgvFq/4h5Guz5IHsAAGBVUeHj+PHj+uIXv6j29nZFo1EtWLBAL774oj71qU/pyJEjevnll/XYY48pHo+rpaVFq1ev1je/+c3xantRhno+DAMvAABYVVT4ePzxx897rKWlRW1tbZfcoPFyetjFbjsAAHCdM3u7+E53fQAAAIucCR8UnAIAMDE4Ez6YagsAwMTgTPgY7Pig5wMAAMucCR9D6YPsAQCAXc6Ej0LBqaQiV5QHAABjyJnw4Z3xM9kDAAB7nAkfw3o+LLYDAADXORM+zsgeFJ0CAGCRQ+HjzJoPiw0BAMBxDoWP0z/T8wEAgD3uhA/bDQAAAJIcCh8+hl0AAJgQnAkfDLsAADAxOBM+mGoLAMDE4Ez4OBM9HwAA2ONM+KDmAwCAicGZ8HFmzQd7uwAAYI874eOMn8keAADY40z4oOAUAICJwZnwwVRbAAAmBofCBwWnAABMBM6ED+l07wcFpwAA2ONU+Biq+yB6AABgj1PhY2jghY4PAADscSt8DKYPCk4BALDHsfDBsAsAALa5FT4G73M54gcAALY4FT7OXGgMAADY4VT4oOYDAAD7nAofham2ZA8AAKxxKnwUptpabQUAAG5zKnyIYRcAAKxzKnww7AIAgH1OhQ/2dgEAwD6nwgd7uwAAYJ9T4aOwyBg9HwAAWONW+KDmAwAA6xwLH/l7wgcAAPa4FT4G7xl2AQDAnqLCx8aNG7VgwQJFIhFFIhG1trbq+eefLxxPJBJas2aN6urqVFVVpdWrV6uzs3PMGz1a7O0CAIB9RYWPqVOn6pFHHtHu3bu1a9cu3XjjjVq1apXeeustSdKDDz6oZ599Vk899ZTa2tp07Ngx3XLLLePS8NFgbxcAAOwLFHPyTTfdNOzx9773PW3cuFE7duzQ1KlT9fjjj2vz5s268cYbJUlPPPGEPvrRj2rHjh36+Mc/PnatHiUWGQMAwL5R13xks1k9+eSTisfjam1t1e7du5VOp7V06dLCOfPmzdO0adO0ffv2875OMplULBYbdhtv9HwAAGBP0eHjjTfeUFVVlcLhsO655x5t2bJFV111lTo6OhQKhVRTUzPs/ClTpqijo+O8r7d+/XpFo9HCraWlpegPMVK+wU9L9AAAwJ6iw8fcuXO1Z88e7dy5U/fee69uv/12vf3226NuwLp169TT01O4HTlyZNSvdTGeGHYBAMC2omo+JCkUCmn27NmSpEWLFum1117TD3/4Q33uc59TKpVSd3f3sN6Pzs5ONTY2nvf1wuGwwuFw8S0fBfZ2AQDAvkte5yOXyymZTGrRokUKBoN65ZVXCsf27dunw4cPq7W19VLfZkywtwsAAPYV1fOxbt06rVy5UtOmTVNvb682b96srVu36sUXX1Q0GtWdd96ptWvXqra2VpFIRPfff79aW1snxEwX6YxFxnLEDwAAbCkqfBw/flxf/OIX1d7ermg0qgULFujFF1/Upz71KUnSD37wA/l8Pq1evVrJZFLLly/Xj3/843Fp+GgUhl3sNgMAAKcVFT4ef/zxCx4vKyvThg0btGHDhktq1HgZ2liOqbYAANjj1N4uvqFxF7IHAADWOBU+ClNtLbcDAACXuRU+2NsFAADrHAsfLDIGAIBtboWPwXt6PgAAsMep8MHeLgAA2OdU+BgqOCV9AABgj1Phw0fBKQAA1jkVPkTBKQAA1jkVPig4BQDAPqfCh4+SDwAArHMqfJxe54P4AQCALU6Fj0LPB9kDAABrnAof7O0CAIB9boUPptoCAGCdk+GD7AEAgD1uhY/BYRd6PgAAsMep8OFz6tMCADAxOfXnmJ4PAADscyt8UPMBAIB1joUP9nYBAMA2p8IHu9oCAGCfU+FjaGM5ogcAAPa4FT7Y2wUAAOucCh/s7QIAgH1OhQ8VptpabgYAAA5zKnwUej6o+gAAwBqnwgfrfAAAYJ9T4cNHwSkAANY5FT4KPR92mwEAgNPcCh9DBadUnAIAYI1b4YOeDwAArHMsfDDVFgAA25wKH6cXGSN9AABgi1Phw7v4KQAAYJw5FT58hWEXej4AALDFqfAhFhkDAMA6p8KHx94uAABY51T4YG8XAADsKyp8rF+/Xtdee62qq6vV0NCgm2++Wfv27Rt2zg033CDP84bd7rnnnjFt9GixtwsAAPYVFT7a2tq0Zs0a7dixQy+99JLS6bSWLVumeDw+7Ly77rpL7e3thdujjz46po0eLfZ2AQDAvkAxJ7/wwgvDHm/atEkNDQ3avXu3rr/++sLzFRUVamxsHJsWjiF6PgAAsO+Saj56enokSbW1tcOe//nPf676+nrNnz9f69atU39//3lfI5lMKhaLDbuNF1Y4BQDAvqJ6Ps6Uy+X0wAMP6LrrrtP8+fMLz3/hC1/Q9OnT1dzcrL179+prX/ua9u3bp1/96lfnfJ3169froYceGm0zijK0yBgFpwAA2DPq8LFmzRq9+eab+s1vfjPs+bvvvrvw8zXXXKOmpiYtWbJEBw8e1KxZs856nXXr1mnt2rWFx7FYTC0tLaNt1gUNDbvQ8wEAgD2jCh/33XefnnvuOW3btk1Tp0694LmLFy+WJB04cOCc4SMcDiscDo+mGUXzUfQBAIB1RYUPY4zuv/9+bdmyRVu3btWMGTMu+jt79uyRJDU1NY2qgWPp9LALAACwpajwsWbNGm3evFnPPPOMqqur1dHRIUmKRqMqLy/XwYMHtXnzZn36059WXV2d9u7dqwcffFDXX3+9FixYMC4foBgee7sAAGBdUeFj48aNkvILiZ3piSee0B133KFQKKSXX35Zjz32mOLxuFpaWrR69Wp985vfHLMGXwpGXQAAsK/oYZcLaWlpUVtb2yU1aDz5mGoLAIB1Tu3twlRbAADscyt8MOwCAIB1ToUP9nYBAMA+p8KH6PkAAMA6p8IHBacAANjnVPig4BQAAPucCh+naz4sNwQAAIc5FT5Oz3YhfQAAYItb4WPwnpoPAADscSt8DA27UPMBAIA1joWP/D2jLgAA2ONU+GCqLQAA9jkVPrzCT6QPAABscSp8+HyDPR85yw0BAMBhToWPIRScAgBgj1PhY6jglJoPAADscSp8sMIpAAD2ORU+2NsFAAD7nAof9HwAAGCfU+GDvV0AALDPsfDBImMAANjmVvgYvCd7AABgj1vhg2EXAACscyp8UHAKAIB9ToWPQs8HAy8AAFjjWPhgbxcAAGxzK3wM3tPzAQCAPU6FDx9TbQEAsM6p8HF6tovddgAA4DK3wkfhJ9IHAAC2OBU+GHYBAMA+p8KHWGQMAADrnAof9HwAAGCfU+GDvV0AALDPrfDBsAsAANY5FT7Y2wUAAPucCh/s7QIAgH2OhQ/2dgEAwDa3wsfgPT0fAADY41T4YKotAAD2FRU+1q9fr2uvvVbV1dVqaGjQzTffrH379g07J5FIaM2aNaqrq1NVVZVWr16tzs7OMW30aHnMtQUAwLqiwkdbW5vWrFmjHTt26KWXXlI6ndayZcsUj8cL5zz44IN69tln9dRTT6mtrU3Hjh3TLbfcMuYNH42h7JFjugsAANYEijn5hRdeGPZ406ZNamho0O7du3X99derp6dHjz/+uDZv3qwbb7xRkvTEE0/oox/9qHbs2KGPf/zjY9fyURgqOCV6AABgzyXVfPT09EiSamtrJUm7d+9WOp3W0qVLC+fMmzdP06ZN0/bt28/5GslkUrFYbNhtvLDIGAAA9o06fORyOT3wwAO67rrrNH/+fElSR0eHQqGQampqhp07ZcoUdXR0nPN11q9fr2g0Wri1tLSMtkkXRcEpAAD2jTp8rFmzRm+++aaefPLJS2rAunXr1NPTU7gdOXLkkl7vQqg3BQDAvqJqPobcd999eu6557Rt2zZNnTq18HxjY6NSqZS6u7uH9X50dnaqsbHxnK8VDocVDodH04yi+QajFsMuAADYU1TPhzFG9913n7Zs2aJXX31VM2bMGHZ80aJFCgaDeuWVVwrP7du3T4cPH1Zra+vYtPgSeGJvFwAAbCuq52PNmjXavHmznnnmGVVXVxfqOKLRqMrLyxWNRnXnnXdq7dq1qq2tVSQS0f3336/W1lbrM10kFcZdmGoLAIA9RYWPjRs3SpJuuOGGYc8/8cQTuuOOOyRJP/jBD+Tz+bR69Wolk0ktX75cP/7xj8eksZeKXW0BALCvqPAxklqJsrIybdiwQRs2bBh1o8YLBacAANjn5N4uFJwCAGCPU+Hj9CJjdtsBAIDLnAwfFJwCAGCPW+FD7O0CAIBtboUPej4AALDOqfDhKxR92G0HAAAucyp8kD0AALDPqfDhY9gFAADrnAofYm8XAACscyp80PMBAIB9ToUPj71dAACwzq3wYbsBAADArfAxNNWWYRcAAOxxKnywtwsAAPY5GT7o+QAAwB63wgd7uwAAYJ1T4cM3+GkNPR8AAFjjVPjwWGQMAADr3Aof7O0CAIB1ToUPVjgFAMA+p8IHe7sAAGCfU+GDng8AAOxzKnx4FH0AAGCdU+GDng8AAOxzKnywyBgAAPa5FT7Y2wUAAOucDB8MuwAAYI9j4YNhFwAAbHMqfPgKwy7EDwAAbHEqfLC3CwAA9jkVPphqCwCAfU6FD7HGGAAA1jkVPhh2AQDAPqfCx9Cwi0TRKQAAtjgVPgp7u4jeDwAAbHEqfJzZ80HRKQAAdjgVPoZqPiSKTgEAsMWt8HHGp6XnAwAAO9wKH2f8TPYAAMCOosPHtm3bdNNNN6m5uVme5+npp58edvyOO+6Q53nDbitWrBir9l6SMwtOAQCAHUWHj3g8roULF2rDhg3nPWfFihVqb28v3H7xi19cUiPHCgWnAADYFyj2F1auXKmVK1de8JxwOKzGxsZRN2q8DCs4JXsAAGDFuNR8bN26VQ0NDZo7d67uvfdedXV1jcfbFM2j5wMAAOuK7vm4mBUrVuiWW27RjBkzdPDgQX3jG9/QypUrtX37dvn9/rPOTyaTSiaThcexWGysm1RwZvggegAAYMeYh4/Pf/7zhZ+vueYaLViwQLNmzdLWrVu1ZMmSs85fv369HnroobFuxjn5WOEUAADrxn2q7cyZM1VfX68DBw6c8/i6devU09NTuB05cmTc2jJ8qi3pAwAAG8a85+ODjh49qq6uLjU1NZ3zeDgcVjgcHu9mSGJvFwAAJoKiw0dfX9+wXoxDhw5pz549qq2tVW1trR566CGtXr1ajY2NOnjwoL761a9q9uzZWr58+Zg2fDSYagsAgH1Fh49du3bpk5/8ZOHx2rVrJUm33367Nm7cqL179+pnP/uZuru71dzcrGXLlunv//7vS9a7cSHDej4stgMAAJcVHT5uuOGGC9ZLvPjii5fUoPHmefkhF3o+AACww6m9XaQzik7JHgAAWOFc+Biabkv2AADADufCx1DZB8MuAADY4V74GBx4IXsAAGCHe+GDng8AAKxyNnyQPQAAsMO58FEoOCV8AABghXPhY2iqrWG+CwAAVjgXPuj5AADALufChyg4BQDAKufCx+lhFwAAYINz4cPnGxp2IX4AAGCDc+Gj0PNB9gAAwArnwsdQwWmO8AEAgBXOhY/CImNUfQAAYIWD4YOptgAA2ORe+Bi8Z6otAAB2uBc+2NsFAACrnAsfrHAKAIBdzoUP9nYBAMAu98IHU20BALDKwfCRv2eFUwAA7HAufBRqPiy3AwAAVzkXPuj5AADALvfCx+A92QMAADucCx/s7QIAgF3OhQ8x7AIAgFXOhQ8KTgEAsMu58MHeLgAA2OVc+PAVprvYbQcAAK5yLnwMZQ8KTgEAsMO58DGEvV0AALDDufDBVFsAAOxyLnywwikAAHY5Fz6YagsAgF3OhQ96PgAAsMvB8DHY80H2AADACvfCx+A9BacAANjhXvhg2AUAAKucCx9MtQUAwK6iw8e2bdt00003qbm5WZ7n6emnnx523Bijb3/722pqalJ5ebmWLl2q/fv3j1V7L5lX+In0AQCADUWHj3g8roULF2rDhg3nPP7oo4/qRz/6kX7yk59o586dqqys1PLly5VIJC65sWPBR8EpAABWBYr9hZUrV2rlypXnPGaM0WOPPaZvfvObWrVqlSTpX/7lXzRlyhQ9/fTT+vznP39prR0L7O0CAIBVY1rzcejQIXV0dGjp0qWF56LRqBYvXqzt27ef83eSyaRisdiw23jyFTa1JX0AAGDDmIaPjo4OSdKUKVOGPT9lypTCsQ9av369otFo4dbS0jKWTTqLJwpOAQCwyfpsl3Xr1qmnp6dwO3LkyLi+H1NtAQCwa0zDR2NjoySps7Nz2POdnZ2FYx8UDocViUSG3cYTBacAANg1puFjxowZamxs1CuvvFJ4LhaLaefOnWptbR3Ltxo1j5oPAACsKnq2S19fnw4cOFB4fOjQIe3Zs0e1tbWaNm2aHnjgAf3DP/yD5syZoxkzZuhb3/qWmpubdfPNN49lu0eNvV0AALCr6PCxa9cuffKTnyw8Xrt2rSTp9ttv16ZNm/TVr35V8Xhcd999t7q7u/UXf/EXeuGFF1RWVjZ2rb4E7O0CAIBdRYePG2644YLFmp7n6eGHH9bDDz98SQ0bLz4KTgEAsMr6bJdSY9gFAAC73Asfg/cUnAIAYId74YNdbQEAsMrB8JG/Z9gFAAA7nAsf7O0CAIBdzoUP9nYBAMAu58KHb+gTM+4CAIAVzoUPej4AALDLufAhFhkDAMAq58KHj6m2AABY5Vz4OL3IGAAAsMG58BHw5+NHJpuz3BIAANzkXPgoD/olSQPprOWWAADgJsIHAAAoKffCRygfPhIpwgcAADY4Fz7K6PkAAMAq58LH6WEXCk4BALDBufBRMTjsMsCwCwAAVjgXPgo1Hwy7AABghXPhg5oPAADsci58FGo+GHYBAMAK98JHiJ4PAABsci980PMBAIBVzoUPaj4AALDLufDBsAsAAHa5Fz4Gez5SmZyyOWO5NQAAuMe58DG0yJjEWh8AANjgXPgIB05/ZIZeAAAoPefCh+d5zHgBAMAi58KHxBLrAADY5Gb4GOz56KfnAwCAknMyfJQF8x+bmg8AAErPyfDBWh8AANjjZvgYHHZJMOwCAEDJORk+WGIdAAB7nAwf5YQPAACscTJ8DK1yyjofAACUnpPhg3U+AACwx8nwQc0HAAD2OBk+Ti+vnrPcEgAA3DPm4eO73/2uPM8bdps3b95Yv80lOV1wmrHcEgAA3BMYjxe9+uqr9fLLL59+k8C4vM2olVNwCgCANeOSCgKBgBobG8fjpccENR8AANgzLjUf+/fvV3Nzs2bOnKnbbrtNhw8fPu+5yWRSsVhs2G28nR52oeYDAIBSG/PwsXjxYm3atEkvvPCCNm7cqEOHDukTn/iEent7z3n++vXrFY1GC7eWlpaxbtJZClNtGXYBAKDkPGOMGc836O7u1vTp0/X9739fd95551nHk8mkkslk4XEsFlNLS4t6enoUiUTGpU2//v1x/fWm13TNFVE9e/9fjMt7AADgklgspmg0OqK/3+NeCVpTU6OPfOQjOnDgwDmPh8NhhcPh8W7GMOxqCwCAPeO+zkdfX58OHjyopqam8X6rETu9zgfhAwCAUhvz8PHlL39ZbW1teuedd/Tb3/5Wn/3sZ+X3+3XrrbeO9VuN2lDPR18yo2xuXEedAADAB4x5+Dh69KhuvfVWzZ07V3/1V3+luro67dixQ5MnTx7rtxq1huqwQgGfegbS+p//a5diibTtJgEA4IxxLzgtVjEFK5fi/+xt14P/tkepTE6NkTKtXfYRfWJOvRojZfI8b9zeFwCAy9GEKjidqD6zoEnNNWV68F/36J2ufn31l3slSeGAT7MbqrRo+iR9ZEq1FkyNan5zVD4fgQQAgLHgbM/HkIFUVv//tj/qpd916K1jMZ3ratRUBBXweaqtDOlPWyapuiygxmiZPjFnsmZOrlTQ7+T+fAAAFBTz99v58HGmVCanjp6E3nivR3uOnNL+43167dBJxS8wK8bnSfMaI/rUVVN0Mp5Szhh9tCmiq5ojmtdYrYqQs51LAACHED7GUDKT1f7OPvl9ng6f7Ndb7/Uomc3pd+29eu3QyQuuFeLzpBn1lbqqOaqFU6P6H7PqZWSUyuRUXRbQlXWVCtBrAgC4DBA+SiSXMzrem9Qrv+/Ujj+e1BU15ZKk37XH9HZ7TCd6kxf8/apwQB+bUatrr6xVOptTJmfUHC3T/5hVr2l1FaX4CAAAjAnCxwRxvDeh37X36q1jPdrxx5Pa/c5JlYcCCgd86u5PXXA4pzlapnDQr7lTqvXnV+aLX+urwqouC6i6LKBoeZBZOQCACYPw8SGQyxm93R7T9oNd2nO0W1WhgHw+T3880afX3jmpi619Fgr41BgpU1M0f5tWW6GrmqNqqS1XQ3WZ6ipDzNABAJQMU20/BHw+T/OviGr+FdGzjnX1JfXuyX4l0lm9frhbbxzt0YETferuT6svmVYinVMqk9Phk/06fLL/3K/vSUG/TzUVQS2/ulELptaoviqkydVhtdRWKFIWHO+PCADAOdHz8SGUzGR1PJZUe09C7T0Dau9J6I8n+vR2e0wdPQl1xVPnnDJ8puqygHI5o/rqsGbUV+rKukrNnFyplkkVipTni2Hrqkq74R8A4MOLno/LXDjgV0tthVpqz12UmsnmdDKeUjpn9IfOXv3HW506eqpfJ3qTOtGbVFc8pd5ERpIU7+rXu139kk6c9Tp1lSGlsvkVYK9qjqgiFNDshipdN7tOkypC6k2kdao/rfKgX5Orw2qoDlOHAgC4KHo+HNQzkNaJ3qT8Pk+dsYQOvR/XO+/H9cf343rv1IB6BtJ6r3ug6NetCgd07ZWT9CctkzR1UrmCAZ8mVQQ1uTqsVCanmvKQpk4qpxYFAC5DFJzikvUMpHX0VL/CAb8OvR/XwRN96k9ltfvdk9p7tEfxZEaV4YBqK0NKpLM60Zu8aJGsJJUH/ZozpUpzGqrVUluu7v60IuVBXd0cUXnQr8qwX5OryggpAPAhQ/jAuDPGDBtiSWVy+kNnr7Yf7NL+471q70koPTj8c6I3qXDAr5PxlFLZ3Ihevyoc0Iz6Sk2qDKm2Ijh4H8rfV4ZUVxnS1VdEVRXO164QVADALmo+MO4+WNsRCvjOO3tnSCab07sn+7W/s1d/6OzTe6cGVFMZ1Pu9Ke0/3qt01iiezKgzllBfMqM33uu5YBt8Xj6kxBIZTaoIqjFaruZomZpqyhTw+dQzkNa8xmpd3RxV0O8p4PeprjKkabUVhBUAsIieD0w4mWxOB07kw8nJeEqn+lM61Z/WqXiq8PhYd2JUdSmSVBHyKxzwqSIU0EemVKm6LKiqskBhhdpwwKePNkVUVxVSZSigipBfleH84nAU1ALAudHzgQ+1gN+neY0RzWu88Je3vWdAfYmMohVBnYyn8lOPu/PTj7M5o4qQX/99uFvvnRpQOpdTOpvT8VhS/ams+lNZneovrrDW50mVoYCaaso0va5S02orlM0Z9acy8vs8Ta4K68r6Si1sqdH02gp5Xr6gt7YypLKg/1IvCwBcNggf+NBqipZLg6M8DdVlFw0rkpTO5hdnM8aoqy+lAyf6lEzn1N2f0tHuAQV8nmIDGf3heK9iA2nFk9nC5oE5I/UmM+rt7NMfOvsu+D6eJwV9PqWyOfl9nqbVVihSFlBVWUCTKkKaWV+pnMmv2TKtrlL1lSFVhgOqDAdUFQ4oUh5QQ3WZjDHK5AzhBcBlhfABpwT9Ps2aXCVJmt0gLZ5Zd9HfyeaMBtJZ9ScziiUyeq97QO92xXXkZL9Cg8M3mazR8d6E9nX06o33epTM5JTK5uTz8r9/6P140W31+zzlBkdFr7kiKp/n6VR/Sk3RMkXKggoH/ZpeW6GGSFhVg6GlqiygcMCv/lRGNeUhzZlSRXABMOEQPoCL8Pu8wh/3hog0u6FK0uTznp/LGXXFU0qks2quKdeJ3qTe6YqrL5FRXzKj470J/fFEXKGATwGfT4dP9qu7P6W+ZEbxVEbxZFaxgbQyZ8xd3nv0dPFtflG4kSsL+lQVDqgiNNSz4j/dyxLKB5aG6rAqwgF5kmoqgoMzisKqrQxpUkVQAb9P6WxOxuSLiwHgUhA+gDHm83maXH16afrGaJkao2VFvUY2Z3SiN6mA31M6m9N/HTqpgM+n+qqQ2nsSgyElo3e7+nWqP79ibe9guEmks6oMBXS8N6FT/fm9gBLplKTUqD6PN1jr0pfMr4obKQtoVkOVGiNlMkbKGaOhmFQW9Ks86FN50K+ykF8VwYDKQ4OPg/nQM6ehSi21FUqmcwoGPBkj9SUzqq0MKegn2AAuIHwAE5Df5w0LLKv+5IqiX8MYo56BtHoTmUJY6UtmB+/zj+ODQ0nHYwklMzllc0bd/Wl1xZM6GU+peyBdCAdDYomMXj/cPRYfc5iAz1N9VVh+n1e4BXyeptdVakokrK6+lDwvH3DKgj6FA/7CDCS/T/J5XuFWGfZrbmO1pk6qUG1lSJGyADOVgAmE8AFcpjzPU01FSDUVoVG/Riab06n+tHoTadVUhOTzpM5YUn/o7FV3f0ryPHnK945IUjKd00A6q0Q6P6NoIJ1VYvB+IJ1Vz0Bav2/vLRTxnm6rlMkZdcQSZ7Vh//ELF/eORNDvKeT3yed5Uv4/8vnybfd5njwvf7085euC6qryC9nVVYVVVxmS53lKZXJKZrKqrwprdkOVKkJ+RcuDipYHFUuklczk5Pc8RSuC8nte4fPnh+vC6hvcT6k85FcynTsjSOXDVMjPVG64g/AB4LwCfp8mV4eHDSPVVIQ0t7F61K+ZyeYDSjjgVzo7+Ec44FdHLKGuvpSyxiiby9+Smaz2d/bpVH+q0IZkOqdEOqtEJqtUJqecyQ9TGWOUNUY5I52Kp7Svo1edsYTiqazSWaN0NnuRlp022jVkLoXvjDBSHvQrPDh8VRHyqzFarqmTylVfFVZ794B6Exn5BnuGzuwpipYHNb0uPwV8aKZWY6RMVWWBwsaSknRlXYUmVYbk93mKJzOqqQipKVqm2sqQjp4aGNz7SfL7fAr48r1JAf/p3qgpkbKLFjLncvn/PhhKw7kQPgCUVMDvU/XgH6Qzi1eba8rVPLjQ25k+Mef8xb0jkUhn87s8DxbMDtWoGGNkjGQ0+NzgsVQmp66+lLriSb3fl1/YzhgpHPQp6Pfp2OBsp1Qmp5P9KfX053uFyoI+ZQaHrYwxhbqX2EBa7/elVB0OSJ40kMoqPPi5B9LZwp5IOaPCGjRnO3VJ12A81FaG5EmFa6nBnyUVhuqMMZpeV6nZDVVqqA6rM5ZUTUVQ1WUB/d8j3fI8T5MqQoUViINDw21+n4KDYad8sFaoIuTXid78cODHZtSqobpM7/cl9X5fUhWhgK6YVK54MqOT8ZT6UxlNieSHLU/FU6oIBVQ9ONW9uiz//gGfpwPH+5TJGdVWhnToRFyeJ81trFZdVVhBn6eBdFadsXwQa64pVzaXD1PR8qB6E/n6Kp/Pk9/LtzXk9ylSfnqIL5nJKpM1qgzzp/aDWOEUAMbZ+fYfMsYonTVKZPLDU4kzhq2G7vuSGbUPruh7oi+pxkiZJlUElc0p39OTy68Fk83lQ9Phk/0K+n35VXmD+bA0kMoWerCyOaN3u/oVS6SVyxmVhwLq7k/peG9S2ZxROOBTU7RMRlImO9gLNdgblcnmlM6as4bNcFpDdVhXTCpXV19KR0/1K2ek+qr8QoOpTE7dA2lVhwMqC/oLIak85Nc778eVzubX9GmoDqsrntSpeFrhgE/hoRqnM2qdwgGfyoJ+Gamw+nMinVV5yK+qwdlsFSG/gn6ffIPDitXhQD5A9wxocnVY3/+rPxnTz84KpwAwgZxvLyHP8xQKeAoFfIqUBUvcquGyOaNT/SnVlOenVp+PMUan+tM60Zss1PqcWfeTfyRVl+X/vBw43qc/dPbqZDylhkiZ3u9NqmcgrYUtUZUF/DrVn1Yml1Mma5TJ5cNNIejkjAZS+SLpeCqjSRUhVYUD+s+D7yuVyam+Kqz6qrB6BtLq6EkoUp5fxK8smB/G83ueJlUGNZDKFmaE9SbyRdjJbE4z6ysVCvjU1ZfSlfUVMiZfY9TTn1Y6l1NZwK+GSFiZrFF7z4ACfp8y2fxQ39Bw4VAAzA72nh3vTer44PDWkPf7hs8068qcfnyqPz3sWF8yo/f7Tv9+KpvTB17uwka4pNAV5+hlLCXCBwBA/sHZRhfjeZ5qB3eXHokpkTJdN7v+UptXch/cuXvocS5n1JvMqCockP8DoXIgldUb7/XoVH9KtZUhTa+tUDjo19FT/UpnjQKDdTlDU+LLQ369d2pAA+msZtbni5iH1gKqrQyrviqkdDZf+5RM55QcLHpOpHOF54ykSYNr81SEAoWZbUOz27K5/HBj1hj1JTJKpHNqqinTtNqKEl/R4QgfAAB8wAdnHg099g0GiHMpD/n1sRm1Zz0fLT//bt/n3hbi/OdfLihDBgAAJUX4AAAAJUX4AAAAJUX4AAAAJUX4AAAAJUX4AAAAJUX4AAAAJUX4AAAAJUX4AAAAJUX4AAAAJUX4AAAAJUX4AAAAJUX4AAAAJTXhdrU1xkiSYrGY5ZYAAICRGvq7PfR3/EImXPjo7e2VJLW0tFhuCQAAKFZvb6+i0egFz/HMSCJKCeVyOR07dkzV1dXyPG9MXzsWi6mlpUVHjhxRJBIZ09e+3HCtisP1GjmuVXG4XiPHtRq58bhWxhj19vaqublZPt+FqzomXM+Hz+fT1KlTx/U9IpEIX8wR4loVh+s1clyr4nC9Ro5rNXJjfa0u1uMxhIJTAABQUoQPAABQUk6Fj3A4rO985zsKh8O2mzLhca2Kw/UaOa5VcbheI8e1Gjnb12rCFZwCAIDLm1M9HwAAwD7CBwAAKCnCBwAAKCnCBwAAKClnwseGDRt05ZVXqqysTIsXL9Z//dd/2W7ShPDd735XnucNu82bN69wPJFIaM2aNaqrq1NVVZVWr16tzs5Oiy0unW3btummm25Sc3OzPM/T008/Pey4MUbf/va31dTUpPLyci1dulT79+8fds7Jkyd12223KRKJqKamRnfeeaf6+vpK+ClK42LX6o477jjre7ZixYph57hyrdavX69rr71W1dXVamho0M0336x9+/YNO2ck/+4OHz6sz3zmM6qoqFBDQ4O+8pWvKJPJlPKjlMRIrtcNN9xw1vfrnnvuGXaOC9dr48aNWrBgQWHhsNbWVj3//POF4xPpe+VE+PjXf/1XrV27Vt/5znf03//931q4cKGWL1+u48eP227ahHD11Vervb29cPvNb35TOPbggw/q2Wef1VNPPaW2tjYdO3ZMt9xyi8XWlk48HtfChQu1YcOGcx5/9NFH9aMf/Ug/+clPtHPnTlVWVmr58uVKJBKFc2677Ta99dZbeumll/Tcc89p27Ztuvvuu0v1EUrmYtdKklasWDHse/aLX/xi2HFXrlVbW5vWrFmjHTt26KWXXlI6ndayZcsUj8cL51zs3102m9VnPvMZpVIp/fa3v9XPfvYzbdq0Sd/+9rdtfKRxNZLrJUl33XXXsO/Xo48+WjjmyvWaOnWqHnnkEe3evVu7du3SjTfeqFWrVumtt96SNMG+V8YBH/vYx8yaNWsKj7PZrGlubjbr16+32KqJ4Tvf+Y5ZuHDhOY91d3ebYDBonnrqqcJzv/vd74wks3379hK1cGKQZLZs2VJ4nMvlTGNjo/nHf/zHwnPd3d0mHA6bX/ziF8YYY95++20jybz22muFc55//nnjeZ557733Stb2UvvgtTLGmNtvv92sWrXqvL/j6rUyxpjjx48bSaatrc0YM7J/d//+7/9ufD6f6ejoKJyzceNGE4lETDKZLO0HKLEPXi9jjPnLv/xL83d/93fn/R2Xr9ekSZPMT3/60wn3vbrsez5SqZR2796tpUuXFp7z+XxaunSptm/fbrFlE8f+/fvV3NysmTNn6rbbbtPhw4clSbt371Y6nR527ebNm6dp06Y5f+0OHTqkjo6OYdcmGo1q8eLFhWuzfft21dTU6M///M8L5yxdulQ+n087d+4seZtt27p1qxoaGjR37lzde++96urqKhxz+Vr19PRIkmprayWN7N/d9u3bdc0112jKlCmFc5YvX65YLFb4f7mXqw9eryE///nPVV9fr/nz52vdunXq7+8vHHPxemWzWT355JOKx+NqbW2dcN+rCbex3Fh7//33lc1mh11MSZoyZYp+//vfW2rVxLF48WJt2rRJc+fOVXt7ux566CF94hOf0JtvvqmOjg6FQiHV1NQM+50pU6aoo6PDToMniKHPf67v1dCxjo4ONTQ0DDseCARUW1vr3PVbsWKFbrnlFs2YMUMHDx7UN77xDa1cuVLbt2+X3+939lrlcjk98MADuu666zR//nxJGtG/u46OjnN+94aOXa7Odb0k6Qtf+IKmT5+u5uZm7d27V1/72te0b98+/epXv5Lk1vV644031NraqkQioaqqKm3ZskVXXXWV9uzZM6G+V5d9+MCFrVy5svDzggULtHjxYk2fPl3/9m//pvLycostw+Xk85//fOHna665RgsWLNCsWbO0detWLVmyxGLL7FqzZo3efPPNYXVWOL/zXa8za4OuueYaNTU1acmSJTp48KBmzZpV6mZaNXfuXO3Zs0c9PT365S9/qdtvv11tbW22m3WWy37Ypb6+Xn6//6yK3s7OTjU2Nlpq1cRVU1Ojj3zkIzpw4IAaGxuVSqXU3d097ByunQqf/0Lfq8bGxrOKmjOZjE6ePOn89Zs5c6bq6+t14MABSW5eq/vuu0/PPfecfv3rX2vq1KmF50fy766xsfGc372hY5ej812vc1m8eLEkDft+uXK9QqGQZs+erUWLFmn9+vVauHChfvjDH06479VlHz5CoZAWLVqkV155pfBcLpfTK6+8otbWVostm5j6+vp08OBBNTU1adGiRQoGg8Ou3b59+3T48GHnr92MGTPU2Ng47NrEYjHt3LmzcG1aW1vV3d2t3bt3F8559dVXlcvlCv/j6KqjR4+qq6tLTU1Nkty6VsYY3XfffdqyZYteffVVzZgxY9jxkfy7a21t1RtvvDEssL300kuKRCK66qqrSvNBSuRi1+tc9uzZI0nDvl+uXK8PyuVySiaTE+97NablqxPUk08+acLhsNm0aZN5++23zd13321qamqGVfS66ktf+pLZunWrOXTokPnP//xPs3TpUlNfX2+OHz9ujDHmnnvuMdOmTTOvvvqq2bVrl2ltbTWtra2WW10avb295vXXXzevv/66kWS+//3vm9dff928++67xhhjHnnkEVNTU2OeeeYZs3fvXrNq1SozY8YMMzAwUHiNFStWmD/90z81O3fuNL/5zW/MnDlzzK233mrrI42bC12r3t5e8+Uvf9ls377dHDp0yLz88svmz/7sz8ycOXNMIpEovIYr1+ree+810WjUbN261bS3txdu/f39hXMu9u8uk8mY+fPnm2XLlpk9e/aYF154wUyePNmsW7fOxkcaVxe7XgcOHDAPP/yw2bVrlzl06JB55plnzMyZM831119feA1XrtfXv/5109bWZg4dOmT27t1rvv71rxvP88x//Md/GGMm1vfKifBhjDH/9E//ZKZNm2ZCoZD52Mc+Znbs2GG7SRPC5z73OdPU1GRCoZC54oorzOc+9zlz4MCBwvGBgQHzt3/7t2bSpEmmoqLCfPaznzXt7e0WW1w6v/71r42ks2633367MSY/3fZb3/qWmTJligmHw2bJkiVm3759w16jq6vL3HrrraaqqspEIhHz13/916a3t9fCpxlfF7pW/f39ZtmyZWby5MkmGAya6dOnm7vuuuus8O/KtTrXdZJknnjiicI5I/l3984775iVK1ea8vJyU19fb770pS+ZdDpd4k8z/i52vQ4fPmyuv/56U1tba8LhsJk9e7b5yle+Ynp6eoa9jgvX62/+5m/M9OnTTSgUMpMnTzZLliwpBA9jJtb3yjPGmLHtSwEAADi/y77mAwAATCyEDwAAUFKEDwAAUFKEDwAAUFKEDwAAUFKEDwAAUFKEDwAAUFKEDwAAUFKEDwAAUFKEDwAAUFKEDwAAUFKEDwAAUFL/D0VlQ+5sdAnVAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x79c4eb53c580>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x79c27e8e6a10>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 256)               4352      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 16)                64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50113 (195.75 KB)\n",
      "Trainable params: 49121 (191.88 KB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
