{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 23:59:05.611942: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-21 23:59:05.616511: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-21 23:59:05.701988: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-21 23:59:05.704674: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-21 23:59:07.425887: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/206/mlp/b/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 2\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 2\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 2\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"AM\\\",\\n    \\\"Features\\\": \\\"Chemical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"AM\\\",\\n    \\\"Features\\\": \\\"Chemical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"209\",\n",
    "    \"Plant\": \"AM\",\n",
    "    \"Features\": \"Chemical\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/209/global_am.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/209/global_am.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/209/global_am.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Cement_Type\\\",\\n        \\\"Factory_Plant\\\",\\n        \\\"Blaine\\\",\\n        # \\\"#200\\\",\\n        \\\"#325\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        # \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Cement_Type\\\",\\n        \\\"Factory_Plant\\\",\\n        \\\"Blaine\\\",\\n        # \\\"#200\\\",\\n        \\\"#325\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        # \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop(\n",
    "    [\n",
    "        \"Cement_Type\",\n",
    "        \"Factory_Plant\",\n",
    "        \"Blaine\",\n",
    "        # \"#200\",\n",
    "        \"#325\",\n",
    "        \"Final setting time\",\n",
    "        \"Initial setting time\",\n",
    "        # \"CS1\",\n",
    "        \"CS3\",\n",
    "        \"CS7\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 23:59:12.126018: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  12.28317411740621\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.255 (0.000)\n",
      "MAE: 1.667 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.891 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.821 (0.000)\n",
      "MAE: 2.064 (0.000)\n",
      "MAPE: 0.049 (0.000)\n",
      "R2: 0.778 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  12.42207015355428\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.263 (0.000)\n",
      "MAE: 1.664 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.890 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.687 (0.000)\n",
      "MAE: 1.994 (0.000)\n",
      "MAPE: 0.047 (0.000)\n",
      "R2: 0.798 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.286152974764507\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.081 (0.000)\n",
      "MAE: 1.543 (0.000)\n",
      "MAPE: 0.035 (0.000)\n",
      "R2: 0.907 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.696 (0.000)\n",
      "MAE: 1.951 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.797 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  18.69244919617971\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.909 (0.000)\n",
      "MAE: 1.412 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.922 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.615 (0.000)\n",
      "MAE: 1.872 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.809 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  22.062924067179363\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.029 (0.000)\n",
      "MAE: 1.486 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.912 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.657 (0.000)\n",
      "MAE: 1.929 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.803 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  29.666831040382384\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.041 (0.000)\n",
      "MAE: 1.500 (0.000)\n",
      "MAPE: 0.034 (0.000)\n",
      "R2: 0.911 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.536 (0.000)\n",
      "MAE: 1.848 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.820 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.89109504620234\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.940 (0.000)\n",
      "MAE: 1.418 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.920 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.614 (0.000)\n",
      "MAE: 1.883 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.809 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.062200446923574\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.980 (0.000)\n",
      "MAE: 1.461 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.916 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.679 (0.000)\n",
      "MAE: 1.916 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.799 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  22.492181185881297\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.815 (0.000)\n",
      "MAE: 1.359 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.930 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.859 (0.000)\n",
      "MAE: 2.063 (0.000)\n",
      "MAPE: 0.049 (0.000)\n",
      "R2: 0.772 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  22.331197468439736\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.924 (0.000)\n",
      "MAE: 1.413 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.921 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.697 (0.000)\n",
      "MAE: 1.925 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.797 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  23.19150963226954\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.019 (0.000)\n",
      "MAE: 1.486 (0.000)\n",
      "MAPE: 0.034 (0.000)\n",
      "R2: 0.913 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.596 (0.000)\n",
      "MAE: 1.903 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.812 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.2425444205602\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.198 (0.000)\n",
      "MAE: 1.610 (0.000)\n",
      "MAPE: 0.036 (0.000)\n",
      "R2: 0.897 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.662 (0.000)\n",
      "MAE: 1.925 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.802 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  13.873429568608602\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.596 (0.000)\n",
      "MAE: 1.961 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.856 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.773 (0.000)\n",
      "MAE: 2.040 (0.000)\n",
      "MAPE: 0.048 (0.000)\n",
      "R2: 0.785 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/209/am/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/209/am/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/209/am/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>209</td>\n",
       "      <td>AM</td>\n",
       "      <td>Chemical</td>\n",
       "      <td>(60402, 10)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_6</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>2.040926</td>\n",
       "      <td>1.499669</td>\n",
       "      <td>0.03382</td>\n",
       "      <td>0.910916</td>\n",
       "      <td>2.536111</td>\n",
       "      <td>1.847565</td>\n",
       "      <td>0.043546</td>\n",
       "      <td>0.82028</td>\n",
       "      <td>-6.144054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category Company Plant  Features   Data Shape Timesteps  Model  \\\n",
       "5  Global Model     209    AM  Chemical  (60402, 10)      None  MLP_6   \n",
       "\n",
       "  Model Params           Scaler Scaler Params  ...  \\\n",
       "5         None  Standard Scaler          None  ...   \n",
       "\n",
       "                 Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "5  {\"train_size\": 0.8, \"test_size\": 0.2}   2.040926  1.499669    0.03382   \n",
       "\n",
       "   R2 Train  RMSE Test  MAE Test  MAPE Test  R2 Test      SCPM  \n",
       "5  0.910916   2.536111  1.847565   0.043546  0.82028 -6.144054  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R²\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  34.95108779668808\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.006 (0.000)\n",
      "MAE: 1.470 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.910 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.006 (0.000)\n",
      "MAE: 1.470 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.910 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/209/mlp/am/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/209/mlp/am/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/209/mlp/am/pre_training/\"\n",
    "model_name = \"mlp_chemical_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7cc9a7c91bd0>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7cc9a5b699f0>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7cc9a5a04460>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7cc9a5a66b30>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA2/klEQVR4nO3deXxU9b3/8feZSTJZJ/tOEiDs+6YYN6wggqhUW6uW9uJSrYh1a/0p7XVra3Fpra1tsVavcm9dWq1o3XdQFJC1LGIgCCSEBEhCZrJOMjPn90dkNLKYwCQnnLyej8c8hsycmfnM15nOu9/zXQzTNE0BAACEgcPqAgAAgH0QLAAAQNgQLAAAQNgQLAAAQNgQLAAAQNgQLAAAQNgQLAAAQNgQLAAAQNhEdPcLBoNB7d69WwkJCTIMo7tfHgAAHAXTNFVXV6ecnBw5HIfvl+j2YLF7927l5eV198sCAIAwKCsrU58+fQ57f7cHi4SEBElthbnd7u5+eQAAcBS8Xq/y8vJCv+OH0+3B4sDpD7fbTbAAAOA4803DGBi8CQAAwoZgAQAAwoZgAQAAwoZgAQAAwoZgAQAAwoZgAQAAwoZgAQAAwoZgAQAAwoZgAQAAwoZgAQAAwoZgAQAAwoZgAQAAwqbbNyHrKg++VSxvs19zzihUpjva6nIAAOiVbNNj8ezKMj358Q5V17dYXQoAAL2WbYKF44ttXIOmaXElAAD0XjYKFm3X5AoAAKxjm2Bh0GMBAIDlbBMsHF+8E4IFAADWsU+wCPVYWFwIAAC9mO2ChUmPBQAAlrFNsPgiV9BjAQCAhWwTLJhuCgCA9WwULNquCRYAAFjHRsHiwBgLiwsBAKAXs02wYB0LAACsZ5tg4WDwJgAAlrNRsKDHAgAAq9koWLRds44FAADWsU2wCI2xCFpcCAAAvZhtggXTTQEAsJ6NggV7hQAAYDXbBQvGWAAAYB3bBAv2CgEAwHq2CRZMNwUAwHr2CRZfvBOCBQAA1rFPsGCvEAAALGebYMFeIQAAWM82wYK9QgAAsJ6NggU9FgAAWM1GwaLtOkiXBQAAlrFNsDBYeRMAAMvZJliwVwgAANbrVLAIBAK6/fbb1a9fP8XExKiwsFC/+tWvesQy2k4HS3oDAGC1iM4cfN9992nBggVauHChhg8frlWrVunyyy9XYmKirr/++q6qsUM4FQIAgPU6FSw+/vhjzZw5UzNmzJAk9e3bV88884w++eSTLimuM5gVAgCA9Tp1KuTkk0/Wu+++qy1btkiS/vOf/2jp0qWaPn36YR/j8/nk9XrbXboC61gAAGC9TvVY3HbbbfJ6vRoyZIicTqcCgYDuuecezZo167CPmT9/vu6+++5jLvSbsG06AADW61SPxT//+U899dRTevrpp7VmzRotXLhQv/3tb7Vw4cLDPmbevHnyeDyhS1lZ2TEXfSgGs0IAALBcp3osbrnlFt1222265JJLJEkjR47Uzp07NX/+fM2ePfuQj3G5XHK5XMde6TdwMHgTAADLdarHorGxUQ5H+4c4nU4Fg8GwFnU0WMcCAADrdarH4rzzztM999yj/Px8DR8+XGvXrtWDDz6oK664oqvq6zC2TQcAwHqdChYPP/ywbr/9dl177bXau3evcnJy9OMf/1h33HFHV9XXYaF1LDgXAgCAZToVLBISEvTQQw/poYce6qJyjh7TTQEAsJ6N9gphgSwAAKxmo2DRds06FgAAWMc2wYK9QgAAsJ5tggWnQgAAsJ6NgkXbNT0WAABYxz7BwsFeIQAAWM02wYK9QgAAsJ5tggV7hQAAYD0bBYu2a3osAACwjo2CBXuFAABgNdsEC4PppgAAWM42wYJTIQAAWM9GwYLBmwAAWM1GwaLtmnUsAACwjm2CRWiMRdDiQgAA6MVsEyzYKwQAAOvZKFi0XTPGAgAA69goWLBXCAAAVrNNsDiwV0iAYAEAgGVsEyyYbgoAgPVsFCzarhm8CQCAdewTLByMsQAAwGr2CRasYwEAgOXsFyzosQAAwDI2ChZt1wzeBADAOjYKFoyxAADAarYJFgazQgAAsJxtggXrWAAAYD37BIsv3gk9FgAAWMc+wSI0xsLiQgAA6MVsEywMppsCAGA52wQLlvQGAMB6NgoWDN4EAMBqNgoWbdesYwEAgHVsEywMeiwAALCcbYIFe4UAAGA9GwWLtmt6LAAAsI6NggV7hQAAYDXbBAv2CgEAwHq2CRahMRZBiwsBAKAXs1+woMcCAADL2ChYtF2TKwAAsI5tggV7hQAAYD3bBAv2CgEAwHqdChZ9+/aVYRgHXebOndtV9XWYw8G26QAAWC2iMwevXLlSgUAg9PfGjRt11lln6aKLLgp7YZ1FjwUAANbrVLBIT09v9/e9996rwsJCTZo0KaxFHQ32CgEAwHqdChZf1dLSor///e+6+eabQz/qh+Lz+eTz+UJ/e73eo33JI2K6KQAA1jvqwZsvvviiamtrddlllx3xuPnz5ysxMTF0ycvLO9qXPCKmmwIAYL2jDhaPP/64pk+frpycnCMeN2/ePHk8ntClrKzsaF/yiA70WAQ4FwIAgGWO6lTIzp079c477+iFF174xmNdLpdcLtfRvEynsFcIAADWO6oeiyeeeEIZGRmaMWNGuOs5ag4GbwIAYLlOB4tgMKgnnnhCs2fPVkTEUY/9DDu2TQcAwHqdDhbvvPOOSktLdcUVV3RFPUeNdSwAALBep7scpk6d2iN7BQ6svMmpEAAArGOjvUJYxwIAAKvZKFi0XZMrAACwjo2CBT0WAABYzTbBgnUsAACwnm2CBetYAABgPdsFi544YwUAgN7CRsGi7ZoeCwAArGObYGEweBMAAMvZJlh8dbopp0MAALCGjYKFEfo3uQIAAGvYMlhwOgQAAGvYJlgYX3knDOAEAMAatgkW9FgAAGA9GwWLL/9NrgAAwBo2Chb0WAAAYDXbBIuv5AqCBQAAFrFNsGjfY2FhIQAA9GK2DBYskAUAgDVsFCy+/Dc9FgAAWMM2wcJg8CYAAJazTbCQvrrDKcECAAAr2CxYtCULcgUAANawZbCgxwIAAGvYKlgYoVMh1tYBAEBvZatgEeqxIFkAAGAJmwWLtmvOhAAAYA2bBYu2ZBEgWQAAYAlbBQuD6aYAAFjKVsHC4Tgw3ZRgAQCAFewVLELTTS0uBACAXspmwaLtmlMhAABYw1bBwghNN7W4EAAAeilbBQsnK28CAGApWwUL1rEAAMBatgoWBj0WAABYylbBwvHFuyFYAABgDXsFC6abAgBgKVsGCxbIAgDAGrYKFmybDgCAtWwVLBwM3gQAwFI2CxZt1wQLAACsYbNgcWCMhcWFAADQS9kqWLCOBQAA1rJVsHAweBMAAEt1OliUl5frBz/4gVJTUxUTE6ORI0dq1apVXVFbpzF4EwAAa0V05uD9+/frlFNO0be+9S29/vrrSk9P19atW5WcnNxV9XXKl3uFECwAALBCp4LFfffdp7y8PD3xxBOh2/r16xf2oo4W26YDAGCtTp0K+fe//60JEybooosuUkZGhsaOHau//e1vR3yMz+eT1+ttd+kqTDcFAMBanQoWn3/+uRYsWKCBAwfqzTff1Jw5c3T99ddr4cKFh33M/PnzlZiYGLrk5eUdc9GHw14hAABYq1PBIhgMaty4cfrNb36jsWPH6uqrr9ZVV12lRx555LCPmTdvnjweT+hSVlZ2zEUfDnuFAABgrU4Fi+zsbA0bNqzdbUOHDlVpaelhH+NyueR2u9tdugp7hQAAYK1OBYtTTjlFxcXF7W7bsmWLCgoKwlrU0WK6KQAA1upUsLjpppu0fPly/eY3v1FJSYmefvppPfroo5o7d25X1dcpji/eDcECAABrdCpYnHDCCVq0aJGeeeYZjRgxQr/61a/00EMPadasWV1VX6ewVwgAANbq1DoWknTuuefq3HPP7Ypajhl7hQAAYC32CgEAAGFjs2BBjwUAAFayWbBou2YdCwAArGGrYHFgjEWAvUIAALCErYIFe4UAAGAtmwULlvQGAMBKtgwWzAoBAMAatgoWBqdCAACwlK2CBT0WAABYy1bBwulgjAUAAFayVbDgVAgAANayVbDgVAgAANayWbBou6bHAgAAa9gsWLBtOgAAVrJVsAhtm865EAAALGGrYMG26QAAWMtmwYJt0wEAsJLNgkXbNetYAABgDVsFC4PppgAAWMpWwYJTIQAAWMtmwaLtmh4LAACsYa9gwV4hAABYylbBgr1CAACwlq2CBXuFAABgLZsFi7ZreiwAALCGzYIFe4UAAGAlWwULg+mmAABYylbBglMhAABYy2bBgsGbAABYyWbBou2adSwAALCGrYJFaIxF0OJCAADopWwVLNgrBAAAa9ksWLRdM8YCAABr2CxYsFcIAABWslWwOLBXSIBgAQCAJWwVLJhuCgCAtWwWLNquGbwJAIA17BUsHIyxAADASrYKFqxjAQCAtWwVLDgVAgCAtWwWLFggCwAAK9kqWCTHRkmS9nh9FlcCAEDvZKtgMTgrQZK0dW+dAsw5BQCg29kqWOSnxMoV4VBza1ClNY1WlwMAQK/TqWBx1113yTCMdpchQ4Z0VW2d5nQYGpgZL0kqrqyzuBoAAHqfTvdYDB8+XBUVFaHL0qVLu6KuozY40y1J2rKHYAEAQHeL6PQDIiKUlZXVFbWExeCsL3osCBYAAHS7TvdYbN26VTk5Oerfv79mzZql0tLSIx7v8/nk9XrbXbrSoMy2AZycCgEAoPt1KlhMnDhRTz75pN544w0tWLBA27dv12mnnaa6usP/iM+fP1+JiYmhS15e3jEXfSQHZoZsr2qQzx/o0tcCAADtGeYxbKxRW1urgoICPfjgg7ryyisPeYzP55PP9+W6El6vV3l5efJ4PHK73Uf70odlmqZG3f2W6pr9evX6UzU8JzHsrwEAQG/j9XqVmJj4jb/fxzTdNCkpSYMGDVJJSclhj3G5XHK73e0uXckwDI3ukyRJWrNzf5e+FgAAaO+YgkV9fb22bdum7OzscNUTFif0TZEkfbKDYAEAQHfqVLD42c9+piVLlmjHjh36+OOPdcEFF8jpdOrSSy/tqvqOygn9kiVJK7fXsIU6AADdqFPTTXft2qVLL71U1dXVSk9P16mnnqrly5crPT29q+o7KmPzkhXpNFTpbVZZTZPyU2OtLgkAgF6hU8Hi2Wef7ao6wiomyqkRuYlaW1qrT3bUECwAAOgmttor5KtO/GKcxbJt1RZXAgBA72HbYHHG4AxJ0kvrylksCwCAbmLbYFFUmKqpwzLlD5r6+aINCrKNOgAAXc62wUKS7jp/uOKinFq9c79eXFdudTkAANierYNFTlKM5p45QJL0wJvFamphiW8AALqSrYOFJF1xSj/lJsWowtOsxz783OpyAACwNdsHi+hIp/7ftMGSpL8s3qbdtU0WVwQAgH3ZPlhI0vmjc3RC32Q1tQZ0z6ubrS4HAADb6hXBwjAM3X3+CDkM6dUNFfqopMrqkgAAsKVeESwkaViOW/9V1FeSdOe/N6nFH7S2IAAAbKjXBAtJuumsQUqNi1LJ3nr9z0fbrS4HAADb6VXBIjEmUrdNHyJJ+u2bxVq5o8biigAAsJdeFSwk6bvj++jcUdnyB03N+ftqfbKdcAEAQLj0umBhGIbu/+4oDct2q6q+Rd/76zItWLzN6rIAALCFXhcsJCk2KkLPXH2SLp6QJ0n67VvF2rqHjcoAADhWvTJYSG3jLe777ihNHZapQNDUXS9v0rZ99WxWBgDAMei1weKAX8wYqiinQx+VVGvy75bo6v9bZXVJAAAct3p9sChIjdMd5w1T39RYGYb0zua92ljusbosAACOS70+WEjSD04q0OJbvqXzRuVIEpuVAQBwlAgWX3HVaf0lSS+vr9C5D39IwAAAoJMIFl8xsk+iTh2QpkDQ1MZyr+59/TPt2t9odVkAABw3CBZf8+fvj9Nj/zVBEwqS5Q+aevSDz7W7tkkNPr/VpQEA0OMZpml26/xKr9erxMREeTweud3u7nzpTvm4pErff2xF6O/EmEjdOm2ILj0xT4ZhWFgZAADdr6O/3/RYHEZRYarGFySH/vY0ternizZo4cc7rCsKAIAejmBxGIZhaMEPxukPl4zRJ7+YrJ+cOUCS9MCbxarwNFlcHQAAPRPB4ggyEqI1c0yuMhKiddOUQRqXn6SGloCufWoNO6MCAHAIBIsOcjgM3XPBSLkiHFpbWquLHlmmf6wstbosAAB6FIJFJwzNduv1G07Tt8e0LaR198ufamd1g8VVAQDQcxAsOql/erwe/N4YTeyXosaWgG55bj0blwEA8AWCxVFwOAz99qLRio1y6pMdNfrnqjJ5m1u1r86nbp69CwBAj8I6FsfgsQ8/169f3azoSIf8AVP+oKm0eJf+MmucTuyXYnV5AACEDetYdIPLTu6rodluNbcG5Q+aMgypqt6n215Yr9ZA0OryAADodgSLYxDhdOix2RP0/6YN1mvXn6Z1t09ValyUPt/XoL8v32l1eQAAdDuCxTHKTYrRtWcM0LActxJjI3Xz1EGS2hbSWrJln8XVAQDQvSKsLsBuLjkhX29srNSHW6t0xZMrlZcco7H5ybph8kD1TYuzujwAALoUPRZh5nQYenz2CbpwbK4CQVM7qhu1aG25pjy4RK+s3211eQAAdClmhXSh0upGldY06tEPP9cHW/YpLsqp1244TQWp9FwAAI4vzArpAfJTY3XqwDQ9cdkJOrFvihpaAvrOgo91+ROfaHOF1+ryAAAIO4JFN3A6DP3+kjFKi3epqr5F7xfv048WrlJtY4vVpQEAEFYEi26SmxSj9342SU//aKL6psaqvLZJt/5rPSt1AgBshWDRjdzRkTp5QJoevnScIp2G3ty0h/UuAAC2wuBNizy+dLt+9cqniopwaHBmglwRDk0ZlqmLxvdRarzL6vIAAGino7/fBAuLmKapHy1cpXc/29vu9nhXhOacUagfn95fEU46lAAAPQPB4jhQ7/Nr0dpypce7VFXv0zOflGrT7rbZIhMKkvX7i8coLyXW4ioBAOim6ab33nuvDMPQjTfeeCxP02vFuyL0w5MKNG1Eln5wUoFevu5UPfi90UpwRWjVzv066/dLtGDxNgZ4AgCOG0cdLFauXKm//vWvGjVqVDjr6dUcDkMXjuujV68/TSf1T1Fza1D3vfGZ/vDuVqtLAwCgQ44qWNTX12vWrFn629/+puTk5HDX1Ovlp8bqmatO0u3nDpMkPfTOVl371Gq9/J/d9F4AAHq0o9qEbO7cuZoxY4amTJmiX//610c81ufzyefzhf72ellxsiMMw9CVp/aTp7FFf3yvRK9tqNRrGyq17PNqjcxNlMOQvjchT4ZhWF0qAAAhnQ4Wzz77rNasWaOVK1d26Pj58+fr7rvv7nRhaHPz1MGaNDhDb2ys0GNLt+vpFaWh+6IjnZo5JtfC6gAAaK9Tp0LKysp0ww036KmnnlJ0dHSHHjNv3jx5PJ7Qpays7KgK7c3GFyTrFzOG6S/fH6f0BJfyv5gpcu/rn6mpJWBxdQAAfKlT001ffPFFXXDBBXI6naHbAoGADMOQw+GQz+drd9+hMN302DW3BjT5d0tUXtukH55UoLvPHy6Hg1MiAICu09Hf706dCpk8ebI2bNjQ7rbLL79cQ4YM0a233vqNoQLhER3p1O3nDtU1f1+j/1u+UzuqG/Td8X101rBMxUYd1bAZAADColO/QgkJCRoxYkS72+Li4pSamnrQ7eha00Zk68HvjdZtL2zQh1ur9OHWKhWmx+m+74xShadZo/skKT+VxbUAAN2L/3t7HLtwXB8Ny3HrX6t36aV1u7VtX4O++8gySZIrwqFbpw3R5af0ZeYIAKDbsKS3TezxNuvq/12l9eUe5SXHqrSmUZL0wHdH6aIJeRZXBwA43rFXSC8UCJpqag0oLsqp3721RX96v0SJMZF65+ZJSk9gx1QAwNHrksGb6NmcDkPxrrb/pDdOGaj3i/dq026vpv/hA/VPi9e+ep/OG52jm88aZHGlAAC7Yl9um4pwOnT/d0cpJS5KVfUt+mRHjbZXNeiP727VK+t3W10eAMCmOBVic82tAa3f5VGFp0mrd+7X/y7bKVeEQwWpsRpfkKwfntRXw3L47wAAODLGWOAg/kBQlz2xUktLqtrdftH4PvrFjKFKio2yqDIAQE9HsMAhBYOmNpR7VFXv0wtryvXqhgpJ0tBst16+7hRFODk7BgA4WEd/v/kV6WUcDkOj85I0eWim/jxrnJ6/pkjJsZHaXOHV35fvlCQ1tQS0ucKrFn/Q4moBAMcbZoX0chP6puhnZw/WLxZt1INvb1F1Q4ueW7VLld5muaMjNOukAv30rEH0ZAAAOoRfC+iSE/I1PMctb7NfD79XokpvsyIchrzNfi1YvE2XP7lS3uZWq8sEABwHGGMBSdL+hhY9tWKnPt/XoKHZbv3gpAK9vXmPbn1+vZpaAxqbn6SFV5wod3Sk1aUCACzA4E2ExcZyj37w+ArVNrZqZG6iFvxgnPoks7kZAPQ2BAuEzcZyj374+Artb2xVQnSExhcka0iWWxP7pSgt3qWBmfGKjnRaXSYAoAsRLBBWZTWNmvv0Gq3f5TnovtykGP1rzsnKSoy2oDIAQHcgWCDsWgNBrdxRox1VjVpTul//KatVpadZdT6/RuYm6tmrT1Kci4lGAGBHBAt0i7KaRp3/p6Xa39iqjASXbpwySFOHZ+qP725VlNOhn58zVA6HYXWZAIBjRLBAt1lTul/XP7NWu/Y3SWrbZTUQbPtY3TZ9iM4dlS2nw1B2YoyVZQIAjgHBAt3K5w/o6RWlevi9EtU0tCgt3qWqep8chhQ0pZhIp567pkgjchOtLhUAcBQIFrBEXXOrPtleo5ML03TTP9bpjU2Voftyk2L07+tOUWq8y8IKAQBHg2AByzW3BvTmpkoNzEjQnKdWa2d1o7Lc0bp1+mANz0nUgPR4xl8AwHGCYIEepWRvnX60cJV2VDeGbhuW7daF43IV4TB0zqhsZSQwXRUAeiqCBXqcppaA/vjeVi3dWqWte+vU3Prl7qm5STH65zVFyk1igCcA9EQEC/Ro+xtatHDZDm3ZU6f1uzzatb9JafFROnNIhn48qVCF6fFWlwgA+AqCBY4bFZ4mXfro8tBpktS4KD1x+Qny+YMakB6v5LgoiysEABAscFxpaglo+efV+u1bxdq02xu6Pcrp0Hmjc/Trb49QTFTbfiSeplYluCIY+AkA3aijv9+ObqwJOKyYKKe+NSRD/3vFiRqY0XYaJC0+Si2BoP61Zpdu/Mda+fwB3ffGZxrzy7d03TNr1M2ZGADQAfRYoMdpbg2osSWglLgofbBln360cJVaAsGDjnvgu6N00YQ8CyoEgN6HHgsct6IjnUr5YlzF6YPS9dvvjVZ0ZNtHNSk2UjNGZUuS5r2wQeN/9bbm/H21Nhxi11UAQPejxwLHhbrmVvn8QSXGRMqQdMmjy7Vq5/7Q/YYh3fPtkfr+xHzrigQAG2PwJmzN5w9oZ3Wj6ppb9fjS7XptQ9vS4QWpsQoETf3p++M0Ji/J2iIBwEYIFug1TNPUPa9u1mNLt4duc0dH6IYpg+QwpJS4KA3MSNDgrAQ5mUkCAEeFYIFexTRNfbi1Sg7D0O/f2aLVXzlNckBqXJR+f/EYnT4o3YIKAeD4RrBAr+VtbtWDb23RHm+zHIahfXU+fVrhVb3Pr0inoVkTC5QWH6XzR+cqPzXW6nIB4LhAsAC+osUf1E3/WKdXN1SEbjMMaXiOW3nJseqTHKNTB6ZrEr0ZAHBIBAvgawJBU/9YWaYd1Q36rLJOH2zZd9AxZw7J0P3fHaW0eJcFFQJAz0WwAL5BWU2jiivrtGt/oz6rrNPzq3fJHzQ1ICNePz1rkD6valBhepxO6JuiVIIGgF6OYAF00pY9dZr9P5+owtPc7nanw9CpA9L0y5nDVZAaZ1F1AGAtVt4EOmlQZoKevfokFabHqU9yjGaMytaQrAQFgqaWbNmny59YKU9TqySpuLJOW/fUWVwxAPQ89FgA36Bkb71++PgKVXiaNbpPooZmu/WPVWVyGIZ+NXNEaLVP0zRlGKyTAcCeOBUChNGGXR5d9NeP1dx68GZo2YnRiopwqHx/k35y5kBdP3mAPE2tSoqNsqBSAOgaBAsgzHZWN2jR2nJt29egC8fl6tPdXj30zha1Btp/hXKTYlRe26RrJhXqtulDLKoWAMKLYAF0gwafX5t2e+UPBPVphVe/fnVzu/t//e0RSoiO0Ji8JPVJjlWFp0m5STGcMgFw3CFYABb4YMs+7fE2a/0uj/5v+c5298VEOtXUGtDUYZn646VjtbO6Uf3S4hQVwRhqAD0fwQKwUIs/qCsXrtTGco/6JMdq026Pgl/5psVGOdXYEtCIXLfmnjFAH5ZUqV9qnGaOzVFGQrR1hQPAYRAsgB5kb12zahtbVeFp1tX/u0o+/8GDQCUp0mnoogl5umHyQGW6CRgAeo4uWcdiwYIFGjVqlNxut9xut4qKivT6668fc7GA3WUkRGtQZoImDUrXS9edokd/OF7v3DxJI3Ldiol06uIJeRqbn6TWgKmnV5Rq2kMf6I2NFaqq91ldOgB0Sqd6LF5++WU5nU4NHDhQpmlq4cKFeuCBB7R27VoNHz68Q89BjwXwpWDQlD9ohsZZfLK9Rne/vEmbdntDx4zLT9J1Zw7QiJxEORyGXBEOJURHWlUygF6q206FpKSk6IEHHtCVV14Z1sKA3qq5NaD73yjWK+t3a1+9T1//hjodhi45IU/nj85RdmKM+iTHyOFglgmArtXlwSIQCOi5557T7NmztXbtWg0bNuyQx/l8Pvl8X3bner1e5eXlESyADthb16y/vL9Nb3+6R7s9TQeFDEmKi3JqXEGyigpTlRgTqQHp8RpXkKxIJ7NNAIRPlwWLDRs2qKioSM3NzYqPj9fTTz+tc84557DH33XXXbr77rsPup1gAXSOPxCUwzC0ckeNHlmyTTuqG1Ve26SWQwwETYyJ1C/OGaopwzLlaWpV39RY1s4AcEy6LFi0tLSotLRUHo9Hzz//vB577DEtWbKEHgvAAv5AUCX76rV0a5U2lHtU3+zX2rJa1TS0tDvulAGpumHyII3OS1SjL6A4VwTrZwDolG4bYzFlyhQVFhbqr3/9a1gLA3B0AkFTj37wuR58u1itAVNOh6FAsP3XPN4VoclDM/SzqYOVlxJrUaUAjicd/f2OONYXCgaD7XokAFjL6TA054xC/bCoQIGAKU9Tq37/zhYtLt6r/Y1t277X+/x6ad1ufbi1SlOGZmhdWa18/qBOLkzVXecPlyvCKdM0tdvTrJzEaE6jAOiwTgWLefPmafr06crPz1ddXZ2efvppLV68WG+++WZX1QfgKMW72r7eibGR+v3FYxQMmqpuaJE7JkIby726898btbHcq3+u2hV6zM7qRnmaWnXVaf314Ntb9OHWKp3YL0X/PWOoRuYmqmRvvVwRTuWn0ssB4NA6dSrkyiuv1LvvvquKigolJiZq1KhRuvXWW3XWWWd1+AU5FQL0DE0tAf3urWK1BoI6fVC6PE2tuvVf6w/arfWAxJhIeZpa5Ypw6LlritQ3LU7NLQFlsEIo0CuwpDeATnt38x498Gax9tX5NDgrQdd9a4CeXVmmNzZVtpt9khoXpYYWv5pbgxqa7ZbDkPqnx+vXM0coMbZt8S6fP6D3P9snnz+g80fncDoFOM4RLACETb3Pr80VXuUmxegHj63Q51UNhzzuQMjYsqdOkkK9H5ed3Fd3njeMcAEcxwgWALrEzuoGPbLkc50xOF3jC5K14vMa+YNB3fXvTaHBoQdkJLhCq4c6DCklLkqj+yTpogl5Ont45jcGjdZAkIW+gB6CYAGgW22u8Op3b23RuIIknTsyR4Yh5STF6IU1u3THS5vU1Bpod/zEfimaOSZXmW6X6n1+7drfpOWfV8vT1KrzRuXo9Y0V+qyyTr+5YKS+PTbXoncF4ACCBYAeo7k1IG9Tq3bVNuntT/fo8aXbD7li6OGMzU9SdIRTUREOfWtwun5Y1FdO9kcBuhXBAkCPVVbTqJfWlevDrVVq9gcVHeFQVmK0RvVJkmmaevqTUo3MTVRqnEv/89H2gx5/Yt8U/XhSf50+KD10qqTFH9TG3R5V17doZG6ishKZrQKEE8ECgC1sLPdo1/5G+fxBldc26U/vlaixpe20Sn5KrOacUaiahhY9tXyndnuaJUmxUU7Nmz5ES0uqFAiamjQoXWcMzmCVUeAYECwA2FJZTaOe+GiHXlpXruqv7YmSHBup+OgIldU0HfKx+SmxGpKVoGZ/UP3T4jTnjELFf7FvCoNEgSMjWACwtQafX48s2aYPtlYpJzFapw5M03fG9ZHDMPTfL27Qv9aU64KxueqfHqfFn+3T6tL9B+2ZYhiSaUoJ0RE6d1S2BmUmaEJBikb2SbToXQE9F8ECQK/29amqnqZWrd9Vq2176+WKdOr51bu0euf+gx5nGNJt04Zo0uB0le9v0vaqBjW1BJQa79LU4ZlKi3fJ29yqvV6fClJjD+rpaPEHFek0WLMDtkOwAIAjME1Tld5mxbkitLHco3c379WWPXX6cGvVER/31d1i81NidfqgNH2626uMhGg1tgb0UUmVnA5Dw7Lduuv84YqOdKi4sk5Oh6Gi/qlKjXd1x9sDwo5gAQCdZJqmnvx4h/70XokkKT3BpcKMeCW4IrS5wqv/7PKEjo1yOtQS6PiUWaltDMhPzhyomoYW5afG6qyhmUqOiwrrewC6CsECAMKstrFFLf6gYl0RchjS0ytKVV7bpFF9ErWvzqegKZ01LFNOw9Bv3yrWK+srFOV0aEx+kvZ6m7WjurHd80VFODRnUqHmnFEoSfrHyjLlJsVoaI5bTyzdLk9Tq1LiotQvLU6nDUpXblKMpLYA1NASCO1gK7WtFeIwDEVFMAgVXYNgAQAW+6zSq+zEGCXGRMrnD+hP75VoxfYa9U2N1fpdHn1W2banSpY7Wu6YCG3ZU3/Y54qKcOiyk/sqJzFaz6/ZpU27vbrylH6a2D9Vi9bu0jub9yojwaW/zBqnUX2SFAyaamjxKyE6MvQcwaCpqoa2JdYz2ZUWnUSwAIAezDRNvbqhQve8ulkVX6y/kRwbqdaAqXqfXyf2TdGkwenaV+fTurJarSur7dDzOh2GkmMj5W32q8UfVF5KjGaOztV/nVyg/3r8k1CYmTEyW9dMKtSm3R4lxUZq/S6P3vtsr66ZVMgS6jgkggUAHAd8/oBeXFuu4sp6XTOpv1yRTpVWN2pErjs0s8Q0Tb316R69sr5CTS1+DctJVGF6nH758qcyDEMzx+Ro+ogsPfrB53rr0z2HfJ0EV4TqfH4dmKxyuP/ldxjSz88ZquTYKOV8cerlk+01WrmjRi3+oE4qTG3b06WxVb+cOVwT+6ce9Bw7qhqUnuBS3BenappbA6qq9yknMUYOlmI/bhEsAMDm/IGgHIbR7se6vLZJ3qZWxbsi5I6O1JubKvXzRRvkD5pyR0fohWtPkbe5Vdc9tUZVDS0an5+sxtaAkmIiFRPp1BubKjv8+oYhzZlUqBunDAqN7Xj5P7v1k2fWKi0+Sj88qa8qPE16bUOFvM1+xbsidNGEPpo3feghx4I0twYUHek89oZBlyBYAAAkSYuL9+rJj3do7rcG6IS+KZLa1tswZcoV8eUPeSBo6oE3i/XxtiolREdoZ3WjAkFT4wuSNbFfikxJyz+v1tAst0prGvXc6l2SpJS4KLX4gzp9UJo+KmnbofbrDixGJkkjcxN1+qA0xbsi5YpwKNMdrf/5aLs27PLod98brfNG56isplE3PLtW2Ykxmv+dkdpR1aDdtU2KjnSqqDBVDsNQcWWdIpyG4qLaQlRibORBrytJH5VUqa7Zr7OHZ7K+yDEgWAAAutRrGyo074UNBwWJEblufXtMrtaU7ldeSqxOHZCmif1Stbh4r3763H9U1+w/7HO6Ihy6bfoQPfbhdpXXti3NHhflVMMX+8NIUk5itEwpNDblgPyUWJ0zMltXn95fCxaXqKk1oJykGN3/RrEk6dQBabp12hCNyHWrpqFFu2ub5Q8GlZsco0iHQ3FfLO+OQyNYAAC6nKexVVv21sk0pfvf+EylNY36+48malBmwiGPL69t0mvrK7SzpkHNrUHVN/u1o7pBw3MSVd3g0+LifaFj+6bGqqk1oD1en1wRDo3ITdTO6kZV1fsktY0biYpwqLEloKbWL4NHhMOQ/2vLtzsM6cBNh1uDJC7Kqe+M76NA0FRVvU8xkU5lfTGrp97XqnNH5Whotlv+QFD3vLZZK3fU6NozBmj6iCxJ0q79TUqNj1JsVMRBz11W06g93maNzU+Ww5Aqvc2qrm9RanyUshNjvrGdg0HT8vEpBAsAQLczTfOoTzfU+/y67V/rVdvYqn5pcfrJmQNkGIY+3LpPZwzOUEpclJpbA3ptQ4UinA6dPTwzdCqnrrlVS7bs0y9f/lR763zKdLs0OMutD7bs049P76+LT8jT79/Zqjc3VarF3xYqMhJcchiG9tQ1H3Yw61fFRDp11/nD9OamPXrvs72h29PiXXJFOFRe26R4V4ROGZCq6voWjeqTpJMLU/WXxSVaU1orqe00UCBo6tMKb+jxWe5ojclL0pj8JI3NS9IJfVNkGNKqnfv1wppd+nhbtUprGnVCQYrOGZmls4ZnKdJpqGRPvUr21at/WrzG5icpzhWh2sYWrd/l0emD0o/qv8GRECwAAL1OTUOL3t28R5OHZoaCyFcHhHqbW1Xb0KrMRFcolPi/6L34aFu1XvnPbqXER6lPcqyaWvzatb9J9c1+7axpbLe3jCvCoQvH5WrR2nI1t7Y9/qvjSL7OYUiuCGeoZ6VtWnCUahp8+lrnivqnxSlomgctqHYkUREODct2a9NujwzD0Kr/niJ39KHHnBwtggUAAGHi8wf0s+fWa/nn1Tqpf6quPLWfxuQlqakloM2VXtU3+zWhb7JW79yvT3d7lRwbpYXLduizyjp9/8R8/eTMAZKkvyzepvQEl75/Yr6S46LU2OLXhl0erSur1X921erDrVWhMSixUU6dMzJbM0ZmKy8lVouL9+q1DRWh3o+cxGgNykrQ1j31ofEokjQ0262HLh6jwVmHPh11tAgWAABYyDRNNbcGFRPV8Sm09T6/XttQoUinoanDskJrgXxViz+oCMeX04xN09TWvfVaV1qrMflJhx3fcqwIFgAAIGw6+vvNvBoAABA2BAsAABA2BAsAABA2BAsAABA2BAsAABA2BAsAABA2BAsAABA2BAsAABA2BAsAABA2BAsAABA2BAsAABA2BAsAABA2BAsAABA2B+/H2sUObKbq9Xq7+6UBAMBROvC7/U2bond7sKirq5Mk5eXldfdLAwCAY1RXV6fExMTD3m+Y3xQ9wiwYDGr37t1KSEiQYRhhe16v16u8vDyVlZUdcZ94tKG9Oo626hzaq3Nor46jrTon3O1lmqbq6uqUk5Mjh+PwIym6vcfC4XCoT58+Xfb8brebD1wn0F4dR1t1Du3VObRXx9FWnRPO9jpST8UBDN4EAABhQ7AAAABhY5tg4XK5dOedd8rlclldynGB9uo42qpzaK/Oob06jrbqHKvaq9sHbwIAAPuyTY8FAACwHsECAACEDcECAACEDcECAACEjW2CxZ///Gf17dtX0dHRmjhxoj755BOrS7LcXXfdJcMw2l2GDBkSur+5uVlz585Vamqq4uPj9Z3vfEd79uyxsOLu9cEHH+i8885TTk6ODMPQiy++2O5+0zR1xx13KDs7WzExMZoyZYq2bt3a7piamhrNmjVLbrdbSUlJuvLKK1VfX9+N76J7fFNbXXbZZQd91qZNm9bumN7SVpI0f/58nXDCCUpISFBGRoa+/e1vq7i4uN0xHfn+lZaWasaMGYqNjVVGRoZuueUW+f3+7nwrXa4jbXXGGWcc9Pm65ppr2h3TG9pKkhYsWKBRo0aFFr0qKirS66+/Hrq/J3yubBEs/vGPf+jmm2/WnXfeqTVr1mj06NE6++yztXfvXqtLs9zw4cNVUVERuixdujR030033aSXX35Zzz33nJYsWaLdu3frwgsvtLDa7tXQ0KDRo0frz3/+8yHvv//++/XHP/5RjzzyiFasWKG4uDidffbZam5uDh0za9Ysbdq0SW+//bZeeeUVffDBB7r66qu76y10m29qK0maNm1au8/aM8880+7+3tJWkrRkyRLNnTtXy5cv19tvv63W1lZNnTpVDQ0NoWO+6fsXCAQ0Y8YMtbS06OOPP9bChQv15JNP6o477rDiLXWZjrSVJF111VXtPl/3339/6L7e0laS1KdPH917771avXq1Vq1apTPPPFMzZ87Upk2bJPWQz5VpAyeeeKI5d+7c0N+BQMDMyckx58+fb2FV1rvzzjvN0aNHH/K+2tpaMzIy0nzuuedCt23evNmUZC5btqybKuw5JJmLFi0K/R0MBs2srCzzgQceCN1WW1trulwu85lnnjFN0zQ//fRTU5K5cuXK0DGvv/66aRiGWV5e3m21d7evt5Vpmubs2bPNmTNnHvYxvbWtDti7d68pyVyyZIlpmh37/r322mumw+EwKysrQ8csWLDAdLvdps/n69430I2+3lamaZqTJk0yb7jhhsM+pre21QHJycnmY4891mM+V8d9j0VLS4tWr16tKVOmhG5zOByaMmWKli1bZmFlPcPWrVuVk5Oj/v37a9asWSotLZUkrV69Wq2tre3abciQIcrPz6fdJG3fvl2VlZXt2icxMVETJ04Mtc+yZcuUlJSkCRMmhI6ZMmWKHA6HVqxY0e01W23x4sXKyMjQ4MGDNWfOHFVXV4fu6+1t5fF4JEkpKSmSOvb9W7ZsmUaOHKnMzMzQMWeffba8Xm/o/53a0dfb6oCnnnpKaWlpGjFihObNm6fGxsbQfb21rQKBgJ599lk1NDSoqKiox3yuun0TsnCrqqpSIBBo10iSlJmZqc8++8yiqnqGiRMn6sknn9TgwYNVUVGhu+++W6eddpo2btyoyspKRUVFKSkpqd1jMjMzVVlZaU3BPciBNjjU5+rAfZWVlcrIyGh3f0REhFJSUnpdG06bNk0XXnih+vXrp23btunnP/+5pk+frmXLlsnpdPbqtgoGg7rxxht1yimnaMSIEZLUoe9fZWXlIT9/B+6zo0O1lSR9//vfV0FBgXJycrR+/XrdeuutKi4u1gsvvCCp97XVhg0bVFRUpObmZsXHx2vRokUaNmyY1q1b1yM+V8d9sMDhTZ8+PfTvUaNGaeLEiSooKNA///lPxcTEWFgZ7OaSSy4J/XvkyJEaNWqUCgsLtXjxYk2ePNnCyqw3d+5cbdy4sd34Jhza4drqq2NxRo4cqezsbE2ePFnbtm1TYWFhd5dpucGDB2vdunXyeDx6/vnnNXv2bC1ZssTqskKO+1MhaWlpcjqdB4163bNnj7KysiyqqmdKSkrSoEGDVFJSoqysLLW0tKi2trbdMbRbmwNtcKTPVVZW1kEDhP1+v2pqanp9G/bv319paWkqKSmR1Hvb6rrrrtMrr7yi999/X3369And3pHvX1ZW1iE/fwfus5vDtdWhTJw4UZLafb56U1tFRUVpwIABGj9+vObPn6/Ro0frD3/4Q4/5XB33wSIqKkrjx4/Xu+++G7otGAzq3XffVVFRkYWV9Tz19fXatm2bsrOzNX78eEVGRrZrt+LiYpWWltJukvr166esrKx27eP1erVixYpQ+xQVFam2tlarV68OHfPee+8pGAyG/oevt9q1a5eqq6uVnZ0tqfe1lWmauu6667Ro0SK999576tevX7v7O/L9Kyoq0oYNG9oFsrfffltut1vDhg3rnjfSDb6prQ5l3bp1ktTu89Ub2upwgsGgfD5fz/lchWUIqMWeffZZ0+VymU8++aT56aefmldffbWZlJTUbtRrb/TTn/7UXLx4sbl9+3bzo48+MqdMmWKmpaWZe/fuNU3TNK+55hozPz/ffO+998xVq1aZRUVFZlFRkcVVd5+6ujpz7dq15tq1a01J5oMPPmiuXbvW3Llzp2mapnnvvfeaSUlJ5ksvvWSuX7/enDlzptmvXz+zqakp9BzTpk0zx44da65YscJcunSpOXDgQPPSSy+16i11mSO1VV1dnfmzn/3MXLZsmbl9+3bznXfeMceNG2cOHDjQbG5uDj1Hb2kr0zTNOXPmmImJiebixYvNioqK0KWxsTF0zDd9//x+vzlixAhz6tSp5rp168w33njDTE9PN+fNm2fFW+oy39RWJSUl5i9/+Utz1apV5vbt282XXnrJ7N+/v3n66aeHnqO3tJVpmuZtt91mLlmyxNy+fbu5fv1687bbbjMNwzDfeust0zR7xufKFsHCNE3z4YcfNvPz882oqCjzxBNPNJcvX251SZa7+OKLzezsbDMqKsrMzc01L774YrOkpCR0f1NTk3nttdeaycnJZmxsrHnBBReYFRUVFlbcvd5//31T0kGX2bNnm6bZNuX09ttvNzMzM02Xy2VOnjzZLC4ubvcc1dXV5qWXXmrGx8ebbrfbvPzyy826ujoL3k3XOlJbNTY2mlOnTjXT09PNyMhIs6CgwLzqqqsOCva9pa1M0zxkW0kyn3jiidAxHfn+7dixw5w+fboZExNjpqWlmT/96U/N1tbWbn43Xeub2qq0tNQ8/fTTzZSUFNPlcpkDBgwwb7nlFtPj8bR7nt7QVqZpmldccYVZUFBgRkVFmenp6ebkyZNDocI0e8bnim3TAQBA2Bz3YywAAEDPQbAAAABhQ7AAAABhQ7AAAABhQ7AAAABhQ7AAAABhQ7AAAABhQ7AAAABhQ7AAAABhQ7AAAABhQ7AAAABhQ7AAAABh8/8BE195lkFYLGQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 256)               2816      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 16)                64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48577 (189.75 KB)\n",
      "Trainable params: 47585 (185.88 KB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
