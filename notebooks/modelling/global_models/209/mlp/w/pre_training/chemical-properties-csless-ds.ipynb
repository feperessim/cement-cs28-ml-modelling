{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 16:16:27.489009: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-21 16:16:27.491277: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-21 16:16:27.539260: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-21 16:16:27.540305: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-21 16:16:28.286909: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/206/mlp/b/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 10\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 10\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 10\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"W\\\",\\n    \\\"Features\\\": \\\"Chemical + Properties CS Less\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"W\\\",\\n    \\\"Features\\\": \\\"Chemical + Properties CS Less\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"209\",\n",
    "    \"Plant\": \"W\",\n",
    "    \"Features\": \"Chemical + Properties CS Less\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/209/global_w.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/209/global_w.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/209/global_w.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f52f4_row0_col0, #T_f52f4_row1_col0, #T_f52f4_row2_col0, #T_f52f4_row3_col0, #T_f52f4_row4_col0, #T_f52f4_row5_col0, #T_f52f4_row6_col0, #T_f52f4_row7_col0, #T_f52f4_row8_col0, #T_f52f4_row9_col0, #T_f52f4_row10_col0, #T_f52f4_row11_col0, #T_f52f4_row12_col0, #T_f52f4_row13_col0, #T_f52f4_row14_col0, #T_f52f4_row15_col0, #T_f52f4_row16_col0 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f52f4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f52f4_level0_col0\" class=\"col_heading level0 col0\" >Zero (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f52f4_level0_row0\" class=\"row_heading level0 row0\" >CaO</th>\n",
       "      <td id=\"T_f52f4_row0_col0\" class=\"data row0 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52f4_level0_row1\" class=\"row_heading level0 row1\" >Insoluble Residue</th>\n",
       "      <td id=\"T_f52f4_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52f4_level0_row2\" class=\"row_heading level0 row2\" >CS7</th>\n",
       "      <td id=\"T_f52f4_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52f4_level0_row3\" class=\"row_heading level0 row3\" >CS3</th>\n",
       "      <td id=\"T_f52f4_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52f4_level0_row4\" class=\"row_heading level0 row4\" >Final setting time</th>\n",
       "      <td id=\"T_f52f4_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52f4_level0_row5\" class=\"row_heading level0 row5\" >Initial setting time</th>\n",
       "      <td id=\"T_f52f4_row5_col0\" class=\"data row5 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52f4_level0_row6\" class=\"row_heading level0 row6\" >#325</th>\n",
       "      <td id=\"T_f52f4_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52f4_level0_row7\" class=\"row_heading level0 row7\" >Blaine</th>\n",
       "      <td id=\"T_f52f4_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52f4_level0_row8\" class=\"row_heading level0 row8\" >Loss on Ignition</th>\n",
       "      <td id=\"T_f52f4_row8_col0\" class=\"data row8 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52f4_level0_row9\" class=\"row_heading level0 row9\" >MgO</th>\n",
       "      <td id=\"T_f52f4_row9_col0\" class=\"data row9 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52f4_level0_row10\" class=\"row_heading level0 row10\" >Fe2O3</th>\n",
       "      <td id=\"T_f52f4_row10_col0\" class=\"data row10 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52f4_level0_row11\" class=\"row_heading level0 row11\" >K2O</th>\n",
       "      <td id=\"T_f52f4_row11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52f4_level0_row12\" class=\"row_heading level0 row12\" >SO3</th>\n",
       "      <td id=\"T_f52f4_row12_col0\" class=\"data row12 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52f4_level0_row13\" class=\"row_heading level0 row13\" >SiO2</th>\n",
       "      <td id=\"T_f52f4_row13_col0\" class=\"data row13 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52f4_level0_row14\" class=\"row_heading level0 row14\" >Al2O3</th>\n",
       "      <td id=\"T_f52f4_row14_col0\" class=\"data row14 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52f4_level0_row15\" class=\"row_heading level0 row15\" >Na2O</th>\n",
       "      <td id=\"T_f52f4_row15_col0\" class=\"data row15 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52f4_level0_row16\" class=\"row_heading level0 row16\" >CS28</th>\n",
       "      <td id=\"T_f52f4_row16_col0\" class=\"data row16 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x706bd1957940>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_formatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_values = {}\n",
    "for col in df.select_dtypes(include=\"number\").columns:\n",
    "    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\n",
    "    zero_values[col] = zero_percentages\n",
    "\n",
    "zero_percentages = pd.Series(zero_values, name=f\"Zero (%)\")\n",
    "zero_percentages = zero_percentages.sort_values(ascending=False)\n",
    "zero_percentages = zero_percentages.to_frame(name=f\"Zero (%)\")\n",
    "zero_percentages.style.background_gradient(cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Factory_Plant\\\",\\n        \\\"Cement_Type\\\",\\n        # \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Factory_Plant\\\",\\n        \\\"Cement_Type\\\",\\n        # \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop(\n",
    "    [\n",
    "        \"Factory_Plant\",\n",
    "        \"Cement_Type\",\n",
    "        # \"CS1\",\n",
    "        \"CS3\",\n",
    "        \"CS7\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 22:32:45.170783: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  10.055364191532135\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.791 (0.000)\n",
      "MAE: 1.357 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.932 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.438 (0.000)\n",
      "MAE: 1.757 (0.000)\n",
      "MAPE: 0.042 (0.000)\n",
      "R2: 0.830 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  10.068839538097382\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.785 (0.000)\n",
      "MAE: 1.345 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.932 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.353 (0.000)\n",
      "MAE: 1.705 (0.000)\n",
      "MAPE: 0.041 (0.000)\n",
      "R2: 0.841 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  13.454772186279296\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.705 (0.000)\n",
      "MAE: 1.308 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.938 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.203 (0.000)\n",
      "MAE: 1.602 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.861 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.330696964263916\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.525 (0.000)\n",
      "MAE: 1.158 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.951 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.311 (0.000)\n",
      "MAE: 1.618 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.847 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  16.456223130226135\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.614 (0.000)\n",
      "MAE: 1.244 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.945 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.422 (0.000)\n",
      "MAE: 1.724 (0.000)\n",
      "MAPE: 0.042 (0.000)\n",
      "R2: 0.832 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.888761552174888\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.626 (0.000)\n",
      "MAE: 1.227 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.944 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.196 (0.000)\n",
      "MAE: 1.591 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.862 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  22.847807065645853\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.548 (0.000)\n",
      "MAE: 1.166 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.949 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.174 (0.000)\n",
      "MAE: 1.561 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.865 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  13.258523746331532\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.579 (0.000)\n",
      "MAE: 1.214 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.947 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.291 (0.000)\n",
      "MAE: 1.661 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.850 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  20.943517887592314\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.482 (0.000)\n",
      "MAE: 1.154 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.953 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.510 (0.000)\n",
      "MAE: 1.817 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.820 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  22.8476766705513\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.501 (0.000)\n",
      "MAE: 1.143 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.952 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.220 (0.000)\n",
      "MAE: 1.596 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.859 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.113702523708344\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.594 (0.000)\n",
      "MAE: 1.202 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.946 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.257 (0.000)\n",
      "MAE: 1.610 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.854 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.359127501646677\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.733 (0.000)\n",
      "MAE: 1.307 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.936 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.180 (0.000)\n",
      "MAE: 1.600 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.864 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  13.468925988674163\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.999 (0.000)\n",
      "MAE: 1.512 (0.000)\n",
      "MAPE: 0.034 (0.000)\n",
      "R2: 0.915 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.289 (0.000)\n",
      "MAE: 1.638 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.850 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/209/w/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/209/w/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/209/w/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>209</td>\n",
       "      <td>W</td>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>(57588, 14)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_7</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>1.548178</td>\n",
       "      <td>1.16633</td>\n",
       "      <td>0.026416</td>\n",
       "      <td>0.949059</td>\n",
       "      <td>2.174181</td>\n",
       "      <td>1.561187</td>\n",
       "      <td>0.037339</td>\n",
       "      <td>0.864596</td>\n",
       "      <td>-4.797856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category Company Plant                       Features   Data Shape  \\\n",
       "6  Global Model     209     W  Chemical + Properties CS Less  (57588, 14)   \n",
       "\n",
       "  Timesteps  Model Model Params           Scaler Scaler Params  ...  \\\n",
       "6      None  MLP_7         None  Standard Scaler          None  ...   \n",
       "\n",
       "                 Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "6  {\"train_size\": 0.8, \"test_size\": 0.2}   1.548178   1.16633   0.026416   \n",
       "\n",
       "   R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "6  0.949059   2.174181  1.561187   0.037339  0.864596 -4.797856  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R²\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 23:20:26.491264: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  28.18086558977763\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.518 (0.000)\n",
      "MAE: 1.148 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.949 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.518 (0.000)\n",
      "MAE: 1.148 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.949 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/209/mlp/w/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_properties_csless_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/209/mlp/w/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_properties_csless_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/209/mlp/w/pre_training/\"\n",
    "model_name = \"mlp_chemical_properties_csless_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7cd4f7f55f30>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAx+0lEQVR4nO3df3xU1YH///dMfvJrEgImITXQaF0VQVTQOPXH2pIHAVkXV7oVzba05QNbm7hFuv5gH4I/ahtF1yJIYe1uBT+LP+p+KypfpaagsGoMEM2KiCm61NDiJFZMBoL5OefzR5ibDATJvUxyCHk9H495MHPvuXfOnEzM23PPPcdnjDECAADoR/y2KwAAAOAWAQYAAPQ7BBgAANDvEGAAAEC/Q4ABAAD9DgEGAAD0OwQYAADQ7xBgAABAv5NouwK9JRKJaN++fRo2bJh8Pp/t6gAAgB4wxujAgQPKycmR33/sfpZTNsDs27dPubm5tqsBAAA82Lt3r04//fRj7j9lA8ywYcMkdTRAIBCwXBsAANAT4XBYubm5zt/xYzllA0z0slEgECDAAADQzxxv+AeDeAEAQL9DgAEAAP0OAQYAAPQ7BBgAANDvEGAAAEC/Q4ABAAD9DgEGAAD0OwQYAADQ7xBgAABAv0OAAQAA/Q4BBgAA9DsEGAAA0O+csos59pb/r/JP2vHnBk0dl61LzxhhuzoAAAxI9MC49NofPtXqN/+o9/eFbVcFAIABiwDjkv/w6t7GbjUAABjQCDAuHc4vMoYIAwCALQQYl3y+jghDfgEAwB4CjEtODwwXkQAAsIYA4xI9MAAA2Oc6wGzZskXXXHONcnJy5PP5tG7dOmdfa2urbr/9do0fP15DhgxRTk6Ovvvd72rfvn0x59i/f7+KiooUCASUnp6uOXPm6ODBgzFl3n33XV1xxRVKTU1Vbm6ulixZ4u0Txtnh/KIIAQYAAGtcB5jGxkZNmDBBK1asOGrfoUOH9Pbbb2vRokV6++239dvf/lbV1dX627/925hyRUVF2rlzp8rKyrR+/Xpt2bJF8+bNc/aHw2FNmTJFY8aMUWVlpR588EHdfffdeuyxxzx8xPjiEhIAAPa5nshu2rRpmjZtWrf70tLSVFZWFrPt0Ucf1SWXXKKamhqNHj1au3bt0oYNG7Rt2zZNmjRJkrR8+XJdffXVeuihh5STk6O1a9eqpaVFv/71r5WcnKzzzjtPVVVVevjhh2OCjg3RHhguIQEAYE+vj4FpaGiQz+dTenq6JKm8vFzp6elOeJGkgoIC+f1+VVRUOGWuvPJKJScnO2UKCwtVXV2tzz//vNv3aW5uVjgcjnn0Bp/TBwMAAGzp1QDT1NSk22+/XTfccIMCgYAkKRQKKTMzM6ZcYmKiMjIyFAqFnDJZWVkxZaKvo2WOVFpaqrS0NOeRm5sb748jSfIfbjHmgQEAwJ5eCzCtra369re/LWOMVq5c2Vtv41i4cKEaGhqcx969e3vpnTp6YBjECwCAPb2ymGM0vHz88cfatGmT0/siSdnZ2aqrq4sp39bWpv379ys7O9spU1tbG1Mm+jpa5kgpKSlKSUmJ58foFmNgAACwL+49MNHwsnv3bv3+97/XiBGxKzYHg0HV19ersrLS2bZp0yZFIhHl5+c7ZbZs2aLW1lanTFlZmc4++2wNHz483lV2hbuQAACwz3WAOXjwoKqqqlRVVSVJ2rNnj6qqqlRTU6PW1lZ961vf0vbt27V27Vq1t7crFAopFAqppaVFknTuuedq6tSpmjt3rrZu3ao33nhDJSUlmjVrlnJyciRJN954o5KTkzVnzhzt3LlTzzzzjB555BEtWLAgfp/cIz8T2QEAYJ3rS0jbt2/XN77xDed1NFTMnj1bd999t1544QVJ0gUXXBBz3KuvvqqrrrpKkrR27VqVlJRo8uTJ8vv9mjlzppYtW+aUTUtL0yuvvKLi4mJNnDhRI0eO1OLFi63fQi11vYREggEAwBbXAeaqq6760j/ePfnDnpGRoSeffPJLy5x//vn67//+b7fV63Wdl5AAAIAtrIXkEmshAQBgHwHGIwbxAgBgDwHGpeggXuaBAQDAHgKMS8wDAwCAfQQYl5gHBgAA+wgwLvm4DQkAAOsIMC45E9lZrgcAAAMZAcatwz0wEUbxAgBgDQHGJZ/ogQEAwDYCjEvchQQAgH0EGJf80QBDHwwAANYQYFxyLiGRXwAAsIYA4xKrUQMAYB8BxiWmgQEAwD4CjFusRg0AgHUEGJcYxAsAgH0EGJeig3iZxw4AAHsIMC4xDwwAAPYRYFzyOc9IMAAA2EKAccnvZxAvAAC2EWA8ipBgAACwhgDjEmNgAACwjwDjEqtRAwBgHwHGJXpgAACwjwDjkp+1kAAAsI4A4xKXkAAAsI8A4xKrUQMAYB8BxiPiCwAA9hBgXPKzGjUAANYRYFyKXkJiIjsAAOwhwLgUXQuJ+AIAgD0EGJd8ziheu/UAAGAgI8C45MwDQ4IBAMAaAoxbh3tgIhHL9QAAYAAjwLjUOQaGHhgAAGwhwLjEWkgAANhHgHGJpQQAALCPAOOSnx4YAACsI8C4xFpIAADYR4BxiUtIAADYR4Bxix4YAACsI8C45CzmaLkeAAAMZAQYl6LzwERIMAAAWEOAcYlBvAAA2Oc6wGzZskXXXHONcnJy5PP5tG7dupj9xhgtXrxYo0aN0qBBg1RQUKDdu3fHlNm/f7+KiooUCASUnp6uOXPm6ODBgzFl3n33XV1xxRVKTU1Vbm6ulixZ4v7T9YJogAEAAPa4DjCNjY2aMGGCVqxY0e3+JUuWaNmyZVq1apUqKio0ZMgQFRYWqqmpySlTVFSknTt3qqysTOvXr9eWLVs0b948Z384HNaUKVM0ZswYVVZW6sEHH9Tdd9+txx57zMNHjC/nLiQ6YAAAsCbR7QHTpk3TtGnTut1njNHSpUt15513asaMGZKkJ554QllZWVq3bp1mzZqlXbt2acOGDdq2bZsmTZokSVq+fLmuvvpqPfTQQ8rJydHatWvV0tKiX//610pOTtZ5552nqqoqPfzwwzFBxwYfq1EDAGBdXMfA7NmzR6FQSAUFBc62tLQ05efnq7y8XJJUXl6u9PR0J7xIUkFBgfx+vyoqKpwyV155pZKTk50yhYWFqq6u1ueff97tezc3NyscDsc8eoOP1agBALAurgEmFApJkrKysmK2Z2VlOftCoZAyMzNj9icmJiojIyOmTHfn6PoeRyotLVVaWprzyM3NPfEP1A1WowYAwL5T5i6khQsXqqGhwXns3bu3V96H1agBALAvrgEmOztbklRbWxuzvba21tmXnZ2turq6mP1tbW3av39/TJnuztH1PY6UkpKiQCAQ8+gNTGQHAIB9cQ0weXl5ys7O1saNG51t4XBYFRUVCgaDkqRgMKj6+npVVlY6ZTZt2qRIJKL8/HynzJYtW9Ta2uqUKSsr09lnn63hw4fHs8quOZeQ6IIBAMAa1wHm4MGDqqqqUlVVlaSOgbtVVVWqqamRz+fT/Pnzdd999+mFF17Qjh079N3vflc5OTm69tprJUnnnnuupk6dqrlz52rr1q164403VFJSolmzZiknJ0eSdOONNyo5OVlz5szRzp079cwzz+iRRx7RggUL4vbBveISEgAA9rm+jXr79u36xje+4byOhorZs2dr9erVuu2229TY2Kh58+apvr5el19+uTZs2KDU1FTnmLVr16qkpESTJ0+W3+/XzJkztWzZMmd/WlqaXnnlFRUXF2vixIkaOXKkFi9ebP0W6g5cQgIAwDafOUWvhYTDYaWlpamhoSGu42F+tzOkf/y/lbpodLp++6PL4nZeAADQ87/fp8xdSH0lOoiXxRwBALCHAONS5zwwAADAFgKMS77O25Cs1gMAgIGMAONS51pIAADAFgKMS9G1kOiAAQDAHgKMS9ErSBESDAAA1hBgXKIHBgAA+wgwLnEXEgAA9hFgXHIWc6QLBgAAawgwLrEWEgAA9hFgXOq8hESCAQDAFgKMW/TAAABgHQHGJR+rUQMAYB0BxiW/0wNDhAEAwBYCjEvMAwMAgH0EGJdYCwkAAPsIMC51LkZNhAEAwBYCjEvOJSTL9QAAYCAjwLgUvYTEYo4AANhDgHGp8xKS1WoAADCgEWBc4i4kAADsI8C45Dt+EQAA0MsIMC5FV6NmDAwAAPYQYFxiNWoAAOwjwHjEatQAANhDgHGJHhgAAOwjwLjkZyI7AACsI8C45GM1agAArCPAuOQT88AAAGAbAcYlVqMGAMA+AoxLfi4hAQBgHQHGtehEdparAQDAAEaAcYlBvAAA2EeAcclZjdpqLQAAGNgIMC75GMULAIB1BBiX/OQXAACsI8C45BOrUQMAYBsBxiXWQgIAwD4CjEesRg0AgD0EGJf8fpYSAADANgKMS85t1AQYAACsIcC41HkXNQkGAABbCDAusRo1AAD2xT3AtLe3a9GiRcrLy9OgQYN05pln6qc//WnM1PvGGC1evFijRo3SoEGDVFBQoN27d8ecZ//+/SoqKlIgEFB6errmzJmjgwcPxru6rjGPHQAA9sU9wDzwwANauXKlHn30Ue3atUsPPPCAlixZouXLlztllixZomXLlmnVqlWqqKjQkCFDVFhYqKamJqdMUVGRdu7cqbKyMq1fv15btmzRvHnz4l1d16IBhnlgAACwJzHeJ3zzzTc1Y8YMTZ8+XZL01a9+VU899ZS2bt0qqaP3ZenSpbrzzjs1Y8YMSdITTzyhrKwsrVu3TrNmzdKuXbu0YcMGbdu2TZMmTZIkLV++XFdffbUeeugh5eTkxLvaPcYlJAAA7It7D8zXv/51bdy4UX/4wx8kSf/zP/+j119/XdOmTZMk7dmzR6FQSAUFBc4xaWlpys/PV3l5uSSpvLxc6enpTniRpIKCAvn9flVUVHT7vs3NzQqHwzGP3hDtgQEAAPbEvQfmjjvuUDgc1jnnnKOEhAS1t7frZz/7mYqKiiRJoVBIkpSVlRVzXFZWlrMvFAopMzMztqKJicrIyHDKHKm0tFT33HNPvD/OUbrmF2NM5+KOAACgz8S9B+Y3v/mN1q5dqyeffFJvv/221qxZo4ceekhr1qyJ91vFWLhwoRoaGpzH3r17e+V9/F0CC5eRAACwI+49MLfeeqvuuOMOzZo1S5I0fvx4ffzxxyotLdXs2bOVnZ0tSaqtrdWoUaOc42pra3XBBRdIkrKzs1VXVxdz3ra2Nu3fv985/kgpKSlKSUmJ98c5StcOl4gx8oseGAAA+lrce2AOHTokvz/2tAkJCYpEIpKkvLw8ZWdna+PGjc7+cDisiooKBYNBSVIwGFR9fb0qKyudMps2bVIkElF+fn68q+yKr0tgoQMGAAA74t4Dc8011+hnP/uZRo8erfPOO0/vvPOOHn74Yf3gBz+QJPl8Ps2fP1/33XefzjrrLOXl5WnRokXKycnRtddeK0k699xzNXXqVM2dO1erVq1Sa2urSkpKNGvWLKt3IHV8gM6nXEICAMCOuAeY5cuXa9GiRfrRj36kuro65eTk6B//8R+1ePFip8xtt92mxsZGzZs3T/X19br88su1YcMGpaamOmXWrl2rkpISTZ48WX6/XzNnztSyZcviXV3Xul5CYjkBAADs8BlzavYjhMNhpaWlqaGhQYFAIG7nPdjcpnF3/U6S9MFPpyo1KSFu5wYAYKDr6d9v1kJyKfY2amvVAABgQCPAuMQlJAAA7CPAuBRzFxL5BQAAKwgwLsX2wAAAABsIMC4dOZEdAADoewQYl7iEBACAfQQYl2LWbiTAAABgBQHGpZjFHEkwAABYQYBxqWsHTIT8AgCAFQQYl2LuQmIQDAAAVhBgXPL5WI0aAADbCDAngA4YAADsIMB44D/cCcMlJAAA7CDAeBC9jER8AQDADgKMB9FRMHTAAABgBwHGg+g4XuaBAQDADgKMB84lJPILAABWEGA8iF5CYjFHAADsIMB44FxCIr8AAGAFAcYDX8yCAgAAoK8RYDygBwYAALsIMB5EV6RmDAwAAHYQYDxw5oGxWgsAAAYuAowXLCUAAIBVBBgP6IEBAMAuAowHfj8T2QEAYBMBxoPOtZBIMAAA2ECA8YDVqAEAsIsA4wGrUQMAYBcBxoPOHhgSDAAANhBgPIjOxBuJ2K0HAAADFQHGg87bqOmBAQDABgKMB6yFBACAXQQYD1iNGgAAuwgwHvjpgQEAwCoCjAc+VqMGAMAqAswJIL4AAGAHAcYDH6tRAwBgFQHGAz9LCQAAYBUBxgN6YAAAsIsA4wFrIQEAYBcBxgNWowYAwC4CjAf0wAAAYBcBxgNnMUcSDAAAVvRKgPnzn/+sf/iHf9CIESM0aNAgjR8/Xtu3b3f2G2O0ePFijRo1SoMGDVJBQYF2794dc479+/erqKhIgUBA6enpmjNnjg4ePNgb1XXNuYREfgEAwIq4B5jPP/9cl112mZKSkvTyyy/r/fff17/+679q+PDhTpklS5Zo2bJlWrVqlSoqKjRkyBAVFhaqqanJKVNUVKSdO3eqrKxM69ev15YtWzRv3rx4V9cTVqMGAMCuxHif8IEHHlBubq4ef/xxZ1teXp7z3BijpUuX6s4779SMGTMkSU888YSysrK0bt06zZo1S7t27dKGDRu0bds2TZo0SZK0fPlyXX311XrooYeUk5MT72q74utMMAAAwIK498C88MILmjRpkv7+7/9emZmZuvDCC/WrX/3K2b9nzx6FQiEVFBQ429LS0pSfn6/y8nJJUnl5udLT053wIkkFBQXy+/2qqKjo9n2bm5sVDodjHr2FiewAALAr7gHmf//3f7Vy5UqdddZZ+t3vfqebbrpJ//RP/6Q1a9ZIkkKhkCQpKysr5risrCxnXygUUmZmZsz+xMREZWRkOGWOVFpaqrS0NOeRm5sb7492FAbxAgBgR9wDTCQS0UUXXaSf//znuvDCCzVv3jzNnTtXq1ativdbxVi4cKEaGhqcx969e3vtvRjECwCAXXEPMKNGjdLYsWNjtp177rmqqamRJGVnZ0uSamtrY8rU1tY6+7Kzs1VXVxezv62tTfv373fKHCklJUWBQCDm0VsYAgMAgF1xDzCXXXaZqqurY7b94Q9/0JgxYyR1DOjNzs7Wxo0bnf3hcFgVFRUKBoOSpGAwqPr6elVWVjplNm3apEgkovz8/HhX2TX/4VZjLSQAAOyI+11It9xyi77+9a/r5z//ub797W9r69ateuyxx/TYY49J6rj8Mn/+fN13330666yzlJeXp0WLFiknJ0fXXnutpI4em6lTpzqXnlpbW1VSUqJZs2ZZvwNJknziEhIAADbFPcBcfPHFeu6557Rw4ULde++9ysvL09KlS1VUVOSUue2229TY2Kh58+apvr5el19+uTZs2KDU1FSnzNq1a1VSUqLJkyfL7/dr5syZWrZsWbyr64mzGjUXkQAAsMJnTtHrIOFwWGlpaWpoaIj7eJgZj76u//lTg/5j9iRNPjfr+AcAAIAe6enfb9ZC8oK7kAAAsIoA44HfuYQEAABsIMB4EL2NmonsAACwgwDjARPZAQBgFwHGA5/zjAQDAIANBBgP/PTAAABgFQHGi8NdMBECDAAAVhBgPOhcC4kEAwCADQQYD5yZeMkvAABYQYDxwFkLyXI9AAAYqAgwHrAaNQAAdhFgPGA1agAA7CLAeMBq1AAA2EWAOQH0wAAAYAcBxgMmsgMAwC4CjAc+ZyI7EgwAADYQYDzonMgOAADYQIDxwNc5ihcAAFhAgPGApQQAALCLAONBtAeGxRwBALCDAOMBayEBAGAXAcYDLiEBAGAXAcYDemAAALCLAOOBM5Gd5XoAADBQEWA86OyBIcIAAGADAcYDVqMGAMAuAowX9MAAAGAVAcYDxsAAAGAXAcaD6G3UTGQHAIAdBBgPGMQLAIBdBBgPfMcvAgAAehEBxoPoWkh0wAAAYAcBxoPoJaQICQYAACsIMB4488BYrgcAAAMVAcYD1kICAMAuAowHrEYNAIBdBBgP/AziBQDAKgKMB8wDAwCAXQQYDxgDAwCAXQQYT7gLCQAAmwgwHtADAwCAXQQYD/xMZAcAgFUEGA+YyA4AALt6PcDcf//98vl8mj9/vrOtqalJxcXFGjFihIYOHaqZM2eqtrY25riamhpNnz5dgwcPVmZmpm699Va1tbX1dnV7xOdMBEOEAQDAhl4NMNu2bdO//du/6fzzz4/Zfsstt+jFF1/Us88+q82bN2vfvn267rrrnP3t7e2aPn26Wlpa9Oabb2rNmjVavXq1Fi9e3JvV7bHOiewAAIANvRZgDh48qKKiIv3qV7/S8OHDne0NDQ36j//4Dz388MP65je/qYkTJ+rxxx/Xm2++qbfeekuS9Morr+j999/Xf/7nf+qCCy7QtGnT9NOf/lQrVqxQS0tLb1W5x1iNGgAAu3otwBQXF2v69OkqKCiI2V5ZWanW1taY7eecc45Gjx6t8vJySVJ5ebnGjx+vrKwsp0xhYaHC4bB27tzZW1XuMVajBgDArsTeOOnTTz+tt99+W9u2bTtqXygUUnJystLT02O2Z2VlKRQKOWW6hpfo/ui+7jQ3N6u5udl5HQ6HT+QjfCkG8QIAYFfce2D27t2rH//4x1q7dq1SU1PjffpjKi0tVVpamvPIzc3ttfdiHhgAAOyKe4CprKxUXV2dLrroIiUmJioxMVGbN2/WsmXLlJiYqKysLLW0tKi+vj7muNraWmVnZ0uSsrOzj7orKfo6WuZICxcuVENDg/PYu3dvvD+aIzoPDKtRAwBgR9wDzOTJk7Vjxw5VVVU5j0mTJqmoqMh5npSUpI0bNzrHVFdXq6amRsFgUJIUDAa1Y8cO1dXVOWXKysoUCAQ0duzYbt83JSVFgUAg5tFbGMQLAIBdcR8DM2zYMI0bNy5m25AhQzRixAhn+5w5c7RgwQJlZGQoEAjo5ptvVjAY1KWXXipJmjJlisaOHavvfOc7WrJkiUKhkO68804VFxcrJSUl3lV2rXMaGBIMAAA29Mog3uP5xS9+Ib/fr5kzZ6q5uVmFhYX65S9/6exPSEjQ+vXrddNNNykYDGrIkCGaPXu27r33XhvVPRpjYAAAsKpPAsxrr70W8zo1NVUrVqzQihUrjnnMmDFj9NJLL/VyzbzhLiQAAOxiLSQPWMwRAAC7CDAecBs1AAB2EWA88DnDeAEAgA0EGA86e2DoggEAwAYCjAfOPDCW6wEAwEBFgPEgegGJQbwAANhBgPGAQbwAANhFgPGAeWAAALCLAOMBPTAAANhFgPHAz11IAABYRYDxgNWoAQCwiwBzAgyjYAAAsIIA4wFjYAAAsIsA44GfiewAALCKAOMBE9kBAGAXAcaD6CUkumAAALCDAOMBE9kBAGAXAcYDVqMGAMAuAowH0XlgIuQXAACsIMB4wBAYAADsIsB4wCUkAADsIsB4QA8MAAB2EWA88PujayERYQAAsIEA44HTA0N+AQDACgKMF6xGDQCAVQQYDzrHwJBgAACwgQDjgZ8eGAAArCLAeBC9jZqJ7AAAsIMA44HPeUaCAQDABgKMB50T2dmtBwAAAxUBxgNWowYAwC4CjAedY2CIMAAA2ECA8cDHXUgAAFhFgPGAtZAAALCLAOMBq1EDAGAXAcaD6ER2AADADgKMBwziBQDALgLMCSC/AABgBwHGA+5CAgDALgKMB6xGDQCAXQQYD6KDeFnMEQAAOwgwHviYCAYAAKsIMB5wCQkAALsIMB6wGjUAAHbFPcCUlpbq4osv1rBhw5SZmalrr71W1dXVMWWamppUXFysESNGaOjQoZo5c6Zqa2tjytTU1Gj69OkaPHiwMjMzdeutt6qtrS3e1fXEuQvJcj0AABio4h5gNm/erOLiYr311lsqKytTa2urpkyZosbGRqfMLbfcohdffFHPPvusNm/erH379um6665z9re3t2v69OlqaWnRm2++qTVr1mj16tVavHhxvKvrSfQSEhPZAQBgh8/08oI+n376qTIzM7V582ZdeeWVamho0GmnnaYnn3xS3/rWtyRJH3zwgc4991yVl5fr0ksv1csvv6y/+Zu/0b59+5SVlSVJWrVqlW6//XZ9+umnSk5OPu77hsNhpaWlqaGhQYFAIK6fqez9Ws19YrsuyE3XuuLL4npuAAAGsp7+/e71MTANDQ2SpIyMDElSZWWlWltbVVBQ4JQ555xzNHr0aJWXl0uSysvLNX78eCe8SFJhYaHC4bB27tzZ7fs0NzcrHA7HPHoLNyEBAGBXrwaYSCSi+fPn67LLLtO4ceMkSaFQSMnJyUpPT48pm5WVpVAo5JTpGl6i+6P7ulNaWqq0tDTnkZubG+dP08kfbTUuIQEAYEWvBpji4mK99957evrpp3vzbSRJCxcuVENDg/PYu3dvr72XT0xkBwCATYm9deKSkhKtX79eW7Zs0emnn+5sz87OVktLi+rr62N6YWpra5Wdne2U2bp1a8z5oncpRcscKSUlRSkpKXH+FMcQvY2ai0gAAFgR9x4YY4xKSkr03HPPadOmTcrLy4vZP3HiRCUlJWnjxo3OturqatXU1CgYDEqSgsGgduzYobq6OqdMWVmZAoGAxo4dG+8qu+aMgSG/AABgRdx7YIqLi/Xkk0/q+eef17Bhw5wxK2lpaRo0aJDS0tI0Z84cLViwQBkZGQoEArr55psVDAZ16aWXSpKmTJmisWPH6jvf+Y6WLFmiUCikO++8U8XFxX3Xy/IlWI0aAAC74h5gVq5cKUm66qqrYrY//vjj+t73vidJ+sUvfiG/36+ZM2equblZhYWF+uUvf+mUTUhI0Pr163XTTTcpGAxqyJAhmj17tu699954V9cT/+EuGOaBAQDAjrgHmJ5MK5OamqoVK1ZoxYoVxywzZswYvfTSS/GsWtz4nItIAADABtZC8oC1kAAAsIsA4wGrUQMAYBcBxgMG8QIAYBcBxgMfg3gBALCKAOMBayEBAGAXAcYDnzOK1249AAAYqAgwHpBfAACwiwDjARPZAQBgFwHGE+5CAgDAJgKMBz5WowYAwCoCjAesRg0AgF0EGA/8TGQHAIBVBBgPOtdCIsEAAGADAcaD6GrUxBcAAOwgwHjAatQAANhFgDkB3IUEAIAdBBgPooN4I+QXAACsIMB4wCUkAADsIsB4EA0wDOMFAMAOAowHPpYSAADAKgKMByzmCACAXQQYDzrXQgIAADYQYDzhEhIAADYRYDxgKQEAAOwiwHjAYo4AANhFgPFgSHKCJKmxpU3tzGYHAECfI8B4kDEkWT5fx0y8+xtbbFcHAIABhwDjQWKCX8MHJ0uS/nKw2XJtAAAYeAgwHp02NEUSAQYAABsIMB6NHEYPDAAAthBgPBoZ7YE5wBgYAAD6GgHGo5FcQgIAwBoCjEfRAPMpAQYAgD5HgPFo5NDoGBguIQEA0NcIMB6NHBYdA0MPDAAAfY0A4xG3UQMAYA8BxqPoGJjPGlsUYTkBAAD6FAHGoxGHx8C0R4w+P8Q4GAAA+hIBxqOkBL/SBydJYiAvAAB9jQBzApgLBgAAOwgwJyA6kPfDuoMyhnEwAAD0lUTbFejPsgIdAeauF3bqvv//fZ02NEWnBVKVOSxFI4emKCnBJ7/Pp6QEnzKGpCg1ya+2dqPU5AQNTUnQkOREDUlJ1ODkBA1KTtDgpESlJvs1KClBg5ISlJhAvgQAoDsEmBPwf644Q58ebNb2P36u5raI9jU0aV9DU9zOn5zgV2qSX4OTE5Xg98kYo4yhyUoflKykBJ+SEvxKSvQryX+M5wl+DUlOUEqiXxEjRYxRgt+nwckJGpycqKQEv9oiESX6O95nUFKCUpMSlJzod86fmNBxzsQEvxITfEryd/yb6PfJ5/PF7bMCAOCGz5zE1z5WrFihBx98UKFQSBMmTNDy5ct1ySWX9OjYcDistLQ0NTQ0KBAI9Go9W9sjqjvQrLpwU8e/B5q1/2CL2iMRRYzU0h7RXw42q7XdKNHv0xct7WpsadPB5jY1NrfpUEu7vmhp1xetHY+T9ycSK9Hviw01xwo7CX4lJ/iUePh1UoJfif5oQOrYnpTgO+L5sc+V6PcpweeT398RpPyHXyf4pQS/Xwl+ye/zKeGY5Xyd+/1dy6lHx/h9IrwBQC/p6d/vk7YH5plnntGCBQu0atUq5efna+nSpSosLFR1dbUyMzNtVy9GUoJfX0kfpK+kDzrhcxlj1NwWcQLNoZZ2NbW2qy1i5FPHgOFwU6ta241a2yNqbYuoLWLU0h5Ra5tRWyTiPG9tj6ixpU0tbRH5fT75fFJbxOiLlnYdamlTa3tHj0xbe0RNrRE1tbWruTWi5rZ2tbYbtbVH1Brp+Le7qW7aIkZtEaMmRU74c/c3MaGnS+CJDTod/3YNQn7/4aDVJUD5j/HcCU5+nxJ86tF7+CTnZ+3zdb72Hz7e5+vy2tfRi+bvsq3jdbRc5+vO8tGyXcsr5jzHKuPvEv5i6qlofTufd+47XL7Lc3+XcpKcz+0cJ0mHyxz5fnLepwfvf/ichFXg5HTS9sDk5+fr4osv1qOPPipJikQiys3N1c0336w77rjjuMf3ZQ/MQBCJGLVGImprN2pr73ze2h5Ra3tHiGptP7w/EjkcgLoe0xmG2to7Alebc9wR+7s9V+f+9ojUHomo3XTUqz1i1G6MIocDVcQc3nbE844yOrr84dfR8m0R0296wdB3YgKVOgOPjgpEnWV0ZPDqcqzk6yZMdQamaKg6br26hLkj69c1UKprvY44/5Hn6PrGXcsfve3Y5Zx3iv3nqDLOc1/nMcf73Ed9xqOO6VKvbup99Pajyx9rf/efx33I7fwOxX5fui977POfaL7u/ud79M+h83nsvlkX5+r809NPrBJH6Nc9MC0tLaqsrNTChQudbX6/XwUFBSovL7dYs4HL7/cpxZ+glJPyGxN/xhwReoxRe3ts0HGCUZdA1H7E9o5yiglHR4auYx8TOVxOX1Kuy3kiklFH+DLGyKhj3FPEyNkWfR0xHeW6vo5EYrd1LW/U5XXkyOO7lu/++KPKRzrraExHvaP1lDrLOvsPHx+tR/SzRbcppnzncfH9TkTfq+uJSboY2IJnjIh7gOmpk/LP0V/+8he1t7crKysrZntWVpY++OCDbo9pbm5Wc3PnfCzhcLhX64hTm893eEyO7YrghHQNPp2BJxryujzvsl8xgSo2ZMkJUbHHOu/T3XZ1BrPIkWW+pD496RyPDWqdPYddA6XzbzfnjoY/cziIRevR9fxSbF06tx1Zk2Md23Vbl/OYY5zfxJY76jMbddO+sccfWYfj1eOo8t183q6bj9UePekNOepn0OVnc9xjj18kpp7HP9/RP7fOcxzdRt39TM/OHtbDWsXfKfPf59LSUt1zzz22qwHgJBIdPyNJCV/SDQ+g/zkpJxoZOXKkEhISVFtbG7O9trZW2dnZ3R6zcOFCNTQ0OI+9e/f2RVUBAIAFJ2WASU5O1sSJE7Vx40ZnWyQS0caNGxUMBrs9JiUlRYFAIOYBAABOTSftJaQFCxZo9uzZmjRpki655BItXbpUjY2N+v73v2+7agAAwLKTNsBcf/31+vTTT7V48WKFQiFdcMEF2rBhw1EDewEAwMBz0s4Dc6KYBwYAgP6np3+/T8oxMAAAAF+GAAMAAPodAgwAAOh3CDAAAKDfIcAAAIB+hwADAAD6HQIMAADodwgwAACg3zlpZ+I9UdH5+cLhsOWaAACAnor+3T7ePLunbIA5cOCAJCk3N9dyTQAAgFsHDhxQWlraMfefsksJRCIR7du3T8OGDZPP54vbecPhsHJzc7V3716WKOgB2qvnaCt3aK+eo616jrZypzfayxijAwcOKCcnR37/sUe6nLI9MH6/X6effnqvnT8QCPDldoH26jnayh3aq+doq56jrdyJd3t9Wc9LFIN4AQBAv0OAAQAA/Q4BxqWUlBTdddddSklJsV2VfoH26jnayh3aq+doq56jrdyx2V6n7CBeAABw6qIHBgAA9DsEGAAA0O8QYAAAQL9DgAEAAP0OAcalFStW6Ktf/apSU1OVn5+vrVu32q6SdXfffbd8Pl/M45xzznH2NzU1qbi4WCNGjNDQoUM1c+ZM1dbWWqxx39qyZYuuueYa5eTkyOfzad26dTH7jTFavHixRo0apUGDBqmgoEC7d++OKbN//34VFRUpEAgoPT1dc+bM0cGDB/vwU/SN47XV9773vaO+a1OnTo0pM1DaqrS0VBdffLGGDRumzMxMXXvttaquro4p05PfvZqaGk2fPl2DBw9WZmambr31VrW1tfXlR+l1PWmrq6666qjv1g9/+MOYMgOhrSRp5cqVOv/8853J6YLBoF5++WVn/8nyvSLAuPDMM89owYIFuuuuu/T2229rwoQJKiwsVF1dne2qWXfeeefpk08+cR6vv/66s++WW27Riy++qGeffVabN2/Wvn37dN1111msbd9qbGzUhAkTtGLFim73L1myRMuWLdOqVatUUVGhIUOGqLCwUE1NTU6ZoqIi7dy5U2VlZVq/fr22bNmiefPm9dVH6DPHaytJmjp1asx37amnnorZP1DaavPmzSouLtZbb72lsrIytba2asqUKWpsbHTKHO93r729XdOnT1dLS4vefPNNrVmzRqtXr9bixYttfKRe05O2kqS5c+fGfLeWLFni7BsobSVJp59+uu6//35VVlZq+/bt+uY3v6kZM2Zo586dkk6i75VBj11yySWmuLjYed3e3m5ycnJMaWmpxVrZd9ddd5kJEyZ0u6++vt4kJSWZZ5991tm2a9cuI8mUl5f3UQ1PHpLMc88957yORCImOzvbPPjgg862+vp6k5KSYp566iljjDHvv/++kWS2bdvmlHn55ZeNz+czf/7zn/us7n3tyLYyxpjZs2ebGTNmHPOYgdpWxhhTV1dnJJnNmzcbY3r2u/fSSy8Zv99vQqGQU2blypUmEAiY5ubmvv0AfejItjLGmL/+6782P/7xj495zEBtq6jhw4ebf//3fz+pvlf0wPRQS0uLKisrVVBQ4Gzz+/0qKChQeXm5xZqdHHbv3q2cnBydccYZKioqUk1NjSSpsrJSra2tMe12zjnnaPTo0bSbpD179igUCsW0T1pamvLz8532KS8vV3p6uiZNmuSUKSgokN/vV0VFRZ/X2bbXXntNmZmZOvvss3XTTTfps88+c/YN5LZqaGiQJGVkZEjq2e9eeXm5xo8fr6ysLKdMYWGhwuGw83/bp6Ij2ypq7dq1GjlypMaNG6eFCxfq0KFDzr6B2lbt7e16+umn1djYqGAweFJ9r07ZxRzj7S9/+Yva29tjfiCSlJWVpQ8++MBSrU4O+fn5Wr16tc4++2x98sknuueee3TFFVfovffeUygUUnJystLT02OOycrKUigUslPhk0i0Dbr7XkX3hUIhZWZmxuxPTExURkbGgGvDqVOn6rrrrlNeXp4++ugj/cu//IumTZum8vJyJSQkDNi2ikQimj9/vi677DKNGzdOknr0uxcKhbr97kX3nYq6aytJuvHGGzVmzBjl5OTo3Xff1e23367q6mr99re/lTTw2mrHjh0KBoNqamrS0KFD9dxzz2ns2LGqqqo6ab5XBBicsGnTpjnPzz//fOXn52vMmDH6zW9+o0GDBlmsGU41s2bNcp6PHz9e559/vs4880y99tprmjx5ssWa2VVcXKz33nsvZuwZunestuo6Tmr8+PEaNWqUJk+erI8++khnnnlmX1fTurPPPltVVVVqaGjQf/3Xf2n27NnavHmz7WrF4BJSD40cOVIJCQlHjbSura1Vdna2pVqdnNLT0/VXf/VX+vDDD5Wdna2WlhbV19fHlKHdOkTb4Mu+V9nZ2UcNFG9ra9P+/fsHfBueccYZGjlypD788ENJA7OtSkpKtH79er366qs6/fTTne09+d3Lzs7u9rsX3XeqOVZbdSc/P1+SYr5bA6mtkpOT9bWvfU0TJ05UaWmpJkyYoEceeeSk+l4RYHooOTlZEydO1MaNG51tkUhEGzduVDAYtFizk8/Bgwf10UcfadSoUZo4caKSkpJi2q26ulo1NTW0m6S8vDxlZ2fHtE84HFZFRYXTPsFgUPX19aqsrHTKbNq0SZFIxPmP7ED1pz/9SZ999plGjRolaWC1lTFGJSUleu6557Rp0ybl5eXF7O/J714wGNSOHTtiQl9ZWZkCgYDGjh3bNx+kDxyvrbpTVVUlSTHfrYHQVscSiUTU3Nx8cn2v4jYceAB4+umnTUpKilm9erV5//33zbx580x6enrMSOuB6Cc/+Yl57bXXzJ49e8wbb7xhCgoKzMiRI01dXZ0xxpgf/vCHZvTo0WbTpk1m+/btJhgMmmAwaLnWfefAgQPmnXfeMe+8846RZB5++GHzzjvvmI8//tgYY8z9999v0tPTzfPPP2/effddM2PGDJOXl2e++OIL5xxTp041F154oamoqDCvv/66Oeuss8wNN9xg6yP1mi9rqwMHDph//ud/NuXl5WbPnj3m97//vbnooovMWWedZZqampxzDJS2uummm0xaWpp57bXXzCeffOI8Dh065JQ53u9eW1ubGTdunJkyZYqpqqoyGzZsMKeddppZuHChjY/Ua47XVh9++KG59957zfbt282ePXvM888/b8444wxz5ZVXOucYKG1ljDF33HGH2bx5s9mzZ4959913zR133GF8Pp955ZVXjDEnz/eKAOPS8uXLzejRo01ycrK55JJLzFtvvWW7StZdf/31ZtSoUSY5Odl85StfMddff7358MMPnf1ffPGF+dGPfmSGDx9uBg8ebP7u7/7OfPLJJxZr3LdeffVVI+mox+zZs40xHbdSL1q0yGRlZZmUlBQzefJkU11dHXOOzz77zNxwww1m6NChJhAImO9///vmwIEDFj5N7/qytjp06JCZMmWKOe2000xSUpIZM2aMmTt37lH/AzFQ2qq7dpJkHn/8cadMT373/vjHP5pp06aZQYMGmZEjR5qf/OQnprW1tY8/Te86XlvV1NSYK6+80mRkZJiUlBTzta99zdx6662moaEh5jwDoa2MMeYHP/iBGTNmjElOTjannXaamTx5shNejDl5vlc+Y4yJX38OAABA72MMDAAA6HcIMAAAoN8hwAAAgH6HAAMAAPodAgwAAOh3CDAAAKDfIcAAAIB+hwADAAD6HQIMAADodwgwAACg3yHAAACAfocAAwAA+p3/B0dGqcu//mhHAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7cd4f7522f50>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7cd4f75cbe20>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7cd4f6b74070>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               3840      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 256)               1024      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 16)                64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49601 (193.75 KB)\n",
      "Trainable params: 48609 (189.88 KB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 16:16:44.777977: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  22.676656313737233\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.548 (0.000)\n",
      "MAE: 1.166 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.949 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.174 (0.000)\n",
      "MAE: 1.561 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.865 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\\nweights_path = \\\"../../../../../../../models/global_models/209/mlp/w/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_properties_csless_vars_partial_ds_weights.h5\\\"\\n\\nfull_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\\nweights_path = \\\"../../../../../../../models/global_models/209/mlp/w/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_properties_csless_vars_partial_ds_weights.h5\\\"\\n\\nfull_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]\n",
    "weights_path = \"../../../../../../../models/global_models/209/mlp/w/pre_training/\"\n",
    "model_name = \"mlp_chemical_properties_csless_vars_partial_ds_weights.h5\"\n",
    "\n",
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
