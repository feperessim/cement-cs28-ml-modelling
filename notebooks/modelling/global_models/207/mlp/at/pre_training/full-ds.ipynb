{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 22:56:57.960809: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-13 22:56:57.964501: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-13 22:56:58.034399: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-13 22:56:58.036470: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-13 22:56:59.370851: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/206/mlp/b/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 1\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 1\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 1\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"207\\\",\\n    \\\"Plant\\\": \\\"AT\\\",\\n    \\\"Features\\\": \\\"Chemical + Physical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"207\\\",\\n    \\\"Plant\\\": \\\"AT\\\",\\n    \\\"Features\\\": \\\"Chemical + Physical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"207\",\n",
    "    \"Plant\": \"AT\",\n",
    "    \"Features\": \"Chemical + Physical\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/207/global_at.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/207/global_at.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/207/global_at.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c7326_row0_col0 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c7326_row1_col0, #T_c7326_row2_col0, #T_c7326_row3_col0, #T_c7326_row4_col0, #T_c7326_row5_col0, #T_c7326_row6_col0, #T_c7326_row7_col0, #T_c7326_row8_col0, #T_c7326_row9_col0, #T_c7326_row10_col0, #T_c7326_row11_col0, #T_c7326_row12_col0, #T_c7326_row13_col0, #T_c7326_row14_col0, #T_c7326_row15_col0, #T_c7326_row16_col0, #T_c7326_row17_col0, #T_c7326_row18_col0 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c7326\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c7326_level0_col0\" class=\"col_heading level0 col0\" >Zero (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c7326_level0_row0\" class=\"row_heading level0 row0\" >#200</th>\n",
       "      <td id=\"T_c7326_row0_col0\" class=\"data row0 col0\" >14.463976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7326_level0_row1\" class=\"row_heading level0 row1\" >CaO</th>\n",
       "      <td id=\"T_c7326_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7326_level0_row2\" class=\"row_heading level0 row2\" >Blaine</th>\n",
       "      <td id=\"T_c7326_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7326_level0_row3\" class=\"row_heading level0 row3\" >CS7</th>\n",
       "      <td id=\"T_c7326_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7326_level0_row4\" class=\"row_heading level0 row4\" >CS3</th>\n",
       "      <td id=\"T_c7326_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7326_level0_row5\" class=\"row_heading level0 row5\" >Final setting time</th>\n",
       "      <td id=\"T_c7326_row5_col0\" class=\"data row5 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7326_level0_row6\" class=\"row_heading level0 row6\" >Initial setting time</th>\n",
       "      <td id=\"T_c7326_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7326_level0_row7\" class=\"row_heading level0 row7\" >Specific Gravity</th>\n",
       "      <td id=\"T_c7326_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7326_level0_row8\" class=\"row_heading level0 row8\" >#400</th>\n",
       "      <td id=\"T_c7326_row8_col0\" class=\"data row8 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7326_level0_row9\" class=\"row_heading level0 row9\" >Insoluble Residue</th>\n",
       "      <td id=\"T_c7326_row9_col0\" class=\"data row9 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7326_level0_row10\" class=\"row_heading level0 row10\" >MgO</th>\n",
       "      <td id=\"T_c7326_row10_col0\" class=\"data row10 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7326_level0_row11\" class=\"row_heading level0 row11\" >Loss on Ignition</th>\n",
       "      <td id=\"T_c7326_row11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7326_level0_row12\" class=\"row_heading level0 row12\" >Fe2O3</th>\n",
       "      <td id=\"T_c7326_row12_col0\" class=\"data row12 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7326_level0_row13\" class=\"row_heading level0 row13\" >K2O</th>\n",
       "      <td id=\"T_c7326_row13_col0\" class=\"data row13 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7326_level0_row14\" class=\"row_heading level0 row14\" >SO3</th>\n",
       "      <td id=\"T_c7326_row14_col0\" class=\"data row14 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7326_level0_row15\" class=\"row_heading level0 row15\" >SiO2</th>\n",
       "      <td id=\"T_c7326_row15_col0\" class=\"data row15 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7326_level0_row16\" class=\"row_heading level0 row16\" >Al2O3</th>\n",
       "      <td id=\"T_c7326_row16_col0\" class=\"data row16 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7326_level0_row17\" class=\"row_heading level0 row17\" >Na2O</th>\n",
       "      <td id=\"T_c7326_row17_col0\" class=\"data row17 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7326_level0_row18\" class=\"row_heading level0 row18\" >CS28</th>\n",
       "      <td id=\"T_c7326_row18_col0\" class=\"data row18 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7368633d2170>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_formatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_values = {}\n",
    "for col in df.select_dtypes(include=\"number\").columns:\n",
    "    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\n",
    "    zero_values[col] = zero_percentages\n",
    "\n",
    "zero_percentages = pd.Series(zero_values, name=f\"Zero (%)\")\n",
    "zero_percentages = zero_percentages.sort_values(ascending=False)\n",
    "zero_percentages = zero_percentages.to_frame(name=f\"Zero (%)\")\n",
    "zero_percentages.style.background_gradient(cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop([\\\"Cement_Type\\\", \\\"Factory_Plant\\\"], axis=1)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop([\\\"Cement_Type\\\", \\\"Factory_Plant\\\"], axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop([\"Cement_Type\", \"Factory_Plant\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 22:57:04.490539: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  11.220712002118429\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.301 (0.000)\n",
      "MAE: 0.990 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.964 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.494 (0.000)\n",
      "MAE: 1.136 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.940 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  12.670363863309225\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.308 (0.000)\n",
      "MAE: 0.987 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.964 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.476 (0.000)\n",
      "MAE: 1.114 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.941 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  16.17485408782959\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.335 (0.000)\n",
      "MAE: 1.043 (0.000)\n",
      "MAPE: 0.024 (0.000)\n",
      "R2: 0.962 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.645 (0.000)\n",
      "MAE: 1.274 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.927 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  18.34156817595164\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.239 (0.000)\n",
      "MAE: 0.955 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.968 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.537 (0.000)\n",
      "MAE: 1.162 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.936 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  21.64664662281672\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.225 (0.000)\n",
      "MAE: 0.930 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.968 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.491 (0.000)\n",
      "MAE: 1.101 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.940 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  31.413189272085827\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.269 (0.000)\n",
      "MAE: 0.962 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.966 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.430 (0.000)\n",
      "MAE: 1.067 (0.000)\n",
      "MAPE: 0.025 (0.000)\n",
      "R2: 0.945 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  30.049268142382303\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.210 (0.000)\n",
      "MAE: 0.912 (0.000)\n",
      "MAPE: 0.020 (0.000)\n",
      "R2: 0.969 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.462 (0.000)\n",
      "MAE: 1.083 (0.000)\n",
      "MAPE: 0.025 (0.000)\n",
      "R2: 0.942 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  19.66421024799347\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.218 (0.000)\n",
      "MAE: 0.933 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.969 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.537 (0.000)\n",
      "MAE: 1.149 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.936 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  28.113857821623483\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.487 (0.000)\n",
      "MAE: 1.173 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.953 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.845 (0.000)\n",
      "MAE: 1.432 (0.000)\n",
      "MAPE: 0.035 (0.000)\n",
      "R2: 0.908 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  28.3958647052447\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.220 (0.000)\n",
      "MAE: 0.934 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.969 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.485 (0.000)\n",
      "MAE: 1.110 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.941 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  28.212075440088906\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.245 (0.000)\n",
      "MAE: 0.945 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.967 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.433 (0.000)\n",
      "MAE: 1.073 (0.000)\n",
      "MAPE: 0.025 (0.000)\n",
      "R2: 0.945 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  17.173461882273354\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.363 (0.000)\n",
      "MAE: 1.030 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.961 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.458 (0.000)\n",
      "MAE: 1.098 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.943 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.544676454861959\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.463 (0.000)\n",
      "MAE: 1.113 (0.000)\n",
      "MAPE: 0.025 (0.000)\n",
      "R2: 0.955 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.515 (0.000)\n",
      "MAE: 1.133 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.938 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/207/at/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/207/at/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/207/at/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>207</td>\n",
       "      <td>AT</td>\n",
       "      <td>Chemical + Physical</td>\n",
       "      <td>(62749, 18)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_6</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>1.2691</td>\n",
       "      <td>0.96152</td>\n",
       "      <td>0.021576</td>\n",
       "      <td>0.966061</td>\n",
       "      <td>1.430276</td>\n",
       "      <td>1.067396</td>\n",
       "      <td>0.025059</td>\n",
       "      <td>0.944895</td>\n",
       "      <td>-3.357727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category Company Plant             Features   Data Shape Timesteps  \\\n",
       "5  Global Model     207    AT  Chemical + Physical  (62749, 18)      None   \n",
       "\n",
       "   Model Model Params           Scaler Scaler Params  ...  \\\n",
       "5  MLP_6         None  Standard Scaler          None  ...   \n",
       "\n",
       "                 Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "5  {\"train_size\": 0.8, \"test_size\": 0.2}     1.2691   0.96152   0.021576   \n",
       "\n",
       "   R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "5  0.966061   1.430276  1.067396   0.025059  0.944895 -3.357727  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  31.98424711227417\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.226 (0.000)\n",
      "MAE: 0.929 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.967 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.226 (0.000)\n",
      "MAE: 0.929 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.967 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/207/mlp/at/pre_training/\\\"\\nmodel_name = \\\"mlp_full_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/207/mlp/at/pre_training/\\\"\\nmodel_name = \\\"mlp_full_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/207/mlp/at/pre_training/\"\n",
    "model_name = \"mlp_full_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7365d9e6b040>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7366e43673a0>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x736606fe9210>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x73667c58d360>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 256)               4864      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 16)                64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50625 (197.75 KB)\n",
      "Trainable params: 49633 (193.88 KB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 63;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
