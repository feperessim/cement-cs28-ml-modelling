{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 22:56:44.633248: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-13 22:56:44.635913: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-13 22:56:44.690769: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-13 22:56:44.692175: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-13 22:56:46.476525: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/206/mlp/b/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 10\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 10\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 10\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"207\\\",\\n    \\\"Plant\\\": \\\"AT\\\",\\n    \\\"Features\\\": \\\"Chemical + Properties CS Less\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"207\\\",\\n    \\\"Plant\\\": \\\"AT\\\",\\n    \\\"Features\\\": \\\"Chemical + Properties CS Less\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"207\",\n",
    "    \"Plant\": \"AT\",\n",
    "    \"Features\": \"Chemical + Properties CS Less\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/207/global_at.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/207/global_at.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/207/global_at.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8af1a_row0_col0 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8af1a_row1_col0, #T_8af1a_row2_col0, #T_8af1a_row3_col0, #T_8af1a_row4_col0, #T_8af1a_row5_col0, #T_8af1a_row6_col0, #T_8af1a_row7_col0, #T_8af1a_row8_col0, #T_8af1a_row9_col0, #T_8af1a_row10_col0, #T_8af1a_row11_col0, #T_8af1a_row12_col0, #T_8af1a_row13_col0, #T_8af1a_row14_col0, #T_8af1a_row15_col0, #T_8af1a_row16_col0, #T_8af1a_row17_col0, #T_8af1a_row18_col0 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8af1a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8af1a_level0_col0\" class=\"col_heading level0 col0\" >Zero (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8af1a_level0_row0\" class=\"row_heading level0 row0\" >#200</th>\n",
       "      <td id=\"T_8af1a_row0_col0\" class=\"data row0 col0\" >14.463976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8af1a_level0_row1\" class=\"row_heading level0 row1\" >CaO</th>\n",
       "      <td id=\"T_8af1a_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8af1a_level0_row2\" class=\"row_heading level0 row2\" >Blaine</th>\n",
       "      <td id=\"T_8af1a_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8af1a_level0_row3\" class=\"row_heading level0 row3\" >CS7</th>\n",
       "      <td id=\"T_8af1a_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8af1a_level0_row4\" class=\"row_heading level0 row4\" >CS3</th>\n",
       "      <td id=\"T_8af1a_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8af1a_level0_row5\" class=\"row_heading level0 row5\" >Final setting time</th>\n",
       "      <td id=\"T_8af1a_row5_col0\" class=\"data row5 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8af1a_level0_row6\" class=\"row_heading level0 row6\" >Initial setting time</th>\n",
       "      <td id=\"T_8af1a_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8af1a_level0_row7\" class=\"row_heading level0 row7\" >Specific Gravity</th>\n",
       "      <td id=\"T_8af1a_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8af1a_level0_row8\" class=\"row_heading level0 row8\" >#400</th>\n",
       "      <td id=\"T_8af1a_row8_col0\" class=\"data row8 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8af1a_level0_row9\" class=\"row_heading level0 row9\" >Insoluble Residue</th>\n",
       "      <td id=\"T_8af1a_row9_col0\" class=\"data row9 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8af1a_level0_row10\" class=\"row_heading level0 row10\" >MgO</th>\n",
       "      <td id=\"T_8af1a_row10_col0\" class=\"data row10 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8af1a_level0_row11\" class=\"row_heading level0 row11\" >Loss on Ignition</th>\n",
       "      <td id=\"T_8af1a_row11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8af1a_level0_row12\" class=\"row_heading level0 row12\" >Fe2O3</th>\n",
       "      <td id=\"T_8af1a_row12_col0\" class=\"data row12 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8af1a_level0_row13\" class=\"row_heading level0 row13\" >K2O</th>\n",
       "      <td id=\"T_8af1a_row13_col0\" class=\"data row13 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8af1a_level0_row14\" class=\"row_heading level0 row14\" >SO3</th>\n",
       "      <td id=\"T_8af1a_row14_col0\" class=\"data row14 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8af1a_level0_row15\" class=\"row_heading level0 row15\" >SiO2</th>\n",
       "      <td id=\"T_8af1a_row15_col0\" class=\"data row15 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8af1a_level0_row16\" class=\"row_heading level0 row16\" >Al2O3</th>\n",
       "      <td id=\"T_8af1a_row16_col0\" class=\"data row16 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8af1a_level0_row17\" class=\"row_heading level0 row17\" >Na2O</th>\n",
       "      <td id=\"T_8af1a_row17_col0\" class=\"data row17 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8af1a_level0_row18\" class=\"row_heading level0 row18\" >CS28</th>\n",
       "      <td id=\"T_8af1a_row18_col0\" class=\"data row18 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x78eeb1593640>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_formatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_values = {}\n",
    "for col in df.select_dtypes(include=\"number\").columns:\n",
    "    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\n",
    "    zero_values[col] = zero_percentages\n",
    "\n",
    "zero_percentages = pd.Series(zero_values, name=f\"Zero (%)\")\n",
    "zero_percentages = zero_percentages.sort_values(ascending=False)\n",
    "zero_percentages = zero_percentages.to_frame(name=f\"Zero (%)\")\n",
    "zero_percentages.style.background_gradient(cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Factory_Plant\\\",\\n        \\\"Cement_Type\\\",\\n        # \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Factory_Plant\\\",\\n        \\\"Cement_Type\\\",\\n        # \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop(\n",
    "    [\n",
    "        \"Factory_Plant\",\n",
    "        \"Cement_Type\",\n",
    "        # \"CS1\",\n",
    "        \"CS3\",\n",
    "        \"CS7\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 22:56:51.321025: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  11.379232748349507\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.812 (0.000)\n",
      "MAE: 1.376 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.931 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.237 (0.000)\n",
      "MAE: 1.703 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.865 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  13.760789465904235\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.809 (0.000)\n",
      "MAE: 1.369 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.931 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.246 (0.000)\n",
      "MAE: 1.687 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.864 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  17.008219222227734\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.680 (0.000)\n",
      "MAE: 1.296 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.941 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.136 (0.000)\n",
      "MAE: 1.623 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.877 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  19.43771061897278\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.538 (0.000)\n",
      "MAE: 1.176 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.950 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.183 (0.000)\n",
      "MAE: 1.639 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.872 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  23.035400394598643\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.589 (0.000)\n",
      "MAE: 1.206 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.947 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.091 (0.000)\n",
      "MAE: 1.545 (0.000)\n",
      "MAPE: 0.036 (0.000)\n",
      "R2: 0.882 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  32.70272440115611\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.635 (0.000)\n",
      "MAE: 1.238 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.944 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.065 (0.000)\n",
      "MAE: 1.537 (0.000)\n",
      "MAPE: 0.036 (0.000)\n",
      "R2: 0.885 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  32.37267172733943\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.586 (0.000)\n",
      "MAE: 1.196 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.947 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.007 (0.000)\n",
      "MAE: 1.495 (0.000)\n",
      "MAPE: 0.035 (0.000)\n",
      "R2: 0.892 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  18.457038919130962\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.580 (0.000)\n",
      "MAE: 1.211 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.947 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.148 (0.000)\n",
      "MAE: 1.594 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.876 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  27.946207988262177\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.453 (0.000)\n",
      "MAE: 1.130 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.955 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.299 (0.000)\n",
      "MAE: 1.739 (0.000)\n",
      "MAPE: 0.042 (0.000)\n",
      "R2: 0.858 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  26.373416248957316\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.517 (0.000)\n",
      "MAE: 1.149 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.952 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.064 (0.000)\n",
      "MAE: 1.514 (0.000)\n",
      "MAPE: 0.035 (0.000)\n",
      "R2: 0.885 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.948517123858135\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.624 (0.000)\n",
      "MAE: 1.226 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.944 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.989 (0.000)\n",
      "MAE: 1.491 (0.000)\n",
      "MAPE: 0.035 (0.000)\n",
      "R2: 0.893 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.967921574910482\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.784 (0.000)\n",
      "MAE: 1.351 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.933 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.043 (0.000)\n",
      "MAE: 1.543 (0.000)\n",
      "MAPE: 0.036 (0.000)\n",
      "R2: 0.888 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.780875078837077\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.948 (0.000)\n",
      "MAE: 1.456 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.920 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.098 (0.000)\n",
      "MAE: 1.572 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.881 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/207/at/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/207/at/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/207/at/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>207</td>\n",
       "      <td>AT</td>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>(62749, 16)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_11</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>1.623589</td>\n",
       "      <td>1.225933</td>\n",
       "      <td>0.027679</td>\n",
       "      <td>0.944453</td>\n",
       "      <td>1.989442</td>\n",
       "      <td>1.490794</td>\n",
       "      <td>0.03518</td>\n",
       "      <td>0.893385</td>\n",
       "      <td>-5.320018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category Company Plant                       Features   Data Shape  \\\n",
       "10  Global Model     207    AT  Chemical + Properties CS Less  (62749, 16)   \n",
       "\n",
       "   Timesteps   Model Model Params           Scaler Scaler Params  ...  \\\n",
       "10      None  MLP_11         None  Standard Scaler          None  ...   \n",
       "\n",
       "                  Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "10  {\"train_size\": 0.8, \"test_size\": 0.2}   1.623589  1.225933   0.027679   \n",
       "\n",
       "    R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "10  0.944453   1.989442  1.490794    0.03518  0.893385 -5.320018  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  31.60436185201009\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.634 (0.000)\n",
      "MAE: 1.252 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.942 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.634 (0.000)\n",
      "MAE: 1.252 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.942 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/207/mlp/at/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_properties_csless_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/207/mlp/at/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_properties_csless_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/207/mlp/at/pre_training/\"\n",
    "model_name = \"mlp_chemical_properties_csless_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x78eeaebf6980>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x78ec4120d810>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x78ec67f3f100>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x78ec84268790>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 256)               4352      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 16)                64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50113 (195.75 KB)\n",
      "Trainable params: 49121 (191.88 KB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
