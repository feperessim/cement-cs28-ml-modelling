{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 22:56:33.423082: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-13 22:56:33.426170: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-13 22:56:33.488304: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-13 22:56:33.489708: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-13 22:56:34.471365: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/206/mlp/b/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 2\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 2\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 2\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"207\\\",\\n    \\\"Plant\\\": \\\"AT\\\",\\n    \\\"Features\\\": \\\"Chemical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"207\\\",\\n    \\\"Plant\\\": \\\"AT\\\",\\n    \\\"Features\\\": \\\"Chemical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"207\",\n",
    "    \"Plant\": \"AT\",\n",
    "    \"Features\": \"Chemical\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/207/global_at.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/207/global_at.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/207/global_at.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Cement_Type\\\",\\n        \\\"Factory_Plant\\\",\\n        \\\"Blaine\\\",\\n        \\\"#200\\\",\\n        #  \\\"#325\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        #  \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Cement_Type\\\",\\n        \\\"Factory_Plant\\\",\\n        \\\"Blaine\\\",\\n        \\\"#200\\\",\\n        #  \\\"#325\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        #  \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop(\n",
    "    [\n",
    "        \"Cement_Type\",\n",
    "        \"Factory_Plant\",\n",
    "        \"Blaine\",\n",
    "        \"#200\",\n",
    "        #  \"#325\",\n",
    "        \"Final setting time\",\n",
    "        \"Initial setting time\",\n",
    "        #  \"CS1\",\n",
    "        \"CS3\",\n",
    "        \"CS7\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 22:56:38.441748: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  10.492697755495707\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.169 (0.000)\n",
      "MAE: 1.605 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.901 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.834 (0.000)\n",
      "MAE: 2.096 (0.000)\n",
      "MAPE: 0.050 (0.000)\n",
      "R2: 0.784 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  11.916760218143462\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.159 (0.000)\n",
      "MAE: 1.592 (0.000)\n",
      "MAPE: 0.036 (0.000)\n",
      "R2: 0.902 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.680 (0.000)\n",
      "MAE: 1.970 (0.000)\n",
      "MAPE: 0.047 (0.000)\n",
      "R2: 0.807 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.649399836858114\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.962 (0.000)\n",
      "MAE: 1.459 (0.000)\n",
      "MAPE: 0.034 (0.000)\n",
      "R2: 0.919 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.622 (0.000)\n",
      "MAE: 1.897 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.815 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  17.530864874521892\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.851 (0.000)\n",
      "MAE: 1.389 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.928 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.666 (0.000)\n",
      "MAE: 1.928 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.809 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  22.56314960718155\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.879 (0.000)\n",
      "MAE: 1.385 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.926 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.640 (0.000)\n",
      "MAE: 1.890 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.812 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  34.93091303904851\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.949 (0.000)\n",
      "MAE: 1.417 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.920 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.554 (0.000)\n",
      "MAE: 1.808 (0.000)\n",
      "MAPE: 0.042 (0.000)\n",
      "R2: 0.824 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  32.50415529410044\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.845 (0.000)\n",
      "MAE: 1.352 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.928 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.612 (0.000)\n",
      "MAE: 1.833 (0.000)\n",
      "MAPE: 0.043 (0.000)\n",
      "R2: 0.816 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  18.774040965239205\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.864 (0.000)\n",
      "MAE: 1.372 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.927 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.619 (0.000)\n",
      "MAE: 1.860 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.815 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  28.728262766202292\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.735 (0.000)\n",
      "MAE: 1.295 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.937 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.814 (0.000)\n",
      "MAE: 2.008 (0.000)\n",
      "MAPE: 0.049 (0.000)\n",
      "R2: 0.787 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  28.92750213543574\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.787 (0.000)\n",
      "MAE: 1.320 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.933 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.673 (0.000)\n",
      "MAE: 1.874 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.808 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  28.969607484340667\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.916 (0.000)\n",
      "MAE: 1.398 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.923 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.537 (0.000)\n",
      "MAE: 1.816 (0.000)\n",
      "MAPE: 0.043 (0.000)\n",
      "R2: 0.827 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  16.400399657090507\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.110 (0.000)\n",
      "MAE: 1.541 (0.000)\n",
      "MAPE: 0.035 (0.000)\n",
      "R2: 0.906 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.572 (0.000)\n",
      "MAE: 1.867 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.822 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.059519223372142\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.310 (0.000)\n",
      "MAE: 1.696 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.888 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.652 (0.000)\n",
      "MAE: 1.899 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.811 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/207/at/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/207/at/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/207/at/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>207</td>\n",
       "      <td>AT</td>\n",
       "      <td>Chemical</td>\n",
       "      <td>(62749, 12)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_11</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>1.916428</td>\n",
       "      <td>1.397956</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.922609</td>\n",
       "      <td>2.537498</td>\n",
       "      <td>1.815843</td>\n",
       "      <td>0.042802</td>\n",
       "      <td>0.826553</td>\n",
       "      <td>-4.948757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category Company Plant  Features   Data Shape Timesteps   Model  \\\n",
       "10  Global Model     207    AT  Chemical  (62749, 12)      None  MLP_11   \n",
       "\n",
       "   Model Params           Scaler Scaler Params  ...  \\\n",
       "10         None  Standard Scaler          None  ...   \n",
       "\n",
       "                  Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "10  {\"train_size\": 0.8, \"test_size\": 0.2}   1.916428  1.397956   0.031623   \n",
       "\n",
       "    R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "10  0.922609   2.537498  1.815843   0.042802  0.826553 -4.948757  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R²\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  32.39331078131993\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.912 (0.000)\n",
      "MAE: 1.409 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.920 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.912 (0.000)\n",
      "MAE: 1.409 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.920 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/207/mlp/at/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/207/mlp/at/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/207/mlp/at/pre_training/\"\n",
    "model_name = \"mlp_chemical_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x73e49fbd1a80>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x73e49faad510>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x73e49d94c100>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x73e49d9b99c0>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 256)               3328      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 16)                64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49089 (191.75 KB)\n",
      "Trainable params: 48097 (187.88 KB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
