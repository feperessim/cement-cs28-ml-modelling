{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 23:49:46.188291: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-09 23:49:46.191270: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-09 23:49:46.249629: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-09 23:49:46.250737: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-09 23:49:47.319519: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/203/mlp/av/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/203/mlp/av/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/203/mlp/av/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 10\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 10\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 10\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"204\\\",\\n    \\\"Plant\\\": \\\"I\\\",\\n    \\\"Features\\\": \\\"Chemical + Properties CS Less\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"204\\\",\\n    \\\"Plant\\\": \\\"I\\\",\\n    \\\"Features\\\": \\\"Chemical + Properties CS Less\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"204\",\n",
    "    \"Plant\": \"I\",\n",
    "    \"Features\": \"Chemical + Properties CS Less\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/204/global_i.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/204/global_i.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/204/global_i.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_aae1a_row0_col0 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aae1a_row1_col0, #T_aae1a_row2_col0, #T_aae1a_row3_col0, #T_aae1a_row4_col0, #T_aae1a_row5_col0, #T_aae1a_row6_col0, #T_aae1a_row7_col0, #T_aae1a_row8_col0, #T_aae1a_row9_col0, #T_aae1a_row10_col0, #T_aae1a_row11_col0, #T_aae1a_row12_col0, #T_aae1a_row13_col0, #T_aae1a_row14_col0, #T_aae1a_row15_col0, #T_aae1a_row16_col0, #T_aae1a_row17_col0 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_aae1a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_aae1a_level0_col0\" class=\"col_heading level0 col0\" >Zero (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_aae1a_level0_row0\" class=\"row_heading level0 row0\" >#200</th>\n",
       "      <td id=\"T_aae1a_row0_col0\" class=\"data row0 col0\" >13.965377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae1a_level0_row1\" class=\"row_heading level0 row1\" >CaO</th>\n",
       "      <td id=\"T_aae1a_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae1a_level0_row2\" class=\"row_heading level0 row2\" >MgO</th>\n",
       "      <td id=\"T_aae1a_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae1a_level0_row3\" class=\"row_heading level0 row3\" >CS7</th>\n",
       "      <td id=\"T_aae1a_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae1a_level0_row4\" class=\"row_heading level0 row4\" >CS3</th>\n",
       "      <td id=\"T_aae1a_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae1a_level0_row5\" class=\"row_heading level0 row5\" >CS1</th>\n",
       "      <td id=\"T_aae1a_row5_col0\" class=\"data row5 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae1a_level0_row6\" class=\"row_heading level0 row6\" >Final setting time</th>\n",
       "      <td id=\"T_aae1a_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae1a_level0_row7\" class=\"row_heading level0 row7\" >Initial setting time</th>\n",
       "      <td id=\"T_aae1a_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae1a_level0_row8\" class=\"row_heading level0 row8\" >#325</th>\n",
       "      <td id=\"T_aae1a_row8_col0\" class=\"data row8 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae1a_level0_row9\" class=\"row_heading level0 row9\" >Blaine</th>\n",
       "      <td id=\"T_aae1a_row9_col0\" class=\"data row9 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae1a_level0_row10\" class=\"row_heading level0 row10\" >Loss on Ignition</th>\n",
       "      <td id=\"T_aae1a_row10_col0\" class=\"data row10 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae1a_level0_row11\" class=\"row_heading level0 row11\" >Fe2O3</th>\n",
       "      <td id=\"T_aae1a_row11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae1a_level0_row12\" class=\"row_heading level0 row12\" >K2O</th>\n",
       "      <td id=\"T_aae1a_row12_col0\" class=\"data row12 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae1a_level0_row13\" class=\"row_heading level0 row13\" >SO3</th>\n",
       "      <td id=\"T_aae1a_row13_col0\" class=\"data row13 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae1a_level0_row14\" class=\"row_heading level0 row14\" >SiO2</th>\n",
       "      <td id=\"T_aae1a_row14_col0\" class=\"data row14 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae1a_level0_row15\" class=\"row_heading level0 row15\" >Al2O3</th>\n",
       "      <td id=\"T_aae1a_row15_col0\" class=\"data row15 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae1a_level0_row16\" class=\"row_heading level0 row16\" >Na2O</th>\n",
       "      <td id=\"T_aae1a_row16_col0\" class=\"data row16 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aae1a_level0_row17\" class=\"row_heading level0 row17\" >CS28</th>\n",
       "      <td id=\"T_aae1a_row17_col0\" class=\"data row17 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7a55e5951750>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_formatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_values = {}\n",
    "for col in df.select_dtypes(include=\"number\").columns:\n",
    "    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\n",
    "    zero_values[col] = zero_percentages\n",
    "\n",
    "zero_percentages = pd.Series(zero_values, name=f\"Zero (%)\")\n",
    "zero_percentages = zero_percentages.sort_values(ascending=False)\n",
    "zero_percentages = zero_percentages.to_frame(name=f\"Zero (%)\")\n",
    "zero_percentages.style.background_gradient(cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Factory_Plant\\\",\\n        \\\"Cement_Type\\\",\\n        \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Factory_Plant\\\",\\n        \\\"Cement_Type\\\",\\n        \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop(\n",
    "    [\n",
    "        \"Factory_Plant\",\n",
    "        \"Cement_Type\",\n",
    "        \"CS1\",\n",
    "        \"CS3\",\n",
    "        \"CS7\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 23:55:48.795125: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  10.380379152297973\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.804 (0.000)\n",
      "MAE: 1.378 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.930 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.396 (0.000)\n",
      "MAE: 1.788 (0.000)\n",
      "MAPE: 0.043 (0.000)\n",
      "R2: 0.841 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  12.026620149612427\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.823 (0.000)\n",
      "MAE: 1.381 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.929 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.413 (0.000)\n",
      "MAE: 1.770 (0.000)\n",
      "MAPE: 0.042 (0.000)\n",
      "R2: 0.839 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.19644454717636\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.685 (0.000)\n",
      "MAE: 1.293 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.939 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.272 (0.000)\n",
      "MAE: 1.648 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.857 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  18.880775876839955\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.622 (0.000)\n",
      "MAE: 1.232 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.944 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.339 (0.000)\n",
      "MAE: 1.676 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.848 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  20.481080015500385\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.644 (0.000)\n",
      "MAE: 1.238 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.942 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.265 (0.000)\n",
      "MAE: 1.610 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.858 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  31.699862746397653\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.647 (0.000)\n",
      "MAE: 1.236 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.942 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.171 (0.000)\n",
      "MAE: 1.565 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.869 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  27.779689319928487\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.601 (0.000)\n",
      "MAE: 1.202 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.945 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.157 (0.000)\n",
      "MAE: 1.550 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.871 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  17.238311914602914\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.611 (0.000)\n",
      "MAE: 1.214 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.945 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.261 (0.000)\n",
      "MAE: 1.605 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.858 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  24.577796081701916\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.482 (0.000)\n",
      "MAE: 1.156 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.953 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.565 (0.000)\n",
      "MAE: 1.855 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.818 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  24.482766910394034\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.600 (0.000)\n",
      "MAE: 1.209 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.945 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.150 (0.000)\n",
      "MAE: 1.529 (0.000)\n",
      "MAPE: 0.036 (0.000)\n",
      "R2: 0.872 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  23.621381028493246\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.640 (0.000)\n",
      "MAE: 1.228 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.943 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.113 (0.000)\n",
      "MAE: 1.540 (0.000)\n",
      "MAPE: 0.036 (0.000)\n",
      "R2: 0.876 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.123598869641622\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.779 (0.000)\n",
      "MAE: 1.343 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.932 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.203 (0.000)\n",
      "MAE: 1.614 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.865 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.770357004801433\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.843 (0.000)\n",
      "MAE: 1.396 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.927 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.241 (0.000)\n",
      "MAE: 1.628 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.861 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/204/i/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/204/i/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/204/i/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>204</td>\n",
       "      <td>I</td>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>(63772, 14)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_11</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>1.639543</td>\n",
       "      <td>1.227611</td>\n",
       "      <td>0.027533</td>\n",
       "      <td>0.942565</td>\n",
       "      <td>2.113407</td>\n",
       "      <td>1.540013</td>\n",
       "      <td>0.036339</td>\n",
       "      <td>0.876123</td>\n",
       "      <td>-4.682389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category Company Plant                       Features   Data Shape  \\\n",
       "10  Global Model     204     I  Chemical + Properties CS Less  (63772, 14)   \n",
       "\n",
       "   Timesteps   Model Model Params           Scaler Scaler Params  ...  \\\n",
       "10      None  MLP_11         None  Standard Scaler          None  ...   \n",
       "\n",
       "                  Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "10  {\"train_size\": 0.8, \"test_size\": 0.2}   1.639543  1.227611   0.027533   \n",
       "\n",
       "    R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "10  0.942565   2.113407  1.540013   0.036339  0.876123 -4.682389  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R²\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  30.366430274645488\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.616 (0.000)\n",
      "MAE: 1.213 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.942 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.616 (0.000)\n",
      "MAE: 1.213 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.942 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/204/mlp/i/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_properties_csless_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/204/mlp/i/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_properties_csless_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/204/mlp/i/pre_training/\"\n",
    "model_name = \"mlp_chemical_properties_csless_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7a535d026050>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7a54745312a0>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7a53706338e0>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7a53949ee080>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA30klEQVR4nO3deXhU5d3/8c8smck+ScgOYd8JQVmNCFTZxaVqrQttUbtpsW7Vp9JfrbY+LS5P91q1atG2KlWrolZEUAFFQFYBWcMWCAkJ2ddJMnN+f4SMRkASmOQkZ96v65orZuZM8p27E+bT873PfdsMwzAEAAAQBHazCwAAANZBsAAAAEFDsAAAAEFDsAAAAEFDsAAAAEFDsAAAAEFDsAAAAEFDsAAAAEHj7Ohf6Pf7deTIEcXExMhms3X0rwcAAGfAMAxVVlYqPT1ddvupz0t0eLA4cuSIMjIyOvrXAgCAIDh06JB69Ohxysc7PFjExMRIaiosNja2o389AAA4AxUVFcrIyAh8jp9KhweL5vZHbGwswQIAgC7mdNMYmLwJAACChmABAACChmABAACChmABAACChmABAACChmABAACChmABAACChmABAACChmABAACChmABAACChmABAACChmABAACCpsM3IWsvv313lyrrGnXzpH5K9YSbXQ4AACHJMmcsFq47pGc/PqCS6nqzSwEAIGRZJljYj+/i6jcMcwsBACCEWShYNCULggUAAOaxYLAwuRAAAEKYdYLF8VfiI1kAAGAaywQLx/EzFgatEAAATGOZYEErBAAA81kmWBzPFbRCAAAwkWWChcNOKwQAALNZJljQCgEAwHyWCRa248HCxxkLAABMY5lg4Tj+SlggCwAA81gmWNi53BQAANNZJlgEWiF+kwsBACCEWSZYONiEDAAA01kmWNAKAQDAfJYLFrRCAAAwj3WCBVeFAABgOusEi8ACWQQLAADMQrAAAABBY51gcXyvED9zLAAAMI11ggWXmwIAYLo2BYvevXvLZrOdcJs7d2571ddqtEIAADCfsy0Hr1u3Tj6fL/D9tm3bNHXqVF199dVBL6yt2N0UAADztSlYJCUltfj+oYceUr9+/TRp0qSgFnUmaIUAAGC+NgWLL6qvr9e//vUv3XXXXYF9Ok7G6/XK6/UGvq+oqDjTX/mVAmcsOGUBAIBpznjy5uuvv66ysjLdcMMNX3nc/Pnz5fF4AreMjIwz/ZVfyWGnFQIAgNnOOFg888wzmjlzptLT07/yuHnz5qm8vDxwO3To0Jn+yq9koxUCAIDpzqgVcvDgQS1btkyvvvrqaY91u91yu91n8mva5PO9QggWAACY5YzOWCxYsEDJycmaNWtWsOs5Y82tEE5YAABgnjYHC7/frwULFmjOnDlyOs947mfQ0QoBAMB8bQ4Wy5YtU25urm666ab2qOeMBVohBAsAAEzT5lMO06ZNk9EJP7wdNlohAACYzTp7hRx/JaxjAQCAeawTLGiFAABgOssFC05YAABgHgsFi6avnXH+BwAAocI6wcLOAlkAAJjNOsGCVggAAKazULBo+korBAAA81gnWNAKAQDAdNYJFrRCAAAwnYWCRdNX9goBAMA8lgkWjsAZC4IFAABmsUywsBEsAAAwnWWCBXMsAAAwn2WChYNNyAAAMJ1lggWtEAAAzGeZYEErBAAA81kmWNAKAQDAfJYJFnZaIQAAmM4ywcJGKwQAANNZJlg4jq+86eOMBQAAprFMsGjehIzdTQEAMI9lgkVzK4TdTQEAMI9lgoWDORYAAJjOMsGieXdTWiEAAJjHQsGCVggAAGazTrCw0woBAMBs1gkWx1shLJAFAIB5LBQsWHkTAACzWSdYNLdC/CYXAgBACLNOsKAVAgCA6SwULGiFAABgNgsGC5MLAQAghFkoWDR95YwFAADmsUywcAQmbxIsAAAwi2WCBa0QAADMZ5lgYaMVAgCA6SwTLJpbIewVAgCAeSwTLJpbIZywAADAPJYJFrRCAAAwn2WChaN523SCBQAAprFMsGjeK4RcAQCAeawTLGiFAABgOgsFC64KAQDAbJYLFpywAADAPJYLFrRCAAAwj3WCxfFXQisEAADzWCdYsFcIAACms1ywMGiFAABgGssEC0dzK4RgAQCAaSwTLGzNrRB6IQAAmMYywYLLTQEAMJ9lggV7hQAAYL42B4u8vDx961vfUrdu3RQREaHhw4dr/fr17VFbm7C7KQAA5nO25eDS0lKNHz9eF154oRYvXqykpCTt2bNH8fHx7VVfqzVvQsYUCwAAzNOmYPHwww8rIyNDCxYsCNzXp0+foBd1JhxM3gQAwHRtaoW88cYbGj16tK6++molJyfr3HPP1VNPPfWVz/F6vaqoqGhxaw/sbgoAgPnaFCz27dunxx9/XAMGDNCSJUt0yy236LbbbtNzzz13yufMnz9fHo8ncMvIyDjrok/GxsqbAACYzma0YalKl8ul0aNH6+OPPw7cd9ttt2ndunVavXr1SZ/j9Xrl9XoD31dUVCgjI0Pl5eWKjY09i9JbKqmu18gHl0qS9v3m4sCcCwAAcPYqKirk8XhO+/ndpjMWaWlpGjp0aIv7hgwZotzc3FM+x+12KzY2tsWtPXwxR9AOAQDAHG0KFuPHj9euXbta3Ld792716tUrqEWdieZWiEQ7BAAAs7QpWNx5551as2aNfvOb3ygnJ0cvvPCC/va3v2nu3LntVV+rOexfDBYkCwAAzNCmYDFmzBi99tprevHFF5WZmakHH3xQf/jDHzR79uz2qq/VaIUAAGC+Nq1jIUmXXHKJLrnkkvao5azYaYUAAGA6y+wV8sVg4SNZAABgCgsFi8//uw1X0AIAgCCyTLBoOXnTxEIAAAhhlgkWNlohAACYzjLBQvq8HUIrBAAAc1gqWDjYOh0AAFNZKlg0t0N8nLEAAMAUlgoWga3TOWUBAIApLBUsHMfPWHDCAgAAc1gqWNhphQAAYCpLBYvmK07ZKwQAAHNYKlgErgphjgUAAKawVLBoboWQKwAAMIelgoUtECxIFgAAmMFSwcJx/NWwpDcAAOawVLCwc7kpAACmsmSwoBUCAIA5rBUsmlshBAsAAExhrWARaIUQLAAAMIMlgwVzNwEAMIfFgkXTV64KAQDAHBYLFkzeBADATJYMFuQKAADMYa1gcbwXQisEAABzWCtYsLspAACmsliwoBUCAICZrBUsaIUAAGAqawULWiEAAJjKYsGCBbIAADCTpYKFg3UsAAAwlaWChY1WCAAAprJUsHDYaYUAAGAmSwWLwBwLkgUAAKawVLCgFQIAgLksFSxohQAAYC5LBQtaIQAAmMtiwaLpK60QAADMYbFgQSsEAAAzWTJY+DhjAQCAKawVLI6/GoNgAQCAKawVLJi8CQCAqSwZLHzkCgAATGGxYNH0lVYIAADmsFawsLO7KQAAZrJWsGhuhfhNLgQAgBBlsWDR9JUzFgAAmMNSwaJ5rxDmWAAAYA5LBQsbrRAAAExlqWBBKwQAAHNZKlg4bLRCAAAwk6WChY29QgAAMJWlggW7mwIAYK42BYsHHnhANputxW3w4MHtVVubOY6/GuZYAABgDmdbnzBs2DAtW7bs8x/gbPOPaDdsQgYAgLnanAqcTqdSU1Pbo5azZqMVAgCAqdo8x2LPnj1KT09X3759NXv2bOXm5n7l8V6vVxUVFS1u7YVWCAAA5mpTsBg3bpyeffZZvfPOO3r88ce1f/9+TZgwQZWVlad8zvz58+XxeAK3jIyMsy76VGiFAABgrjYFi5kzZ+rqq69WVlaWpk+frrfffltlZWV66aWXTvmcefPmqby8PHA7dOjQWRd9KrRCAAAw11nNvIyLi9PAgQOVk5NzymPcbrfcbvfZ/JpWc9jYNh0AADOd1ToWVVVV2rt3r9LS0oJVz1lhSW8AAMzVpmBx9913a8WKFTpw4IA+/vhjXXHFFXI4HLruuuvaq742sdub51iYXAgAACGqTa2Qw4cP67rrrlNxcbGSkpJ0wQUXaM2aNUpKSmqv+trETisEAABTtSlYLFy4sL3qCIrmVgh7hQAAYA5L7RXisDfvbmpyIQAAhChLBYvA7qZcbwoAgCksFSy4KgQAAHNZKljQCgEAwFyWCha0QgAAMJelggWtEAAAzGWpYNG8pHcjZywAADCFpYJFqidckpRbUmNyJQAAhCZLBYshabGSpH1FVapr8JlcDQAAocdSwSI5xq34yDD5DSmnsMrscgAACDmWChY2m02DUmMkSTsLKk2uBgCA0GOpYCFJg1Ob2iE78ytMrgQAgNBjuWAxJI0zFgAAmMVywSJwxqKAMxYAAHQ0ywWLgSkxstmkY1X1Kqr0ml0OAAAhxXLBIsLlUN/EKEnSptxSk6sBACC0WC5YSNL5/RIlSR/lHDO5EgAAQoslg8WEAU3B4sM9BAsAADqSJYPFef26yWG3af+xah1ieW8AADqMJYNFbHiYzs2Ik0Q7BACAjmTJYCFJFxxvh6zcXWRyJQAAhA7LBosLByVLklbsLmJDMgAAOohlg0VWD4/SPeGqqfdx1gIAgA5i2WBhs9k0PTNVkvTOtgKTqwEAIDRYNlhI0szMNEnSsh1HVd/oN7kaAACsz9LBYlSveCVGu1VR16gP99AOAQCgvVk6WDjsNl02Il2S9J+Nh02uBgAA67N0sJCkb4zqIUlatr1QpdX1JlcDAIC1WT5YDE2P1dC0WNX7/Fq0Oc/scgAAsDTLBwvp87MWv3l7p55auU+GYZhcEQAA1hQSweL6cT01eXCy6n1+/frtHXprS77ZJQEAYEkhESzCwxx6es5o/XBiX0nSo0t2qaKugTkXAAAEWUgEC6lpwazbpwxQUoxbuSU1GvmrpRr3m/e0I7/C7NIAALCMkAkWkhTpcuquqQMlSY1+Q/U+v17bxIROAACCJaSChSRdOyZDT3xrlG6fPECStOSzAiZzAgAQJCEXLGw2m2Zkpur7E/vK5bTrYHGNdh+tMrssAAAsIeSCRbNot1MX9E+UJL37GZuUAQAQDCEbLCRp+rAUSdLLGw6rrsFncjUAAHR9IR0sZmWlKyW26SqRxz7IMbscAAC6vJAOFtFup3552TBJ0l+X79U3n1itpduPmlwVAABdV0gHC0maPixVV5zbXT6/oU8OlGju8xuVU1hpdlkAAHRJIR8sbDabfvfNEXrnjgmaMCBR9T6//ueVLfL5uQQVAIC2CvlgITWFi8GpsXr4qixFu53amFumpz7cZ3ZZAAB0OQSLL0iPi9B9lwyRJP3fkl3aerjc5IoAAOhaCBZf8s3RGZoxLFWNfkN3vbRZjT6/2SUBANBlECy+xGazaf6VwxUXGaY9hVV6af1hs0sCAKDLIFicRHyUS7dd1LSXyMPv7NQlf/5Q8xfvMLkqAAA6P4LFKXzrvF7q1S1S5bUN2pZXoSdX7NOrGzl7AQDAVyFYnILLaddT3xmt2ycP0HVje0qS7nt9m3IK2bAMAIBTcZpdQGc2MCVGA6fGyOc3tK+oSmv3l2jO3z/R498aqW7RbnWPizC7RAAAOhWbYRgduhJURUWFPB6PysvLFRsb25G/+qwUV3l19ROrte9YdeC+6cNS9ItLhxEwAACW19rPb1ohrdQt2q1/fHesRmTEKSbcKbtNWvLZUX39sVU6WlFndnkAAHQKZxUsHnroIdlsNt1xxx1BKqdz6xEfqUVzx2vrA9P19u0T1D85WkWVXv3o+Y2qb2S9CwAAzjhYrFu3Tk8++aSysrKCWU+XMTg1Vk99Z7Riwp3acLBUf3xvt9klAQBgujMKFlVVVZo9e7aeeuopxcfHB7umLqNPYpQeuaopWD2xYp+25bEEOAAgtJ1RsJg7d65mzZqlKVOmnPZYr9erioqKFjcrmTk8TRcPT5XPb+j6p9boln9t0L4iLkkFAISmNgeLhQsXauPGjZo/f36rjp8/f748Hk/glpGR0eYiO7tfXpapXt0iVVHXqMXbCnTl4x9rw8ESs8sCAKDDtSlYHDp0SLfffruef/55hYeHt+o58+bNU3l5eeB26NChMyq0M0uKcWvpnZP0n1uyNSIjTmU1DfrW058QLgAAIadN61i8/vrruuKKK+RwOAL3+Xw+2Ww22e12eb3eFo+dTFddx6K1auob9cN/btCHe44pJtyp524aq5E9Q3ceCgDAGlr7+d2mYFFZWamDBw+2uO/GG2/U4MGD9dOf/lSZmZlBK6wrq633ac7fP9EnB0rkctr181lDdPWoDEW4vjp0AQDQWbXLAlkxMTHKzMxscYuKilK3bt1aFSpCRYTLoQU3jtHUoSmqb/TrF4s+09hfL9Mbnx4xuzQAANoVK2+2kyi3U09+a5R+PmuIMhIiVOlt1O0LN+nl9dabYwIAQDP2CukAfr+h+xZt0/Nrc+Ww2/TeXZPUOzHK7LIAAGg19grpROx2m/7365maNDBJPr+hPyxjlU4AgDURLDqIzWbTPdMHSZIWfXpEnx4qM7cgAADaAcGiA2V29+ji4akyDOmqxz/Wr97crroGn9llAQAQNASLDvaryzM1eXCyGv2G/r5qv65+YrVW7y2Wz9+hU10AAGgXTN40yQc7C3XnS5tVVtMgSRqWHquXb85WpMtpcmUAAJyIyZud3IWDk/Xf2ybomtEZinY79dmRCj21cr/ZZQEAcFYIFibqHhehh7+RpYeuGi5JenLlXuWV1ZpcFQAAZ45g0QnMGp6mczLiVFPv0wUPv68bFnyiam+j2WUBANBmBItOwGaz6eGrsjQ4NUaGIS3fVaS7X/5UH+89po25pWaXBwBAqzF5s5NZd6BE1z+1Rg2+z/9neWbOaE0ekmJiVQCAUMfkzS5qTO8E/fqK4bLbpKjju6He9dKn2llQYXJlAACcHmcsOqma+kY57DZ984nV+vRwuSTpwkFJ+uvsUWy/DgDocJyx6OIiXU65nQ498e1Rumhwsuw26YNdRXp+7UGzSwMA4JQIFp1cmidCf79hjOZf2XRJ6hMr9qq0ul6NPr/JlQEAcCKCRRdx5cge6pkQqWNV9Tr3waUa9b/L9MHOQrPLAgCgBYJFFxHmsOsn0wYGvi+vbdD3/rFe/1x9QB08TQYAgFNi8mYXs+dopSLdTv323V16dWOeJGnGsFTNu3iwenWLMrk6AIBVtfbzm2DRRRmGoWc+2q+H39mpBp8hh92m8f0TNWt4qr45OkM2m83sEgEAFtLaz2+20uyibDabvjehr87r202PLtmlFbuLtPL4zdvo13eye5tdIgAgBDHHoovL7O7RczeN1bK7JurG8b0lSQ8t3qlDJTXmFgYACEkEC4vonxyj+2YN1dg+Caqp92nOgk/0yf4SFZTXMbkTANBhmGNhMQeLq/XNJ1fraIU3cN/AlGj9v1lDNWlgkomVAQC6MlbeDFG9ukXpndsn6rIR6Yp0OWS3SbuPVmnO3z/R21vzzS4PAGBxnLGwuPKaBj343+16ZcNhxUeGacmdE5UcE252WQCALoYzFpAkeSLD9JsrhmtYeqxKaxo0/qH3demfP9K+oiqzSwMAWBDBIgS4nHb9/ppzlOYJV4PP0Na8cv3wnxt04Fi1cgoJGACA4KEVEkIafX4dKK7R9U+tUWHl55M7H7t+pGZlpZlYGQCgs6MVghM4HXb1T47WX64fKbfz8//pH3xru2rqG02sDABgFQSLEDS2T4I++dkUbbpvqjISIlRQUacH39qhKm+jVuUc01Mr9+n3S3erykvYAAC0DUt6hyhPZJgk6eezhuqH/9ygFz/J1cJ1ufpiY+xoRZ0euirLpAoBAF0RZyxC3PRhqfr9NSOU5gmXYUiJ0W5NG5oiSVq47pDe3pqvPUcrTa4SANBVMHkTkqS6Bp8KyuvUMyFSdrtN9/5nixauOxR4/OGrhuuaMT1NrBAAYCYmb6JNwsMc6p0YJbu9abv1e2cO1rD0WMWEN3XLHnlnlyrrGswsEQDQBRAscFJxkS7997YJ2njfVPVNjFJxdb0eXbJLDT6/2aUBADoxggW+UpjDrp9dPESS9I/VBzXxkQ/04Z4ik6sCAHRWzLHAaRmGoec+PqC/fLBXx6q8stuk8f0TVVPv089nDdG5PePNLhEA0M6YY4GgsdlsumF8H3300wv1jVE95DekD/cc04aDpfrBPzfoaEWd2SUCADoJzligTQzD0Hs7CpVfXqt/rcnVrqOVSvOE66LBybpn+iDFRbrMLhEA0A5a+/nNAlloE5vNpinH17mYMCBJ33jiY+WX1+n5tbkqr23QX64faXKFAAAz0QrBGeudGKX37/6a/nDNOZKk/27NZ7dUAAhxBAucldjwMH393O6aOjRFhiH95KXNuu/1bdpZUGF2aQAAExAsEBS3XTRAkvTp4XL9c81Bff2xVXru4wMqr2VRLQAIJUzeRNC8tumwduZXatuRcq3KKZYkOe02DU2P1eXndNdN43vLZrOZXCUA4EwweRMd7opze0jnSj6/oQWr9uvf6w5pT2GVthwu15bD5eoeF64ZmWmSpAafX2EOTpgBgNXwLzuCzmG36XsT+mrpXZP04f9cqG+d17R52a/e3K6a+kb9/aP9ynrgXT2xYq/JlQIAgo1WCNpdbb1PU363QnllteoeF6G8slpJTW2SN398gYak8T4AgM6OlTfRaUS4HHr06izFuJ2BUJHmCVej39DdL3+q3OIakysEAAQLZyzQYaq8jXrr0yOy222aNDBJU363QpV1jQpz2HTzpH66bfIA5l0AQCfV2s9vggVMs6ugUr9+e4dW7m7aLXV4d4/mXthfU4emyGHn6hEA6EwIFugy3tpyRPNe3arKukZJ0jkZcXr0G1kakBJjcmUAgGYEC3QphRV1em71Af3j44Oq9DYFjFG94vXji/rra4OSTa4OAECwQJeUX16rXyz6TEu3Hw3cd9tF/XX7lIG0RwDARO1yVcjjjz+urKwsxcbGKjY2VtnZ2Vq8ePFZFws0S/NE6KnvjNaaeZMD61/86f0czX56jb7+2CqNf+h9bThYYnKVAIBTadMZizfffFMOh0MDBgyQYRh67rnn9Oijj2rTpk0aNmxYq34GZyzQFos25+ne/2xVbYMvcJ/LadfPZg7WtWN7KjzMYWJ1ABA6OqwVkpCQoEcffVTf/e53g1oY0Gz30Ur97t3dGpIWq615ZVq2o1CSFOVyaGBqjC4bka5vn9dLTi5VBYB20+57hfh8Pr388suqrq5Wdnb2KY/zer3yer0tCgPaYmBKjJ749ihJUqPPr+fX5uqpD/fpcGmtNuWWaVNumf6x+qBG94rXtWN7alSveJMrBoDQ1eYzFlu3blV2drbq6uoUHR2tF154QRdffPEpj3/ggQf0y1/+8oT7OWOBs+HzG8oprNKafcX6/bLdKqtp2p7d5bTr6e+M1sSBSSZXCADW0m6tkPr6euXm5qq8vFyvvPKKnn76aa1YsUJDhw496fEnO2ORkZFBsEDQlNc0aNXeY3pp/SEt31WkMIdN4/p00+xxPTVzeJrZ5QGAJXTYHIspU6aoX79+evLJJ4NaGNBW9Y1+3b5wkxZvKwjcN3Voikb08Cg+yqX0uAhd0D+RZcMB4Ay0+xyLZn6/v8UZCcAsLqddf509UnuLqvSfjXn628p9Wrr9aIs1MdI84bpzykB9c0yGiZUCgHW1KVjMmzdPM2fOVM+ePVVZWakXXnhBy5cv15IlS9qrPqBNbDab+ifH6KczBmvW8DT9d2u+SqrqVVJTr025Zcovr9P//GeLtuSV6f5Lh3H2AgCCrE3BorCwUN/5zneUn58vj8ejrKwsLVmyRFOnTm2v+oAzltndo8zunsD3dQ0+Pf3hPv126W79a02u9hZW66+zRyo+ymVilQBgLSzpjZCzbPtR3b5wk6rrfYpxO3XZOemamZkmd5hdxVVeTRmSwpoYAPAl7BUCfIVdBZWa+8JG5RRWnfDYtWMy9PNLhmr7kQqN6hXPHiUAIIIFcFp+v6HV+4q1aHOeVu4+JptNKqiok2FIseFOVdQ16tIR6frDNecQLgCEvA67KgToqux2m8b3T9T4/omB+/7y/h7937u7VVHXtHX7m58eUUSYXQ9flRU4xmYjZADAqRAsgC/40df6KzzMIbfTLk+kS3f+e7NeWn9YdptNq/cVKybcqWdvHKvEaLfZpQJAp0QrBPgK/1xzUPe9vq3FfUPTYvXiD85TQXmdHl+eoxvG99E5GXHmFAgAHYRWCBAE3z6vlw6X1OhvH+7TZSPStSqnWNvzK3Tbi5uUW1Kj/ceq9f7OQj1701glRLrkctrVLdolt5Pt3AGEJs5YAK1QU9+oSJdT2/LKdeXjH6u+0X/KY6PdTl05srtumzyAlgkAy2jt5zcX6wOtEOlqOrmX2d2jBy8fFrj//64eoTG942WzSVEuh1wOu6q8jfrH6oP6zjOfqKa+0aySAcAUtEKANrpmTE81+Aw57DZ9Y1QPfWNUD/n9hux2m/x+Q6v2HtOd/96s7fkV+vYzn+i8vgnKTPcoIcql3JIaXTg4mTMZACyLVgjQDjYcLNF1f1uret+JLZOeCZF64fvj1CM+0oTKAODMsEAWYLLPjpTrg52Fyiur06bcUlV5G1XX4NexKq+6x0XojVvHKz7SpXqfX+FhTPYE0LlxVQhgsmHpHg1L97S4r6C8Ttf+bbUOFNfozpc+VWFFnfJKa/X7a87RlKEpJlUKAMHDGQugg312pFxff2yVGnyf/+nZbVJ8pEsx4U79+4fZcjvtOlRSq8zusaz0CaBT4KoQoJMalu7RPdMHSZIGpcToypHd5Tek4up6HSiu0a/e2q7LH1ulS//ykWb+8UOt2VdscsUA0HqcsQBMsrOgQr27RcnttGtnQaX2FlXp1hc2nXBcjNupN358gQ6X1shpt2toWqw8kWEmVAwglDF5E+iCbn1ho97aki+n3aZnbhijP723RxsOlsppt6nR3/Sn6nLadd+sIYpyO7X/WLVuntRPUW6mSwFoX0zeBLqgn88aqipvoy4/J12TBiZpQHK0Lv7ThyqraVBcZJiiXE7lldXqvkWfBZ5TVOnVQ1/YfRUAzMQZC6CT21VQqU25pZqVlaZot1NPrtynR97ZqfhIl0pq6mUY0oxhqTpW5VWEy6FxfRI05/zeigmnXQIgeGiFABZWVOlVTLhTv313l576cP8Jj8eEOzW2d4Lyymp1uLRWv7lyuC4bkW5CpQCsgmABhIC6Bp/++N4e2W3S4NRYldU2aMGq/dpXVN3iOJtNOr9fN1XVNWriwCRdN7an0uMiTKoaQFdEsABClM9v6NPDZdqcW6aEKJfWHSjR82tzWxyTEOXSG7eOl9Nul88w1J2QAeA0CBYAJEmGYWjp9qMqrPQqPMyhJ1fs1Z7CKiXHuFVU5ZVhSEPSYpXdt5vS48JVWOnVyt1FSvOE6y/Xj+SKEwCSCBYATuFwaY0u+8sqlVTXS2pa9dN/in8Fxvfvpr/OHiVPBBNBgVBHsABwSp8eKtPzaw/q6tEZ6pcUrQ/3FGnDwVJV1DYoyu3UgORoPbpkl6rrfQpz2HR+v0TNyEzVFed2Z8M0IEQRLACclbX7ivX/Xt+mnMKqwH2DU2P019kj1TcpWhsOlqq0ul6TBiUpzMHuAIDVESwABEVOYZWWfFagBasO6FiVVy6nXWN6x2tVTtMeJonRbk0blqJxfRKU5onQuT3jCBqABREsAARVYUWd7nxpcyBQSE1XlzTP1Wg2KCVGc87vrYLyWo3sFa/sft1UUF6nVE+43E7aKEBXRbAAEHSGYWj13mL9d2u+Lj+nu87tGaePco7pg52F2llQqZ35Faqoa2zxHJtNMgwpIsyhiQMTNef83sru243t4IEuhmABoMOVVNfr/97dpZyjVUqLC9f7OwpV6W1ssYmaJA1Lj9WQtFgt23FUqbHhmjo0Rd+b0FflNQ3KLanR+P4ED6CzIVgAMF1tvU/ltQ1KjnFrR0GFFn5ySC9vOKS6Bv8Jx8aGO1XlbZTfkCYMSNT9lw5T/+RoE6oGcDIECwCdUml1vV5cl6uj5XWaNixVRZVe/en9PYFlyMMcNjX4mv5ZGpIWqwkDEnVe3wSN6Z3AxmqAiQgWALqM+ka/Fm/L18CUGLmcdv36vzu0YneRfF9onzjtNo3tk6CkGLcq6xpV7W3U1KEpuuLc7pr36lb16hap/5kxmCtSgHZCsADQpZVU1+vDPUVavbdYq/cV62BxzUmP6xblUvHxK1NG9oyTz5DSPeG66YI+6pUQqW7RbjnszNcAzhbBAoClHDhWrRW7i1Tf6FdshFN5pbX60/s5kqT4yDDVNvhOOncjzROu703oq5E94/SfjYe15LOj6t0tUlec20PXj+vZ0S8D6LJa+/nN7kIAuoTeiVHqnRjV4r70uAi9ueWIfnbxEDX6DL2+OU+Z6R6t2ntMS7cfVbW3UfnldXrwre0tnldU6dW6A6Uqq63X1wYmq9HvV8+ESMVFurT7aKVe/CRXV43soczuno58iYAlcMYCgGV5G316ef1hLdqcp71F1erVLVJzv9ZfG3NL9dfle084fmzvBG07Uq6aep/Cw+y6d8ZgeSLD9MxH+9XQaOh314zQsHSP6hv92ppXrj6JUUqIcgWebxgGl8nCsmiFAMBXeHTJTj32wV7FhjvlDnOoqNIbeOyL8za+yOW0a9LAJG0/UqG8slq5HHZNz0zVhYOSAkue/+OmsRqQEtORLwXoEAQLADiNiroGxbidstlsyiur1SvrD8sdZteN43vr6Q/3a+XuIpXXNmjykGTtyK/U+zsLA88ND7OfdE5H97gIZXaPVW5JrXrER+iSrDRdmpUuOxNI0cURLAAgiPx+Q+sOlGhHfoUi3U5dNiJde45W6cV1ufo455jG9knQugOl2n+s+oTnpnvC5XTYlRDlUs+ESPXqFhmY01FaXa/hPTwaksa/h+jcCBYA0MFyi2v067e3q3dilMb0StCWvHI98+E+Vdf7TvvcCQMSdWlWuup9fm3KLdO2vHJFuh3KTPdo4sAkNfj8Kq7yalZWeot5HUBHIVgAQCdQWl2vHQUVcjnsKqr0KrekRgdLapRbXKPy2gZFuhxad6BE/lb+Sxzjduq2yQN04/jecjrsKq9t0Np9xYqLdCkuMkyRLoe6x0UwiRRBR7AAgC4it7hGr23K0/LdhYp2O3VORpxG9IhTTYNP6w+U6MM9xxQR5pDPb2jX0UpJTcudXzQ4SS+tP9xi4qkkDU6N0exxPTV1aKoeXbJLO/IrZLdL8ZEunZMRp+9N6CtPRJh2H63UO9sKNDAlWhMHJinSxQoEODWCBQBYjN9v6OUNh/Sbt3eqvLYhcH+aJ1xhDruqvI2qqG0I7CTbvGX9l3kiwtSrW6S25ZUHzpSEh9k1cUCSbrqgj87r263F8Ucr6vTC2lzVNfh017SBssmmam+j4mnJhBSCBQBYVFGlV298ekRbDpepf1K0vj+xr8LDHJKk8poGvbbpsP7yQY6OVdVrUEqM7po2UC6HXfnldfr7qv3KKawK/KwL+ifqQHG1DpfWBu7rkxilugafUmLD5fMb2p5fEdi3ZerQFO3Ir1BhhVd/uPYcXTw8TZK0/UiFduRXqNHv1/j+ieoRHympaR8Yl5P9W6yAYAEAIayyrkEbc8s0rk9CIHRIUqPPrw0HS1VW26CeCZEakhYrw2gKDy+szdXCdYdabP7WbERGnLbllbd4zG6Tbr1ogAor6rRw3aEWxydGuxThcuhQSa3G9UnQH649R2meiPZ7wWh3BAsAQJsdLq3RgWM1ig536khZrfyGoVG94pXmidCLn+Tq569v03l9E5QaG6H/bDwceJ7NJp3Xp5safH5tOlR2QjiJiwzTNWMylBDp0s6CSm04WKowh029ukWpZ0Kk8strVVxVr2nDUjSiR5yqvI06WFyj+KgwxUe69OrGPEW5nbp+bE/V+/zqHhehVE+4JCmvrFZbD5erb1KU+iVFq8Hn18rdRTpQXC2/IU0ckKSh6XzenC2CBQAg6MprGxQb7pRhSG9tzdezq/arqMqrh67M0vj+iZKkKm+j9hVVqcrbqNjwMP3PK1u0Pb8iqHWEOWyaNTxNu49WtfjZNpvktNvU4Gv50XZB/0Q9+e1RinQ59MGuQr226YiuHZMRqBmnR7AAAHQKDT6/3ttxVG9tyZfdZmta56N3vGyy6WBJtXJLapQQ6VKky6E3Pj2ikup6RbgcyoiPVF5ZrQ6X1mpmZqoKK71asbtInoiwFlfC2G3SgOQY5ZbUqLahac2QdE+4xvRJULXXpxW7C9XgM3RB/0TVN/r1yYESSU3h5Ibze+tQSa0SY1wamBKj/snR6hblVlKMO7BeSF5ZrRZ8tF9j+yRo6tAU2Ww2+fyGfH5DLqdd5TUN2pJXJofdpqwecYp2N11dU9fgU15ZrXp3i5LDAiuvEiwAAJbTvNHbyt1F+mBXoYale3ThoCR1i3bL5zdUWlOvGq9PPeIjAsuob8wt1bV/W6P6xqYl2N1Ou4akxWrzobKv/F39kqLUu1uU1u4vUZW3UZI0smec4iNd2pBbqmpvoyYNTNbafcWqPP54YrRLd08bpDCHXb99d5eOlNcpIcqlET08SvVEyPGFeaw2NdUXHmbXyJ7xGj8gUbHhYfL5DR0srtaxqnqdkxGnstp6rdlXosmDkyVJa/cXK7tvoiJcDnUkggUAAMe9sy1fv3xzuyYNTNLtUwYoOSZcv1u6SzmFVRrZM16lNQ3ac7RS+45Vq7y2QSVf2oRuUEqM9h2rOqHF0qx7XIQafH4VfmlNkVNd8nsybmdTwNh2pFyVdU1BJTnGrcq6RtU2+DQgOVo+w9C+ompldo/Vb68+R8VVXr25JV/hYXbdM32QduRXalNuqb43oW/bB+k0CBYAAJyh0up6bcwt1dEKr+IiwzR9WKoOl9Zozb5i1Tf6NSg1Vm6nXe9uL9DAlBhdmpWuBr9fTyzfp2U7jkqSJg5M1A8n9dOugkrlFFapsMIrQ0YgaBhf+F2r9h7TvqLP95kJD7MrPMyhspqm9UpcDrvqfSduevdFzbvy2m3Su3dOUv/k6KCOCcECAIAuwjAMbc0r1+ZDZRre3aOsHnFq9Pv1wc5CRbmdGpgSo5+/vk0up13fvaCPHnjjM+3Ir1BClEsX9E/Sh3uKVFjpld0mfXN0hu6aOlDJseFBrbFdgsX8+fP16quvaufOnYqIiND555+vhx9+WIMGDQp6YQAA4NSa55tITYumLdqcp68NSlL/5Jh2+X2t/fxu03JoK1as0Ny5c7VmzRotXbpUDQ0NmjZtmqqrT9wmGAAAtJ8vbjSXFOPW9yb0bbdQ0RZn1QopKipScnKyVqxYoYkTJ7bqOZyxAACg62nt5/dZbWVXXl4uSUpISDjlMV6vV17v57NkKyqCu0gKAADoPM54Zxi/36877rhD48ePV2Zm5imPmz9/vjweT+CWkZFxpr8SAAB0cmfcCrnlllu0ePFiffTRR+rRo8cpjzvZGYuMjAxaIQAAdCHt2gq59dZb9dZbb2nlypVfGSokye12y+12n8mvAQAAXUybgoVhGPrxj3+s1157TcuXL1efPn3aqy4AANAFtSlYzJ07Vy+88IIWLVqkmJgYFRQUSJI8Ho8iIiLapUAAANB1tGmOxRevmf2iBQsW6IYbbmjVz+ByUwAAup52mWPRwat/AwCALuaMLzcFAAD4MoIFAAAIGoIFAAAIGoIFAAAImrPaK+RMNE8AZc8QAAC6jubP7dNdyNHhwaKyslKS2DMEAIAuqLKyUh6P55SPn9W26WfC7/fryJEjiomJOeW6GGeieQ+SQ4cOsT5GKzBercdYtQ3j1TaMV+sxVm0T7PEyDEOVlZVKT0+X3X7qmRQdfsbCbrefdn+RsxEbG8sbrg0Yr9ZjrNqG8Wobxqv1GKu2CeZ4fdWZimZM3gQAAEFDsAAAAEFjmWDhdrt1//33s0V7KzFercdYtQ3j1TaMV+sxVm1j1nh1+ORNAABgXZY5YwEAAMxHsAAAAEFDsAAAAEFDsAAAAEFjmWDx2GOPqXfv3goPD9e4ceP0ySefmF2S6R544AHZbLYWt8GDBwcer6ur09y5c9WtWzdFR0frqquu0tGjR02suGOtXLlSl156qdLT02Wz2fT666+3eNwwDP3iF79QWlqaIiIiNGXKFO3Zs6fFMSUlJZo9e7ZiY2MVFxen7373u6qqqurAV9ExTjdWN9xwwwnvtRkzZrQ4JlTGSpLmz5+vMWPGKCYmRsnJyfr617+uXbt2tTimNX9/ubm5mjVrliIjI5WcnKx77rlHjY2NHflS2l1rxuprX/vaCe+vm2++ucUxoTBWkvT4448rKysrsOhVdna2Fi9eHHi8M7yvLBEs/v3vf+uuu+7S/fffr40bN2rEiBGaPn26CgsLzS7NdMOGDVN+fn7g9tFHHwUeu/POO/Xmm2/q5Zdf1ooVK3TkyBFdeeWVJlbbsaqrqzVixAg99thjJ338kUce0Z/+9Cc98cQTWrt2raKiojR9+nTV1dUFjpk9e7Y+++wzLV26VG+99ZZWrlypH/zgBx31EjrM6cZKkmbMmNHivfbiiy+2eDxUxkqSVqxYoblz52rNmjVaunSpGhoaNG3aNFVXVweOOd3fn8/n06xZs1RfX6+PP/5Yzz33nJ599ln94he/MOMltZvWjJUkff/732/x/nrkkUcCj4XKWElSjx499NBDD2nDhg1av369LrroIl1++eX67LPPJHWS95VhAWPHjjXmzp0b+N7n8xnp6enG/PnzTazKfPfff78xYsSIkz5WVlZmhIWFGS+//HLgvh07dhiSjNWrV3dQhZ2HJOO1114LfO/3+43U1FTj0UcfDdxXVlZmuN1u48UXXzQMwzC2b99uSDLWrVsXOGbx4sWGzWYz8vLyOqz2jvblsTIMw5gzZ45x+eWXn/I5oTpWzQoLCw1JxooVKwzDaN3f39tvv23Y7XajoKAgcMzjjz9uxMbGGl6vt2NfQAf68lgZhmFMmjTJuP3220/5nFAdq2bx8fHG008/3WneV13+jEV9fb02bNigKVOmBO6z2+2aMmWKVq9ebWJlncOePXuUnp6uvn37avbs2crNzZUkbdiwQQ0NDS3GbfDgwerZsyfjJmn//v0qKChoMT4ej0fjxo0LjM/q1asVFxen0aNHB46ZMmWK7Ha71q5d2+E1m2358uVKTk7WoEGDdMstt6i4uDjwWKiPVXl5uSQpISFBUuv+/lavXq3hw4crJSUlcMz06dNVUVER+H+nVvTlsWr2/PPPKzExUZmZmZo3b55qamoCj4XqWPl8Pi1cuFDV1dXKzs7uNO+rDt+ELNiOHTsmn8/XYpAkKSUlRTt37jSpqs5h3LhxevbZZzVo0CDl5+frl7/8pSZMmKBt27apoKBALpdLcXFxLZ6TkpKigoICcwruRJrH4GTvq+bHCgoKlJyc3OJxp9OphISEkBvDGTNm6Morr1SfPn20d+9e/exnP9PMmTO1evVqORyOkB4rv9+vO+64Q+PHj1dmZqYktervr6Cg4KTvv+bHrOhkYyVJ119/vXr16qX09HRt2bJFP/3pT7Vr1y69+uqrkkJvrLZu3ars7GzV1dUpOjpar732moYOHarNmzd3ivdVlw8WOLWZM2cG/jsrK0vjxo1Tr1699NJLLykiIsLEymA11157beC/hw8frqysLPXr10/Lly/X5MmTTazMfHPnztW2bdtazG/CyZ1qrL44F2f48OFKS0vT5MmTtXfvXvXr16+jyzTdoEGDtHnzZpWXl+uVV17RnDlztGLFCrPLCujyrZDExEQ5HI4TZr0ePXpUqampJlXVOcXFxWngwIHKyclRamqq6uvrVVZW1uIYxq1J8xh81fsqNTX1hAnCjY2NKikpCfkx7Nu3rxITE5WTkyMpdMfq1ltv1VtvvaUPPvhAPXr0CNzfmr+/1NTUk77/mh+zmlON1cmMGzdOklq8v0JprFwul/r3769Ro0Zp/vz5GjFihP74xz92mvdVlw8WLpdLo0aN0nvvvRe4z+/367333lN2draJlXU+VVVV2rt3r9LS0jRq1CiFhYW1GLddu3YpNzeXcZPUp08fpaamthifiooKrV27NjA+2dnZKisr04YNGwLHvP/++/L7/YF/+ELV4cOHVVxcrLS0NEmhN1aGYejWW2/Va6+9pvfff199+vRp8Xhr/v6ys7O1devWFoFs6dKlio2N1dChQzvmhXSA043VyWzevFmSWry/QmGsTsXv98vr9Xae91VQpoCabOHChYbb7TaeffZZY/v27cYPfvADIy4ursWs11D0k5/8xFi+fLmxf/9+Y9WqVcaUKVOMxMREo7Cw0DAMw7j55puNnj17Gu+//76xfv16Izs728jOzja56o5TWVlpbNq0ydi0aZMhyfjd735nbNq0yTh48KBhGIbx0EMPGXFxccaiRYuMLVu2GJdffrnRp08fo7a2NvAzZsyYYZx77rnG2rVrjY8++sgYMGCAcd1115n1ktrNV41VZWWlcffddxurV6829u/fbyxbtswYOXKkMWDAAKOuri7wM0JlrAzDMG655RbD4/EYy5cvN/Lz8wO3mpqawDGn+/trbGw0MjMzjWnTphmbN2823nnnHSMpKcmYN2+eGS+p3ZxurHJycoxf/epXxvr16439+/cbixYtMvr27WtMnDgx8DNCZawMwzDuvfdeY8WKFcb+/fuNLVu2GPfee69hs9mMd9991zCMzvG+skSwMAzD+POf/2z07NnTcLlcxtixY401a9aYXZLprrnmGiMtLc1wuVxG9+7djWuuucbIyckJPF5bW2v86Ec/MuLj443IyEjjiiuuMPLz802suGN98MEHhqQTbnPmzDEMo+mS0/vuu89ISUkx3G63MXnyZGPXrl0tfkZxcbFx3XXXGdHR0UZsbKxx4403GpWVlSa8mvb1VWNVU1NjTJs2zUhKSjLCwsKMXr16Gd///vdPCPahMlaGYZx0rCQZCxYsCBzTmr+/AwcOGDNnzjQiIiKMxMRE4yc/+YnR0NDQwa+mfZ1urHJzc42JEycaCQkJhtvtNvr372/cc889Rnl5eYufEwpjZRiGcdNNNxm9evUyXC6XkZSUZEyePDkQKgyjc7yv2DYdAAAETZefYwEAADoPggUAAAgaggUAAAgaggUAAAgaggUAAAgaggUAAAgaggUAAAgaggUAAAgaggUAAAgaggUAAAgaggUAAAgaggUAAAia/w/8/X3kEdKdyQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 256)               3840      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 16)                64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49601 (193.75 KB)\n",
      "Trainable params: 48609 (189.88 KB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
