{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 23:49:34.655909: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-09 23:49:34.659553: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-09 23:49:34.726343: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-09 23:49:34.727884: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-09 23:49:35.786601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 2\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 2\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 2\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"204\\\",\\n    \\\"Plant\\\": \\\"I\\\",\\n    \\\"Features\\\": \\\"Chemical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"204\\\",\\n    \\\"Plant\\\": \\\"I\\\",\\n    \\\"Features\\\": \\\"Chemical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"204\",\n",
    "    \"Plant\": \"I\",\n",
    "    \"Features\": \"Chemical\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/204/global_i.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/204/global_i.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/204/global_i.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Cement_Type\\\",\\n        \\\"Factory_Plant\\\",\\n        \\\"Blaine\\\",\\n        \\\"#200\\\",\\n        \\\"#325\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Cement_Type\\\",\\n        \\\"Factory_Plant\\\",\\n        \\\"Blaine\\\",\\n        \\\"#200\\\",\\n        \\\"#325\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop(\n",
    "    [\n",
    "        \"Cement_Type\",\n",
    "        \"Factory_Plant\",\n",
    "        \"Blaine\",\n",
    "        \"#200\",\n",
    "        \"#325\",\n",
    "        \"Final setting time\",\n",
    "        \"Initial setting time\",\n",
    "        \"CS1\",\n",
    "        \"CS3\",\n",
    "        \"CS7\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 23:49:40.122318: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  9.722051493326823\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.306 (0.000)\n",
      "MAE: 1.701 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.886 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.869 (0.000)\n",
      "MAE: 2.113 (0.000)\n",
      "MAPE: 0.050 (0.000)\n",
      "R2: 0.772 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  11.379880746205648\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.303 (0.000)\n",
      "MAE: 1.688 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.887 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.800 (0.000)\n",
      "MAE: 2.043 (0.000)\n",
      "MAPE: 0.048 (0.000)\n",
      "R2: 0.783 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.287730089823405\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.088 (0.000)\n",
      "MAE: 1.546 (0.000)\n",
      "MAPE: 0.035 (0.000)\n",
      "R2: 0.907 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.820 (0.000)\n",
      "MAE: 2.004 (0.000)\n",
      "MAPE: 0.048 (0.000)\n",
      "R2: 0.779 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  17.112026139100394\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.979 (0.000)\n",
      "MAE: 1.464 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.916 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.798 (0.000)\n",
      "MAE: 1.971 (0.000)\n",
      "MAPE: 0.047 (0.000)\n",
      "R2: 0.783 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  19.011014290650685\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.017 (0.000)\n",
      "MAE: 1.465 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.913 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.761 (0.000)\n",
      "MAE: 1.938 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.789 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  32.269111613432564\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.077 (0.000)\n",
      "MAE: 1.507 (0.000)\n",
      "MAPE: 0.034 (0.000)\n",
      "R2: 0.908 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.669 (0.000)\n",
      "MAE: 1.885 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.802 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  26.731842557589214\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.002 (0.000)\n",
      "MAE: 1.452 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.914 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.640 (0.000)\n",
      "MAE: 1.849 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.807 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  16.46207925081253\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.985 (0.000)\n",
      "MAE: 1.444 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.916 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.770 (0.000)\n",
      "MAE: 1.942 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.787 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.92808641195297\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.986 (0.000)\n",
      "MAE: 1.486 (0.000)\n",
      "MAPE: 0.034 (0.000)\n",
      "R2: 0.916 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.942 (0.000)\n",
      "MAE: 2.090 (0.000)\n",
      "MAPE: 0.051 (0.000)\n",
      "R2: 0.760 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.84575811624527\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.933 (0.000)\n",
      "MAE: 1.403 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.920 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.710 (0.000)\n",
      "MAE: 1.876 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.796 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.88243165810903\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.050 (0.000)\n",
      "MAE: 1.483 (0.000)\n",
      "MAPE: 0.034 (0.000)\n",
      "R2: 0.910 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.649 (0.000)\n",
      "MAE: 1.868 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.805 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.348175712426503\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.203 (0.000)\n",
      "MAE: 1.600 (0.000)\n",
      "MAPE: 0.036 (0.000)\n",
      "R2: 0.896 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.647 (0.000)\n",
      "MAE: 1.884 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.806 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  13.45397902727127\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.485 (0.000)\n",
      "MAE: 1.829 (0.000)\n",
      "MAPE: 0.041 (0.000)\n",
      "R2: 0.868 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.763 (0.000)\n",
      "MAE: 1.978 (0.000)\n",
      "MAPE: 0.047 (0.000)\n",
      "R2: 0.788 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/204/i/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/204/i/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/204/i/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>204</td>\n",
       "      <td>I</td>\n",
       "      <td>Chemical</td>\n",
       "      <td>(63772, 9)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_7</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>2.002008</td>\n",
       "      <td>1.451933</td>\n",
       "      <td>0.032659</td>\n",
       "      <td>0.914363</td>\n",
       "      <td>2.639735</td>\n",
       "      <td>1.848646</td>\n",
       "      <td>0.043633</td>\n",
       "      <td>0.806738</td>\n",
       "      <td>-5.255988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category Company Plant  Features  Data Shape Timesteps  Model  \\\n",
       "6  Global Model     204     I  Chemical  (63772, 9)      None  MLP_7   \n",
       "\n",
       "  Model Params           Scaler Scaler Params  ...  \\\n",
       "6         None  Standard Scaler          None  ...   \n",
       "\n",
       "                 Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "6  {\"train_size\": 0.8, \"test_size\": 0.2}   2.002008  1.451933   0.032659   \n",
       "\n",
       "   R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "6  0.914363   2.639735  1.848646   0.043633  0.806738 -5.255988  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  28.918602899710336\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.957 (0.000)\n",
      "MAE: 1.414 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.915 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.957 (0.000)\n",
      "MAE: 1.414 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.915 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/204/mlp/i/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/204/mlp/i/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/204/mlp/i/pre_training/\"\n",
    "model_name = \"mlp_chemical_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x76e5c7a2e1a0>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x76e5c590a0e0>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x76e5c59a8850>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x76e5c580dd80>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 256)               2560      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 16)                64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48321 (188.75 KB)\n",
      "Trainable params: 47329 (184.88 KB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
