{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 23:56:07.472158: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-09 23:56:07.475983: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-09 23:56:07.541355: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-09 23:56:07.542859: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-09 23:56:08.840960: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/203/mlp/av/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/203/mlp/av/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/203/mlp/av/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 1\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 1\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 1\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"204\\\",\\n    \\\"Plant\\\": \\\"I\\\",\\n    \\\"Features\\\": \\\"Chemical + Physical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"204\\\",\\n    \\\"Plant\\\": \\\"I\\\",\\n    \\\"Features\\\": \\\"Chemical + Physical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"204\",\n",
    "    \"Plant\": \"I\",\n",
    "    \"Features\": \"Chemical + Physical\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/204/global_i.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/204/global_i.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/204/global_i.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_cbe5a_row0_col0 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cbe5a_row1_col0, #T_cbe5a_row2_col0, #T_cbe5a_row3_col0, #T_cbe5a_row4_col0, #T_cbe5a_row5_col0, #T_cbe5a_row6_col0, #T_cbe5a_row7_col0, #T_cbe5a_row8_col0, #T_cbe5a_row9_col0, #T_cbe5a_row10_col0, #T_cbe5a_row11_col0, #T_cbe5a_row12_col0, #T_cbe5a_row13_col0, #T_cbe5a_row14_col0, #T_cbe5a_row15_col0, #T_cbe5a_row16_col0, #T_cbe5a_row17_col0 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_cbe5a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_cbe5a_level0_col0\" class=\"col_heading level0 col0\" >Zero (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_cbe5a_level0_row0\" class=\"row_heading level0 row0\" >#200</th>\n",
       "      <td id=\"T_cbe5a_row0_col0\" class=\"data row0 col0\" >13.965377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbe5a_level0_row1\" class=\"row_heading level0 row1\" >CaO</th>\n",
       "      <td id=\"T_cbe5a_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbe5a_level0_row2\" class=\"row_heading level0 row2\" >MgO</th>\n",
       "      <td id=\"T_cbe5a_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbe5a_level0_row3\" class=\"row_heading level0 row3\" >CS7</th>\n",
       "      <td id=\"T_cbe5a_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbe5a_level0_row4\" class=\"row_heading level0 row4\" >CS3</th>\n",
       "      <td id=\"T_cbe5a_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbe5a_level0_row5\" class=\"row_heading level0 row5\" >CS1</th>\n",
       "      <td id=\"T_cbe5a_row5_col0\" class=\"data row5 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbe5a_level0_row6\" class=\"row_heading level0 row6\" >Final setting time</th>\n",
       "      <td id=\"T_cbe5a_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbe5a_level0_row7\" class=\"row_heading level0 row7\" >Initial setting time</th>\n",
       "      <td id=\"T_cbe5a_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbe5a_level0_row8\" class=\"row_heading level0 row8\" >#325</th>\n",
       "      <td id=\"T_cbe5a_row8_col0\" class=\"data row8 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbe5a_level0_row9\" class=\"row_heading level0 row9\" >Blaine</th>\n",
       "      <td id=\"T_cbe5a_row9_col0\" class=\"data row9 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbe5a_level0_row10\" class=\"row_heading level0 row10\" >Loss on Ignition</th>\n",
       "      <td id=\"T_cbe5a_row10_col0\" class=\"data row10 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbe5a_level0_row11\" class=\"row_heading level0 row11\" >Fe2O3</th>\n",
       "      <td id=\"T_cbe5a_row11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbe5a_level0_row12\" class=\"row_heading level0 row12\" >K2O</th>\n",
       "      <td id=\"T_cbe5a_row12_col0\" class=\"data row12 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbe5a_level0_row13\" class=\"row_heading level0 row13\" >SO3</th>\n",
       "      <td id=\"T_cbe5a_row13_col0\" class=\"data row13 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbe5a_level0_row14\" class=\"row_heading level0 row14\" >SiO2</th>\n",
       "      <td id=\"T_cbe5a_row14_col0\" class=\"data row14 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbe5a_level0_row15\" class=\"row_heading level0 row15\" >Al2O3</th>\n",
       "      <td id=\"T_cbe5a_row15_col0\" class=\"data row15 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbe5a_level0_row16\" class=\"row_heading level0 row16\" >Na2O</th>\n",
       "      <td id=\"T_cbe5a_row16_col0\" class=\"data row16 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbe5a_level0_row17\" class=\"row_heading level0 row17\" >CS28</th>\n",
       "      <td id=\"T_cbe5a_row17_col0\" class=\"data row17 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x760cccff7190>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_formatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_values = {}\n",
    "for col in df.select_dtypes(include=\"number\").columns:\n",
    "    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\n",
    "    zero_values[col] = zero_percentages\n",
    "\n",
    "zero_percentages = pd.Series(zero_values, name=f\"Zero (%)\")\n",
    "zero_percentages = zero_percentages.sort_values(ascending=False)\n",
    "zero_percentages = zero_percentages.to_frame(name=f\"Zero (%)\")\n",
    "zero_percentages.style.background_gradient(cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop([\\\"Cement_Type\\\", \\\"Factory_Plant\\\"], axis=1)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop([\\\"Cement_Type\\\", \\\"Factory_Plant\\\"], axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop([\"Cement_Type\", \"Factory_Plant\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 23:56:13.858159: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  9.923983653386435\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.320 (0.000)\n",
      "MAE: 1.007 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.963 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.617 (0.000)\n",
      "MAE: 1.222 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.927 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  11.382565462589264\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.361 (0.000)\n",
      "MAE: 1.038 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.960 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.578 (0.000)\n",
      "MAE: 1.196 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.931 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.26669108470281\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.343 (0.000)\n",
      "MAE: 1.049 (0.000)\n",
      "MAPE: 0.025 (0.000)\n",
      "R2: 0.961 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.644 (0.000)\n",
      "MAE: 1.273 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.925 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  17.671821892261505\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.367 (0.000)\n",
      "MAE: 1.060 (0.000)\n",
      "MAPE: 0.024 (0.000)\n",
      "R2: 0.960 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.678 (0.000)\n",
      "MAE: 1.283 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.922 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  19.16631704568863\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.247 (0.000)\n",
      "MAE: 0.943 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.967 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.555 (0.000)\n",
      "MAE: 1.144 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.933 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  30.996540820598604\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.273 (0.000)\n",
      "MAE: 0.963 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.965 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.503 (0.000)\n",
      "MAE: 1.120 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.937 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  26.923540389537813\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.260 (0.000)\n",
      "MAE: 0.956 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.966 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.502 (0.000)\n",
      "MAE: 1.119 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.937 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  16.77530665397644\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.261 (0.000)\n",
      "MAE: 0.959 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.966 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.549 (0.000)\n",
      "MAE: 1.138 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.933 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.50129243930181\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.843 (0.000)\n",
      "MAE: 1.475 (0.000)\n",
      "MAPE: 0.034 (0.000)\n",
      "R2: 0.927 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.017 (0.000)\n",
      "MAE: 1.573 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.887 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.326775205135345\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.279 (0.000)\n",
      "MAE: 0.969 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.965 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.538 (0.000)\n",
      "MAE: 1.126 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.934 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.160072922706604\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.352 (0.000)\n",
      "MAE: 1.047 (0.000)\n",
      "MAPE: 0.024 (0.000)\n",
      "R2: 0.961 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.582 (0.000)\n",
      "MAE: 1.205 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.931 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.415709559122721\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.370 (0.000)\n",
      "MAE: 1.040 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.960 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.500 (0.000)\n",
      "MAE: 1.115 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.938 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.184451977411905\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.474 (0.000)\n",
      "MAE: 1.117 (0.000)\n",
      "MAPE: 0.025 (0.000)\n",
      "R2: 0.954 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.532 (0.000)\n",
      "MAE: 1.146 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.935 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/204/i/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/204/i/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/204/i/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>204</td>\n",
       "      <td>I</td>\n",
       "      <td>Chemical + Physical</td>\n",
       "      <td>(63772, 17)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_12</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>1.370023</td>\n",
       "      <td>1.039622</td>\n",
       "      <td>0.02332</td>\n",
       "      <td>0.959896</td>\n",
       "      <td>1.500256</td>\n",
       "      <td>1.114947</td>\n",
       "      <td>0.026209</td>\n",
       "      <td>0.937575</td>\n",
       "      <td>-2.960318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category Company Plant             Features   Data Shape Timesteps  \\\n",
       "11  Global Model     204     I  Chemical + Physical  (63772, 17)      None   \n",
       "\n",
       "     Model Model Params           Scaler Scaler Params  ...  \\\n",
       "11  MLP_12         None  Standard Scaler          None  ...   \n",
       "\n",
       "                  Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "11  {\"train_size\": 0.8, \"test_size\": 0.2}   1.370023  1.039622    0.02332   \n",
       "\n",
       "    R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "11  0.959896   1.500256  1.114947   0.026209  0.937575 -2.960318  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R²\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  18.3820108850797\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.317 (0.000)\n",
      "MAE: 0.999 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.961 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.317 (0.000)\n",
      "MAE: 0.999 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.961 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/204/mlp/i/pre_training/\\\"\\nmodel_name = \\\"mlp_full_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/204/mlp/i/pre_training/\\\"\\nmodel_name = \\\"mlp_full_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/204/mlp/i/pre_training/\"\n",
    "model_name = \"mlp_full_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x760a83f28490>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x760b20169fc0>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x760aa160cb20>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGiCAYAAABH4aTnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8Y0lEQVR4nO3deXxU9b3/8feZSWayT/aNLARk30QQRFxAqEgVwaVu2FJttSrWWq1br1qttqjt9Ufr9WqrrUvr7hWsVq0Lu+w7yE4ChCUkLMmELJNk5vz+CAxGIhCZzElyXs/HYx6P5JyTmc98HxPy5rsdwzRNUwAAAGHisLoAAABgL4QPAAAQVoQPAAAQVoQPAAAQVoQPAAAQVoQPAAAQVoQPAAAQVoQPAAAQVoQPAAAQVoQPAAAQVi0OH3PmzNG4ceOUnZ0twzA0ffr04Ln6+nrdd9996tevn2JjY5Wdna0f/ehH2r17dyhrBgAA7ViLw0dVVZUGDBigZ5999phz1dXVWr58uR566CEtX75c7733njZu3KhLL700JMUCAID2zziVG8sZhqFp06ZpwoQJ33rNkiVLNGTIEG3fvl15eXnf9aUAAEAHEdHaL1BRUSHDMJSYmNjseZ/PJ5/PF/w+EAjowIEDSklJkWEYrV0eAAAIAdM0VVlZqezsbDkcxx9YadXwUVtbq/vuu0/XXnutEhISmr1mypQpevTRR1uzDAAAECbFxcXKyck57jWtNuxSX1+vK664Qjt37tSsWbO+NXx8s+ejoqJCeXl5Ki4u/tafAQAAbYvX61Vubq7Ky8vl8XiOe22r9HzU19frqquu0vbt2zVjxozjhgi32y23233M8YSEBMIHAADtzMlMmQh5+DgSPDZv3qyZM2cqJSUl1C8BAADasRaHj0OHDmnLli3B74uKirRy5UolJycrKytLV155pZYvX64PP/xQfr9fJSUlkqTk5GS5XK7QVQ4AANqlFs/5mDVrlkaOHHnM8UmTJumRRx5RQUFBsz83c+ZMjRgx4oTP7/V65fF4VFFRwbALAADtREv+fre452PEiBE6Xl45hfmrAADABri3CwAACCvCBwAACCvCBwAACCvCBwAACCvCBwAACCvCBwAACCvCBwAACCvCBwAACKtWubFcW1RW6dPzs7cq0unQ/WN7Wl0OAAC2ZZueD29tvf42r0ivL9pudSkAANiabcKHy9n4Vuv9bP8OAICVbBM+IoPhI2BxJQAA2JuNwochSWoImNz8DgAAC9knfEQcfasMvQAAYB37hA/H18MHQy8AAFjFPuHj8LCLRPgAAMBKtgkfToch43D+qCN8AABgGduED8MwgiteGpjzAQCAZWwTPqSv7/VBzwcAAFaxVfg4Mu+D8AEAgHVsFT4iDvd81DUw7AIAgFVsFT4YdgEAwHq2Ch9HdzklfAAAYBWbhQ+GXQAAsJotwwfDLgAAWMdm4YPVLgAAWM1m4YOeDwAArGbL8FHHDqcAAFjGXuEj4sj26vR8AABgFVuFDxdzPgAAsJytwkeEg2EXAACsZqvwcWTYpb6Bng8AAKxir/DBsAsAAJazVfg4cm+XhgDDLgAAWMVW4ePo9ur0fAAAYBVbhY8Ihl0AALCcrcKHix1OAQCwnK3Cx9Ht1ZnzAQCAVWwaPuj5AADAKvYKHxHM+QAAwGq2Ch8uhl0AALCcrcJHhKOx56OOng8AACxjq/DB9uoAAFjPXuGDHU4BALCcrcIH+3wAAGA9W4UPtlcHAMB6tgofbK8OAID1bBU+WGoLAID1bBU+2OEUAADr2Sx8MOwCAIDV7BU+Ihh2AQDAavYKHw6GXQAAsJq9wgc3lgMAwHL2Ch/s8wEAgOVsFT5cbK8OAIDlbBU+WGoLAID1bBU+ju5waso06f0AAMAKtgofR3o+JJbbAgBgFVuFD1eT8MHQCwAAVrBV+Diyw6kkNdDzAQCAJWwVPpwOQ8bh/FFHzwcAAJawVfgwDIMVLwAAWKzF4WPOnDkaN26csrOzZRiGpk+f3uS8aZp6+OGHlZWVpejoaI0ePVqbN28OVb2nLNLBLqcAAFipxeGjqqpKAwYM0LPPPtvs+aeeekp//vOf9fzzz2vRokWKjY3VmDFjVFtbe8rFhsLRm8sRPgAAsEJES39g7NixGjt2bLPnTNPU1KlT9eCDD2r8+PGSpFdffVUZGRmaPn26rrnmmlOrNgSObrHOhFMAAKwQ0jkfRUVFKikp0ejRo4PHPB6Phg4dqgULFjT7Mz6fT16vt8mjNR3dYp2eDwAArBDS8FFSUiJJysjIaHI8IyMjeO6bpkyZIo/HE3zk5uaGsqRjRDqZ8wEAgJUsX+3ywAMPqKKiIvgoLi5u1deLYNgFAABLhTR8ZGZmSpL27t3b5PjevXuD577J7XYrISGhyaM1sdQWAABrhTR8FBQUKDMzU1988UXwmNfr1aJFizRs2LBQvtR35mLYBQAAS7V4tcuhQ4e0ZcuW4PdFRUVauXKlkpOTlZeXpzvvvFOPP/64unXrpoKCAj300EPKzs7WhAkTQln3d3a054NhFwAArNDi8LF06VKNHDky+P1dd90lSZo0aZJefvll3XvvvaqqqtLNN9+s8vJynXPOOfrkk08UFRUVuqpPAcMuAABYq8XhY8SIETLNb+81MAxDv/3tb/Xb3/72lAprLREMuwAAYCnLV7uEm4ueDwAALGW78BHc4ZQ5HwAAWMJ+4ePwvV0a6PkAAMAStgsf7sPho6beb3ElAADYk+3CR6zLKUmqqSN8AABgBduFj2hX4wKfKh/hAwAAK9gufAR7PuobLK4EAAB7sl34iHHT8wEAgJVsFz6O9HxU19HzAQCAFWwXPqKD4YOeDwAArGC78BF7ZMIp4QMAAEvYLnzEuA/3fPgYdgEAwAr2Cx+Hez4YdgEAwBq2Cx9MOAUAwFq2Cx/Bpbb0fAAAYAnbhY8jPR91DQHVc3M5AADCznbh48hSW4l5HwAAWMF24cPldCjCYUji5nIAAFjBduHDMAzFHO79qGLSKQAAYWe78CFJsYcnnVZzfxcAAMLOluEjmp4PAAAsY8vwcWSLdeZ8AAAQfrYMH8z5AADAOrYOH8z5AAAg/OwZPoK7nNLzAQBAuNkyfBy9vws9HwAAhJstw8fRO9vS8wEAQLjZNHwcnnDKnA8AAMLOluEjuMkYPR8AAISdLcNHDHM+AACwjC3DR2xwzgfhAwCAcLNl+Ahur+5j2AUAgHCzZfiIdTPsAgCAVWwZPlhqCwCAdWwaPuj5AADAKjYNH4e3V2fOBwAAYWfL8BF3eJ+PQ74GmaZpcTUAANiLLcOHJzpSkhQwpSqGXgAACCtbho+oSIcinYYkqaKm3uJqAACwF1uGD8Mwgr0fFdWEDwAAwsmW4UOSEg6HD28t4QMAgHCyb/iIOtzzwbALAABhZdvwERx2IXwAABBWtg8fXsIHAABhZdvwkRDduNcH4QMAgPCybfgI9nzUssspAADhZPvwwZwPAADCy7bhg9UuAABYw7bhgwmnAABYw/bhg54PAADCy7bhI4HwAQCAJWwbPjxsrw4AgCVsGz6O9HzU1gfka/BbXA0AAPZh2/AR746QYTR+7a1hrw8AAMLFtuHD4TAU727c5ZR5HwAAhI9tw4ckeWKYdAoAQLjZOnwc2WiMSacAAISPrcMHG40BABB+hA8RPgAACCdbh4/Ew3M+9lfVWVwJAAD2Yevwke2JliTtLq+xuBIAAOzD1uGjU1Jj+Nh5kPABAEC42Dp85CTFSJJ20fMBAEDYhDx8+P1+PfTQQyooKFB0dLS6du2qxx57TKZphvqlTtmRno/d5TUKBNpefQAAdEQRoX7CJ598Us8995xeeeUV9enTR0uXLtUNN9wgj8ejO+64I9Qvd0oy4t1yOgzV+02VVvqU6YmyuiQAADq8kIeP+fPna/z48br44oslSZ07d9Ybb7yhxYsXN3u9z+eTz+cLfu/1ekNd0reKcDqU5YnSzoM12lVeTfgAACAMQj7scvbZZ+uLL77Qpk2bJEmrVq3SvHnzNHbs2GavnzJlijweT/CRm5sb6pKOq1Mik04BAAinkIeP+++/X9dcc4169uypyMhIDRw4UHfeeacmTpzY7PUPPPCAKioqgo/i4uJQl3RcRyadEj4AAAiPkA+7vP3223rttdf0+uuvq0+fPlq5cqXuvPNOZWdna9KkScdc73a75Xa7Q13GSTsy6ZQVLwAAhEfIw8c999wT7P2QpH79+mn79u2aMmVKs+HDajkMuwAAEFYhH3aprq6Ww9H0aZ1OpwKBQKhfKiRyjvR8HKy2uBIAAOwh5D0f48aN0+9+9zvl5eWpT58+WrFihZ5++mndeOONoX6pkPj6Lqf+gCmnw7C4IgAAOraQh49nnnlGDz30kG677TaVlpYqOztbP/vZz/Twww+H+qVCIicpRjEup6rr/CosO6RuGfFWlwQAQIcW8vARHx+vqVOnaurUqaF+6lbhdBjqm+3R4m0HtGpnBeEDAIBWZut7uxzRP8cjSVpVXG5tIQAA2ADhQ1L/3ERJ0uqd5ZbWAQCAHRA+JA043POxfk+l6hra5qocAAA6CsKHpLzkGCXGRKrOH9CGkvDdWwYAADsifEgyDEP9OjHvAwCAcCB8HDYwL0mStGz7QYsrAQCgYyN8HDa0IFmStKjogEzTtLgaAAA6LsLHYQPzEhXhMLSnopb7vAAA0IoIH4fFuCLU9/C8j8VFByyuBgCAjovw8TVHhl4IHwAAtB7Cx9cMORI+thE+AABoLYSPrxncOVmRTkNF+6q0hAACAECrIHx8jSc6UlcOypUk/enzzRZXAwBAx0T4+IbbRnRVhMPQvC37tJTeDwAAQo7w8Q25yTG6clCOJOmp/2xkzw8AAEKM8NGMO0Z1kzvCocVFBzRjQ6nV5QAA0KEQPpqRnRitG88pkCQ98fEGBQL0fgAAECqEj29x64iuindHaHPpIS0s3G91OQAAdBiEj2+REBWpcadnS5LeWbbT4moAAOg4CB/HcdXgxmW3H63ZI29tvcXVAADQMRA+jmNAjkfd0uPkawjoXyt3W10OAAAdAuHjOAzD0NVnNvZ+/P3LIvmZeAoAwCkjfJzANUPylBAVocKyKn22rsTqcgAAaPcIHycQ547QpLM7S5L+d9ZWlt0CAHCKCB8n4cdnd1Z0pFOrd1bo5fnbrC4HAIB2jfBxElLi3Pr193tKatx07KvdFRZXBABA+0X4OEnXn5Wv0b3SVecP6NZ/Lld5dZ3VJQEA0C4RPk6SYRj6w5UDlJscrR0HqvXzN1Zw0zkAAL4DwkcLJMW69MKPBisq0qG5m/dp2faDVpcEAEC7Q/hooZ6ZCfp+vyxJ0rQVuyyuBgCA9ofw8R1cPjBHkvTh6j2qawhYXA0AAO0L4eM7GNY1RenxblXU1OupTzZo9c5yq0sCAKDdIHx8B06HoQkDO0mSXpxXpMv/d76K9lVZXBUAAO0D4eM7mjziNE0e2VVd02LVEDD14txCq0sCAKBdIHx8R56YSN0zpqd+d1k/SdK7y3Zq3yGfxVUBAND2ET5O0dCCZPXP8cjXENDri3ZYXQ4AAG0e4eMUGYaha4fkSZLmb91ncTUAALR9hI8Q6J/jkSR9tdvLrqcAAJwA4SMEuqXHy+V0qLK2QcUHaqwuBwCANo3wEQKuCIe6Z8ZJkj5YvVtXPjdfn63ba3FVAAC0TYSPEOmb3Tj08t+fbtTS7Qc15aP1DMEAANAMwkeI9MlOkCQFDueNwn1VWlFcbl1BAAC0UYSPEOnTyXPMsXeX7bSgEgAA2jbCR4j0ykyQw2j8+spBjTee+2DVblX5GiysCgCAtofwESLRLqduv6CbLumfpccn9FV+Sowqaxv02w/WWV0aAABtCuEjhO76Xnf9z3VnKCrSqScu7y/DkN5aWqyP1uyxujQAANoMwkcrGdY1RbeN6CpJmvr5Jla+AABwGOGjFf3s/K6KinRo095DWsnKFwAAJBE+WlVCVKS+3zdLkvT/Pt+su95ayf1fAAC2R/hoZT8YnCtJmrOpTO+t2KX7/2+NAgGGYAAA9kX4aGVndUlW76zGDcginYZ2HKjWvC30fgAA7Ivw0coMw9AbN52lufeO1MSh+ZKk1xZtt7gqAACsQ/gIA09MpHKTY3Td0DxJ0ufrS1VSUWtxVQAAWIPwEUbdM+I1pCBZ/oCpv80rtLocAAAsEWF1AXZz64iuWlx0QK8t2qGMhCgdrK7THaO6yR3htLo0AADCgvARZiO6p6l3VoLW7fHq8X+vlySlxLp14zkFFlcGAEB4MOwSZoZh6K7vdZckuSMam//52VtVW++3siwAAMKG8GGB0b0zNPNXI7T416OV7YlSaaVP/1jAChgAgD0QPixSkBorT0ykbh15miTpdx+t1+MfrpOfDcgAAB0c4cNi1w3J0w3DO0uSXpxXxCoYAECHR/iwmNNh6Dfj+uix8X0kSX/8dJO2lB6yuCoAAFoP4aONuP6sfJ3XPU11DQE9+sFXVpcDAECraZXwsWvXLl1//fVKSUlRdHS0+vXrp6VLl7bGS3UYhmHo8fF9ZRjS3M37tKq4XD99Zan+uZCJqACAjiXk+3wcPHhQw4cP18iRI/Xxxx8rLS1NmzdvVlJSUqhfqsPJS4nROaelau7mffrR3xeroqZe87fu02UDOynWzZYsAICOIeR/0Z588knl5ubqpZdeCh4rKGADrZP1g8G5mrt5nypq6iVJ1XV+fbK2RFcMyrG4MgAAQiPkwy7/+te/NHjwYP3gBz9Qenq6Bg4cqBdeeOFbr/f5fPJ6vU0ednZh7wwlRDVmQk90pCTp3WU7rSwJAICQCnn4KCws1HPPPadu3brpP//5j2699VbdcccdeuWVV5q9fsqUKfJ4PMFHbm5uqEtqV6IinXrk0j4a0ydD//zJUBmGtKBwv4oPVFtdGgAAIWGYphnSXa1cLpcGDx6s+fPnB4/dcccdWrJkiRYsWHDM9T6fTz6fL/i91+tVbm6uKioqlJCQEMrS2qXrX1ykeVv26Zeju+sXo7tZXQ4AAM3yer3yeDwn9fc75D0fWVlZ6t27d5NjvXr10o4dO5q93u12KyEhockDR115eK7Hu8uLFQiYCnFWBAAg7EIePoYPH66NGzc2ObZp0ybl5+eH+qVsYUyfTMW5I1R8oEY//Psinf3EDC3bftDqsgAA+M5CHj5++ctfauHChfr973+vLVu26PXXX9df//pXTZ48OdQvZQvRLqcu6Z8lSfpyy37tqajVHW+sUEV1vcWVAQDw3YQ8fJx55pmaNm2a3njjDfXt21ePPfaYpk6dqokTJ4b6pWzjmiF5kqSkmEh1SozWrvIa3ft/qxiCAQC0SyGfcHqqWjJhxU7W7KxQVmKUdpfX6Irn5qveb+qeMT00+fBdcQEAsJKlE07ROvrleJQa51b/nEQ9Nr6vJOmPn25kDxAAQLtD+GiHrhmSp0nD8mWa0q/eWaWXviyyuiQAAE4a4aOdeuTSPrr5vC6SpMf/vV6rd5ZbWxAAACeJ8NFOGYahX3+/ly4dkC1/wNQ976yWr8FvdVkAAJwQ4aOde+TSPkqNc2nj3krd8o9lqq5rsLokAACOi/DRziXHuvT/rj5dUZEOzdxYpkuemad3ljbuhgoAQFtE+OgAzu2Wptd+OlRJMZEqLKvSPe+u1tQvNltdFgAAzSJ8dBCD8pM1+96RumNU483nnp25RauKy60tCgCAZhA+OpCEqEjd9b3uGnd4Euov316p2nomoQIA2hbCRwf02Pg+So93q7CsSk9+ssHqcgAAaILw0QElxrj05JX9JUkvfblNH63ZY3FFAAAcRfjooEb2SNf1ZzXekG7y68v1/OytqvcHLK4KAADCR4f2yLg+mjg0T6YpPfHxBo2ZOkdbyw5ZXRYAwOYIHx1YhNOhxyf01e8v66fkWJcKy6p011sr5WcPEACAhQgfHZxhGLpuaJ4+/sW5indHaNXOCv1jwTarywIA2BjhwyYyEqJ079iekqQnPtmgRYX7La4IAGBXhA8bmTgkTxf0TFdtfUA3vrxEczeXWV0SAMCGDNM029QEAK/XK4/Ho4qKCiUkJFhdTodTW+/XjS8v0fytjT0f53VPU1JMpH4xqpu6pMVZXB0AoL1qyd9vej5sJirSqb9NOjO4DHfOpjK9v3K37np7FTejAwCEBeHDhqJdTj0+oZ/+79az9dj4Pop1ObWyuFzvLt9pdWkAABsgfNjYoPwk/XBY5+DN6O59d7XOnvKF5m3eZ3FlAICOjPAB3TC8QCN6pEmSdlfU6u53VqrK12BxVQCAjorwAbkiHHr5hiFa+fD3lJcco71en56ZscXqsgAAHVSE1QWg7UiMcemhS3rrpleX6q9ztso0Tc3bsk9Oh6E3bz5LMS4+LgCAU0fPB5oY3StdE4fmKWBKf5lTqK92e7V6Z4Wmr9htdWkAgA6C8IEmDMPQ4xP66qFLeis1zqX+OR5J0qsLtqmNbQkDAGinCB84hmEY+sk5BVr64Pf0j58MVXSkUxtKKvXaoh2qqK63ujwAQDtH+MBxeaIjddkZnSRJD05fq/P/OFNF+6osrgoA0J4RPnBCvxzdXVcPzlW2J0rl1fW6880VqvcHrC4LANBOET5wQmnxbj15ZX+9e+vZ8kRHatXOCj3+4TrmgAAAvhPCB05admK0nri8nyTplQXbde+7q/XO0mI2JAMAtAjhAy0ytl+WHpvQV5L0zrKduufd1bruhYWqa2AYBgBwcggfaLEfnpWv568/Q5cP7KSEqAit2lmhJz7eYHVZAIB2gvCB7+Sivll6+urT9fRVp0uS/v5lkf7zVYm1RQEA2gXCB07J6N4ZuuncAknSPe+sUvGBaosrAgC0dYQPnLJ7L+qpgXmJ8tY26PbXlzP/AwBwXIQPnLJIp0PPXDswuAx38uvLdddbK/XF+r1WlwYAaIMIHwiJnKQY/fEHAyRJn63bq/dW7NJPX12q52dvVU2d3+LqAABtiWG2sZ2ivF6vPB6PKioqlJCQYHU5aKGXvyzS/K375TAMfXJ4Amp0pFO3nN9Vt19wmpZtP6juGXFKjHFZXCkAIJRa8veb8IFWYZqmXl2wXX+dU6hd5TWSpPR4t0orfRqQm6jpt50twzAsrhIAECot+fvNsAtahWEYmnR2Z827b6R+d1lfOQyptNInSVpVXK4v1pdKknaX1+g/X5WwVTsA2EiE1QWgYzMMQxOH5is/OVbLdxzUXm+tXlu0Q1O/2KTze6Tp+r8tUmFZlf587UBdOiDb6nIBAGFAzwfC4pxuqbpjVDfdfWEPxbicWrvLqx8eDh6S9M8F2y2uEAAQLoQPhFVyrEv3jukhSVpYeCB4fPG2A9q8t9KqsgAAYUT4QNj9eHhBcFfU/JQYXdAzXZL04twi5n4AgA0w5wOWeGBsLw3unKzeWQnavr9aMzaU6q2lxarzB/TkFf3liiAXA0BHxb/wsITDYWhMn0zlJsfonG6pevDiXnI6DE1bsUt//mKz1eUBAFoR4QNtwk/P7aKpV58uSXp+9lat3+O1tiAAQKshfKDNGDcgW2P6ZKghYOqnryzVy18W6e63V+nZmVtUW88W7QDQUbDDKdqUUm+trnh+vooP1DQ53iUtVj89p4suPT1bcW6mKgFAW8P26mjXqnwNmvr5Ji3edlCn53j00doSlR3eHTUzIUpTrzldZ3VJsbhKAMDXET7QoVTU1OvtJcV6deE2FR+okcOQnrn2DF3cP8vq0gAAhxE+0CFV+Rr0X9PWaPrK3YpxOXXbiK7aVV6ruy/srtQ4d5NrTdPUk59sVHxUhCaPPM2iigHAPlry95vBc7Qbse4I/fEHA1Ra6dP8rfv1x083SZLcEQ49cmmfJtcuLDyg52dvlSRdOyRPybGusNcLAGgeq13QrkQ4HfrztQN1em6iuqbFSpL+tWq36hoCTa57Y/GO4NdrdlWEtUYAwPERPtDupMa5NX3ycP3nzvOUFu/Wgao6vbVkhz5YtVslFbU6WFWnT9aWBK9fs7PcumIBAMdg2AXtVoTToQmnZ+uFuUV66P2vJElOh6GkGJfq/Ed7QlbvpOcDANoSej7Qrl0xKEeG0fh1p8Ro+QOm9h1qXJZ73dA8SQy7AEBbQ88H2rWemQl69cYhkqRzTkvVjgPVOlhdr2xPlGLdEXpj8Q7tqahVWaVPafHuEzwbACAcCB9o987tlhb8Oj8lVvlf23+sa1qctpQe0tpdFRrZM92C6gAA38SwCzq0/p08kqRfT1ujF+cWav/hIRkAgHXYZAwd2qa9lfrh3xZpr/do6HBHONQ/x6Mnr+ivLmlxFlYHAB1HS/5+t3rPxxNPPCHDMHTnnXe29ksBx+ieEa/Z94zU7y7rq/45jb0gvoaAlmw7qEv/50t9uHq3xRUCgP20as/HkiVLdNVVVykhIUEjR47U1KlTT/gz9HygNR2oqtO+Qz49OH2tFhcdkCT1zIxXibdWP7+gm244u7PW7fGqR2a8Ip2MSgLAyWoTPR+HDh3SxIkT9cILLygpKam1XgZokeRYl7pnxOv1nw7VbSO6SpI2lFSqvLpej324TqOfnq1Lnpmna/66UOXVdRZXCwAdU6uFj8mTJ+viiy/W6NGjj3udz+eT1+tt8gBaW4TToXsv6qkPf36Onrl2oG46t0CSVLivSpK0bPtBXf6/8/XpVyWq9weO91QAgBZqlaW2b775ppYvX64lS5ac8NopU6bo0UcfbY0ygBPq28mjvp08uqR/ljISolRSUasLeqbrrrdXqXBflW7+xzJFOg0N65qqZ64dKE90pNUlA0C7F/I5H8XFxRo8eLA+++wz9e/fX5I0YsQInX766c3O+fD5fPL5jq5E8Hq9ys3NZc4HLFVeXacX5hbq1QXbVVnbIEm6qE+mnrv+DBlHtlQFAAS1ZM5HyMPH9OnTddlll8npdAaP+f1+GYYhh8Mhn8/X5Nw3MeEUbUkgYGrJtgO6/m+LVO839aNh+frl6O5KinXpnaXFWllcrocu6a2oyG//TAOAHVgaPiorK7V9+/Ymx2644Qb17NlT9913n/r27Xvcnyd8oC16+csiPfLBOklSUkyknrt+kH54OJA8eHEv/fTcLhZXCADWasnf75DP+YiPjz8mYMTGxiolJeWEwQNoq348vED5KbF6/N/rtLWsSj/622LV+xtz+1/mFOr6s/Lp/QCAk8RGBsBJGtkzXS9OOlPuCIfqDq+ASYiKUFmlT3/+YrP8gTa1WTAAtFlsrw600POzt+qJjzdo+GkpGtc/W/e/t0aS1LdTgh66uLccDkMlFbUalJ+k7MRoi6sFgPCwdNgF6Oh+dl4X9evkUd9sjxKiI1RV59fUzzdp7S6vrv7rwibXThyap8cn9GWFDAB8DT0fQAjsO+TTf3+6SW8u2aGEqEjlJkfrq91emab0wNie6p4Zrz7ZCUqPj7K6VABoFZaudjlVhA+0ZzV1fkU4DUU6HfrrnK36/UcbgufS49167adD1S0jXjM3lmrmhlL9YlQ3pcS5LawYAEKDYRfAItGuoytebjq3i9bs8urD1bsV545QaaVPV/1lga46M1cvzi2SP2CqsKxKr9w4RE4HwzIA7IOeD6AVmaaphoCpQ7UNmvTSYq3eWXHMNT8+u7N+NaaH4tz8XwBA+8WwC9AG1db79c+F2/XSl9s0tEuyzipI0b3/t1qS5HI65HBII7qn68kr+3MPGQDtDuEDaCc+XL1bT3+6KXg3XUnqmhar64bma1z/LKUnMEEVQPtA+ADaEX/A1K6DNdpTUaM73lyhvd7GGy2mxrn18S/O1YYSr9Li3eqZye8DgLaL8AG0U2WVPr27bKfeXLJD2/dXKy3erbJKn6IiHfrX7eeoe0a81SUCQLMIH0A7t3lvpS55Zp58DYHgsa5psbr+rHyVeGvlqw9o0tmdVZAaa2GVAHAU4QPoAD5es0cvz9+m64bm6Xf/Xq/SSl+T8ymxLo0bkK21uyr0yKV91LeTx6JKAYDwAXQ4G0sq9cLcQtXU+5US69LSbQe1bo83eH5IQbLe/tkwCysEYHdsMgZ0MD0y4/XHHwwIfu+trdev31sjX0NAszaWanHRAS0s3K/t+6v06oLtcjoM3XJ+V43tm8l9ZQC0OfR8AO3cPe+s0jvLdsowpG/+Nt90boH+6+Le1hQGwFZa8vfbEaaaALSSn53fJRg8sjxRevDiXrp95GmSpBfmFunv84o0Y8NebdtXpZe/LNK4Z+bpi/V7La4agJ3R8wF0AHM3l8lb06AL+2Qo0tn4f4opH63XX+YUNnt9apxLs+4ZyZbuAEKGOR+AzZzbLe2YY/eM6aG93lqt3lUhl9OhwrIqxbqdckU4tNfr0x8+2aAxfTLlrW1QTlI0q2UAhA09H4BN1DUEFOEw9Om6vbrln8uOOX/riK761YU9uMMugO+Eng8Ax3BFNA7HjOmToSsH5Wj+ln2Ki4qQO8KpNbsq9Nysrfr0qxKN7ZulgGnqsoGd1I0dVQG0Ano+AOhfq3brv95bo0pfQ/BYfFSE3rjpLPXt5NFeb63qGgLKTY6xsEoAbRmbjAFoMW9tvd5ZulOb91Zq3R6vVu+skCvCoc4pMdpcekimKV02sJPO756mCKehwfnJyvRw110AjQgfAE5JZW29fvLyUi3ediB4rLl9RH4wKEdPXNH/hPNETNPUe8t3qWt6nE7PTWyFigFYjfAB4JQFAqYK91WpsOyQemUlaH9Vnf5nxhbV1DeooqZeX+32yjSlc7ulqsrXoPyUWF03NE9ndk4+5rn+tWq37nhjhdLj3Vr4wCg5mNQKdDiEDwCt7oNVu3XHmyuO6Q05q0uyHry4d3Dpbr0/oO89PVvb9ldLkj78+Tks6wU6IFa7AGh14wZkS5JmbizV0IJkLd9ermkrdmlh4QFd/tx8/f6yfrp8YCf9dU5hMHhI0uxNZYQPwObo+QAQMrvKa/Sb99fq8/WlkqR4d0RwBU2/Th6t2VWhIZ2T9fYt3IEX6Gi4twsAS3RKjNZffzhYd4zqpliXU5W+BkVFOnTvRT30P9cNlCQt23FQD05fo6c/26QtpYe075BPdQ0BSVJtvV+BQJv6/xCAVkDPB4BWUVvv19pdFcpLjlF6QuOS3Av+OEuF+6qOudZhSJ7oSB2srteAHI/evmWY3BHOcJcM4BQw4RRAm/Tusp16fvZWDSlIVvGBai3Yul8NzfR0XDU4R1/t9io51qX/nXiG4qMiLagWQEsQPgC0G6ZpqqzSp/1Vdfpqt1e/emdVk/On5yaqa1qcClJjNHnkafIdHqKJiqRnBGhLWO0CoN0wDEPpCVFKT4hSz8x4zdiwVx+tKdHg/CRtLKnUyuJyrSwulySt2+PVwsIDqvcH9OOzO+uHZ+VrfUmlpq/YpZ+cU8AqGqCdoOcDQJtS7w9oza4K9e/k0Ve7vfr7l0WKcTn1xuLiY651GNKRUZv0eLd+/f1e+mRtiTqnxuqygZ3UI5Mb4wHhwrALgA7nlfnb9MyMzbr6zFz1yfboxbmFWr6jXE6HoaQYl/Yd8jW53mFId1/YQ2d3TZEpKScxOjjxFUDoET4A2ELxgWq5IxyqqKnX+Ge/VHWdX9cOyVWp16cvNpQec/1ZXZI14fROKq30aVjXFJ3ZOVm19X7mjwAhQPgAYDvFB6pVW+9Xt4x4maapt5cW65kZWyQ13hBvT0WNvrmwJjnWpQNVderbKUEX98vWzoPV2lp2SNGRTt0/thfDNkALED4A4Bt2ldfof2duUWFZlRJjIvX5+r2q93/7P3/uCIfuu6infjQsX3X+gH793hotKNyvn57TRT86Oz+4D4k/YKq6roHlwLA9wgcAnEBpZa12HqxRWpxb7y7bqS2lh5SfEqOuaXH6YPVuzdpYJqlx11apMbwc0TMzXndf2EPTVuzU3M37VFnboMH5Sbp1RFed1z1Nr8zfpq5pcRrZM92S9wZYgfABAKcgEDD1xpId+sN/Nqq8ul6SlBrn0g3DC/TSl0Xad6iu2Z8zDKl/J49W7ayQJP12fB9NHJovp8MIW+2AVQgfABAC3tp6rSouV02dX2d2TlZSrEslFbW6/fXlWr7joCYM7KRJwzorNd6tP3++WW8tbVwObBiN80ykxuGbM/KSNLp3hmrr/aprCCg1zqXLzshRnPvktlqq9wcU6eRWXGjbCB8A0IpM09QhX9N5HqZp6r8/3aSP1uzRo+P7aNn2g3pu1tbgjqzf1DUtVneM6iZ/wFRGQpQ6JUarIdA4Uba6rkFDClJ0Rl6i/jqnUG8s3qGJQ/P14MW9FNFMCPHW1uutxcX6fv+s4DAREG6EDwBoA/wBU0X7qvSfr0q0YsdBJcW45I506PN1pSrx1rb4+c7tlqrHxvdV59RY1db79cnaEvXP8ei/pq3VgsL9GpDj0bTbhsvBMA8sQPgAgDZs3yGffvfv9dpxoFrRkU6VeGu182C1ausDGtkjTQWpcVpUtF/r9niVFOPSD8/K1/OzG3tRIp2G7r6whxYW7g9Oiv26p67sr6sG51rwrmB3hA8AaGdM05SvIdBkw7PK2nrFuCLkdBjavLdSj/97vWZvOho4IhyGGgKmDEO6qE+mPl5boqSYSD0+oZ/OyE/U/kN12ra/Sr2zEtQlLU5S4xBNbZ2/yW6vu8trVFvvlzvSqagIh1Li3OF74+gwCB8A0AGZpql/LNyuRz9Yp4Bp6vnrB6kgNVYNflOnpcdpwrNfat0eb7M/m5scLadhaPuBapmm1CU1Vp2SorWrvEaFZVVNrj27a4qmXn269h2q086D1YqKdOqc01LDMpxTXl2nxBhXq78OQo/wAQAd2Oa9laqtD6hfTtO7+Fb5GvSXOYV6Zf42Vdc1KNYdodykGK3b45X/a9u7fv2GfFJjD0q0yylfQ0B13zJBdlTPdN0wvEB7KmpUWulTQWqsRvVKD262drJM05RhNB9i3ly8Q/e/t0Z3f6+7fj6qW4ueF9YjfAAAgvYf8mlrWZX8AVNd02MVFenU0m0HVFFTr+jICJ19WooSDq/c2VJ6SDf/Y6kKy6oU745Ql7RYrS+pbDaUJMZEavyAbJmSdhyo1rnd0jRuQJa8NQ36xZsr5A+YGtkzXaN7pev03CQVlh3SLf9cJqfD0CPj+ujs01LV4A9oS9khdU6J1fl/mKm9Xp+cDkPvTx6uvp08x7wm2i7CBwDgO2vwB7S7vFadkqLldBhas7NCD/9rrSprG5TliVJqnFsLtu5vdsWOw5DcEU7V1PubHI93RyhgmqqqO3p8SOdklVbWatv+auUkRWvnwaO7yHZKjNYl/bN01Zm5MiS9tbRYDsNQj4x4fb9fllwRDjX4A5q/db/W7KqQy+nQDcM7N7sUGeFB+AAAtCp/wNTczWX6cPUeRUU6lJcco4/XlmjFjnJJ0uD8JF03NE+zNpZp1sZSeWsbJEmD8pPUOytBry3afsyN/iTp9pGn6a2lxSqr9EmSnA5DDkNN7sPTKTFaA3I9WlVc0WTb+4v6ZOpP156u2vqA/rO2RNmJ0Tq7a4ocDkPvr9yld5bu1Lb9VRqcn6S7L+yh3OQY1dT5taBwn9bvqVTXtFiN6pWhytoGJUZHsmS5hQgfAABLFO2r0vo93ibzQfwBUxtLKrXjQLVG9EhTVKRTeypq9P7K3XJHONS3k0f3vbta7kin3rv1bNXU+zVzQ6k+WrNHX2woldS4x0lBaqw+XlsSDCaSlBLr0lldUvTZur2q8weUHu+WP2Bqf1XjFvhZniidlh6nuZv3NanT5XToysE5mr2xrEmAObKCqEtqrK4+M1f/XLRdgYA0tEuyhhYka9fBGq3bU6luGXGKinCqzu/XFWfkKDsxWoVlVcpJjpbL6VBhWZVW7yxXTlKMzumWqkWF+xUwpWFdUxQImAqY5in30uypqNFer0+n5yYGj+0qb7xfkSsi/D1AhA8AQLvjD5jH3AdnVXG5quoaNKxLigzDUG29XzM2lKrUW6ukWJfG9MlUVKRTczeX6RdvrtSBw6EjLzlGB6vrVHm4x8UwpNtGdNXgzsn629wizdtyNIxkJLg1OD9ZCwv3B0NLS0Q4DLkjHE2GlL7ukv5Z+nD1HkmNvTPLdhxUhMPQ01edrsSYSG0o8WrXwRq5I5xKiI6QYRhasHW/aur8uqhvprpnxCspNlJJMa7gUuwvt+zTz/6xTId8DXrlxiE6v3ua/m/ZTv3q3VUqSInVX344SN0y4lv8Xk4F4QMAYDt1DQHN3Vym2vqAvtc7QwHT1Jdb9mnB1v0a2TNdw09LldS44mb2pjL9ZXah+ud49IvR3RTjipCvwa+SilrFuCL0+4/Wa86mMt18Xhf1ykrQoqL9WrqtcZfawZ2TVLivSoGAqd0VtZpzeO+VOHeEDvkaw068O0K5yTHfuvT5u8ryRCnWHaHCskPBYateWQl6bHwfXffiouDE4BiXU3eO7qazu6bK6TDUMzNe/1y4XZ+vL1WnpGj1zIzXD8/K/9aVR98F4QMAgDD5aneF/AFT/Tp55K1tkGma8kQ3rh6a+vlmvTC3ULeN6Kp+OYl6df42XdArXcu2H9R7y3cp1uVU304e5SXHqN4fUGVtg6rqGjQgJ1HuCIc+X1+q0kqfyqvr1PCNSTKX9M/S7I1lqjwceCTpgp7pqq33a/7W/U2uzUhwa6/36HBVXnKM5tw7MqTtQPgAAKCNaG44SZIqauoV63Ke1NwP0zTlrWnQptJKVfka1CsrQRkJUXp25hb94T8bJUmje2Vo6jWnKybSqXeX79T/zNii2nq/Kmrqg1vz33p+VzUETMW4nLr9gtDupUL4AADABhr8Ab2zbKe6Z8RpUH5ys9eUV9fp32v2aEBOYqvunUL4AAAAYdWSv9/sxgIAAMKK8AEAAMKK8AEAAMKK8AEAAMKK8AEAAMKK8AEAAMKK8AEAAMIq5OFjypQpOvPMMxUfH6/09HRNmDBBGzduDPXLAACAdirk4WP27NmaPHmyFi5cqM8++0z19fW68MILVVVVFeqXAgAA7VCr73BaVlam9PR0zZ49W+edd94Jr2eHUwAA2p+W/P2OaO1iKioqJEnJyc3vOe/z+eTzHb3Tntcb2tsPAwCAtqVVJ5wGAgHdeeedGj58uPr27dvsNVOmTJHH4wk+cnNzW7MkAABgsVYddrn11lv18ccfa968ecrJyWn2muZ6PnJzcxl2AQCgHWkTwy633367PvzwQ82ZM+dbg4ckud1uud3u4PdHshDDLwAAtB9H/m6fTJ9GyMOHaZr6+c9/rmnTpmnWrFkqKCho0c9XVlZKEsMvAAC0Q5WVlfJ4PMe9JuTDLrfddptef/11vf/+++rRo0fwuMfjUXR09Al/PhAIaPfu3YqPj5dhGKEsLTikU1xczJDOSaC9Th5t1TK0V8vQXiePtmqZULaXaZqqrKxUdna2HI7jTykNefj4tsDw0ksv6cc//nEoX6rFWMbbMrTXyaOtWob2ahna6+TRVi1jVXu1yrALAADAt+HeLgAAIKxsFT7cbrd+85vfNFldg29He5082qplaK+Wob1OHm3VMla1V6tvrw4AAPB1tur5AAAA1iN8AACAsCJ8AACAsCJ8AACAsCJ8AACAsLJN+Hj22WfVuXNnRUVFaejQoVq8eLHVJbUJjzzyiAzDaPLo2bNn8Hxtba0mT56slJQUxcXF6YorrtDevXstrDi85syZo3Hjxik7O1uGYWj69OlNzpumqYcfflhZWVmKjo7W6NGjtXnz5ibXHDhwQBMnTlRCQoISExP1k5/8RIcOHQrjuwiPE7XVj3/842M+axdddFGTa+zSVlOmTNGZZ56p+Ph4paena8KECdq4cWOTa07md2/Hjh26+OKLFRMTo/T0dN1zzz1qaGgI51sJi5NprxEjRhzz+brllluaXGOX9nruuefUv39/JSQkKCEhQcOGDdPHH38cPN8WPlu2CB9vvfWW7rrrLv3mN7/R8uXLNWDAAI0ZM0alpaVWl9Ym9OnTR3v27Ak+5s2bFzz3y1/+Uh988IHeeecdzZ49W7t379bll19uYbXhVVVVpQEDBujZZ59t9vxTTz2lP//5z3r++ee1aNEixcbGasyYMaqtrQ1eM3HiRH311Vf67LPPgnd6vvnmm8P1FsLmRG0lSRdddFGTz9obb7zR5Lxd2mr27NmaPHmyFi5cqM8++0z19fW68MILVVVVFbzmRL97fr9fF198serq6jR//ny98sorevnll/Xwww9b8ZZa1cm0lyTddNNNTT5fTz31VPCcndorJydHTzzxhJYtW6alS5fqggsu0Pjx4/XVV19JaiOfLdMGhgwZYk6ePDn4vd/vN7Ozs80pU6ZYWFXb8Jvf/MYcMGBAs+fKy8vNyMhI85133gkeW79+vSnJXLBgQZgqbDskmdOmTQt+HwgEzMzMTPMPf/hD8Fh5ebnpdrvNN954wzRN01y3bp0pyVyyZEnwmo8//tg0DMPctWtX2GoPt2+2lWma5qRJk8zx48d/68/Yta1M0zRLS0tNSebs2bNN0zy5372PPvrIdDgcZklJSfCa5557zkxISDB9Pl9430CYfbO9TNM0zz//fPMXv/jFt/6MndvLNE0zKSnJfPHFF9vMZ6vD93zU1dVp2bJlGj16dPCYw+HQ6NGjtWDBAgsrazs2b96s7OxsdenSRRMnTtSOHTskScuWLVN9fX2TtuvZs6fy8vJoO0lFRUUqKSlp0j4ej0dDhw4Nts+CBQuUmJiowYMHB68ZPXq0HA6HFi1aFPaarTZr1iylp6erR48euvXWW7V///7gOTu3VUVFhSQpOTlZ0sn97i1YsED9+vVTRkZG8JoxY8bI6/UG/4fbUX2zvY547bXXlJqaqr59++qBBx5QdXV18Jxd28vv9+vNN99UVVWVhg0b1mY+WyG/sVxbs2/fPvn9/iaNKEkZGRnasGGDRVW1HUOHDtXLL7+sHj16aM+ePXr00Ud17rnnau3atSopKZHL5VJiYmKTn8nIyFBJSYk1BbchR9qguc/WkXMlJSVKT09vcj4iIkLJycm2a8OLLrpIl19+uQoKCrR161b9+te/1tixY7VgwQI5nU7btlUgENCdd96p4cOHq2/fvpJ0Ur97JSUlzX72jpzrqJprL0m67rrrlJ+fr+zsbK1evVr33XefNm7cqPfee0+S/dprzZo1GjZsmGpraxUXF6dp06apd+/eWrlyZZv4bHX48IHjGzt2bPDr/v37a+jQocrPz9fbb7+t6OhoCytDR3PNNdcEv+7Xr5/69++vrl27atasWRo1apSFlVlr8uTJWrt2bZO5Vvh239ZeX58b1K9fP2VlZWnUqFHaunWrunbtGu4yLdejRw+tXLlSFRUVevfddzVp0iTNnj3b6rKCOvywS2pqqpxO5zEzeffu3avMzEyLqmq7EhMT1b17d23ZskWZmZmqq6tTeXl5k2tou0ZH2uB4n63MzMxjJjY3NDTowIEDtm/DLl26KDU1VVu2bJFkz7a6/fbb9eGHH2rmzJnKyckJHj+Z373MzMxmP3tHznVE39ZezRk6dKgkNfl82am9XC6XTjvtNA0aNEhTpkzRgAED9Kc//anNfLY6fPhwuVwaNGiQvvjii+CxQCCgL774QsOGDbOwsrbp0KFD2rp1q7KysjRo0CBFRkY2abuNGzdqx44dtJ2kgoICZWZmNmkfr9erRYsWBdtn2LBhKi8v17Jly4LXzJgxQ4FAIPiPo13t3LlT+/fvV1ZWliR7tZVpmrr99ts1bdo0zZgxQwUFBU3On8zv3rBhw7RmzZomge2zzz5TQkKCevfuHZ43EiYnaq/mrFy5UpKafL7s0l7NCQQC8vl8beezFZJpq23cm2++abrdbvPll182161bZ958881mYmJik5m8dnX33Xebs2bNMouKiswvv/zSHD16tJmammqWlpaapmmat9xyi5mXl2fOmDHDXLp0qTls2DBz2LBhFlcdPpWVleaKFSvMFStWmJLMp59+2lyxYoW5fft20zRN84knnjATExPN999/31y9erU5fvx4s6CgwKypqQk+x0UXXWQOHDjQXLRokTlv3jyzW7du5rXXXmvVW2o1x2uryspK81e/+pW5YMECs6ioyPz888/NM844w+zWrZtZW1sbfA67tNWtt95qejwec9asWeaePXuCj+rq6uA1J/rda2hoMPv27WteeOGF5sqVK81PPvnETEtLMx944AEr3lKrOlF7bdmyxfztb39rLl261CwqKjLff/99s0uXLuZ5550XfA47tdf9999vzp492ywqKjJXr15t3n///aZhGOann35qmmbb+GzZInyYpmk+88wzZl5enulyucwhQ4aYCxcutLqkNuHqq682s7KyTJfLZXbq1Mm8+uqrzS1btgTP19TUmLfddpuZlJRkxsTEmJdddpm5Z88eCysOr5kzZ5qSjnlMmjTJNM3G5bYPPfSQmZGRYbrdbnPUqFHmxo0bmzzH/v37zWuvvdaMi4szExISzBtuuMGsrKy04N20ruO1VXV1tXnhhReaaWlpZmRkpJmfn2/edNNNx/wHwC5t1Vw7STJfeuml4DUn87u3bds2c+zYsWZ0dLSZmppq3n333WZ9fX2Y303rO1F77dixwzzvvPPM5ORk0+12m6eddpp5zz33mBUVFU2exy7tdeONN5r5+fmmy+Uy09LSzFGjRgWDh2m2jc+WYZqmGZo+FAAAgBPr8HM+AABA20L4AAAAYUX4AAAAYUX4AAAAYUX4AAAAYUX4AAAAYUX4AAAAYUX4AAAAYUX4AAAAYUX4AAAAYUX4AAAAYfX/Ach0ym5tKNCXAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x760a5b5688e0>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 256)               4608      \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45825 (179.00 KB)\n",
      "Trainable params: 45825 (179.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
