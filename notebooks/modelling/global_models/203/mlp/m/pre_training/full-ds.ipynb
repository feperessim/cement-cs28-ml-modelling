{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 22:38:38.482235: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-27 22:38:38.489181: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-27 22:38:38.618702: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-27 22:38:38.622584: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-27 22:38:40.611508: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/203/mlp/av/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/203/mlp/av/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/203/mlp/av/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 1\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 1\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 1\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"203\\\",\\n    \\\"Plant\\\": \\\"M\\\",\\n    \\\"Features\\\": \\\"Chemical + Physical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"203\\\",\\n    \\\"Plant\\\": \\\"M\\\",\\n    \\\"Features\\\": \\\"Chemical + Physical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"203\",\n",
    "    \"Plant\": \"M\",\n",
    "    \"Features\": \"Chemical + Physical\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/203/global_m.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/203/global_m.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/203/global_m.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8202e_row0_col0 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8202e_row1_col0, #T_8202e_row2_col0, #T_8202e_row3_col0, #T_8202e_row4_col0, #T_8202e_row5_col0, #T_8202e_row6_col0, #T_8202e_row7_col0, #T_8202e_row8_col0, #T_8202e_row9_col0, #T_8202e_row10_col0, #T_8202e_row11_col0, #T_8202e_row12_col0, #T_8202e_row13_col0 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8202e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8202e_level0_col0\" class=\"col_heading level0 col0\" >Zero (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8202e_level0_row0\" class=\"row_heading level0 row0\" >#200</th>\n",
       "      <td id=\"T_8202e_row0_col0\" class=\"data row0 col0\" >15.097999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8202e_level0_row1\" class=\"row_heading level0 row1\" >MgO</th>\n",
       "      <td id=\"T_8202e_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8202e_level0_row2\" class=\"row_heading level0 row2\" >Na2O</th>\n",
       "      <td id=\"T_8202e_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8202e_level0_row3\" class=\"row_heading level0 row3\" >SO3</th>\n",
       "      <td id=\"T_8202e_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8202e_level0_row4\" class=\"row_heading level0 row4\" >K2O</th>\n",
       "      <td id=\"T_8202e_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8202e_level0_row5\" class=\"row_heading level0 row5\" >Loss on Ignition</th>\n",
       "      <td id=\"T_8202e_row5_col0\" class=\"data row5 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8202e_level0_row6\" class=\"row_heading level0 row6\" >Blaine</th>\n",
       "      <td id=\"T_8202e_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8202e_level0_row7\" class=\"row_heading level0 row7\" >#325</th>\n",
       "      <td id=\"T_8202e_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8202e_level0_row8\" class=\"row_heading level0 row8\" >Initial setting time</th>\n",
       "      <td id=\"T_8202e_row8_col0\" class=\"data row8 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8202e_level0_row9\" class=\"row_heading level0 row9\" >Final setting time</th>\n",
       "      <td id=\"T_8202e_row9_col0\" class=\"data row9 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8202e_level0_row10\" class=\"row_heading level0 row10\" >CS1</th>\n",
       "      <td id=\"T_8202e_row10_col0\" class=\"data row10 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8202e_level0_row11\" class=\"row_heading level0 row11\" >CS3</th>\n",
       "      <td id=\"T_8202e_row11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8202e_level0_row12\" class=\"row_heading level0 row12\" >CS7</th>\n",
       "      <td id=\"T_8202e_row12_col0\" class=\"data row12 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8202e_level0_row13\" class=\"row_heading level0 row13\" >CS28</th>\n",
       "      <td id=\"T_8202e_row13_col0\" class=\"data row13 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7b59137d3b50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_formatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_values = {}\n",
    "for col in df.select_dtypes(include=\"number\").columns:\n",
    "    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\n",
    "    zero_values[col] = zero_percentages\n",
    "\n",
    "zero_percentages = pd.Series(zero_values, name=f\"Zero (%)\")\n",
    "zero_percentages = zero_percentages.sort_values(ascending=False)\n",
    "zero_percentages = zero_percentages.to_frame(name=f\"Zero (%)\")\n",
    "zero_percentages.style.background_gradient(cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop([\\\"Cement_Type\\\", \\\"Factory_Plant\\\"], axis=1)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop([\\\"Cement_Type\\\", \\\"Factory_Plant\\\"], axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop([\"Cement_Type\", \"Factory_Plant\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 22:38:47.248057: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  10.713880829016368\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.341 (0.000)\n",
      "MAE: 1.014 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.958 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.643 (0.000)\n",
      "MAE: 1.222 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.924 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  10.039047666390736\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.348 (0.000)\n",
      "MAE: 1.015 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.957 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.612 (0.000)\n",
      "MAE: 1.202 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.926 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  13.013732349872589\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.305 (0.000)\n",
      "MAE: 1.012 (0.000)\n",
      "MAPE: 0.024 (0.000)\n",
      "R2: 0.960 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.675 (0.000)\n",
      "MAE: 1.269 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.921 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.522393564383188\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.318 (0.000)\n",
      "MAE: 1.030 (0.000)\n",
      "MAPE: 0.024 (0.000)\n",
      "R2: 0.959 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.712 (0.000)\n",
      "MAE: 1.304 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.917 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  17.922234324614205\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.246 (0.000)\n",
      "MAE: 0.948 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.963 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.580 (0.000)\n",
      "MAE: 1.170 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.929 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  23.89224559466044\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.265 (0.000)\n",
      "MAE: 0.954 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.962 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.536 (0.000)\n",
      "MAE: 1.128 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.933 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  22.329213480154674\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.209 (0.000)\n",
      "MAE: 0.921 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.966 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.553 (0.000)\n",
      "MAE: 1.148 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.932 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  12.146601271629333\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.228 (0.000)\n",
      "MAE: 0.935 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.964 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.584 (0.000)\n",
      "MAE: 1.160 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.929 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  17.24601000547409\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.748 (0.000)\n",
      "MAE: 1.394 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.928 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.094 (0.000)\n",
      "MAE: 1.607 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.876 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  17.754049289226533\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.255 (0.000)\n",
      "MAE: 0.947 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.963 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.585 (0.000)\n",
      "MAE: 1.154 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.929 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  20.647370862960816\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.233 (0.000)\n",
      "MAE: 0.928 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.964 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.533 (0.000)\n",
      "MAE: 1.124 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.933 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  13.38093633254369\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.378 (0.000)\n",
      "MAE: 1.038 (0.000)\n",
      "MAPE: 0.024 (0.000)\n",
      "R2: 0.955 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.562 (0.000)\n",
      "MAE: 1.170 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.931 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  13.380785882472992\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.534 (0.000)\n",
      "MAE: 1.160 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.945 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.690 (0.000)\n",
      "MAE: 1.251 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.919 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/203/m/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/203/m/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/203/m/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>203</td>\n",
       "      <td>M</td>\n",
       "      <td>Chemical + Physical</td>\n",
       "      <td>(58776, 13)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_11</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>1.232502</td>\n",
       "      <td>0.927556</td>\n",
       "      <td>0.021195</td>\n",
       "      <td>0.964206</td>\n",
       "      <td>1.533163</td>\n",
       "      <td>1.123563</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.933408</td>\n",
       "      <td>-3.12109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category Company Plant             Features   Data Shape Timesteps  \\\n",
       "10  Global Model     203     M  Chemical + Physical  (58776, 13)      None   \n",
       "\n",
       "     Model Model Params           Scaler Scaler Params  ...  \\\n",
       "10  MLP_11         None  Standard Scaler          None  ...   \n",
       "\n",
       "                  Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "10  {\"train_size\": 0.8, \"test_size\": 0.2}   1.232502  0.927556   0.021195   \n",
       "\n",
       "    R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test     SCPM  \n",
       "10  0.964206   1.533163  1.123563   0.026443  0.933408 -3.12109  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R²\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  36.42193460861842\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.227 (0.000)\n",
      "MAE: 0.920 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.963 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.227 (0.000)\n",
      "MAE: 0.920 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.963 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/203/mlp/m/pre_training/\\\"\\nmodel_name = \\\"mlp_full_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/203/mlp/m/pre_training/\\\"\\nmodel_name = \\\"mlp_full_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/203/mlp/m/pre_training/\"\n",
    "model_name = \"mlp_full_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7b56b3e655d0>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7b5911f8cf40>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7b56a21b43d0>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7b56a8c4e5f0>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 256)               3584      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 16)                64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49345 (192.75 KB)\n",
      "Trainable params: 48353 (188.88 KB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
