{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 22:38:27.835732: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-27 22:38:27.842353: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-27 22:38:27.962444: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-27 22:38:27.963917: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-27 22:38:30.114686: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/203/mlp/av/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/203/mlp/av/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/203/mlp/av/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 10\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 10\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 10\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"203\\\",\\n    \\\"Plant\\\": \\\"M\\\",\\n    \\\"Features\\\": \\\"Chemical + Properties CS Less\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"203\\\",\\n    \\\"Plant\\\": \\\"M\\\",\\n    \\\"Features\\\": \\\"Chemical + Properties CS Less\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"203\",\n",
    "    \"Plant\": \"M\",\n",
    "    \"Features\": \"Chemical + Properties CS Less\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/203/global_m.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/203/global_m.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/203/global_m.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3ef52_row0_col0 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ef52_row1_col0, #T_3ef52_row2_col0, #T_3ef52_row3_col0, #T_3ef52_row4_col0, #T_3ef52_row5_col0, #T_3ef52_row6_col0, #T_3ef52_row7_col0, #T_3ef52_row8_col0, #T_3ef52_row9_col0, #T_3ef52_row10_col0, #T_3ef52_row11_col0, #T_3ef52_row12_col0, #T_3ef52_row13_col0 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3ef52\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3ef52_level0_col0\" class=\"col_heading level0 col0\" >Zero (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3ef52_level0_row0\" class=\"row_heading level0 row0\" >#200</th>\n",
       "      <td id=\"T_3ef52_row0_col0\" class=\"data row0 col0\" >15.097999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ef52_level0_row1\" class=\"row_heading level0 row1\" >MgO</th>\n",
       "      <td id=\"T_3ef52_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ef52_level0_row2\" class=\"row_heading level0 row2\" >Na2O</th>\n",
       "      <td id=\"T_3ef52_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ef52_level0_row3\" class=\"row_heading level0 row3\" >SO3</th>\n",
       "      <td id=\"T_3ef52_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ef52_level0_row4\" class=\"row_heading level0 row4\" >K2O</th>\n",
       "      <td id=\"T_3ef52_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ef52_level0_row5\" class=\"row_heading level0 row5\" >Loss on Ignition</th>\n",
       "      <td id=\"T_3ef52_row5_col0\" class=\"data row5 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ef52_level0_row6\" class=\"row_heading level0 row6\" >Blaine</th>\n",
       "      <td id=\"T_3ef52_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ef52_level0_row7\" class=\"row_heading level0 row7\" >#325</th>\n",
       "      <td id=\"T_3ef52_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ef52_level0_row8\" class=\"row_heading level0 row8\" >Initial setting time</th>\n",
       "      <td id=\"T_3ef52_row8_col0\" class=\"data row8 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ef52_level0_row9\" class=\"row_heading level0 row9\" >Final setting time</th>\n",
       "      <td id=\"T_3ef52_row9_col0\" class=\"data row9 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ef52_level0_row10\" class=\"row_heading level0 row10\" >CS1</th>\n",
       "      <td id=\"T_3ef52_row10_col0\" class=\"data row10 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ef52_level0_row11\" class=\"row_heading level0 row11\" >CS3</th>\n",
       "      <td id=\"T_3ef52_row11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ef52_level0_row12\" class=\"row_heading level0 row12\" >CS7</th>\n",
       "      <td id=\"T_3ef52_row12_col0\" class=\"data row12 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ef52_level0_row13\" class=\"row_heading level0 row13\" >CS28</th>\n",
       "      <td id=\"T_3ef52_row13_col0\" class=\"data row13 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x72c378313730>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_formatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_values = {}\n",
    "for col in df.select_dtypes(include=\"number\").columns:\n",
    "    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\n",
    "    zero_values[col] = zero_percentages\n",
    "\n",
    "zero_percentages = pd.Series(zero_values, name=f\"Zero (%)\")\n",
    "zero_percentages = zero_percentages.sort_values(ascending=False)\n",
    "zero_percentages = zero_percentages.to_frame(name=f\"Zero (%)\")\n",
    "zero_percentages.style.background_gradient(cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Factory_Plant\\\",\\n        \\\"Cement_Type\\\",\\n        \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Factory_Plant\\\",\\n        \\\"Cement_Type\\\",\\n        \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop(\n",
    "    [\n",
    "        \"Factory_Plant\",\n",
    "        \"Cement_Type\",\n",
    "        \"CS1\",\n",
    "        \"CS3\",\n",
    "        \"CS7\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 22:38:36.726672: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  10.555807455380757\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.889 (0.000)\n",
      "MAE: 1.435 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.916 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.617 (0.000)\n",
      "MAE: 1.968 (0.000)\n",
      "MAPE: 0.047 (0.000)\n",
      "R2: 0.806 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  9.887052190303802\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.823 (0.000)\n",
      "MAE: 1.381 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.922 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.474 (0.000)\n",
      "MAE: 1.839 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.827 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  12.665816056728364\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.650 (0.000)\n",
      "MAE: 1.272 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.936 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.281 (0.000)\n",
      "MAE: 1.679 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.853 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.475658412774404\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.512 (0.000)\n",
      "MAE: 1.150 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.946 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.351 (0.000)\n",
      "MAE: 1.680 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.843 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  17.644309822718302\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.604 (0.000)\n",
      "MAE: 1.214 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.939 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.415 (0.000)\n",
      "MAE: 1.724 (0.000)\n",
      "MAPE: 0.041 (0.000)\n",
      "R2: 0.835 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  23.712998147805532\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.625 (0.000)\n",
      "MAE: 1.234 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.938 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.348 (0.000)\n",
      "MAE: 1.681 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.844 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  22.411077328523\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.543 (0.000)\n",
      "MAE: 1.165 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.944 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.296 (0.000)\n",
      "MAE: 1.648 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.851 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  11.89581607580185\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.565 (0.000)\n",
      "MAE: 1.186 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.942 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.416 (0.000)\n",
      "MAE: 1.706 (0.000)\n",
      "MAPE: 0.041 (0.000)\n",
      "R2: 0.835 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  16.62299898862839\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.425 (0.000)\n",
      "MAE: 1.109 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.952 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.621 (0.000)\n",
      "MAE: 1.865 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.805 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  17.149900754292805\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.549 (0.000)\n",
      "MAE: 1.168 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.943 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.381 (0.000)\n",
      "MAE: 1.682 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.839 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  19.173669811089834\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.601 (0.000)\n",
      "MAE: 1.210 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.940 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.274 (0.000)\n",
      "MAE: 1.651 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.854 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  12.066602432727814\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.755 (0.000)\n",
      "MAE: 1.326 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.927 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.282 (0.000)\n",
      "MAE: 1.686 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.852 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  12.023448967933655\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.982 (0.000)\n",
      "MAE: 1.482 (0.000)\n",
      "MAPE: 0.034 (0.000)\n",
      "R2: 0.907 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.369 (0.000)\n",
      "MAE: 1.717 (0.000)\n",
      "MAPE: 0.041 (0.000)\n",
      "R2: 0.841 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/203/m/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/203/m/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/203/m/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>203</td>\n",
       "      <td>M</td>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>(58776, 10)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_11</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>1.600529</td>\n",
       "      <td>1.21049</td>\n",
       "      <td>0.027658</td>\n",
       "      <td>0.939638</td>\n",
       "      <td>2.273791</td>\n",
       "      <td>1.650719</td>\n",
       "      <td>0.039234</td>\n",
       "      <td>0.853531</td>\n",
       "      <td>-3.908729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category Company Plant                       Features   Data Shape  \\\n",
       "10  Global Model     203     M  Chemical + Properties CS Less  (58776, 10)   \n",
       "\n",
       "   Timesteps   Model Model Params           Scaler Scaler Params  ...  \\\n",
       "10      None  MLP_11         None  Standard Scaler          None  ...   \n",
       "\n",
       "                  Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "10  {\"train_size\": 0.8, \"test_size\": 0.2}   1.600529   1.21049   0.027658   \n",
       "\n",
       "    R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "10  0.939638   2.273791  1.650719   0.039234  0.853531 -3.908729  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  36.40073442061742\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.600 (0.000)\n",
      "MAE: 1.203 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.938 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.600 (0.000)\n",
      "MAE: 1.203 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.938 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/203/mlp/m/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_properties_csless_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/203/mlp/m/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_properties_csless_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/203/mlp/m/pre_training/\"\n",
    "model_name = \"mlp_chemical_properties_csless_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x72c10e2047c0>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x72c28811a860>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x72c15542caf0>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x72c10dbc1f60>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 256)               2816      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 16)                64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48577 (189.75 KB)\n",
      "Trainable params: 47585 (185.88 KB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
