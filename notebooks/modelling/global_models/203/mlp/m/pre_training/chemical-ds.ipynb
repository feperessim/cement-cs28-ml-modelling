{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 22:38:15.826323: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-27 22:38:15.832072: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-27 22:38:15.936340: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-27 22:38:15.939961: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-27 22:38:17.945016: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/203/mlp/av/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/203/mlp/av/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/203/mlp/av/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 2\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 2\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 2\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"203\\\",\\n    \\\"Plant\\\": \\\"M\\\",\\n    \\\"Features\\\": \\\"Chemical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"203\\\",\\n    \\\"Plant\\\": \\\"M\\\",\\n    \\\"Features\\\": \\\"Chemical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"203\",\n",
    "    \"Plant\": \"M\",\n",
    "    \"Features\": \"Chemical\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/203/global_m.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/203/global_m.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/203/global_m.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Cement_Type\\\",\\n        \\\"Factory_Plant\\\",\\n        \\\"Blaine\\\",\\n        \\\"#200\\\",\\n        \\\"#325\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Cement_Type\\\",\\n        \\\"Factory_Plant\\\",\\n        \\\"Blaine\\\",\\n        \\\"#200\\\",\\n        \\\"#325\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop(\n",
    "    [\n",
    "        \"Cement_Type\",\n",
    "        \"Factory_Plant\",\n",
    "        \"Blaine\",\n",
    "        \"#200\",\n",
    "        \"#325\",\n",
    "        \"Final setting time\",\n",
    "        \"Initial setting time\",\n",
    "        \"CS1\",\n",
    "        \"CS3\",\n",
    "        \"CS7\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 22:38:23.432686: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  10.666668395201365\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.737 (0.000)\n",
      "MAE: 2.007 (0.000)\n",
      "MAPE: 0.047 (0.000)\n",
      "R2: 0.824 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.374 (0.000)\n",
      "MAE: 2.506 (0.000)\n",
      "MAPE: 0.060 (0.000)\n",
      "R2: 0.677 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  9.623632657527924\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.608 (0.000)\n",
      "MAE: 1.900 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.840 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.202 (0.000)\n",
      "MAE: 2.358 (0.000)\n",
      "MAPE: 0.056 (0.000)\n",
      "R2: 0.710 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  12.147266232967377\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.325 (0.000)\n",
      "MAE: 1.681 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.873 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.111 (0.000)\n",
      "MAE: 2.206 (0.000)\n",
      "MAPE: 0.053 (0.000)\n",
      "R2: 0.726 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.609142482280731\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.177 (0.000)\n",
      "MAE: 1.564 (0.000)\n",
      "MAPE: 0.036 (0.000)\n",
      "R2: 0.888 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.112 (0.000)\n",
      "MAE: 2.164 (0.000)\n",
      "MAPE: 0.052 (0.000)\n",
      "R2: 0.726 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  17.35858411391576\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.294 (0.000)\n",
      "MAE: 1.634 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.876 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.077 (0.000)\n",
      "MAE: 2.168 (0.000)\n",
      "MAPE: 0.052 (0.000)\n",
      "R2: 0.732 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  24.003095956643424\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.370 (0.000)\n",
      "MAE: 1.692 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.868 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.002 (0.000)\n",
      "MAE: 2.129 (0.000)\n",
      "MAPE: 0.051 (0.000)\n",
      "R2: 0.745 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  20.69829232295354\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.227 (0.000)\n",
      "MAE: 1.597 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.883 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.116 (0.000)\n",
      "MAE: 2.193 (0.000)\n",
      "MAPE: 0.052 (0.000)\n",
      "R2: 0.725 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  12.090474840005239\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.239 (0.000)\n",
      "MAE: 1.601 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.882 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.075 (0.000)\n",
      "MAE: 2.177 (0.000)\n",
      "MAPE: 0.052 (0.000)\n",
      "R2: 0.732 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  16.27630825837453\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.084 (0.000)\n",
      "MAE: 1.530 (0.000)\n",
      "MAPE: 0.036 (0.000)\n",
      "R2: 0.898 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.207 (0.000)\n",
      "MAE: 2.265 (0.000)\n",
      "MAPE: 0.055 (0.000)\n",
      "R2: 0.709 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  16.715019977092744\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.209 (0.000)\n",
      "MAE: 1.589 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.885 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.070 (0.000)\n",
      "MAE: 2.127 (0.000)\n",
      "MAPE: 0.051 (0.000)\n",
      "R2: 0.733 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  20.130836232503256\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.345 (0.000)\n",
      "MAE: 1.672 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.870 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.009 (0.000)\n",
      "MAE: 2.141 (0.000)\n",
      "MAPE: 0.051 (0.000)\n",
      "R2: 0.744 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  12.635901204744975\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.476 (0.000)\n",
      "MAE: 1.782 (0.000)\n",
      "MAPE: 0.041 (0.000)\n",
      "R2: 0.856 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.059 (0.000)\n",
      "MAE: 2.209 (0.000)\n",
      "MAPE: 0.053 (0.000)\n",
      "R2: 0.735 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  11.600291498502095\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.734 (0.000)\n",
      "MAE: 1.974 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.824 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.275 (0.000)\n",
      "MAE: 2.364 (0.000)\n",
      "MAPE: 0.057 (0.000)\n",
      "R2: 0.696 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/203/m/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/203/m/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/203/m/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>203</td>\n",
       "      <td>M</td>\n",
       "      <td>Chemical</td>\n",
       "      <td>(58776, 5)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_6</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>2.370335</td>\n",
       "      <td>1.692201</td>\n",
       "      <td>0.039413</td>\n",
       "      <td>0.867609</td>\n",
       "      <td>3.002285</td>\n",
       "      <td>2.129317</td>\n",
       "      <td>0.050989</td>\n",
       "      <td>0.744642</td>\n",
       "      <td>-4.257691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category Company Plant  Features  Data Shape Timesteps  Model  \\\n",
       "5  Global Model     203     M  Chemical  (58776, 5)      None  MLP_6   \n",
       "\n",
       "  Model Params           Scaler Scaler Params  ...  \\\n",
       "5         None  Standard Scaler          None  ...   \n",
       "\n",
       "                 Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "5  {\"train_size\": 0.8, \"test_size\": 0.2}   2.370335  1.692201   0.039413   \n",
       "\n",
       "   R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "5  0.867609   3.002285  2.129317   0.050989  0.744642 -4.257691  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  35.48595084746679\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.375 (0.000)\n",
      "MAE: 1.694 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.863 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.375 (0.000)\n",
      "MAE: 1.694 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.863 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/203/mlp/m/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/203/mlp/m/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/203/mlp/m/pre_training/\"\n",
    "model_name = \"mlp_chemical_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x75e2e3203c40>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x75e2e32eb6d0>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x75e2e1186380>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x75e2e1018ee0>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 256)               1536      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 16)                64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47297 (184.75 KB)\n",
      "Trainable params: 46305 (180.88 KB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
