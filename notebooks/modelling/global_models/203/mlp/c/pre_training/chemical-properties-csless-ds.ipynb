{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 12:01:02.103533: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-28 12:01:02.106217: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-28 12:01:02.164434: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-28 12:01:02.166346: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-28 12:01:03.292775: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/206/mlp/b/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 10\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 10\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 10\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"203\\\",\\n    \\\"Plant\\\": \\\"C\\\",\\n    \\\"Features\\\": \\\"Chemical + Properties CS Less\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"203\\\",\\n    \\\"Plant\\\": \\\"C\\\",\\n    \\\"Features\\\": \\\"Chemical + Properties CS Less\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"203\",\n",
    "    \"Plant\": \"C\",\n",
    "    \"Features\": \"Chemical + Properties CS Less\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/203/global_c.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/203/global_c.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/203/global_c.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9253f_row0_col0 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9253f_row1_col0, #T_9253f_row2_col0, #T_9253f_row3_col0, #T_9253f_row4_col0, #T_9253f_row5_col0, #T_9253f_row6_col0, #T_9253f_row7_col0, #T_9253f_row8_col0, #T_9253f_row9_col0, #T_9253f_row10_col0, #T_9253f_row11_col0, #T_9253f_row12_col0, #T_9253f_row13_col0, #T_9253f_row14_col0, #T_9253f_row15_col0, #T_9253f_row16_col0, #T_9253f_row17_col0 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9253f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9253f_level0_col0\" class=\"col_heading level0 col0\" >Zero (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9253f_level0_row0\" class=\"row_heading level0 row0\" >#200</th>\n",
       "      <td id=\"T_9253f_row0_col0\" class=\"data row0 col0\" >13.854418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9253f_level0_row1\" class=\"row_heading level0 row1\" >CaO</th>\n",
       "      <td id=\"T_9253f_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9253f_level0_row2\" class=\"row_heading level0 row2\" >MgO</th>\n",
       "      <td id=\"T_9253f_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9253f_level0_row3\" class=\"row_heading level0 row3\" >CS7</th>\n",
       "      <td id=\"T_9253f_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9253f_level0_row4\" class=\"row_heading level0 row4\" >CS3</th>\n",
       "      <td id=\"T_9253f_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9253f_level0_row5\" class=\"row_heading level0 row5\" >Final setting time</th>\n",
       "      <td id=\"T_9253f_row5_col0\" class=\"data row5 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9253f_level0_row6\" class=\"row_heading level0 row6\" >Initial setting time</th>\n",
       "      <td id=\"T_9253f_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9253f_level0_row7\" class=\"row_heading level0 row7\" >#325</th>\n",
       "      <td id=\"T_9253f_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9253f_level0_row8\" class=\"row_heading level0 row8\" >Blaine</th>\n",
       "      <td id=\"T_9253f_row8_col0\" class=\"data row8 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9253f_level0_row9\" class=\"row_heading level0 row9\" >Insoluble Residue</th>\n",
       "      <td id=\"T_9253f_row9_col0\" class=\"data row9 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9253f_level0_row10\" class=\"row_heading level0 row10\" >Loss on Ignition</th>\n",
       "      <td id=\"T_9253f_row10_col0\" class=\"data row10 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9253f_level0_row11\" class=\"row_heading level0 row11\" >Fe2O3</th>\n",
       "      <td id=\"T_9253f_row11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9253f_level0_row12\" class=\"row_heading level0 row12\" >K2O</th>\n",
       "      <td id=\"T_9253f_row12_col0\" class=\"data row12 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9253f_level0_row13\" class=\"row_heading level0 row13\" >SO3</th>\n",
       "      <td id=\"T_9253f_row13_col0\" class=\"data row13 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9253f_level0_row14\" class=\"row_heading level0 row14\" >SiO2</th>\n",
       "      <td id=\"T_9253f_row14_col0\" class=\"data row14 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9253f_level0_row15\" class=\"row_heading level0 row15\" >Al2O3</th>\n",
       "      <td id=\"T_9253f_row15_col0\" class=\"data row15 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9253f_level0_row16\" class=\"row_heading level0 row16\" >Na2O</th>\n",
       "      <td id=\"T_9253f_row16_col0\" class=\"data row16 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9253f_level0_row17\" class=\"row_heading level0 row17\" >CS28</th>\n",
       "      <td id=\"T_9253f_row17_col0\" class=\"data row17 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x77784c5a1f00>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_formatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_values = {}\n",
    "for col in df.select_dtypes(include=\"number\").columns:\n",
    "    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\n",
    "    zero_values[col] = zero_percentages\n",
    "\n",
    "zero_percentages = pd.Series(zero_values, name=f\"Zero (%)\")\n",
    "zero_percentages = zero_percentages.sort_values(ascending=False)\n",
    "zero_percentages = zero_percentages.to_frame(name=f\"Zero (%)\")\n",
    "zero_percentages.style.background_gradient(cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Factory_Plant\\\",\\n        \\\"Cement_Type\\\",\\n        # \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Factory_Plant\\\",\\n        \\\"Cement_Type\\\",\\n        # \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop(\n",
    "    [\n",
    "        \"Factory_Plant\",\n",
    "        \"Cement_Type\",\n",
    "        # \"CS1\",\n",
    "        \"CS3\",\n",
    "        \"CS7\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 12:01:09.416274: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  10.914081903298696\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.775 (0.000)\n",
      "MAE: 1.340 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.932 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.307 (0.000)\n",
      "MAE: 1.700 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.852 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  11.145259908835094\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.780 (0.000)\n",
      "MAE: 1.343 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.932 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.242 (0.000)\n",
      "MAE: 1.645 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.860 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.569132991631825\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.697 (0.000)\n",
      "MAE: 1.315 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.938 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.270 (0.000)\n",
      "MAE: 1.663 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.857 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  20.419529243310294\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.564 (0.000)\n",
      "MAE: 1.182 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.948 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.285 (0.000)\n",
      "MAE: 1.594 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.855 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  21.526001652081806\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.592 (0.000)\n",
      "MAE: 1.212 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.946 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.267 (0.000)\n",
      "MAE: 1.640 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.857 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  31.11098458766937\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.640 (0.000)\n",
      "MAE: 1.239 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.942 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.184 (0.000)\n",
      "MAE: 1.587 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.868 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  27.60256004333496\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.575 (0.000)\n",
      "MAE: 1.191 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.947 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.179 (0.000)\n",
      "MAE: 1.578 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.868 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  19.558137579758963\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.582 (0.000)\n",
      "MAE: 1.202 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.946 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.329 (0.000)\n",
      "MAE: 1.662 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.849 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  28.656411381562553\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.628 (0.000)\n",
      "MAE: 1.255 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.943 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.413 (0.000)\n",
      "MAE: 1.779 (0.000)\n",
      "MAPE: 0.043 (0.000)\n",
      "R2: 0.838 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  26.537901337941488\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.478 (0.000)\n",
      "MAE: 1.123 (0.000)\n",
      "MAPE: 0.025 (0.000)\n",
      "R2: 0.953 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.267 (0.000)\n",
      "MAE: 1.638 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.857 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.031547574202218\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.631 (0.000)\n",
      "MAE: 1.241 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.943 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.260 (0.000)\n",
      "MAE: 1.621 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.858 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.84024892648061\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.765 (0.000)\n",
      "MAE: 1.340 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.933 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.224 (0.000)\n",
      "MAE: 1.644 (0.000)\n",
      "MAPE: 0.039 (0.000)\n",
      "R2: 0.863 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.699751989046733\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.098 (0.000)\n",
      "MAE: 1.583 (0.000)\n",
      "MAPE: 0.035 (0.000)\n",
      "R2: 0.906 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.382 (0.000)\n",
      "MAE: 1.690 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.843 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"path = (\\n    f\\\"../../../../../../../reports/results/global_models/203/c/pre_training/full/\\\"\\n)\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/203/c/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/203/c/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>203</td>\n",
       "      <td>C</td>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>(64225, 15)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_7</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>1.575163</td>\n",
       "      <td>1.190551</td>\n",
       "      <td>0.026782</td>\n",
       "      <td>0.94682</td>\n",
       "      <td>2.178677</td>\n",
       "      <td>1.578247</td>\n",
       "      <td>0.037357</td>\n",
       "      <td>0.868214</td>\n",
       "      <td>-5.679654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category Company Plant                       Features   Data Shape  \\\n",
       "6  Global Model     203     C  Chemical + Properties CS Less  (64225, 15)   \n",
       "\n",
       "  Timesteps  Model Model Params           Scaler Scaler Params  ...  \\\n",
       "6      None  MLP_7         None  Standard Scaler          None  ...   \n",
       "\n",
       "                 Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "6  {\"train_size\": 0.8, \"test_size\": 0.2}   1.575163  1.190551   0.026782   \n",
       "\n",
       "   R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "6   0.94682   2.178677  1.578247   0.037357  0.868214 -5.679654  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  34.34187292257945\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.565 (0.000)\n",
      "MAE: 1.179 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.945 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.565 (0.000)\n",
      "MAE: 1.179 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.945 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/203/mlp/c/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_properties_csless_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/203/mlp/c/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_properties_csless_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/203/mlp/c/pre_training/\"\n",
    "model_name = \"mlp_chemical_properties_csless_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7776d96adbd0>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyDUlEQVR4nO3df3wV1YH///dMflwQSMIPk5AaaLSsiiBa0HirdW3Jg4CsCyvdima7VPnC1iasSFeFXcAftY2iaxFKYe3uCj4Wf9T9LFh5KGsKAg81RohmRURESw0t3GCNyeWH+Xnn+0dyJ7khSGa84STk9Xw8bnPvzJmZM4eb5u2ZM3Msx3EcAQAA9CK26QoAAAB4RYABAAC9DgEGAAD0OgQYAADQ6xBgAABAr0OAAQAAvQ4BBgAA9DoEGAAA0Oskmq5Ad4lEIjp06JAGDRoky7JMVwcAAHSB4zg6evSosrKyZNun7mc5awPMoUOHlJ2dbboaAADAh4MHD+q888475XrPAWbHjh165JFHVF5ersOHD2vDhg2aPn26JKmxsVGLFy/WSy+9pN///vdKTU1VXl6eHnroIWVlZbn7qK6u1rx58/Tiiy/Ktm3NmDFDjz/+uAYOHOiWeffdd1VYWKidO3fq3HPP1bx583T33Xd3uZ6DBg2S1NIAKSkpXk8TAAAYEA6HlZ2d7f4dPxXPAeb48eMaN26cbrvtNt14440x606cOKG3335bS5Ys0bhx4/T555/rjjvu0F//9V9r165dbrmCggIdPnxYJSUlamxs1K233qq5c+fq6aefdis/adIk5eXlac2aNdq9e7duu+02paWlae7cuV2qZ/SyUUpKCgEGAIBe5nTDP6yvMpmjZVkxPTCd2blzp6688kp98sknGjFihPbu3avRo0dr586dmjBhgiRp8+bNuv766/XHP/5RWVlZWr16tf7lX/5FoVBIycnJkqSFCxdq48aN+uCDD7pUt3A4rNTUVNXW1hJgAADoJbr697vb70Kqra2VZVlKS0uTJJWWliotLc0NL5KUl5cn27ZVVlbmlrn22mvd8CJJ+fn52rdvnz7//PNOj1NfX69wOBzzAgAAZ6duDTB1dXW65557dPPNN7spKhQKKT09PaZcYmKihgwZolAo5JbJyMiIKRP9HC3TUXFxsVJTU90XA3gBADh7dVuAaWxs1Pe//305jqPVq1d312FcixYtUm1trfs6ePBgtx8TAACY0S23UUfDyyeffKKtW7fGXMPKzMzUkSNHYso3NTWpurpamZmZbpmqqqqYMtHP0TIdBQIBBQKBeJ4GAADooeLeAxMNL/v379fvfvc7DR06NGZ9MBhUTU2NysvL3WVbt25VJBJRbm6uW2bHjh1qbGx0y5SUlOjCCy/U4MGD411lAADQy3gOMMeOHVNFRYUqKiokSQcOHFBFRYUqKyvV2Nio733ve9q1a5fWr1+v5uZmhUIhhUIhNTQ0SJIuvvhiTZ48WXPmzNFbb72l119/XUVFRZo5c6b7rJhbbrlFycnJmj17tvbs2aPnnntOjz/+uBYsWBC/MwcAAL2W59uot23bpu985zsnLZ81a5buu+8+5eTkdLrdq6++quuuu05Sy4PsioqKYh5kt2LFilM+yG7YsGGaN2+e7rnnni7Xk9uoAQDofbr69/srPQemJyPAAADQ+/SY58AAAADEGwEGAAD0OgQYAADQ63TLc2DOZv+v/I/a/adaTR6TqavOH3r6DQAAQNzRA+PRtg8/1do3/qD3DzHXEgAAphBgPLJbZ/c+K2/dAgCglyDAeNSaX3SW3n0OAECvQIDxyLJaIgz5BQAAcwgwHrk9MFxEAgDAGAKMV9ExMOQXAACMIcB4ZEcvIRmuBwAAfRkBxqPoJaQIXTAAABhDgPHI4hISAADGEWA8stw+GAAAYAoBxqO2Hhi6YAAAMIUA4xHPgQEAwDwCjEfRHpgIAQYAAGMIMB7xIDsAAMwjwHjEXUgAAJhHgPEoehcS+QUAAHMIMB7ZbdNRG60HAAB9GQHGo+hdSAziBQDAHAKMTwziBQDAHAKMRwziBQDAPAKMRwziBQDAPAKMRzY9MAAAGEeA8Yi5kAAAMI8A45E7F5LhegAA0JcRYDxqewwMEQYAAFMIMF4xBgYAAOMIMB7ZXEICAMA4AoxH0UtIEbpgAAAwhgDjEQ+yAwDAPAKMR5bbBwMAAEwhwHjEc2AAADCPAOMRz4EBAMA8AoxHDOIFAMA8AoxHDOIFAMA8AoxHzEYNAIB5BBiP6IEBAMA8AoxHtnsXNQkGAABTCDAeRe9CikQMVwQAgD6MAOOTQw8MAADGEGA8YgwMAADmEWA84i4kAADMI8B4ZNMDAwCAcQQYj5gLCQAA8zwHmB07duiGG25QVlaWLMvSxo0bY9Y7jqOlS5dq+PDh6t+/v/Ly8rR///6YMtXV1SooKFBKSorS0tI0e/ZsHTt2LKbMu+++q29/+9vq16+fsrOztWzZMu9n1w24hAQAgHmeA8zx48c1btw4rVq1qtP1y5Yt04oVK7RmzRqVlZVpwIABys/PV11dnVumoKBAe/bsUUlJiTZt2qQdO3Zo7ty57vpwOKxJkyZp5MiRKi8v1yOPPKL77rtPTzzxhI9TjC96YAAAMC/R6wZTpkzRlClTOl3nOI6WL1+uxYsXa9q0aZKkp556ShkZGdq4caNmzpypvXv3avPmzdq5c6cmTJggSVq5cqWuv/56Pfroo8rKytL69evV0NCg//zP/1RycrIuueQSVVRU6LHHHosJOiYRXwAAMCeuY2AOHDigUCikvLw8d1lqaqpyc3NVWloqSSotLVVaWpobXiQpLy9Ptm2rrKzMLXPttdcqOTnZLZOfn699+/bp888/7/TY9fX1CofDMa/uEH2QHR0wAACYE9cAEwqFJEkZGRkxyzMyMtx1oVBI6enpMesTExM1ZMiQmDKd7aP9MToqLi5Wamqq+8rOzv7qJ9SJ6F1IERIMAADGnDV3IS1atEi1tbXu6+DBg91ynOhUSMQXAADMiWuAyczMlCRVVVXFLK+qqnLXZWZm6siRIzHrm5qaVF1dHVOms320P0ZHgUBAKSkpMa/uYLmjeLtl9wAAoAviGmBycnKUmZmpLVu2uMvC4bDKysoUDAYlScFgUDU1NSovL3fLbN26VZFIRLm5uW6ZHTt2qLGx0S1TUlKiCy+8UIMHD45nlT1ryy8kGAAATPEcYI4dO6aKigpVVFRIahm4W1FRocrKSlmWpfnz5+vBBx/Ub3/7W+3evVt///d/r6ysLE2fPl2SdPHFF2vy5MmaM2eO3nrrLb3++usqKirSzJkzlZWVJUm65ZZblJycrNmzZ2vPnj167rnn9Pjjj2vBggVxO3G/3EtI5BcAAIzxfBv1rl279J3vfMf9HA0Vs2bN0tq1a3X33Xfr+PHjmjt3rmpqanTNNddo8+bN6tevn7vN+vXrVVRUpIkTJ8q2bc2YMUMrVqxw16empuqVV15RYWGhxo8fr2HDhmnp0qU94hbq6CUkBvECAGCO5ZylT2QLh8NKTU1VbW1tXMfDrC/7RP+y4T1NGp2hJ/5+wuk3AAAAXdbVv99nzV1IZwpTCQAAYB4BxiOL2agBADCOAOOR5b4jwQAAYAoBxiPbHcRruCIAAPRhBBivmI0aAADjCDAeMZUAAADmEWA8YjZqAADMI8B4RA8MAADmEWA8sltbjDEwAACYQ4DxyH2QHfkFAABjCDAeMRs1AADmEWB8ogcGAABzCDAecRcSAADmEWA8slsvIUVIMAAAGEOA8YjZqAEAMI8A45HFg2AAADCOAONRW34hwQAAYAoBxiP3NmryCwAAxhBgPHLvQjJcDwAA+jICjEfRS0jchQQAgDkEGI94DgwAAOYRYDziJiQAAMwjwHjUdhs1EQYAAFMIMB7ZDOIFAMA4AoxXTCUAAIBxBBiPuIIEAIB5BBiPuAsJAADzCDAecRcSAADmEWA8cgfx0gUDAIAxBBiPmAsJAADzCDAeMRs1AADmEWC8ogcGAADjCDAeWeJBdgAAmEaA8ch2e2CIMAAAmEKA8YjnwAAAYB4BxiP3LiSz1QAAoE8jwHjUNpUAEQYAAFMIMB7RAwMAgHkEGI8YAwMAgHkEGI+il5AiJBgAAIwhwHhEDwwAAOYRYDyyTl8EAAB0MwKMRxYPsgMAwDgCjEe2xVQCAACYRoDxiUG8AACYQ4DxyGI2agAAjCPAeMRs1AAAmBf3ANPc3KwlS5YoJydH/fv31wUXXKCf/vSnMYNeHcfR0qVLNXz4cPXv3195eXnav39/zH6qq6tVUFCglJQUpaWlafbs2Tp27Fi8q+sZPTAAAJgX9wDz8MMPa/Xq1frlL3+pvXv36uGHH9ayZcu0cuVKt8yyZcu0YsUKrVmzRmVlZRowYIDy8/NVV1fnlikoKNCePXtUUlKiTZs2aceOHZo7d268q+tZdBAvfTAAAJiTGO8dvvHGG5o2bZqmTp0qSfr617+uZ555Rm+99Zaklt6X5cuXa/HixZo2bZok6amnnlJGRoY2btyomTNnau/evdq8ebN27typCRMmSJJWrlyp66+/Xo8++qiysrLiXe0ui+aXCPkFAABj4t4D861vfUtbtmzRhx9+KEn6v//7P7322muaMmWKJOnAgQMKhULKy8tzt0lNTVVubq5KS0slSaWlpUpLS3PDiyTl5eXJtm2VlZV1etz6+nqFw+GYV3dgNmoAAMyLew/MwoULFQ6HddFFFykhIUHNzc362c9+poKCAklSKBSSJGVkZMRsl5GR4a4LhUJKT0+PrWhiooYMGeKW6ai4uFj3339/vE/nJMxGDQCAeXHvgfnNb36j9evX6+mnn9bbb7+tdevW6dFHH9W6devifagYixYtUm1trfs6ePBgNx2JuZAAADAt7j0wd911lxYuXKiZM2dKksaOHatPPvlExcXFmjVrljIzMyVJVVVVGj58uLtdVVWVLrvsMklSZmamjhw5ErPfpqYmVVdXu9t3FAgEFAgE4n06J7GZSgAAAOPi3gNz4sQJ2XbsbhMSEhSJRCRJOTk5yszM1JYtW9z14XBYZWVlCgaDkqRgMKiamhqVl5e7ZbZu3apIJKLc3Nx4V9kTZqMGAMC8uPfA3HDDDfrZz36mESNG6JJLLtE777yjxx57TLfddpuklgAwf/58Pfjggxo1apRycnK0ZMkSZWVlafr06ZKkiy++WJMnT9acOXO0Zs0aNTY2qqioSDNnzjR6B5LUbhCv0VoAANC3xT3ArFy5UkuWLNGPf/xjHTlyRFlZWfqHf/gHLV261C1z99136/jx45o7d65qamp0zTXXaPPmzerXr59bZv369SoqKtLEiRNl27ZmzJihFStWxLu6njEbNQAA5lnOWfqXOBwOKzU1VbW1tUpJSYnbfis/O6FrH3lV5yQn6P0HJsdtvwAAoOt/v5kLySOmEgAAwDwCjEdtT+IlwQAAYAoBxiP3LiTD9QAAoC8jwHgUvQuJBAMAgDkEGI/aphIgwQAAYAoBxiObB9kBAGAcAcaj6CUkBvECAGAOAcYrZqMGAMA4AoxHFrNRAwBgHAHGI8s6fRkAANC9CDAe2e0SzFk6CwMAAD0eAcaj9h0wEfILAABGEGA8an8JiR4YAADMIMB4ZLXrgyG+AABgBgHGq5geGHPVAACgLyPAeGS3DzD0wQAAYAQBxiMr5i4kgxUBAKAPI8B41P4uJAIMAABmEGA8sriEBACAcQQYj2LuQiK/AABgBAHGo9geGAAAYAIBxqP2ASZCFwwAAEYQYDziEhIAAOYRYDyKmY2aAAMAgBEEGI9i8wsJBgAAEwgwHtk8yA4AAOMIMB4xiBcAAPMIMB7FTCVgsB4AAPRlBJivgA4YAADMIMD4EO2EYRAvAABmEGB8sNsSDAAAMIAA40N0FEyEAAMAgBEEGB+4hAQAgFkEGB+i0wkwiBcAADMIMH4wBAYAAKMIMD7Y0QBDFwwAAEYQYHzgEhIAAGYRYHxwB/ESYAAAMIIA40P0NmruQgIAwAwCjA/R+ZDogQEAwAwCjA88iBcAALMIMD60PYmXCAMAgAkEGB+4hAQAgFkEGB+il5C4iAQAgBkEGB/cu5DILwAAGEGA8cGOXkIyXA8AAPoqAowP0UtIDOIFAMAMAowvDOIFAMCkbgkwf/rTn/R3f/d3Gjp0qPr376+xY8dq165d7nrHcbR06VINHz5c/fv3V15envbv3x+zj+rqahUUFCglJUVpaWmaPXu2jh071h3V9YypBAAAMCvuAebzzz/X1VdfraSkJL388st6//339a//+q8aPHiwW2bZsmVasWKF1qxZo7KyMg0YMED5+fmqq6tzyxQUFGjPnj0qKSnRpk2btGPHDs2dOzfe1fWFqQQAADArMd47fPjhh5Wdna0nn3zSXZaTk+O+dxxHy5cv1+LFizVt2jRJ0lNPPaWMjAxt3LhRM2fO1N69e7V582bt3LlTEyZMkCStXLlS119/vR599FFlZWWddNz6+nrV19e7n8PhcLxPzWXzHBgAAIyKew/Mb3/7W02YMEF/+7d/q/T0dF1++eX69a9/7a4/cOCAQqGQ8vLy3GWpqanKzc1VaWmpJKm0tFRpaWlueJGkvLw82batsrKyTo9bXFys1NRU95WdnR3vU3NxCQkAALPiHmB+//vfa/Xq1Ro1apT+93//V7fffrv+8R//UevWrZMkhUIhSVJGRkbMdhkZGe66UCik9PT0mPWJiYkaMmSIW6ajRYsWqba21n0dPHgw3qfm4hISAABmxf0SUiQS0YQJE/Tzn/9cknT55Zfrvffe05o1azRr1qx4H84VCAQUCAS6bf/tMZUAAABmxb0HZvjw4Ro9enTMsosvvliVlZWSpMzMTElSVVVVTJmqqip3XWZmpo4cORKzvqmpSdXV1W6ZnoD8AgCAGXEPMFdffbX27dsXs+zDDz/UyJEjJbUM6M3MzNSWLVvc9eFwWGVlZQoGg5KkYDCompoalZeXu2W2bt2qSCSi3NzceFfZM7u11Ry6YAAAMCLul5DuvPNOfetb39LPf/5zff/739dbb72lJ554Qk888YSklssv8+fP14MPPqhRo0YpJydHS5YsUVZWlqZPny6ppcdm8uTJmjNnjtasWaPGxkYVFRVp5syZnd6BdKZZraNgIuQXAACMiHuAueKKK7RhwwYtWrRIDzzwgHJycrR8+XIVFBS4Ze6++24dP35cc+fOVU1Nja655hpt3rxZ/fr1c8usX79eRUVFmjhxomzb1owZM7RixYp4V9cXZqMGAMAsyzlLr4OEw2GlpqaqtrZWKSkpcd33dY+8qj98dkL//aOgJnx9SFz3DQBAX9bVv9/MheSDxWzUAAAYRYDxgQfZAQBgFgHGh+gQmAgJBgAAIwgwPvAgOwAAzCLA+MBUAgAAmEWA8cFqSzAAAMAAAowP0QfZkV8AADCDAONDtAeGQbwAAJhBgPGBQbwAAJhFgPGBITAAAJhFgPGh7UF2RBgAAEwgwPjgBhiz1QAAoM8iwPhgu2NgiDAAAJhAgPHBHQNDfgEAwAgCjB/chQQAgFEEGB+4CwkAALMIMD5wFxIAAGYRYHyIDuKNkF8AADCCAOOD5b4jwQAAYAIBxoe2S0hm6wEAQF9FgPGB2agBADCLAOMHPTAAABhFgPHBbg0wERIMAABGEGB84BISAABmEWB84DkwAACYRYDxwbJOXwYAAHQfAowP7iUkOmAAADCCAOODxSBeAACMIsD4YDEbNQAARhFgfGA2agAAzCLA+MBdSAAAmEWA8YEeGAAAzCLA+GC7Y2CIMAAAmECA8YHZqAEAMIsA4wtTCQAAYBIBxgd6YAAAMIsA40PbIF4SDAAAJhBgfIgO4o2QXwAAMIIA44M7mSPXkAAAMIIA44M7BsZsNQAA6LMIMD4wGzUAAGYRYPxgKgEAAIwiwPjAIF4AAMwiwPjAXEgAAJhFgPGB2agBADCLAOODdfoiAACgGxFgfLAs7kICAMCkbg8wDz30kCzL0vz5891ldXV1Kiws1NChQzVw4EDNmDFDVVVVMdtVVlZq6tSpOuecc5Senq677rpLTU1N3V3dLoleQoqQYAAAMKJbA8zOnTv1b//2b7r00ktjlt9555168cUX9fzzz2v79u06dOiQbrzxRnd9c3Ozpk6dqoaGBr3xxhtat26d1q5dq6VLl3ZndbvMYjZqAACM6rYAc+zYMRUUFOjXv/61Bg8e7C6vra3Vf/zHf+ixxx7Td7/7XY0fP15PPvmk3njjDb355puSpFdeeUXvv/++/uu//kuXXXaZpkyZop/+9KdatWqVGhoaOj1efX29wuFwzKu7MBs1AABmdVuAKSws1NSpU5WXlxezvLy8XI2NjTHLL7roIo0YMUKlpaWSpNLSUo0dO1YZGRlumfz8fIXDYe3Zs6fT4xUXFys1NdV9ZWdnd8NZtWA2agAAzOqWAPPss8/q7bffVnFx8UnrQqGQkpOTlZaWFrM8IyNDoVDILdM+vETXR9d1ZtGiRaqtrXVfBw8ejMOZdI4eGAAAzEqM9w4PHjyoO+64QyUlJerXr1+8d39KgUBAgUDgjBzLdu9CIsEAAGBC3HtgysvLdeTIEX3zm99UYmKiEhMTtX37dq1YsUKJiYnKyMhQQ0ODampqYrarqqpSZmamJCkzM/Oku5Kin6NlTKIHBgAAs+IeYCZOnKjdu3eroqLCfU2YMEEFBQXu+6SkJG3ZssXdZt++faqsrFQwGJQkBYNB7d69W0eOHHHLlJSUKCUlRaNHj453lX3gLiQAAEyK+yWkQYMGacyYMTHLBgwYoKFDh7rLZ8+erQULFmjIkCFKSUnRvHnzFAwGddVVV0mSJk2apNGjR+sHP/iBli1bplAopMWLF6uwsPCMXSb6MvTAAABgVtwDTFf84he/kG3bmjFjhurr65Wfn69f/epX7vqEhARt2rRJt99+u4LBoAYMGKBZs2bpgQceMFHdk3AXEgAAZp2RALNt27aYz/369dOqVau0atWqU24zcuRIvfTSS91cM3+ig3gj5BcAAIxgLiQfLLcLhgQDAIAJBBgf2i4hAQAAEwgwPjAbNQAAZhFgvgIG8QIAYAYBxgebHhgAAIwiwPgQHcTLXUgAAJhBgPGB58AAAGAWAcYHi9uQAAAwigDjg3sXkuF6AADQVxFgfGibC4kIAwCACQQYHywxlQAAACYRYHxgNmoAAMwiwPjAXUgAAJhFgPGBHhgAAMwiwPhgu/dRAwAAEwgwPkTjS4QuGAAAjCDA+MFcSAAAGEWA8YFBvAAAmEWA8YFBvAAAmEWA8cFmKgEAAIwiwPjgXkKiCwYAACMIMD5wCQkAALMIMD5Y3IUEAIBRBJivgLuQAAAwgwDjg00PDAAARhFgfIiOgYkQYAAAMIIA4wMPsgMAwCwCjA9WW4IBAAAGEGB8sMSD7AAAMIkA40Pbc2CIMAAAmECA8SH6HBgG8QIAYAYBxgeGwAAAYBYBxgcuIQEAYBYBxgd6YAAAMIsA44NtR7tgzNYDAIC+igDjQ7QHJsIlJAAAjCDA+MFcSAAAGEWA8YGpBAAAMIsA40PbXUhm6wEAQF9FgPHBtphKAAAAkwgwPriXkOiCAQDACAKMD1xCAgDALAKMD8xGDQCAWQQYP5hKAAAAowgwPjCIFwAAswgwPrQ9iddoNQAA6LMIMD4wGzUAAGbFPcAUFxfriiuu0KBBg5Senq7p06dr3759MWXq6upUWFiooUOHauDAgZoxY4aqqqpiylRWVmrq1Kk655xzlJ6errvuuktNTU3xrq4v0QADAADMiHuA2b59uwoLC/Xmm2+qpKREjY2NmjRpko4fP+6WufPOO/Xiiy/q+eef1/bt23Xo0CHdeOON7vrm5mZNnTpVDQ0NeuONN7Ru3TqtXbtWS5cujXd1fXHvQqIDBgAAIyynm6+DfPrpp0pPT9f27dt17bXXqra2Vueee66efvppfe9735MkffDBB7r44otVWlqqq666Si+//LL+6q/+SocOHVJGRoYkac2aNbrnnnv06aefKjk5+aTj1NfXq76+3v0cDoeVnZ2t2tpapaSkxPWcXqj4k+54tkJXf2Oo1v9/V8V13wAA9GXhcFipqamn/fvd7WNgamtrJUlDhgyRJJWXl6uxsVF5eXlumYsuukgjRoxQaWmpJKm0tFRjx451w4sk5efnKxwOa8+ePZ0ep7i4WKmpqe4rOzu7u05JVus1pEik2w4BAAC+RLcGmEgkovnz5+vqq6/WmDFjJEmhUEjJyclKS0uLKZuRkaFQKOSWaR9eouuj6zqzaNEi1dbWuq+DBw/G+WzaMBs1AABmJXbnzgsLC/Xee+/ptdde687DSJICgYACgUC3H0diKgEAAEzrth6YoqIibdq0Sa+++qrOO+88d3lmZqYaGhpUU1MTU76qqkqZmZlumY53JUU/R8uYxFQCAACYFfcA4ziOioqKtGHDBm3dulU5OTkx68ePH6+kpCRt2bLFXbZv3z5VVlYqGAxKkoLBoHbv3q0jR464ZUpKSpSSkqLRo0fHu8qe2W3XkAAAgAFxv4RUWFiop59+Wi+88IIGDRrkjllJTU1V//79lZqaqtmzZ2vBggUaMmSIUlJSNG/ePAWDQV11VcsdPZMmTdLo0aP1gx/8QMuWLVMoFNLixYtVWFh4xi4TfZnoJaQI15AAADAi7gFm9erVkqTrrrsuZvmTTz6pH/7wh5KkX/ziF7JtWzNmzFB9fb3y8/P1q1/9yi2bkJCgTZs26fbbb1cwGNSAAQM0a9YsPfDAA/Gurk9cQgIAwKS4B5iuPFamX79+WrVqlVatWnXKMiNHjtRLL70Uz6rFDVMJAABgFnMh+cAQGAAAzCLA+GBbTCUAAIBJBBgfuIQEAIBZBBgf3ABjthoAAPRZBBgfmI0aAACzCDB+uD0wJBgAAEwgwPjAIF4AAMwiwPgQvY06QoABAMAIAowP3IUEAIBZBBgfLLcPBgAAmECA8aGtB8ZsPQAA6KsIMD5Y3IUEAIBRBBgfopeQGMQLAIAZBBgfGMQLAIBZBBgfmI0aAACzCDA+WEyGBACAUQQYH2zyCwAARhFgfIh2wEQYAwMAgBEEGF+YCwkAAJMIMD7wHBgAAMwiwPjg3oVEfgEAwAgCjA/Ru5AIMAAAmEGA8cHmQXYAABhFgPEhOpUA8QUAADMIMD4wGzUAAGYRYL4C7kICAMAMAowP9MAAAGAWAcYHuzXBRAgwAAAYQYDxIdoDwzBeAADMIMD4YDGVAAAARhFgfLCYjRoAAKMIMD60TSVAhAEAwAQCjA8Wg3gBADCKAOODxVQCAAAYRYDxwb2EZLQWAAD0XQQYHwJJCZKkusZmNTVHDNcGAIC+hwDjw/CUfuqflKDGZkeV1SdMVwcAgD6HAOODbVv6RvpASdKHVccM1wYAgL6HAOPTqIyWALO/6qjhmgAA0PcQYHz6i4xBkqQPj9ADAwDAmUaA8WlUOj0wAACYQoDxKdoD8/tPj3MnEgAAZxgBxqevpfVX/6QENTRH9Al3IgEAcEYRYHyybcsdyPvUG3/Q6x/9WXsPh1UVrlNDEz0yAAB0p0TTFejNxn4tVe/+sVbrSj/RutJPYtYNCiQqpX+SBgYSNahfy2tgvyT3fXKCrYjjaEAgUYP6JWlQIFGBRFvJra9AYoL7OZBoK5DU8jnQui4pwXLnZAIAoK8hwHwFd0++SF8fOkBv/v4zVVaf0OcnGlR9vEERRzpa36Sj9U3ddmzbkgafk6zUc5LcsNNZ0Akk2UpOsBVIspVk20qwLSXalpITbfVLSlC/pJafgURbibatxARLSQm2Em1LiQkt++mfnKAByYnqlxTdvm0/tk2IAgCceZZzls5IGA6HlZqaqtraWqWkpJyx40Yijmq/aFT1iQYdq2vS0bomHa1rbAk00fd1TWpuncr6WH3LsmP1TWpoiqi+KaKG1ld9U0T1Tc2qb2xd3kMHC7eEHUtJrQEoMcFWUmsA6nx5bEhKSrDc8OQu62T7U20TfR+77OSySa11SLRb17fuO6H1uEkJLcEMAGBOV/9+9+gemFWrVumRRx5RKBTSuHHjtHLlSl155ZWmq/WlbNvS4AHJGjwgOe77jkQcNTS3hJm6xmZVH29Q+IvG1qDTEnbqGqPhp/mkENQUcdQccdQUiai+MaK61uXRn40RR03NETU1O2qMtPysb2rWiYZmfdHQrKZI51m3KeKoKeKoTj0zYHlhWVKSbcu2pYjTNuN4gm0pwWrpcYp5b7V+bn3Zllp/WjG9VB3L29F1lqUEO3ab9vuM2cYta7f8tGL3Ha2/bVmyWt9bstxlsftrt8xqK9P2XrKinyXZdofPluWWadv25M9262VO27Jk27F1i06L2lLP1m071Nty69GyzLZaNmvbT9s6y9bJy6y2/dnt98XlV6DX67EB5rnnntOCBQu0Zs0a5ebmavny5crPz9e+ffuUnp5uunpG2LalfnaC+iUlKLV/kjJS+p3R4zc1t4SgiNMSWJqbndbw0hJ2mloDUGNzy7LGZsfdprE5Wqbj+lOXjYaopuaO4Sr2OE3Nrdt0ttxd376ebfXtyHHU0tPVHLu8sfms7Kjs82zr9IEnJmBZnYewqM5y0UmhTG0Bqv3xTlrX+j+nCnexx223Tbt6uD/bhcW2fZ9im9PtU7F1t902OrleJ7WFZcXsz+pkmdq1RVs5K+acLLUr4ER/tLyJXlPoeG0hWl/3HDqcb/tzdj932L6z5R23i1nX8d+p3YKT/g1PeaxTf8esLznYl9fXT506/8f93vjzNOZrqZ2u62499hJSbm6urrjiCv3yl7+UJEUiEWVnZ2vevHlauHDhabc3dQkJvYfjREPXyWEpEnFk222/2s2tvVfNTsu6ZqflcyQi9330FXE6lHWXSU2RiPs+Zj8d9tG2rU46ZsfjRJyWejhy5DitPUdyJEct69yf0W1bzj26P6d1ffufjtpvJ8mJ/ey0Kx9xWv50xHx2Tv4c3S5aXq3bONHPrQs77s9R7PGi6wCYt+Lmy/XX47Lius9efQmpoaFB5eXlWrRokbvMtm3l5eWptLS0023q6+tVX1/vfg6Hw91eT/RultUyfiYpQeqvBNPVgUcdQ000KEkdApkkJybgtZVXu8DXPpg5HZe1O140QLXFsGh9Oqtj23E7fnb36W7brpxiw517PEcx4a91q5jtom3T/nNnvRSn28Zpt/HJZWPb81Tn324PJx2zY3CNbZeTl0UP0r5t2vdkSe16DDr0HjntKhiz/3aV7lj99ufjxCw/9YnGbnPq78eXH8vpdPnJxzp1udj6dlzX+XYnHeoUbdNxf9Gn0pvQIwPMn//8ZzU3NysjIyNmeUZGhj744INOtykuLtb9999/JqoHoAdwL+mc1EEOoC84ax5kt2jRItXW1rqvgwcPmq4SAADoJj2yB2bYsGFKSEhQVVVVzPKqqiplZmZ2uk0gEFAgEDgT1QMAAIb1yB6Y5ORkjR8/Xlu2bHGXRSIRbdmyRcFg0GDNAABAT9Aje2AkacGCBZo1a5YmTJigK6+8UsuXL9fx48d16623mq4aAAAwrMcGmJtuukmffvqpli5dqlAopMsuu0ybN28+aWAvAADoe3rsc2C+Kp4DAwBA79PVv989cgwMAADAlyHAAACAXocAAwAAeh0CDAAA6HUIMAAAoNchwAAAgF6HAAMAAHqdHvsgu68q+nibcDhsuCYAAKCron+3T/eYurM2wBw9elSSlJ2dbbgmAADAq6NHjyo1NfWU68/aJ/FGIhEdOnRIgwYNkmVZcdtvOBxWdna2Dh48yBN+u4D26jrayhvaq+toq66jrbzpjvZyHEdHjx5VVlaWbPvUI13O2h4Y27Z13nnnddv+U1JS+HJ7QHt1HW3lDe3VdbRV19FW3sS7vb6s5yWKQbwAAKDXIcAAAIBehwDjUSAQ0L333qtAIGC6Kr0C7dV1tJU3tFfX0VZdR1t5Y7K9ztpBvAAA4OxFDwwAAOh1CDAAAKDXIcAAAIBehwADAAB6HQIMAADodQgwHq1atUpf//rX1a9fP+Xm5uqtt94yXSXj7rvvPlmWFfO66KKL3PV1dXUqLCzU0KFDNXDgQM2YMUNVVVUGa3xm7dixQzfccIOysrJkWZY2btwYs95xHC1dulTDhw9X//79lZeXp/3798eUqa6uVkFBgVJSUpSWlqbZs2fr2LFjZ/AszozTtdUPf/jDk75rkydPjinTV9qquLhYV1xxhQYNGqT09HRNnz5d+/btiynTld+9yspKTZ06Veecc47S09N11113qamp6UyeSrfrSltdd911J323fvSjH8WU6QttJUmrV6/WpZde6j5dNxgM6uWXX3bX95TvFQHGg+eee04LFizQvffeq7ffflvjxo1Tfn6+jhw5Yrpqxl1yySU6fPiw+3rttdfcdXfeeadefPFFPf/889q+fbsOHTqkG2+80WBtz6zjx49r3LhxWrVqVafrly1bphUrVmjNmjUqKyvTgAEDlJ+fr7q6OrdMQUGB9uzZo5KSEm3atEk7duzQ3Llzz9QpnDGnaytJmjx5csx37ZlnnolZ31faavv27SosLNSbb76pkpISNTY2atKkSTp+/Lhb5nS/e83NzZo6daoaGhr0xhtvaN26dVq7dq2WLl1q4pS6TVfaSpLmzJkT891atmyZu66vtJUknXfeeXrooYdUXl6uXbt26bvf/a6mTZumPXv2SOpB3ysHXXbllVc6hYWF7ufm5mYnKyvLKS4uNlgr8+69915n3Lhxna6rqalxkpKSnOeff95dtnfvXkeSU1paeoZq2HNIcjZs2OB+jkQiTmZmpvPII4+4y2pqapxAIOA888wzjuM4zvvvv+9Icnbu3OmWefnllx3Lspw//elPZ6zuZ1rHtnIcx5k1a5Yzbdq0U27TV9vKcRznyJEjjiRn+/btjuN07XfvpZdecmzbdkKhkFtm9erVTkpKilNfX39mT+AM6thWjuM4f/mXf+nccccdp9ymr7ZV1ODBg51///d/71HfK3pguqihoUHl5eXKy8tzl9m2rby8PJWWlhqsWc+wf/9+ZWVl6fzzz1dBQYEqKyslSeXl5WpsbIxpt4suukgjRoyg3SQdOHBAoVAopn1SU1OVm5vrtk9paanS0tI0YcIEt0xeXp5s21ZZWdkZr7Np27ZtU3p6ui688ELdfvvt+uyzz9x1fbmtamtrJUlDhgyR1LXfvdLSUo0dO1YZGRlumfz8fIXDYfe/ts9GHdsqav369Ro2bJjGjBmjRYsW6cSJE+66vtpWzc3NevbZZ3X8+HEFg8Ee9b06a2ejjrc///nPam5ujvkHkaSMjAx98MEHhmrVM+Tm5mrt2rW68MILdfjwYd1///369re/rffee0+hUEjJyclKS0uL2SYjI0OhUMhMhXuQaBt09r2KrguFQkpPT49Zn5iYqCFDhvS5Npw8ebJuvPFG5eTk6OOPP9Y///M/a8qUKSotLVVCQkKfbatIJKL58+fr6quv1pgxYySpS797oVCo0+9edN3ZqLO2kqRbbrlFI0eOVFZWlt59913dc8892rdvn/7nf/5HUt9rq927dysYDKqurk4DBw7Uhg0bNHr0aFVUVPSY7xUBBl/ZlClT3PeXXnqpcnNzNXLkSP3mN79R//79DdYMZ5uZM2e678eOHatLL71UF1xwgbZt26aJEycarJlZhYWFeu+992LGnqFzp2qr9uOkxo4dq+HDh2vixIn6+OOPdcEFF5zpahp34YUXqqKiQrW1tfrv//5vzZo1S9u3bzddrRhcQuqiYcOGKSEh4aSR1lVVVcrMzDRUq54pLS1Nf/EXf6GPPvpImZmZamhoUE1NTUwZ2q1FtA2+7HuVmZl50kDxpqYmVVdX9/k2PP/88zVs2DB99NFHkvpmWxUVFWnTpk169dVXdd5557nLu/K7l5mZ2el3L7rubHOqtupMbm6uJMV8t/pSWyUnJ+sb3/iGxo8fr+LiYo0bN06PP/54j/peEWC6KDk5WePHj9eWLVvcZZFIRFu2bFEwGDRYs57n2LFj+vjjjzV8+HCNHz9eSUlJMe22b98+VVZW0m6ScnJylJmZGdM+4XBYZWVlbvsEg0HV1NSovLzcLbN161ZFIhH3/2T7qj/+8Y/67LPPNHz4cEl9q60cx1FRUZE2bNigrVu3KicnJ2Z9V373gsGgdu/eHRP6SkpKlJKSotGjR5+ZEzkDTtdWnamoqJCkmO9WX2irU4lEIqqvr+9Z36u4DQfuA5599lknEAg4a9eudd5//31n7ty5TlpaWsxI677oJz/5ibNt2zbnwIEDzuuvv+7k5eU5w4YNc44cOeI4juP86Ec/ckaMGOFs3brV2bVrlxMMBp1gMGi41mfO0aNHnXfeecd55513HEnOY4895rzzzjvOJ5984jiO4zz00ENOWlqa88ILLzjvvvuuM23aNCcnJ8f54osv3H1MnjzZufzyy52ysjLntddec0aNGuXcfPPNpk6p23xZWx09etT5p3/6J6e0tNQ5cOCA87vf/c755je/6YwaNcqpq6tz99FX2ur22293UlNTnW3btjmHDx92XydOnHDLnO53r6mpyRkzZowzadIkp6Kiwtm8ebNz7rnnOosWLTJxSt3mdG310UcfOQ888ICza9cu58CBA84LL7zgnH/++c61117r7qOvtJXjOM7ChQud7du3OwcOHHDeffddZ+HChY5lWc4rr7ziOE7P+V4RYDxauXKlM2LECCc5Odm58sornTfffNN0lYy76aabnOHDhzvJycnO1772Neemm25yPvroI3f9F1984fz4xz92Bg8e7JxzzjnO3/zN3ziHDx82WOMz69VXX3UknfSaNWuW4zgtt1IvWbLEycjIcAKBgDNx4kRn3759Mfv47LPPnJtvvtkZOHCgk5KS4tx6663O0aNHDZxN9/qytjpx4oQzadIk59xzz3WSkpKckSNHOnPmzDnpPyD6Slt11k6SnCeffNIt05XfvT/84Q/OlClTnP79+zvDhg1zfvKTnziNjY1n+Gy61+naqrKy0rn22mudIUOGOIFAwPnGN77h3HXXXU5tbW3MfvpCWzmO49x2223OyJEjneTkZOfcc891Jk6c6IYXx+k53yvLcRwnfv05AAAA3Y8xMAAAoNchwAAAgF6HAAMAAHodAgwAAOh1CDAAAKDXIcAAAIBehwADAAB6HQIMAADodQgwAACg1yHAAACAXocAAwAAep3/Hy82zLu0WgDbAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7777835c09a0>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7776d98007c0>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x77784d9a6530>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 256)               4096      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 16)                64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49857 (194.75 KB)\n",
      "Trainable params: 48865 (190.88 KB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
