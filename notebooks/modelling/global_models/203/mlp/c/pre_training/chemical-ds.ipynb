{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 12:00:45.950156: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-28 12:00:45.952514: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-28 12:00:46.004243: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-28 12:00:46.005318: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-28 12:00:46.904887: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/206/mlp/b/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 2\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 2\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 2\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"203\\\",\\n    \\\"Plant\\\": \\\"C\\\",\\n    \\\"Features\\\": \\\"Chemical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"203\\\",\\n    \\\"Plant\\\": \\\"C\\\",\\n    \\\"Features\\\": \\\"Chemical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"203\",\n",
    "    \"Plant\": \"C\",\n",
    "    \"Features\": \"Chemical\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/203/global_c.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/203/global_c.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/203/global_c.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"df_copy = df.drop(\\n    [\\n        \\\"Cement_Type\\\",\\n        \\\"Factory_Plant\\\",\\n        \\\"Blaine\\\",\\n        \\\"#200\\\",\\n        \\\"#325\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        # \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.drop(\\n    [\\n        \\\"Cement_Type\\\",\\n        \\\"Factory_Plant\\\",\\n        \\\"Blaine\\\",\\n        \\\"#200\\\",\\n        \\\"#325\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        # \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.drop(\n",
    "    [\n",
    "        \"Cement_Type\",\n",
    "        \"Factory_Plant\",\n",
    "        \"Blaine\",\n",
    "        \"#200\",\n",
    "        \"#325\",\n",
    "        \"Final setting time\",\n",
    "        \"Initial setting time\",\n",
    "        # \"CS1\",\n",
    "        \"CS3\",\n",
    "        \"CS7\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 12:00:51.141963: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  10.391272286574045\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.224 (0.000)\n",
      "MAE: 1.636 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.894 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.945 (0.000)\n",
      "MAE: 2.104 (0.000)\n",
      "MAPE: 0.050 (0.000)\n",
      "R2: 0.759 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  10.909545628229777\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.228 (0.000)\n",
      "MAE: 1.637 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.894 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.747 (0.000)\n",
      "MAE: 1.998 (0.000)\n",
      "MAPE: 0.047 (0.000)\n",
      "R2: 0.790 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.008872763315837\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.081 (0.000)\n",
      "MAE: 1.558 (0.000)\n",
      "MAPE: 0.036 (0.000)\n",
      "R2: 0.907 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.816 (0.000)\n",
      "MAE: 2.030 (0.000)\n",
      "MAPE: 0.049 (0.000)\n",
      "R2: 0.780 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  20.2491202155749\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.921 (0.000)\n",
      "MAE: 1.406 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.921 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.858 (0.000)\n",
      "MAE: 2.005 (0.000)\n",
      "MAPE: 0.048 (0.000)\n",
      "R2: 0.773 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  22.127643664677937\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.002 (0.000)\n",
      "MAE: 1.465 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.914 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.792 (0.000)\n",
      "MAE: 2.003 (0.000)\n",
      "MAPE: 0.048 (0.000)\n",
      "R2: 0.783 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  31.781531051794687\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.030 (0.000)\n",
      "MAE: 1.482 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.912 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.572 (0.000)\n",
      "MAE: 1.844 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.816 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  28.682516980171204\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.950 (0.000)\n",
      "MAE: 1.439 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.919 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.647 (0.000)\n",
      "MAE: 1.897 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.806 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  18.593239879608156\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.956 (0.000)\n",
      "MAE: 1.432 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.918 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.754 (0.000)\n",
      "MAE: 1.924 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.789 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.408451382319132\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.852 (0.000)\n",
      "MAE: 1.380 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.926 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.869 (0.000)\n",
      "MAE: 2.031 (0.000)\n",
      "MAPE: 0.049 (0.000)\n",
      "R2: 0.771 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  27.73634030818939\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.864 (0.000)\n",
      "MAE: 1.363 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.926 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.722 (0.000)\n",
      "MAE: 1.941 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.794 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  27.826534314950308\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.001 (0.000)\n",
      "MAE: 1.468 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.914 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.616 (0.000)\n",
      "MAE: 1.896 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.810 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  16.93253090381622\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.164 (0.000)\n",
      "MAE: 1.583 (0.000)\n",
      "MAPE: 0.036 (0.000)\n",
      "R2: 0.900 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.657 (0.000)\n",
      "MAE: 1.917 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.804 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  16.21142667531967\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.514 (0.000)\n",
      "MAE: 1.833 (0.000)\n",
      "MAPE: 0.041 (0.000)\n",
      "R2: 0.865 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.744 (0.000)\n",
      "MAE: 1.968 (0.000)\n",
      "MAPE: 0.047 (0.000)\n",
      "R2: 0.791 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"path = (\\n    f\\\"../../../../../../../reports/results/global_models/203/c/pre_training/full/\\\"\\n)\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/203/c/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/203/c/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>203</td>\n",
       "      <td>C</td>\n",
       "      <td>Chemical</td>\n",
       "      <td>(64225, 10)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_6</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>2.029546</td>\n",
       "      <td>1.481871</td>\n",
       "      <td>0.03344</td>\n",
       "      <td>0.911713</td>\n",
       "      <td>2.572088</td>\n",
       "      <td>1.844021</td>\n",
       "      <td>0.043676</td>\n",
       "      <td>0.816323</td>\n",
       "      <td>-7.016482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category Company Plant  Features   Data Shape Timesteps  Model  \\\n",
       "5  Global Model     203     C  Chemical  (64225, 10)      None  MLP_6   \n",
       "\n",
       "  Model Params           Scaler Scaler Params  ...  \\\n",
       "5         None  Standard Scaler          None  ...   \n",
       "\n",
       "                 Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "5  {\"train_size\": 0.8, \"test_size\": 0.2}   2.029546  1.481871    0.03344   \n",
       "\n",
       "   R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "5  0.911713   2.572088  1.844021   0.043676  0.816323 -7.016482  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R²\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  35.48254475990931\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.996 (0.000)\n",
      "MAE: 1.455 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.911 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.996 (0.000)\n",
      "MAE: 1.455 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.911 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/203/mlp/c/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/203/mlp/c/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/203/mlp/c/pre_training/\"\n",
    "model_name = \"mlp_chemical_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ab1e36b9e40>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ab1e349db70>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ab1e33348b0>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ab1e339d0c0>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
