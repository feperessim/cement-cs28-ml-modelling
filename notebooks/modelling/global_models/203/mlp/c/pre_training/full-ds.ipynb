{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 12:01:21.626402: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-28 12:01:21.629584: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-28 12:01:21.717524: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-28 12:01:21.719548: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-28 12:01:23.052449: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/206/mlp/b/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/206/mlp/b/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 1\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 1\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 1\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"203\\\",\\n    \\\"Plant\\\": \\\"C\\\",\\n    \\\"Features\\\": \\\"Chemical + Physical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"203\\\",\\n    \\\"Plant\\\": \\\"C\\\",\\n    \\\"Features\\\": \\\"Chemical + Physical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"203\",\n",
    "    \"Plant\": \"C\",\n",
    "    \"Features\": \"Chemical + Physical\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/203/global_c.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/203/global_c.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/203/global_c.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d4f6c_row0_col0 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4f6c_row1_col0, #T_d4f6c_row2_col0, #T_d4f6c_row3_col0, #T_d4f6c_row4_col0, #T_d4f6c_row5_col0, #T_d4f6c_row6_col0, #T_d4f6c_row7_col0, #T_d4f6c_row8_col0, #T_d4f6c_row9_col0, #T_d4f6c_row10_col0, #T_d4f6c_row11_col0, #T_d4f6c_row12_col0, #T_d4f6c_row13_col0, #T_d4f6c_row14_col0, #T_d4f6c_row15_col0, #T_d4f6c_row16_col0, #T_d4f6c_row17_col0 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d4f6c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d4f6c_level0_col0\" class=\"col_heading level0 col0\" >Zero (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d4f6c_level0_row0\" class=\"row_heading level0 row0\" >#200</th>\n",
       "      <td id=\"T_d4f6c_row0_col0\" class=\"data row0 col0\" >13.854418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4f6c_level0_row1\" class=\"row_heading level0 row1\" >CaO</th>\n",
       "      <td id=\"T_d4f6c_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4f6c_level0_row2\" class=\"row_heading level0 row2\" >MgO</th>\n",
       "      <td id=\"T_d4f6c_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4f6c_level0_row3\" class=\"row_heading level0 row3\" >CS7</th>\n",
       "      <td id=\"T_d4f6c_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4f6c_level0_row4\" class=\"row_heading level0 row4\" >CS3</th>\n",
       "      <td id=\"T_d4f6c_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4f6c_level0_row5\" class=\"row_heading level0 row5\" >Final setting time</th>\n",
       "      <td id=\"T_d4f6c_row5_col0\" class=\"data row5 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4f6c_level0_row6\" class=\"row_heading level0 row6\" >Initial setting time</th>\n",
       "      <td id=\"T_d4f6c_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4f6c_level0_row7\" class=\"row_heading level0 row7\" >#325</th>\n",
       "      <td id=\"T_d4f6c_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4f6c_level0_row8\" class=\"row_heading level0 row8\" >Blaine</th>\n",
       "      <td id=\"T_d4f6c_row8_col0\" class=\"data row8 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4f6c_level0_row9\" class=\"row_heading level0 row9\" >Insoluble Residue</th>\n",
       "      <td id=\"T_d4f6c_row9_col0\" class=\"data row9 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4f6c_level0_row10\" class=\"row_heading level0 row10\" >Loss on Ignition</th>\n",
       "      <td id=\"T_d4f6c_row10_col0\" class=\"data row10 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4f6c_level0_row11\" class=\"row_heading level0 row11\" >Fe2O3</th>\n",
       "      <td id=\"T_d4f6c_row11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4f6c_level0_row12\" class=\"row_heading level0 row12\" >K2O</th>\n",
       "      <td id=\"T_d4f6c_row12_col0\" class=\"data row12 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4f6c_level0_row13\" class=\"row_heading level0 row13\" >SO3</th>\n",
       "      <td id=\"T_d4f6c_row13_col0\" class=\"data row13 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4f6c_level0_row14\" class=\"row_heading level0 row14\" >SiO2</th>\n",
       "      <td id=\"T_d4f6c_row14_col0\" class=\"data row14 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4f6c_level0_row15\" class=\"row_heading level0 row15\" >Al2O3</th>\n",
       "      <td id=\"T_d4f6c_row15_col0\" class=\"data row15 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4f6c_level0_row16\" class=\"row_heading level0 row16\" >Na2O</th>\n",
       "      <td id=\"T_d4f6c_row16_col0\" class=\"data row16 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4f6c_level0_row17\" class=\"row_heading level0 row17\" >CS28</th>\n",
       "      <td id=\"T_d4f6c_row17_col0\" class=\"data row17 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7df2ca793790>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_formatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_values = {}\n",
    "for col in df.select_dtypes(include=\"number\").columns:\n",
    "    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\n",
    "    zero_values[col] = zero_percentages\n",
    "\n",
    "zero_percentages = pd.Series(zero_values, name=f\"Zero (%)\")\n",
    "zero_percentages = zero_percentages.sort_values(ascending=False)\n",
    "zero_percentages = zero_percentages.to_frame(name=f\"Zero (%)\")\n",
    "zero_percentages.style.background_gradient(cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop([\\\"Cement_Type\\\", \\\"Factory_Plant\\\"], axis=1)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop([\\\"Cement_Type\\\", \\\"Factory_Plant\\\"], axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop([\"Cement_Type\", \"Factory_Plant\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 12:01:28.698460: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  10.87720872561137\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.301 (0.000)\n",
      "MAE: 0.991 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.964 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.536 (0.000)\n",
      "MAE: 1.162 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.934 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  10.974878533681233\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.338 (0.000)\n",
      "MAE: 1.018 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.962 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.557 (0.000)\n",
      "MAE: 1.175 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.933 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.748545861244201\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.372 (0.000)\n",
      "MAE: 1.071 (0.000)\n",
      "MAPE: 0.025 (0.000)\n",
      "R2: 0.960 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.677 (0.000)\n",
      "MAE: 1.287 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.922 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  20.840523421764374\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.431 (0.000)\n",
      "MAE: 1.120 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.956 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.746 (0.000)\n",
      "MAE: 1.344 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.915 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  21.567782628536225\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.266 (0.000)\n",
      "MAE: 0.973 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.966 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.619 (0.000)\n",
      "MAE: 1.220 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.927 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  31.904461014270783\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.286 (0.000)\n",
      "MAE: 0.971 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.965 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.513 (0.000)\n",
      "MAE: 1.119 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.936 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  27.74093032280604\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.241 (0.000)\n",
      "MAE: 0.947 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.967 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.549 (0.000)\n",
      "MAE: 1.157 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.933 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  19.752224338054656\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.232 (0.000)\n",
      "MAE: 0.938 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.967 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.549 (0.000)\n",
      "MAE: 1.139 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.933 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  28.502085057894387\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.759 (0.000)\n",
      "MAE: 1.392 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.934 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.967 (0.000)\n",
      "MAE: 1.521 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.893 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  26.3301029642423\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.261 (0.000)\n",
      "MAE: 0.953 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.966 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.548 (0.000)\n",
      "MAE: 1.141 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.933 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  24.80375502506892\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.305 (0.000)\n",
      "MAE: 0.997 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.963 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.541 (0.000)\n",
      "MAE: 1.144 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.934 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  16.253725854555764\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.346 (0.000)\n",
      "MAE: 1.014 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.961 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.529 (0.000)\n",
      "MAE: 1.140 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.935 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.30298671722412\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.541 (0.000)\n",
      "MAE: 1.190 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.949 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.651 (0.000)\n",
      "MAE: 1.265 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.924 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"path = (\\n    f\\\"../../../../../../../reports/results/global_models/203/c/pre_training/full/\\\"\\n)\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/203/c/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/203/c/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>203</td>\n",
       "      <td>C</td>\n",
       "      <td>Chemical + Physical</td>\n",
       "      <td>(64225, 17)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_6</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>1.286314</td>\n",
       "      <td>0.971342</td>\n",
       "      <td>0.021765</td>\n",
       "      <td>0.964536</td>\n",
       "      <td>1.513177</td>\n",
       "      <td>1.119076</td>\n",
       "      <td>0.026312</td>\n",
       "      <td>0.936429</td>\n",
       "      <td>-3.395397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category Company Plant             Features   Data Shape Timesteps  \\\n",
       "5  Global Model     203     C  Chemical + Physical  (64225, 17)      None   \n",
       "\n",
       "   Model Model Params           Scaler Scaler Params  ...  \\\n",
       "5  MLP_6         None  Standard Scaler          None  ...   \n",
       "\n",
       "                 Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "5  {\"train_size\": 0.8, \"test_size\": 0.2}   1.286314  0.971342   0.021765   \n",
       "\n",
       "   R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "5  0.964536   1.513177  1.119076   0.026312  0.936429 -3.395397  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  36.26489783922831\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.253 (0.000)\n",
      "MAE: 0.942 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.965 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.253 (0.000)\n",
      "MAE: 0.942 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.965 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/203/mlp/c/pre_training/\\\"\\nmodel_name = \\\"mlp_full_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/203/mlp/c/pre_training/\\\"\\nmodel_name = \\\"mlp_full_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/203/mlp/c/pre_training/\"\n",
    "model_name = \"mlp_full_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7df22b9fdea0>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7df186c41240>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7df186c236a0>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7df2a270fc40>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 256)               4608      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 16)                64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50369 (196.75 KB)\n",
      "Trainable params: 49377 (192.88 KB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
