{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 02:11:21.076568: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-01 02:11:21.080539: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-01 02:11:21.176477: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-01 02:11:21.178286: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-01 02:11:22.922700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/203/mlp/av/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/203/mlp/av/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/203/mlp/av/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 10\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 10\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 10\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"203\\\",\\n    \\\"Plant\\\": \\\"AV\\\",\\n    \\\"Features\\\": \\\"Chemical + Properties CS Less\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"203\\\",\\n    \\\"Plant\\\": \\\"AV\\\",\\n    \\\"Features\\\": \\\"Chemical + Properties CS Less\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"203\",\n",
    "    \"Plant\": \"AV\",\n",
    "    \"Features\": \"Chemical + Properties CS Less\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/203/global_av.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/203/global_av.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/203/global_av.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_87f8e_row0_col0 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_87f8e_row1_col0, #T_87f8e_row2_col0, #T_87f8e_row3_col0, #T_87f8e_row4_col0, #T_87f8e_row5_col0, #T_87f8e_row6_col0, #T_87f8e_row7_col0, #T_87f8e_row8_col0, #T_87f8e_row9_col0, #T_87f8e_row10_col0, #T_87f8e_row11_col0, #T_87f8e_row12_col0, #T_87f8e_row13_col0, #T_87f8e_row14_col0, #T_87f8e_row15_col0, #T_87f8e_row16_col0, #T_87f8e_row17_col0, #T_87f8e_row18_col0 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_87f8e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_87f8e_level0_col0\" class=\"col_heading level0 col0\" >Zero (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_87f8e_level0_row0\" class=\"row_heading level0 row0\" >#200</th>\n",
       "      <td id=\"T_87f8e_row0_col0\" class=\"data row0 col0\" >14.181221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87f8e_level0_row1\" class=\"row_heading level0 row1\" >CaO</th>\n",
       "      <td id=\"T_87f8e_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87f8e_level0_row2\" class=\"row_heading level0 row2\" >Blaine</th>\n",
       "      <td id=\"T_87f8e_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87f8e_level0_row3\" class=\"row_heading level0 row3\" >CS7</th>\n",
       "      <td id=\"T_87f8e_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87f8e_level0_row4\" class=\"row_heading level0 row4\" >CS3</th>\n",
       "      <td id=\"T_87f8e_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87f8e_level0_row5\" class=\"row_heading level0 row5\" >CS1</th>\n",
       "      <td id=\"T_87f8e_row5_col0\" class=\"data row5 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87f8e_level0_row6\" class=\"row_heading level0 row6\" >Final setting time</th>\n",
       "      <td id=\"T_87f8e_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87f8e_level0_row7\" class=\"row_heading level0 row7\" >Initial setting time</th>\n",
       "      <td id=\"T_87f8e_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87f8e_level0_row8\" class=\"row_heading level0 row8\" >#325</th>\n",
       "      <td id=\"T_87f8e_row8_col0\" class=\"data row8 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87f8e_level0_row9\" class=\"row_heading level0 row9\" >Insoluble Residue</th>\n",
       "      <td id=\"T_87f8e_row9_col0\" class=\"data row9 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87f8e_level0_row10\" class=\"row_heading level0 row10\" >MgO</th>\n",
       "      <td id=\"T_87f8e_row10_col0\" class=\"data row10 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87f8e_level0_row11\" class=\"row_heading level0 row11\" >Loss on Ignition</th>\n",
       "      <td id=\"T_87f8e_row11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87f8e_level0_row12\" class=\"row_heading level0 row12\" >Fe2O3</th>\n",
       "      <td id=\"T_87f8e_row12_col0\" class=\"data row12 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87f8e_level0_row13\" class=\"row_heading level0 row13\" >K2O</th>\n",
       "      <td id=\"T_87f8e_row13_col0\" class=\"data row13 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87f8e_level0_row14\" class=\"row_heading level0 row14\" >SO3</th>\n",
       "      <td id=\"T_87f8e_row14_col0\" class=\"data row14 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87f8e_level0_row15\" class=\"row_heading level0 row15\" >SiO2</th>\n",
       "      <td id=\"T_87f8e_row15_col0\" class=\"data row15 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87f8e_level0_row16\" class=\"row_heading level0 row16\" >Al2O3</th>\n",
       "      <td id=\"T_87f8e_row16_col0\" class=\"data row16 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87f8e_level0_row17\" class=\"row_heading level0 row17\" >Na2O</th>\n",
       "      <td id=\"T_87f8e_row17_col0\" class=\"data row17 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87f8e_level0_row18\" class=\"row_heading level0 row18\" >CS28</th>\n",
       "      <td id=\"T_87f8e_row18_col0\" class=\"data row18 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x773a89e136d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_formatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_values = {}\n",
    "for col in df.select_dtypes(include=\"number\").columns:\n",
    "    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\n",
    "    zero_values[col] = zero_percentages\n",
    "\n",
    "zero_percentages = pd.Series(zero_values, name=f\"Zero (%)\")\n",
    "zero_percentages = zero_percentages.sort_values(ascending=False)\n",
    "zero_percentages = zero_percentages.to_frame(name=f\"Zero (%)\")\n",
    "zero_percentages.style.background_gradient(cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Factory_Plant\\\",\\n        \\\"Cement_Type\\\",\\n        \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Factory_Plant\\\",\\n        \\\"Cement_Type\\\",\\n        \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop(\n",
    "    [\n",
    "        \"Factory_Plant\",\n",
    "        \"Cement_Type\",\n",
    "        \"CS1\",\n",
    "        \"CS3\",\n",
    "        \"CS7\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 02:11:29.008249: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  11.02017761071523\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.741 (0.000)\n",
      "MAE: 1.317 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.935 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.331 (0.000)\n",
      "MAE: 1.693 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.845 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  12.252132002512614\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.769 (0.000)\n",
      "MAE: 1.336 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.933 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.394 (0.000)\n",
      "MAE: 1.737 (0.000)\n",
      "MAPE: 0.041 (0.000)\n",
      "R2: 0.837 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.22342035373052\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.706 (0.000)\n",
      "MAE: 1.317 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.938 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.287 (0.000)\n",
      "MAE: 1.671 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.851 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  22.397840106487273\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.556 (0.000)\n",
      "MAE: 1.191 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.948 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.310 (0.000)\n",
      "MAE: 1.656 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.848 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  21.447870981693267\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.625 (0.000)\n",
      "MAE: 1.244 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.944 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.317 (0.000)\n",
      "MAE: 1.664 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.847 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  32.09703688621521\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.613 (0.000)\n",
      "MAE: 1.209 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.944 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.148 (0.000)\n",
      "MAE: 1.558 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.869 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  27.87658949693044\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.564 (0.000)\n",
      "MAE: 1.188 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.948 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.224 (0.000)\n",
      "MAE: 1.610 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.859 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.618540199597676\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.583 (0.000)\n",
      "MAE: 1.215 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.946 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.312 (0.000)\n",
      "MAE: 1.660 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.848 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  24.178879527250924\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.577 (0.000)\n",
      "MAE: 1.209 (0.000)\n",
      "MAPE: 0.028 (0.000)\n",
      "R2: 0.947 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.433 (0.000)\n",
      "MAE: 1.756 (0.000)\n",
      "MAPE: 0.043 (0.000)\n",
      "R2: 0.832 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  23.785559900601704\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.508 (0.000)\n",
      "MAE: 1.157 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.951 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.219 (0.000)\n",
      "MAE: 1.601 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.860 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  24.081892116864523\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.600 (0.000)\n",
      "MAE: 1.206 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.945 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.202 (0.000)\n",
      "MAE: 1.608 (0.000)\n",
      "MAPE: 0.038 (0.000)\n",
      "R2: 0.862 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.22253894408544\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.770 (0.000)\n",
      "MAE: 1.332 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.933 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.098 (0.000)\n",
      "MAE: 1.544 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.875 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.220946927865347\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.064 (0.000)\n",
      "MAE: 1.555 (0.000)\n",
      "MAPE: 0.035 (0.000)\n",
      "R2: 0.909 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.367 (0.000)\n",
      "MAE: 1.663 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.841 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/203/av/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/203/av/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/203/av/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>203</td>\n",
       "      <td>AV</td>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>(62752, 15)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_12</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>1.770027</td>\n",
       "      <td>1.331644</td>\n",
       "      <td>0.029981</td>\n",
       "      <td>0.933092</td>\n",
       "      <td>2.097774</td>\n",
       "      <td>1.544445</td>\n",
       "      <td>0.036729</td>\n",
       "      <td>0.87478</td>\n",
       "      <td>-7.226809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category Company Plant                       Features   Data Shape  \\\n",
       "11  Global Model     203    AV  Chemical + Properties CS Less  (62752, 15)   \n",
       "\n",
       "   Timesteps   Model Model Params           Scaler Scaler Params  ...  \\\n",
       "11      None  MLP_12         None  Standard Scaler          None  ...   \n",
       "\n",
       "                  Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "11  {\"train_size\": 0.8, \"test_size\": 0.2}   1.770027  1.331644   0.029981   \n",
       "\n",
       "    R2 Train  RMSE Test  MAE Test  MAPE Test  R2 Test      SCPM  \n",
       "11  0.933092   2.097774  1.544445   0.036729  0.87478 -7.226809  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  16.2257821281751\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.746 (0.000)\n",
      "MAE: 1.312 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.932 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.746 (0.000)\n",
      "MAE: 1.312 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.932 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/203/mlp/av/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_properties_csless_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/203/mlp/av/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_properties_csless_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/203/mlp/av/pre_training/\"\n",
    "model_name = \"mlp_chemical_properties_csless_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x773815b35000>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x77396077c8e0>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x77381a31c100>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x77397811bd00>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 256)               4096      \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45313 (177.00 KB)\n",
      "Trainable params: 45313 (177.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
