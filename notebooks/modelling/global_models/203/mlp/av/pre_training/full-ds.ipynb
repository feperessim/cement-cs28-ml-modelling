{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 02:11:44.018421: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-01 02:11:44.022401: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-01 02:11:44.121126: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-01 02:11:44.122435: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-01 02:11:45.733810: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/203/mlp/av/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/203/mlp/av/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/203/mlp/av/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 1\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 1\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 1\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"203\\\",\\n    \\\"Plant\\\": \\\"AV\\\",\\n    \\\"Features\\\": \\\"Chemical + Physical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"203\\\",\\n    \\\"Plant\\\": \\\"AV\\\",\\n    \\\"Features\\\": \\\"Chemical + Physical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"203\",\n",
    "    \"Plant\": \"AV\",\n",
    "    \"Features\": \"Chemical + Physical\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/203/global_av.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/203/global_av.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/203/global_av.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_05061_row0_col0 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_05061_row1_col0, #T_05061_row2_col0, #T_05061_row3_col0, #T_05061_row4_col0, #T_05061_row5_col0, #T_05061_row6_col0, #T_05061_row7_col0, #T_05061_row8_col0, #T_05061_row9_col0, #T_05061_row10_col0, #T_05061_row11_col0, #T_05061_row12_col0, #T_05061_row13_col0, #T_05061_row14_col0, #T_05061_row15_col0, #T_05061_row16_col0, #T_05061_row17_col0, #T_05061_row18_col0 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_05061\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_05061_level0_col0\" class=\"col_heading level0 col0\" >Zero (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_05061_level0_row0\" class=\"row_heading level0 row0\" >#200</th>\n",
       "      <td id=\"T_05061_row0_col0\" class=\"data row0 col0\" >14.181221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05061_level0_row1\" class=\"row_heading level0 row1\" >CaO</th>\n",
       "      <td id=\"T_05061_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05061_level0_row2\" class=\"row_heading level0 row2\" >Blaine</th>\n",
       "      <td id=\"T_05061_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05061_level0_row3\" class=\"row_heading level0 row3\" >CS7</th>\n",
       "      <td id=\"T_05061_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05061_level0_row4\" class=\"row_heading level0 row4\" >CS3</th>\n",
       "      <td id=\"T_05061_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05061_level0_row5\" class=\"row_heading level0 row5\" >CS1</th>\n",
       "      <td id=\"T_05061_row5_col0\" class=\"data row5 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05061_level0_row6\" class=\"row_heading level0 row6\" >Final setting time</th>\n",
       "      <td id=\"T_05061_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05061_level0_row7\" class=\"row_heading level0 row7\" >Initial setting time</th>\n",
       "      <td id=\"T_05061_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05061_level0_row8\" class=\"row_heading level0 row8\" >#325</th>\n",
       "      <td id=\"T_05061_row8_col0\" class=\"data row8 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05061_level0_row9\" class=\"row_heading level0 row9\" >Insoluble Residue</th>\n",
       "      <td id=\"T_05061_row9_col0\" class=\"data row9 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05061_level0_row10\" class=\"row_heading level0 row10\" >MgO</th>\n",
       "      <td id=\"T_05061_row10_col0\" class=\"data row10 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05061_level0_row11\" class=\"row_heading level0 row11\" >Loss on Ignition</th>\n",
       "      <td id=\"T_05061_row11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05061_level0_row12\" class=\"row_heading level0 row12\" >Fe2O3</th>\n",
       "      <td id=\"T_05061_row12_col0\" class=\"data row12 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05061_level0_row13\" class=\"row_heading level0 row13\" >K2O</th>\n",
       "      <td id=\"T_05061_row13_col0\" class=\"data row13 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05061_level0_row14\" class=\"row_heading level0 row14\" >SO3</th>\n",
       "      <td id=\"T_05061_row14_col0\" class=\"data row14 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05061_level0_row15\" class=\"row_heading level0 row15\" >SiO2</th>\n",
       "      <td id=\"T_05061_row15_col0\" class=\"data row15 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05061_level0_row16\" class=\"row_heading level0 row16\" >Al2O3</th>\n",
       "      <td id=\"T_05061_row16_col0\" class=\"data row16 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05061_level0_row17\" class=\"row_heading level0 row17\" >Na2O</th>\n",
       "      <td id=\"T_05061_row17_col0\" class=\"data row17 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05061_level0_row18\" class=\"row_heading level0 row18\" >CS28</th>\n",
       "      <td id=\"T_05061_row18_col0\" class=\"data row18 col0\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x70a0953049d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_formatted_code = \"zero_values = {}\\nfor col in df.select_dtypes(include=\\\"number\\\").columns:\\n    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\\n    zero_values[col] = zero_percentages\\n\\nzero_percentages = pd.Series(zero_values, name=f\\\"Zero (%)\\\")\\nzero_percentages = zero_percentages.sort_values(ascending=False)\\nzero_percentages = zero_percentages.to_frame(name=f\\\"Zero (%)\\\")\\nzero_percentages.style.background_gradient(cmap=\\\"Reds\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_values = {}\n",
    "for col in df.select_dtypes(include=\"number\").columns:\n",
    "    zero_percentages = (df[df[col].eq(0)].shape[0] / df.shape[0]) * 100\n",
    "    zero_values[col] = zero_percentages\n",
    "\n",
    "zero_percentages = pd.Series(zero_values, name=f\"Zero (%)\")\n",
    "zero_percentages = zero_percentages.sort_values(ascending=False)\n",
    "zero_percentages = zero_percentages.to_frame(name=f\"Zero (%)\")\n",
    "zero_percentages.style.background_gradient(cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop([\\\"Cement_Type\\\", \\\"Factory_Plant\\\"], axis=1)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop([\\\"Cement_Type\\\", \\\"Factory_Plant\\\"], axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop([\"Cement_Type\", \"Factory_Plant\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 02:11:52.112154: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  11.38948974609375\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.282 (0.000)\n",
      "MAE: 0.970 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.965 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.531 (0.000)\n",
      "MAE: 1.150 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.933 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  12.72915586233139\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.303 (0.000)\n",
      "MAE: 0.982 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.964 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.479 (0.000)\n",
      "MAE: 1.120 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.938 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.639243578910827\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.364 (0.000)\n",
      "MAE: 1.062 (0.000)\n",
      "MAPE: 0.025 (0.000)\n",
      "R2: 0.960 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.624 (0.000)\n",
      "MAE: 1.248 (0.000)\n",
      "MAPE: 0.030 (0.000)\n",
      "R2: 0.925 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  21.808513736724855\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.298 (0.000)\n",
      "MAE: 0.999 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.964 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.589 (0.000)\n",
      "MAE: 1.201 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.928 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  22.40289202531179\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.249 (0.000)\n",
      "MAE: 0.952 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.967 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.535 (0.000)\n",
      "MAE: 1.141 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.933 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  34.016523865858716\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.275 (0.000)\n",
      "MAE: 0.971 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.965 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.514 (0.000)\n",
      "MAE: 1.144 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.935 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  26.4969242254893\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.228 (0.000)\n",
      "MAE: 0.929 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.968 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.482 (0.000)\n",
      "MAE: 1.114 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.937 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.263536143302918\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.255 (0.000)\n",
      "MAE: 0.968 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.966 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.623 (0.000)\n",
      "MAE: 1.221 (0.000)\n",
      "MAPE: 0.029 (0.000)\n",
      "R2: 0.925 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  23.556932961940767\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.727 (0.000)\n",
      "MAE: 1.348 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.936 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.921 (0.000)\n",
      "MAE: 1.489 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.895 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.007851215203605\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.269 (0.000)\n",
      "MAE: 0.967 (0.000)\n",
      "MAPE: 0.022 (0.000)\n",
      "R2: 0.966 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.521 (0.000)\n",
      "MAE: 1.141 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.934 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  24.693535240491233\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.263 (0.000)\n",
      "MAE: 0.953 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.966 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.462 (0.000)\n",
      "MAE: 1.089 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.939 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.53776619831721\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.344 (0.000)\n",
      "MAE: 1.014 (0.000)\n",
      "MAPE: 0.023 (0.000)\n",
      "R2: 0.961 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.461 (0.000)\n",
      "MAE: 1.100 (0.000)\n",
      "MAPE: 0.026 (0.000)\n",
      "R2: 0.939 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.494953461488087\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.607 (0.000)\n",
      "MAE: 1.223 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.945 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.545 (0.000)\n",
      "MAE: 1.155 (0.000)\n",
      "MAPE: 0.027 (0.000)\n",
      "R2: 0.932 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/203/av/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/203/av/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/203/av/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>203</td>\n",
       "      <td>AV</td>\n",
       "      <td>Chemical + Physical</td>\n",
       "      <td>(62752, 18)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_11</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>1.262849</td>\n",
       "      <td>0.953115</td>\n",
       "      <td>0.021435</td>\n",
       "      <td>0.965942</td>\n",
       "      <td>1.46187</td>\n",
       "      <td>1.089246</td>\n",
       "      <td>0.025749</td>\n",
       "      <td>0.93919</td>\n",
       "      <td>-3.386603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category Company Plant             Features   Data Shape Timesteps  \\\n",
       "10  Global Model     203    AV  Chemical + Physical  (62752, 18)      None   \n",
       "\n",
       "     Model Model Params           Scaler Scaler Params  ...  \\\n",
       "10  MLP_11         None  Standard Scaler          None  ...   \n",
       "\n",
       "                  Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "10  {\"train_size\": 0.8, \"test_size\": 0.2}   1.262849  0.953115   0.021435   \n",
       "\n",
       "    R2 Train  RMSE Test  MAE Test  MAPE Test  R2 Test      SCPM  \n",
       "10  0.965942    1.46187  1.089246   0.025749  0.93919 -3.386603  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R²\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  26.921806824207305\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.228 (0.000)\n",
      "MAE: 0.931 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.966 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.228 (0.000)\n",
      "MAE: 0.931 (0.000)\n",
      "MAPE: 0.021 (0.000)\n",
      "R2: 0.966 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/203/mlp/av/pre_training/\\\"\\nmodel_name = \\\"mlp_full_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/203/mlp/av/pre_training/\\\"\\nmodel_name = \\\"mlp_full_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/203/mlp/av/pre_training/\"\n",
    "model_name = \"mlp_full_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x70a0939c9d80>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxu0lEQVR4nO3df3xU1YH///fchCT8moSAyZA1YLRWRZEqaJz6Y23Jg4CsCyttRbOWtnxhaxO3SFclu4I/aouiaxFKYW13BR+LP+p+ClYeypqCwEONEaJZEDFFSw0tTqJiMhDMz7nfP5K5yYQgudcJJyGv5+Mxj8zce+695x4n5s25597js23bFgAAQD9ima4AAACAWwQYAADQ7xBgAABAv0OAAQAA/Q4BBgAA9DsEGAAA0O8QYAAAQL9DgAEAAP1OoukK9JZIJKJDhw5p+PDh8vl8pqsDAAB6wLZtHTlyRFlZWbKsE/eznLYB5tChQ8rOzjZdDQAA4MHBgwd15plnnnD9aRtghg8fLqmtAfx+v+HaAACAngiHw8rOznb+jp/IaRtgopeN/H4/AQYAgH7mZMM/XA/i3bFjh66//nplZWXJ5/Np48aNzrrm5mbdddddGj9+vIYOHaqsrCx997vf1aFDh2L2cfjwYRUUFMjv9ystLU1z587V0aNHY8rs3r1bV199tVJSUpSdna1ly5a5rSoAADhNuQ4w9fX1mjBhglatWnXcumPHjumtt97S4sWL9dZbb+l3v/udKisr9fd///cx5QoKCrR3716VlJRo06ZN2rFjh+bPn++sD4fDmjJlisaOHavy8nI9/PDDuvfee/X44497OEUAAHC68dm2bXve2OfThg0bNHPmzBOW2blzpy6//HJ9+OGHGjNmjPbt26dx48Zp586dmjRpkiRp8+bNuu666/SXv/xFWVlZWr16tf7t3/5NoVBISUlJkqRFixZp48aNeu+993pUt3A4rNTUVNXV1XEJCQCAfqKnf797/TkwdXV18vl8SktLkySVlpYqLS3NCS+SlJeXJ8uyVFZW5pS55pprnPAiSfn5+aqsrNRnn33W7XEaGxsVDodjXgAA4PTUqwGmoaFBd911l2666SYnRYVCIWVkZMSUS0xMVHp6ukKhkFMmMzMzpkz0c7RMV0uXLlVqaqrz4hZqAABOX70WYJqbm/Wd73xHtm1r9erVvXUYR3Fxserq6pzXwYMHe/2YAADAjF65jToaXj788ENt3bo15hpWIBBQTU1NTPmWlhYdPnxYgUDAKVNdXR1TJvo5Wqar5ORkJScnx/M0AABAHxX3HphoeNm/f7/+8Ic/aOTIkTHrg8GgamtrVV5e7izbunWrIpGIcnNznTI7duxQc3OzU6akpETnnXeeRowYEe8qAwCAfsZ1gDl69KgqKipUUVEhSTpw4IAqKipUVVWl5uZmfetb39KuXbu0fv16tba2KhQKKRQKqampSZJ0wQUXaOrUqZo3b57efPNNvfbaayoqKtLs2bOVlZUlSbr55puVlJSkuXPnau/evXr22Wf12GOPaeHChfE7cwAA0G+5vo1627Zt+sY3vnHc8jlz5ujee+9VTk5Ot9u98soruvbaayW1PciuqKhIL7zwgizL0qxZs7RixQoNGzbMKb97924VFhZq586dGjVqlG677TbdddddPa4nt1EDAND/9PTv95d6DkxfRoABAKD/6TPPgQEAAIi303Yyx97y/8r/oj1/rdPUiwK64uyRJ98AAADEHT0wLm3748da+/qf9e4hnvQLAIApBBiXrPbZvU/LgUMAAPQTBBiX2vOLTtOxzwAA9AsEGJd8vrYIQ34BAMAcAoxLTg8MF5EAADCGAONWdAwM+QUAAGMIMC5Z0UtIhusBAMBARoBxKXoJKUIXDAAAxhBgXPJxCQkAAOMIMC75nD4YAABgCgHGpY4eGLpgAAAwhQDjEs+BAQDAPAKMS9EemAgBBgAAYwgwLvEgOwAAzCPAuMRdSAAAmEeAcSl6FxL5BQAAcwgwLlkd01EbrQcAAAMZAcal6F1IDOIFAMAcAoxHDOIFAMAcAoxLDOIFAMA8AoxLDOIFAMA8AoxLFj0wAAAYR4BxibmQAAAwjwDjkjMXkuF6AAAwkBFgXOp4DAwRBgAAUwgwbjEGBgAA4wgwLllcQgIAwDgCjEvRS0gRumAAADCGAOMSD7IDAMA8AoxLPqcPBgAAmEKAcYnnwAAAYB4BxiWeAwMAgHkEGJcYxAsAgHkEGJcYxAsAgHkEGJeYjRoAAPMIMC7RAwMAgHkEGJcs5y5qEgwAAKYQYFyK3oUUiRiuCAAAAxgBxiObHhgAAIwhwLjEGBgAAMwjwLjEXUgAAJhHgHHJogcGAADjCDAuMRcSAADmEWBc4hISAADmEWBcogcGAADzXAeYHTt26Prrr1dWVpZ8Pp82btwYs962bS1ZskSjR4/W4MGDlZeXp/3798eUOXz4sAoKCuT3+5WWlqa5c+fq6NGjMWV2796tq6++WikpKcrOztayZcvcn10vIr4AAGCO6wBTX1+vCRMmaNWqVd2uX7ZsmVasWKE1a9aorKxMQ4cOVX5+vhoaGpwyBQUF2rt3r0pKSrRp0ybt2LFD8+fPd9aHw2FNmTJFY8eOVXl5uR5++GHde++9evzxxz2cYnxZ7V0wdMAAAGBOotsNpk2bpmnTpnW7zrZtLV++XHfffbdmzJghSXryySeVmZmpjRs3avbs2dq3b582b96snTt3atKkSZKklStX6rrrrtMjjzyirKwsrV+/Xk1NTfqv//ovJSUl6cILL1RFRYUeffTRmKBjQvQSUoQEAwCAMXEdA3PgwAGFQiHl5eU5y1JTU5Wbm6vS0lJJUmlpqdLS0pzwIkl5eXmyLEtlZWVOmWuuuUZJSUlOmfz8fFVWVuqzzz7r9tiNjY0Kh8Mxr94QnQqJ+AIAgDlxDTChUEiSlJmZGbM8MzPTWRcKhZSRkRGzPjExUenp6TFluttH52N0tXTpUqWmpjqv7OzsL39C3fA5o3h7ZfcAAKAHTpu7kIqLi1VXV+e8Dh482CvH6cgvJBgAAEyJa4AJBAKSpOrq6pjl1dXVzrpAIKCampqY9S0tLTp8+HBMme720fkYXSUnJ8vv98e8egOzUQMAYF5cA0xOTo4CgYC2bNniLAuHwyorK1MwGJQkBYNB1dbWqry83CmzdetWRSIR5ebmOmV27Nih5uZmp0xJSYnOO+88jRgxIp5Vdq1jDAw9MAAAmOI6wBw9elQVFRWqqKiQ1DZwt6KiQlVVVfL5fFqwYIEeeOAB/f73v9eePXv03e9+V1lZWZo5c6Yk6YILLtDUqVM1b948vfnmm3rttddUVFSk2bNnKysrS5J08803KykpSXPnztXevXv17LPP6rHHHtPChQvjduJeMRs1AADmub6NeteuXfrGN77hfI6Gijlz5mjt2rW68847VV9fr/nz56u2tlZXXXWVNm/erJSUFGeb9evXq6ioSJMnT5ZlWZo1a5ZWrFjhrE9NTdXLL7+swsJCTZw4UaNGjdKSJUuM30ItMZUAAAB9gc8+TZ+JHw6HlZqaqrq6uriOh3n6zSoV/26P8i7I1G/mTDr5BgAAoMd6+vf7tLkL6VSxmAsJAADjCDAucQkJAADzCDBu0QMDAIBxBBiXmEoAAADzCDAu+ZiNGgAA4wgwLlnMRg0AgHEEGJeiD7IDAADmEGBccu5CogMGAABjCDAuMRs1AADmEWBcYhAvAADmEWBcig6BYRAvAADmEGBcYjZqAADMI8C4xFQCAACYR4BxycejeAEAMI4A45LFXUgAABhHgHGtLcFEyC8AABhDgHHJx2zUAAAYR4BxiSEwAACYR4BxiQfZAQBgHgHGpY5BvAAAwBQCjEuMgQEAwDwCjEvMRg0AgHkEGLd4DgwAAMYRYFxy7kIivwAAYAwBxiWLu5AAADCOAONSdBBvhAQDAIAxBBiXfM5FJAAAYAoBxqWO26jN1gMAgIGMAONSx1QCJBgAAEwhwLjEVAIAAJhHgHGJQbwAAJhHgHGJ2agBADCPAOOSz8dsjgAAmEaAcYn8AgCAeQQYlyxmowYAwDgCjGttCSZCfgEAwBgCjEs+ZqMGAMA4AoxLzEYNAIB5BBiXeJAdAADmEWBcspjLEQAA4wgwLvmcQbx0wQAAYAoBxiVmowYAwDwCjEfchQQAgDkEGJfogQEAwDwCjEtW9C4kw/UAAGAgI8C45GMqAQAAjIt7gGltbdXixYuVk5OjwYMH65xzztFPf/rTmD/4tm1ryZIlGj16tAYPHqy8vDzt378/Zj+HDx9WQUGB/H6/0tLSNHfuXB09ejTe1XUtehcS+QUAAHPiHmAeeughrV69Wr/85S+1b98+PfTQQ1q2bJlWrlzplFm2bJlWrFihNWvWqKysTEOHDlV+fr4aGhqcMgUFBdq7d69KSkq0adMm7dixQ/Pnz493dV1jNmoAAMxLjPcOX3/9dc2YMUPTp0+XJJ111ll6+umn9eabb0pq631Zvny57r77bs2YMUOS9OSTTyozM1MbN27U7NmztW/fPm3evFk7d+7UpEmTJEkrV67Uddddp0ceeURZWVnxrnaPdUwlQIQBAMCUuPfAfP3rX9eWLVv0xz/+UZL0f//3f3r11Vc1bdo0SdKBAwcUCoWUl5fnbJOamqrc3FyVlpZKkkpLS5WWluaEF0nKy8uTZVkqKyuLd5Vd8TGIFwAA4+LeA7No0SKFw2Gdf/75SkhIUGtrq372s5+poKBAkhQKhSRJmZmZMdtlZmY660KhkDIyMmIrmpio9PR0p0xXjY2NamxsdD6Hw+G4nVNn0UtIkQgRBgAAU+LeA/Pb3/5W69ev11NPPaW33npL69at0yOPPKJ169bF+1Axli5dqtTUVOeVnZ3dK8dxLiH1yt4BAEBPxD3A3HHHHVq0aJFmz56t8ePH65ZbbtHtt9+upUuXSpICgYAkqbq6Oma76upqZ10gEFBNTU3M+paWFh0+fNgp01VxcbHq6uqc18GDB+N9apI6LiGRYAAAMCfuAebYsWOyrNjdJiQkKBKJSJJycnIUCAS0ZcsWZ304HFZZWZmCwaAkKRgMqra2VuXl5U6ZrVu3KhKJKDc3t9vjJicny+/3x7x6Az0wAACYF/cxMNdff71+9rOfacyYMbrwwgv19ttv69FHH9UPfvADSW09GAsWLNADDzygc889Vzk5OVq8eLGysrI0c+ZMSdIFF1ygqVOnat68eVqzZo2am5tVVFSk2bNnG70DSer0JF7uQgIAwJi4B5iVK1dq8eLF+tGPfqSamhplZWXpn/7pn7RkyRKnzJ133qn6+nrNnz9ftbW1uuqqq7R582alpKQ4ZdavX6+ioiJNnjxZlmVp1qxZWrFiRbyr65oziJf8AgCAMT77NO1KCIfDSk1NVV1dXVwvJx08fExXL3tFKYMsvffTaXHbLwAA6Pnfb+ZCconZqAEAMI8A4xIPsgMAwDwCjEsWtyEBAGAcAcal6GzUEa4hAQBgDAHGJZ5jBwCAeQQYl5iNGgAA8wgwbtEDAwCAcQQYlzqexGu4IgAADGAEGJd8nd5zGQkAADMIMC45s1GLXhgAAEwhwLgU0wNjrBYAAAxsBBiXOnXAcAkJAABDCDAuxVxCMlgPAAAGMgKMS517YHgaLwAAZhBgXIq9C8lYNQAAGNAIMC51voQEAADMIMC4RA8MAADmEWBcsmIG8ZJgAAAwgQDjUuwgXnP1AABgICPAfAk8BwYAADMIMC7FPMjOXDUAABjQCDAu+cRcSAAAmEaAccliMiQAAIwjwLjU+TkwPIkXAAAzCDAu0QEDAIB5BBiXmI0aAADzCDAuMRs1AADmEWA8iGYYxsAAAGAGAcYDpw+G/AIAgBEEGA+il5HILwAAmEGA8SDaA8MVJAAAzCDAeBAdA8Ns1AAAmEGA8SB6CYnZqAEAMIMA40HHJSQSDAAAJhBgPHAuIZFfAAAwggDjgS9mQgEAAHCqEWA8oAcGAACzCDAeWM4gXhIMAAAmEGA8cAbxGq0FAAADFwHGC+cSEhEGAAATCDAe0AMDAIBZBBgPnLmQSDAAABhBgPHA4hISAABGEWA8YDZqAADMIsB4wGzUAACYRYDxgNmoAQAwiwDjCYN4AQAwqVcCzF//+lf94z/+o0aOHKnBgwdr/Pjx2rVrl7Petm0tWbJEo0eP1uDBg5WXl6f9+/fH7OPw4cMqKCiQ3+9XWlqa5s6dq6NHj/ZGdV2LDuLlSbwAAJgR9wDz2Wef6corr9SgQYP00ksv6d1339W///u/a8SIEU6ZZcuWacWKFVqzZo3Kyso0dOhQ5efnq6GhwSlTUFCgvXv3qqSkRJs2bdKOHTs0f/78eFfXE+ZCAgDArMR47/Chhx5Sdna2nnjiCWdZTk6O8962bS1fvlx33323ZsyYIUl68sknlZmZqY0bN2r27Nnat2+fNm/erJ07d2rSpEmSpJUrV+q6667TI488oqysrHhX2xVmowYAwKy498D8/ve/16RJk/Ttb39bGRkZuuSSS/TrX//aWX/gwAGFQiHl5eU5y1JTU5Wbm6vS0lJJUmlpqdLS0pzwIkl5eXmyLEtlZWXdHrexsVHhcDjm1VvogQEAwKy4B5g//elPWr16tc4991z97//+r2699Vb98z//s9atWydJCoVCkqTMzMyY7TIzM511oVBIGRkZMesTExOVnp7ulOlq6dKlSk1NdV7Z2dnxPjWH5TwHhgQDAIAJcQ8wkUhEl156qX7+85/rkksu0fz58zVv3jytWbMm3oeKUVxcrLq6Oud18ODBXj2eJEXILwAAGBH3ADN69GiNGzcuZtkFF1ygqqoqSVIgEJAkVVdXx5Sprq521gUCAdXU1MSsb2lp0eHDh50yXSUnJ8vv98e8eouPqQQAADAq7gHmyiuvVGVlZcyyP/7xjxo7dqyktgG9gUBAW7ZscdaHw2GVlZUpGAxKkoLBoGpra1VeXu6U2bp1qyKRiHJzc+NdZdc6HmQHAABMiPtdSLfffru+/vWv6+c//7m+853v6M0339Tjjz+uxx9/XFLbPEILFizQAw88oHPPPVc5OTlavHixsrKyNHPmTEltPTZTp051Lj01NzerqKhIs2fPNn4HktRxFxIdMAAAmBH3AHPZZZdpw4YNKi4u1v3336+cnBwtX75cBQUFTpk777xT9fX1mj9/vmpra3XVVVdp8+bNSklJccqsX79eRUVFmjx5sizL0qxZs7RixYp4V9cTy7mLmgQDAIAJPvs0HcgRDoeVmpqqurq6uI+H+cYj23Tgk3o998OgLjsrPa77BgBgIOvp32/mQvKA2agBADCLAOMFdyEBAGAUAcYDpwfGaC0AABi4CDAeOE/iJcEAAGAEAcYDHmQHAIBZBBgPnOfAGK4HAAADFQHGA2ajBgDALALMl8Bs1AAAmEGA8YBBvAAAmEWA8SB6CSlCggEAwAgCjAfMRg0AgFkEGA98IsEAAGASAcaDjh4YEgwAACYQYDzwMYgXAACjCDAeROdCihBgAAAwggDjAVMJAABgFgHGA2ajBgDALAKMB4yBAQDALAKMB1a0C4Y+GAAAjCDAeBB9DgyDeAEAMIMA4wWzUQMAYBQBxoOOQbwkGAAATCDAeOCjBwYAAKMIMB5Y0buQDNcDAICBigDjAQ+yAwDALAKMB9G7kMgvAACYQYDxgNmoAQAwiwDzJdADAwCAGQQYDyymEgAAwCgCjAfRS0gREgwAAEYQYDxgNmoAAMwiwHjg6xjFCwAADCDAeMBUAgAAmEWA8cDHIF4AAIwiwHjQMYjXbD0AABioCDAecAkJAACzCDAeMBs1AABmEWA8cOZCMlwPAAAGKgKMB1a01eiCAQDACAKMB9EeGAbxAgBgBgHGC2cMDAkGAAATCDAeMJUAAABmEWA84EF2AACYRYDxwGIqJAAAjCLAeOBcQqILBgAAIwgwHnAJCQAAswgwHjCVAAAAZvV6gHnwwQfl8/m0YMECZ1lDQ4MKCws1cuRIDRs2TLNmzVJ1dXXMdlVVVZo+fbqGDBmijIwM3XHHHWppaent6vYMUwkAAGBUrwaYnTt36j/+4z908cUXxyy//fbb9cILL+i5557T9u3bdejQId1www3O+tbWVk2fPl1NTU16/fXXtW7dOq1du1ZLlizpzer2mOVjKgEAAEzqtQBz9OhRFRQU6Ne//rVGjBjhLK+rq9N//ud/6tFHH9U3v/lNTZw4UU888YRef/11vfHGG5Kkl19+We+++67++7//W1/72tc0bdo0/fSnP9WqVavU1NTUW1XuseglpAhdMAAAGNFrAaawsFDTp09XXl5ezPLy8nI1NzfHLD///PM1ZswYlZaWSpJKS0s1fvx4ZWZmOmXy8/MVDoe1d+/ebo/X2NiocDgc8+otzEYNAIBZib2x02eeeUZvvfWWdu7cedy6UCikpKQkpaWlxSzPzMxUKBRyynQOL9H10XXdWbp0qe6777441P7kfE4fDAAAMCHuPTAHDx7Uj3/8Y61fv14pKSnx3v0JFRcXq66uznkdPHiw147lYy4kAACMinuAKS8vV01NjS699FIlJiYqMTFR27dv14oVK5SYmKjMzEw1NTWptrY2Zrvq6moFAgFJUiAQOO6upOjnaJmukpOT5ff7Y169JfocGGajBgDAjLgHmMmTJ2vPnj2qqKhwXpMmTVJBQYHzftCgQdqyZYuzTWVlpaqqqhQMBiVJwWBQe/bsUU1NjVOmpKREfr9f48aNi3eVXWMMDAAAZsV9DMzw4cN10UUXxSwbOnSoRo4c6SyfO3euFi5cqPT0dPn9ft12220KBoO64oorJElTpkzRuHHjdMstt2jZsmUKhUK6++67VVhYqOTk5HhX2TUeZAcAgFm9Moj3ZH7xi1/IsizNmjVLjY2Nys/P169+9StnfUJCgjZt2qRbb71VwWBQQ4cO1Zw5c3T//febqO5x6IEBAMCsUxJgtm3bFvM5JSVFq1at0qpVq064zdixY/Xiiy/2cs28id6FRH4BAMAM5kLywOIuJAAAjCLAeMBs1AAAmEWA+RIYxAsAgBkEGA8YxAsAgFkEGA8YxAsAgFkEGA+ig3iZjRoAADMIMB74Op5kBwAADCDAeODchWS4HgAADFQEGA+cDhguIQEAYAQBxgvuQgIAwCgCjAdW+yWkCAEGAAAjCDAeMBs1AABmEWA84EF2AACYRYDxwOf0wQAAABMIMB74mI0aAACjCDAe+BjECwCAUQQYDxjECwCAWQQYDxjECwCAWQQYD5iNGgAAswgwHtADAwCAWQQYDyzuQgIAwCgCjAfObNTkFwAAjCDAfAnchQQAgBkEGA8YAwMAgFkEGA+4CwkAALMIMB5EB/FG6IIBAMAIAowHvo5H8QIAAAMIMB5wCQkAALMIMB4wGzUAAGYRYDxwngNjuB4AAAxUBBgPokNgIiQYAACMIMB4wCUkAADMIsB4wE1IAACYRYDxwOd0wZitBwAAAxUBxgNnNmoSDAAARhBgvGjvgYlEDNcDAIABigDjQccYGHpgAAAwgQDjAbNRAwBgFgHGA6YSAADALAKMBxY9MAAAGEWA8YAH2QEAYBYBxgMuIQEAYBYBxgt6YAAAMIoA4wFTCQAAYBYBxgOrfRAMHTAAAJhBgPEgOog3QoIBAMCIuAeYpUuX6rLLLtPw4cOVkZGhmTNnqrKyMqZMQ0ODCgsLNXLkSA0bNkyzZs1SdXV1TJmqqipNnz5dQ4YMUUZGhu644w61tLTEu7qeRAMMAAAwI+4BZvv27SosLNQbb7yhkpISNTc3a8qUKaqvr3fK3H777XrhhRf03HPPafv27Tp06JBuuOEGZ31ra6umT5+upqYmvf7661q3bp3Wrl2rJUuWxLu6njh3IdEBAwCAET67l2+l+fjjj5WRkaHt27frmmuuUV1dnc444ww99dRT+ta3viVJeu+993TBBReotLRUV1xxhV566SX93d/9nQ4dOqTMzExJ0po1a3TXXXfp448/VlJS0kmPGw6HlZqaqrq6Ovn9/rie0/MVf9WPn6nQlV8ZqfX/3xVx3TcAAANZT/9+9/oYmLq6OklSenq6JKm8vFzNzc3Ky8tzypx//vkaM2aMSktLJUmlpaUaP368E14kKT8/X+FwWHv37u3tKp+Uj0G8AAAYldibO49EIlqwYIGuvPJKXXTRRZKkUCikpKQkpaWlxZTNzMxUKBRyynQOL9H10XXdaWxsVGNjo/M5HA7H6zSOEx0CwyBeAADM6NUemMLCQr3zzjt65plnevMwktoGD6empjqv7OzsXjsWs1EDAGBWrwWYoqIibdq0Sa+88orOPPNMZ3kgEFBTU5Nqa2tjyldXVysQCDhlut6VFP0cLdNVcXGx6urqnNfBgwfjeDaxmEoAAACz4h5gbNtWUVGRNmzYoK1btyonJydm/cSJEzVo0CBt2bLFWVZZWamqqioFg0FJUjAY1J49e1RTU+OUKSkpkd/v17hx47o9bnJysvx+f8yrt/h4FC8AAEbFfQxMYWGhnnrqKT3//PMaPny4M2YlNTVVgwcPVmpqqubOnauFCxcqPT1dfr9ft912m4LBoK64ou2OnilTpmjcuHG65ZZbtGzZMoVCId19990qLCxUcnJyvKvsmhW9hESCAQDAiLgHmNWrV0uSrr322pjlTzzxhL73ve9Jkn7xi1/IsizNmjVLjY2Nys/P169+9SunbEJCgjZt2qRbb71VwWBQQ4cO1Zw5c3T//ffHu7oetSWYCPkFAAAj4h5gevJYmZSUFK1atUqrVq06YZmxY8fqxRdfjGfV4sbHbNQAABjFXEgeMAQGAACzCDAe8CA7AADMIsB40DGIFwAAmECA8YAxMAAAmEWA8YDZqAEAMIsA4wXPgQEAwCgCjAfOXUjkFwAAjCDAeGBxFxIAAEYRYDyIDuKNkGAAADCCAOOBz7mIBAAATCDAeNBxG7XZegAAMFARYDzomEqABAMAgAkEGA+YSgAAALMIMB4wiBcAALMIMB4wGzUAAGYRYDzw+ZjNEQAAkwgwHpBfAAAwiwDjgcVs1AAAGEWA8aQtwUTILwAAGEGA8cDHbNQAABhFgPGA2agBADCLAOMBD7IDAMAsAowHFnM5AgBgFAHGA58ziJcuGAAATCDAeMBs1AAAmEWA+RK4CwkAADMIMB7QAwMAgFkEGA8sHw+yAwDAJAKMBz7nLiQSDAAAJhBgPIjehcQlJAAAzCDAeMBs1AAAmEWA8aBjKgEiDAAAJhBgPPAxiBcAAKMIMB503EZNggEAwAQCjAfOJSSjtQAAYOAiwHiQlNjWbI3NEUW4jgQAwClHgPEg4E9RouVTU2tEoXCD6eoAADDgEGA8SEywNCZ9iCTpwCf1hmsDAMDAQ4DxKGfUUEkEGAAATCDAeHRWe4D5MwEGAIBTjgDjkRNgPiXAAABwqhFgPDq7PcD8iR4YAABOOQKMR9EemIOHj6mlNWK4NgAADCwEGI9G+1OUnGipudXWoVpupQYA4FQiwHhkWT6NHdl2K/X7Hx8xXBsAAAaWRNMV6M9yRg3VH6uPat6T5RqTPkTpQ5M0YkiShqckKmWQpeTEBKUMSlDKIEuDB3W8TxmU0L6u8/KOdSmJCUpJspSUYDkTRwIAgA4EmC/h+1fm6P2ao/rg43od+KQ+7s+E8fnUFmaiwab9lZzYFm6SEi0NSvC1/2z7nNz+PjmxPRwlJWhI+3aW5ZPl88nyScmJCRqS1LY8KdGnBMtSouVTYoJPie3vEyyfBiVYSrB8zr6TEixZFqEKAGCWz+7DUyqvWrVKDz/8sEKhkCZMmKCVK1fq8ssv79G24XBYqampqqurk9/v79V6Hqr9XAcPH9Nnx5r0aX2T6htb1NAcUUNza9vPltb2962dlnesa2yO6PPmjjJ9fXqlQQk+JSVYSkxoC0uDEtqCTmL78uj7mHWWpaTEjveJlk8JCT4nKCX4On/uHKCi+7G6vG/bX6LV8T4attpCWltQ8/k6jpGY0H4cq207y5ISLav9s49gBgB9QE//fvfZHphnn31WCxcu1Jo1a5Sbm6vly5crPz9flZWVysjIMF29GFlpg5WVNjgu+7JtW82tthN6YsNNW/hpbImouTWippaImtp/Nnf52dDSVvbzplZn+9aILVtSa8RWY3NEx5pb9HlTq1oitlpabbVEImqNtB2/NdL2uW15bKJqbrXV3NoqqTUu59xX+HzqCDvtwcbnkyyfT7729VZ7AOocehLbQ9OJAlLnMglW2z6ivWEJvs6fY98n+Hzyte/P8qnTNl0+t9czIRrcottb7dt3Kd95ndXl/KS2ffkUrYvkU0c7dA6GHfuMfu7YnzptH7tNp2N22adi6tIRJqN18/li69b23qdo0c6fo/uIHhfA6afP9sDk5ubqsssu0y9/+UtJUiQSUXZ2tm677TYtWrTopNufyh6Y0100VEXDUmNLa3tYstXc2hZymlojamntWNZ8kvcRuy00tUYiaolEA1Pbz+j7lta2QNX0BfuLhraWiK2mlrbyEbutzhHbdj537DfS53u40Ds6BxsnFKltYefPnUOrOm/TzfaKCUzHB7C24HV8sGrftTq/iX6O7l/OMdrr2elztFzsdsdv4+uyb51omy/aX6cKnqxeTpt2qWvX+nat14mOrW7Oobtjd1fXmPPuph4xy7op1905fFGd1encY+t54noff5wu7XmCevW0rt2W6+Fee7q/b0/M1vgzU3tWuIf6dQ9MU1OTysvLVVxc7CyzLEt5eXkqLS3tdpvGxkY1NjY6n8PhcK/Xc6Dw+XxKSmwbB6Nk07X58iIRW63RAGXbMeGmNRINVtGeJ1u2rbZQpPZAFFH7dpHj9hHdLhL92eU4EbttXTRURezoq+2zbdtqjUgRu/19+7pIJBrI1Gmbts92p6AW6RTc7Ghwa9/XccdsPw+1n1v7W9m23f5TznZt9Yn9Gfv++HVtQbIjTJ64TOy63hI9v9iDkGaBL2PSWelxDzA91ScDzCeffKLW1lZlZmbGLM/MzNR7773X7TZLly7Vfffddyqqh37Osnyy5NOgBNM1QXc6dwp3DVWdQ070fdfQpWgY6rLcVjSsdXy2uwSnzsu7C3Ndt+38Prp99NjqWq/O5TqdX+dztjsvU2zhzttE1x2/v479qMt+Otex6zZd66Nu9t+1Xic6tr6orH2Cup6gvse1U3fH7rKfrm3aZffH1fFE67vbR9dtu6trd+u7O17n/Xded/x/i+7Z3da4+3qeeB9fcgeSvpo57KRlekufDDBeFBcXa+HChc7ncDis7OxsgzUC4EXM+Jeu11kAoF2fDDCjRo1SQkKCqqurY5ZXV1crEAh0u01ycrKSk0+D6xsAAOCk+uSTeJOSkjRx4kRt2bLFWRaJRLRlyxYFg0GDNQMAAH1Bn+yBkaSFCxdqzpw5mjRpki6//HItX75c9fX1+v73v2+6agAAwLA+G2BuvPFGffzxx1qyZIlCoZC+9rWvafPmzccN7AUAAANPn30OzJfFc2AAAOh/evr3u0+OgQEAAPgiBBgAANDvEGAAAEC/Q4ABAAD9DgEGAAD0OwQYAADQ7xBgAABAv0OAAQAA/U6ffRLvlxV9Pl84HDZcEwAA0FPRv9sne87uaRtgjhw5IknKzs42XBMAAODWkSNHlJqaesL1p+1UApFIRIcOHdLw4cPl8/nitt9wOKzs7GwdPHiQKQp6gPbqOdrKHdqr52irnqOt3OmN9rJtW0eOHFFWVpYs68QjXU7bHhjLsnTmmWf22v79fj9fbhdor56jrdyhvXqOtuo52sqdeLfXF/W8RDGIFwAA9DsEGAAA0O8QYFxKTk7WPffco+TkZNNV6Rdor56jrdyhvXqOtuo52sodk+112g7iBQAApy96YAAAQL9DgAEAAP0OAQYAAPQ7BBgAANDvEGBcWrVqlc466yylpKQoNzdXb775pukqGXfvvffK5/PFvM4//3xnfUNDgwoLCzVy5EgNGzZMs2bNUnV1tcEan1o7duzQ9ddfr6ysLPl8Pm3cuDFmvW3bWrJkiUaPHq3BgwcrLy9P+/fvjylz+PBhFRQUyO/3Ky0tTXPnztXRo0dP4VmcGidrq+9973vHfdemTp0aU2agtNXSpUt12WWXafjw4crIyNDMmTNVWVkZU6Ynv3tVVVWaPn26hgwZooyMDN1xxx1qaWk5lafS63rSVtdee+1x360f/vCHMWUGQltJ0urVq3XxxRc7D6cLBoN66aWXnPV95XtFgHHh2Wef1cKFC3XPPfforbfe0oQJE5Sfn6+amhrTVTPuwgsv1EcffeS8Xn31VWfd7bffrhdeeEHPPfectm/frkOHDumGG24wWNtTq76+XhMmTNCqVau6Xb9s2TKtWLFCa9asUVlZmYYOHar8/Hw1NDQ4ZQoKCrR3716VlJRo06ZN2rFjh+bPn3+qTuGUOVlbSdLUqVNjvmtPP/10zPqB0lbbt29XYWGh3njjDZWUlKi5uVlTpkxRfX29U+Zkv3utra2aPn26mpqa9Prrr2vdunVau3atlixZYuKUek1P2kqS5s2bF/PdWrZsmbNuoLSVJJ155pl68MEHVV5erl27dumb3/ymZsyYob1790rqQ98rGz12+eWX24WFhc7n1tZWOysry166dKnBWpl3zz332BMmTOh2XW1trT1o0CD7ueeec5bt27fPlmSXlpaeohr2HZLsDRs2OJ8jkYgdCATshx9+2FlWW1trJycn208//bRt27b97rvv2pLsnTt3OmVeeukl2+fz2X/9619PWd1Pta5tZdu2PWfOHHvGjBkn3GagtpVt23ZNTY0tyd6+fbtt2z373XvxxRdty7LsUCjklFm9erXt9/vtxsbGU3sCp1DXtrJt2/7bv/1b+8c//vEJtxmobRU1YsQI+ze/+U2f+l7RA9NDTU1NKi8vV15enrPMsizl5eWptLTUYM36hv379ysrK0tnn322CgoKVFVVJUkqLy9Xc3NzTLudf/75GjNmDO0m6cCBAwqFQjHtk5qaqtzcXKd9SktLlZaWpkmTJjll8vLyZFmWysrKTnmdTdu2bZsyMjJ03nnn6dZbb9Wnn37qrBvIbVVXVydJSk9Pl9Sz373S0lKNHz9emZmZTpn8/HyFw2HnX9uno65tFbV+/XqNGjVKF110kYqLi3Xs2DFn3UBtq9bWVj3zzDOqr69XMBjsU9+r03Yyx3j75JNP1NraGvMfRJIyMzP13nvvGapV35Cbm6u1a9fqvPPO00cffaT77rtPV199td555x2FQiElJSUpLS0tZpvMzEyFQiEzFe5Dom3Q3fcqui4UCikjIyNmfWJiotLT0wdcG06dOlU33HCDcnJy9MEHH+hf//VfNW3aNJWWliohIWHAtlUkEtGCBQt05ZVX6qKLLpKkHv3uhUKhbr970XWno+7aSpJuvvlmjR07VllZWdq9e7fuuusuVVZW6ne/+52kgddWe/bsUTAYVENDg4YNG6YNGzZo3Lhxqqio6DPfKwIMvrRp06Y57y+++GLl5uZq7Nix+u1vf6vBgwcbrBlON7Nnz3bejx8/XhdffLHOOeccbdu2TZMnTzZYM7MKCwv1zjvvxIw9Q/dO1Fadx0mNHz9eo0eP1uTJk/XBBx/onHPOOdXVNO68885TRUWF6urq9D//8z+aM2eOtm/fbrpaMbiE1EOjRo1SQkLCcSOtq6urFQgEDNWqb0pLS9NXv/pVvf/++woEAmpqalJtbW1MGdqtTbQNvuh7FQgEjhso3tLSosOHDw/4Njz77LM1atQovf/++5IGZlsVFRVp06ZNeuWVV3TmmWc6y3vyuxcIBLr97kXXnW5O1Fbdyc3NlaSY79ZAaqukpCR95Stf0cSJE7V06VJNmDBBjz32WJ/6XhFgeigpKUkTJ07Uli1bnGWRSERbtmxRMBg0WLO+5+jRo/rggw80evRoTZw4UYMGDYppt8rKSlVVVdFuknJychQIBGLaJxwOq6yszGmfYDCo2tpalZeXO2W2bt2qSCTi/E92oPrLX/6iTz/9VKNHj5Y0sNrKtm0VFRVpw4YN2rp1q3JycmLW9+R3LxgMas+ePTGhr6SkRH6/X+PGjTs1J3IKnKytulNRUSFJMd+tgdBWJxKJRNTY2Ni3vldxGw48ADzzzDN2cnKyvXbtWvvdd9+158+fb6elpcWMtB6IfvKTn9jbtm2zDxw4YL/22mt2Xl6ePWrUKLumpsa2bdv+4Q9/aI8ZM8beunWrvWvXLjsYDNrBYNBwrU+dI0eO2G+//bb99ttv25LsRx991H777bftDz/80LZt237wwQfttLQ0+/nnn7d3795tz5gxw87JybE///xzZx9Tp061L7nkErusrMx+9dVX7XPPPde+6aabTJ1Sr/mitjpy5Ij9L//yL3Zpaal94MAB+w9/+IN96aWX2ueee67d0NDg7GOgtNWtt95qp6am2tu2bbM/+ugj53Xs2DGnzMl+91paWuyLLrrInjJlil1RUWFv3rzZPuOMM+zi4mITp9RrTtZW77//vn3//ffbu3btsg8cOGA///zz9tlnn21fc801zj4GSlvZtm0vWrTI3r59u33gwAF79+7d9qJFi2yfz2e//PLLtm33ne8VAcallStX2mPGjLGTkpLsyy+/3H7jjTdMV8m4G2+80R49erSdlJRk/83f/I1944032u+//76z/vPPP7d/9KMf2SNGjLCHDBli/8M//IP90UcfGazxqfXKK6/Yko57zZkzx7bttlupFy9ebGdmZtrJycn25MmT7crKyph9fPrpp/ZNN91kDxs2zPb7/fb3v/99+8iRIwbOpnd9UVsdO3bMnjJlin3GGWfYgwYNsseOHWvPmzfvuH9ADJS26q6dJNlPPPGEU6Ynv3t//vOf7WnTptmDBw+2R40aZf/kJz+xm5ubT/HZ9K6TtVVVVZV9zTXX2Onp6XZycrL9la98xb7jjjvsurq6mP0MhLaybdv+wQ9+YI8dO9ZOSkqyzzjjDHvy5MlOeLHtvvO98tm2bcevPwcAAKD3MQYGAAD0OwQYAADQ7xBgAABAv0OAAQAA/Q4BBgAA9DsEGAAA0O8QYAAAQL9DgAEAAP0OAQYAAPQ7BBgAANDvEGAAAEC/Q4ABAAD9zv8PogiHRHnT36UAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x709e66f2e890>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x70a0901b4d00>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x709e8459af50>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 256)               4864      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 16)                64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50625 (197.75 KB)\n",
      "Trainable params: 49633 (193.88 KB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
