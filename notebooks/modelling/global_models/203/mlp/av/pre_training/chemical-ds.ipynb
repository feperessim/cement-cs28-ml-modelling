{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 02:11:05.312304: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-01 02:11:05.316943: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-01 02:11:05.412635: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-01 02:11:05.414929: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-01 02:11:07.077479: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Best model save\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\nfrom pickle import dump\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best model save\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/203/mlp/av/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_formatted_code = \"checkpoint_filepath = (\\n    \\\"../../../../../../../models/global_models/203/mlp/av/pre_training/\\\"\\n)\\n\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor=\\\"val_loss\\\",\\n    mode=\\\"min\\\",\\n    save_best_only=True,\\n)\\n\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_filepath = (\n",
    "    \"../../../../../../../models/global_models/203/mlp/av/pre_training/\"\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP1:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP1:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP2:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP2:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP3:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP3:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP4:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP4:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP5:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP5:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP6:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"selu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP6:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"selu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP7:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n\\n        # First Dense layer with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        # Subsequent Dense layers with Batch Normalization\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP7:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # First Dense layer with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())  # Add BatchNormalization\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        # Subsequent Dense layers with Batch Normalization\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP8:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP8:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP9:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP9:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP10:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=512, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP10:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=512, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP11:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\"))\\n        model.add(tf.keras.layers.BatchNormalization())\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP11:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP12:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP12:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP13:\\n    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\\n        self.model = self.get_model()\\n        self.batch_size = 64\\n        self.epochs = 300\\n        self.verbose = verbose\\n        self.callbacks = callbacks\\n        self.validation_split = validation_split\\n\\n    def fit(self, X=None, y=None):\\n        self.history = self.model.fit(\\n            X,\\n            y,\\n            batch_size=self.batch_size,\\n            epochs=self.epochs,\\n            verbose=self.verbose,\\n            callbacks=self.callbacks,\\n            validation_split=self.validation_split,\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=256, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=128, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.25))\\n        model.add(tf.keras.layers.Dense(units=64, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=32, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"elu\\\")),\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP13:\n",
    "    def __init__(self, callbacks=None, validation_split=0.0, verbose=0):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 300\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.history = self.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            verbose=self.verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.25))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"elu\")),\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    # os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"index_to_save = 2\\nmodel_index = 1\";\n",
       "                var nbb_formatted_code = \"index_to_save = 2\\nmodel_index = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 2\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"203\\\",\\n    \\\"Plant\\\": \\\"AV\\\",\\n    \\\"Features\\\": \\\"Chemical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Global Model\\\",\\n    \\\"Company\\\": \\\"203\\\",\\n    \\\"Plant\\\": \\\"AV\\\",\\n    \\\"Features\\\": \\\"Chemical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Global Model\",\n",
    "    \"Company\": \"203\",\n",
    "    \"Plant\": \"AV\",\n",
    "    \"Features\": \"Chemical\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/203/global_av.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../../data/processed/203/global_av.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../../data/processed/203/global_av.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Cement_Type\\\",\\n        \\\"Factory_Plant\\\",\\n        \\\"Blaine\\\",\\n        \\\"#200\\\",\\n        \\\"#325\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy().drop(\\n    [\\n        \\\"Cement_Type\\\",\\n        \\\"Factory_Plant\\\",\\n        \\\"Blaine\\\",\\n        \\\"#200\\\",\\n        \\\"#325\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy().drop(\n",
    "    [\n",
    "        \"Cement_Type\",\n",
    "        \"Factory_Plant\",\n",
    "        \"Blaine\",\n",
    "        \"#200\",\n",
    "        \"#325\",\n",
    "        \"Final setting time\",\n",
    "        \"Initial setting time\",\n",
    "        \"CS1\",\n",
    "        \"CS3\",\n",
    "        \"CS7\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training parameter choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 02:11:11.909128: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  11.389439308643341\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP1()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.217 (0.000)\n",
      "MAE: 1.625 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.895 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.800 (0.000)\n",
      "MAE: 2.036 (0.000)\n",
      "MAPE: 0.049 (0.000)\n",
      "R2: 0.777 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  13.382683408260345\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP2()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP2()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.229 (0.000)\n",
      "MAE: 1.629 (0.000)\n",
      "MAPE: 0.037 (0.000)\n",
      "R2: 0.894 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.793 (0.000)\n",
      "MAE: 2.037 (0.000)\n",
      "MAPE: 0.049 (0.000)\n",
      "R2: 0.778 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.947652514775594\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP3()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP3()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.052 (0.000)\n",
      "MAE: 1.522 (0.000)\n",
      "MAPE: 0.035 (0.000)\n",
      "R2: 0.910 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.783 (0.000)\n",
      "MAE: 1.990 (0.000)\n",
      "MAPE: 0.048 (0.000)\n",
      "R2: 0.780 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  21.549699254830678\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP4()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP4()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.894 (0.000)\n",
      "MAE: 1.398 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.923 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.745 (0.000)\n",
      "MAE: 1.936 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.786 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  22.05204567114512\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP5()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP5()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.960 (0.000)\n",
      "MAE: 1.438 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.918 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.766 (0.000)\n",
      "MAE: 1.974 (0.000)\n",
      "MAPE: 0.047 (0.000)\n",
      "R2: 0.782 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  34.680495162804924\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.005 (0.000)\n",
      "MAE: 1.450 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.914 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.651 (0.000)\n",
      "MAE: 1.868 (0.000)\n",
      "MAPE: 0.044 (0.000)\n",
      "R2: 0.800 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  26.223986518383025\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP7()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP7()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.910 (0.000)\n",
      "MAE: 1.391 (0.000)\n",
      "MAPE: 0.032 (0.000)\n",
      "R2: 0.922 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.670 (0.000)\n",
      "MAE: 1.907 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.797 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  15.485251983006796\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP8()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP8()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.980 (0.000)\n",
      "MAE: 1.459 (0.000)\n",
      "MAPE: 0.034 (0.000)\n",
      "R2: 0.916 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.809 (0.000)\n",
      "MAE: 2.004 (0.000)\n",
      "MAPE: 0.048 (0.000)\n",
      "R2: 0.775 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  23.828570568561553\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP9()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP9()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.804 (0.000)\n",
      "MAE: 1.342 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.930 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.898 (0.000)\n",
      "MAE: 2.010 (0.000)\n",
      "MAPE: 0.049 (0.000)\n",
      "R2: 0.761 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.204789034525554\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP10()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP10()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.892 (0.000)\n",
      "MAE: 1.379 (0.000)\n",
      "MAPE: 0.031 (0.000)\n",
      "R2: 0.924 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.795 (0.000)\n",
      "MAE: 1.939 (0.000)\n",
      "MAPE: 0.046 (0.000)\n",
      "R2: 0.778 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  25.091979392369588\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP11()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP11()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.986 (0.000)\n",
      "MAE: 1.440 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.916 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.688 (0.000)\n",
      "MAE: 1.908 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.794 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.64374913374583\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP12()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP12()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.198 (0.000)\n",
      "MAE: 1.602 (0.000)\n",
      "MAPE: 0.036 (0.000)\n",
      "R2: 0.897 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.671 (0.000)\n",
      "MAE: 1.882 (0.000)\n",
      "MAPE: 0.045 (0.000)\n",
      "R2: 0.797 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  14.648485676447551\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Split train test sets\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=0.2, random_state=SEED, shuffle=False\\n)\\n\\n# Define callbacks for early stop\\nmodel_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP13()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x_train, y_train)\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Split train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=SEED, shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks for early stop\n",
    "model_early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP13()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.393 (0.000)\n",
      "MAE: 1.741 (0.000)\n",
      "MAPE: 0.040 (0.000)\n",
      "R2: 0.878 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.797 (0.000)\n",
      "MAE: 1.984 (0.000)\n",
      "MAPE: 0.047 (0.000)\n",
      "R2: 0.777 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_formatted_code = \"# Print the results\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\n# save the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"train_size\\\": 0.8, \\\"test_size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\nresults_dict_copy[\\\"Model\\\"] = f\\\"MLP_{model_index}\\\"\\nscores = {key: [value] for key, value in scores.items()}\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\nmodel_index += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "# save the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"train_size\": 0.8, \"test_size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "results_dict_copy[\"Model\"] = f\"MLP_{model_index}\"\n",
    "scores = {key: [value] for key, value in scores.items()}\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "model_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/203/av/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = f\\\"../../../../../../../reports/results/global_models/203/av/pre_training/full/\\\"\\nfilename = f\\\"mlp_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"../../../../../../../reports/results/global_models/203/av/pre_training/full/\"\n",
    "filename = f\"mlp_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Features</th>\n",
       "      <th>Data Shape</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Scaler Params</th>\n",
       "      <th>...</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>MAE Train</th>\n",
       "      <th>MAPE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>MAPE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "      <th>SCPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Global Model</td>\n",
       "      <td>203</td>\n",
       "      <td>AV</td>\n",
       "      <td>Chemical</td>\n",
       "      <td>(62752, 10)</td>\n",
       "      <td>None</td>\n",
       "      <td>MLP_6</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"train_size\": 0.8, \"test_size\": 0.2}</td>\n",
       "      <td>2.004959</td>\n",
       "      <td>1.450005</td>\n",
       "      <td>0.032968</td>\n",
       "      <td>0.914152</td>\n",
       "      <td>2.651179</td>\n",
       "      <td>1.868412</td>\n",
       "      <td>0.044415</td>\n",
       "      <td>0.799999</td>\n",
       "      <td>-6.511135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category Company Plant  Features   Data Shape Timesteps  Model  \\\n",
       "5  Global Model     203    AV  Chemical  (62752, 10)      None  MLP_6   \n",
       "\n",
       "  Model Params           Scaler Scaler Params  ...  \\\n",
       "5         None  Standard Scaler          None  ...   \n",
       "\n",
       "                 Cross Validation Params RMSE Train MAE Train MAPE Train  \\\n",
       "5  {\"train_size\": 0.8, \"test_size\": 0.2}   2.004959  1.450005   0.032968   \n",
       "\n",
       "   R2 Train  RMSE Test  MAE Test  MAPE Test   R2 Test      SCPM  \n",
       "5  0.914152   2.651179  1.868412   0.044415  0.799999 -6.511135  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_formatted_code = \"# Concatenating the results\\nddf = pd.concat(results_to_save).reset_index(drop=True)\\nddf_copy = ddf.copy()\\n\\n# Define the columns to standardize\\ncols = [\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]\\n\\n# Standardize all the metrics including R\\u00b2\\nscaler = StandardScaler()\\nstandardized_metrics = scaler.fit_transform(ddf_copy[cols])\\n\\n# Creating a new DataFrame with standardized values\\nstandardized_df = pd.DataFrame(\\n    standardized_metrics,\\n    columns=cols,\\n)\\n\\n# Summing all standardized metrics and subtracting the standardized R2\\nstandardized_df[\\\"Result\\\"] = (\\n    standardized_df[\\\"RMSE Test\\\"]\\n    + standardized_df[\\\"MAE Test\\\"]\\n    + standardized_df[\\\"MAPE Test\\\"]\\n    - standardized_df[\\\"R2 Test\\\"]\\n)\\n\\n# Update the SCPM in ddf_copy\\nddf_copy[\\\"SCPM\\\"] = standardized_df[\\\"Result\\\"]\\n\\n# Finding the row with the minimum SCPM value\\noptimal_row = ddf_copy[ddf_copy[\\\"SCPM\\\"].eq(ddf_copy[\\\"SCPM\\\"].min())]\\n\\n# Display the result\\noptimal_row\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenating the results\n",
    "ddf = pd.concat(results_to_save).reset_index(drop=True)\n",
    "ddf_copy = ddf.copy()\n",
    "\n",
    "# Define the columns to standardize\n",
    "cols = [\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]\n",
    "\n",
    "# Standardize all the metrics including R\n",
    "scaler = StandardScaler()\n",
    "standardized_metrics = scaler.fit_transform(ddf_copy[cols])\n",
    "\n",
    "# Creating a new DataFrame with standardized values\n",
    "standardized_df = pd.DataFrame(\n",
    "    standardized_metrics,\n",
    "    columns=cols,\n",
    ")\n",
    "\n",
    "# Summing all standardized metrics and subtracting the standardized R2\n",
    "standardized_df[\"Result\"] = (\n",
    "    standardized_df[\"RMSE Test\"]\n",
    "    + standardized_df[\"MAE Test\"]\n",
    "    + standardized_df[\"MAPE Test\"]\n",
    "    - standardized_df[\"R2 Test\"]\n",
    ")\n",
    "\n",
    "# Update the SCPM in ddf_copy\n",
    "ddf_copy[\"SCPM\"] = standardized_df[\"Result\"]\n",
    "\n",
    "# Finding the row with the minimum SCPM value\n",
    "optimal_row = ddf_copy[ddf_copy[\"SCPM\"].eq(ddf_copy[\"SCPM\"].min())]\n",
    "\n",
    "# Display the result\n",
    "optimal_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train best model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes Elapsed:  27.465367317199707\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_formatted_code = \"# Set seeds for reproducibility\\nset_seeds()\\n\\n# Define training pipeline\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP6()),\\n    ]\\n)\\n\\n# Fit the model\\nstart = time.time()\\npipeline.fit(x.copy(), y.copy())\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\\n\\n# Make predictions\\ny_train_pred = pipeline.predict(x)\\nscores = score_regression_metrics(y, y_train_pred, y, y_train_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds()\n",
    "\n",
    "# Define training pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP6()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()\n",
    "pipeline.fit(x.copy(), y.copy())\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(x)\n",
    "scores = score_regression_metrics(y, y_train_pred, y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.997 (0.000)\n",
      "MAE: 1.446 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.911 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.997 (0.000)\n",
      "MAE: 1.446 (0.000)\n",
      "MAPE: 0.033 (0.000)\n",
      "R2: 0.911 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_formatted_code = \"print_scores(scores, METRICS, METRICS_DICT)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"weights_path = \\\"../../../../../../../models/global_models/203/mlp/av/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_vars_weights.h5\\\"\";\n",
       "                var nbb_formatted_code = \"weights_path = \\\"../../../../../../../models/global_models/203/mlp/av/pre_training/\\\"\\nmodel_name = \\\"mlp_chemical_vars_weights.h5\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_path = \"../../../../../../../models/global_models/203/mlp/av/pre_training/\"\n",
    "model_name = \"mlp_chemical_vars_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_formatted_code = \"model = pipeline.named_steps[\\\"estimator\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_formatted_code = \"full_path = os.path.join(weights_path, model_name)\\nmodel.model.save_weights(full_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_path = os.path.join(weights_path, model_name)\n",
    "model.model.save_weights(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7e2051995a20>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\n\\nplt.plot(model.history.history[\\\"loss\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7e205186dd50>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7e20517081f0>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"loss\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7e2051771990>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_formatted_code = \"plt.plot(model.history.history[\\\"RMSE\\\"][1:])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"RMSE\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 256)               2816      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 16)                64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48577 (189.75 KB)\n",
      "Trainable params: 47585 (185.88 KB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"model.model.summary()\";\n",
       "                var nbb_formatted_code = \"model.model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
