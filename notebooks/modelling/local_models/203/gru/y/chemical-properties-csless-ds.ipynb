{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "812be3a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:18:16.639865Z",
     "iopub.status.busy": "2024-04-04T21:18:16.639456Z",
     "iopub.status.idle": "2024-04-04T21:18:16.757050Z",
     "shell.execute_reply": "2024-04-04T21:18:16.755678Z"
    },
    "papermill": {
     "duration": 0.138465,
     "end_time": "2024-04-04T21:18:16.759026",
     "exception": false,
     "start_time": "2024-04-04T21:18:16.620561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d896fcbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:18:16.798064Z",
     "iopub.status.busy": "2024-04-04T21:18:16.797563Z",
     "iopub.status.idle": "2024-04-04T21:18:19.910937Z",
     "shell.execute_reply": "2024-04-04T21:18:19.910010Z"
    },
    "papermill": {
     "duration": 3.147933,
     "end_time": "2024-04-04T21:18:19.915129",
     "exception": false,
     "start_time": "2024-04-04T21:18:16.767196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-04 18:18:18.161895: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-04 18:18:18.164167: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-04 18:18:18.212192: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-04 18:18:18.213190: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-04 18:18:19.115333: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Plotting\\nimport matplotlib.pyplot as plt\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.model_selection import TimeSeriesSplit\\nfrom sklearn.model_selection import RepeatedKFold\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.model_selection import cross_validate\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.preprocessing import RobustScaler\\n\\n# Metrics\\nfrom sklearn.metrics import mean_squared_error\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.metrics import mean_absolute_percentage_error\\nfrom sklearn.metrics import r2_score\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import BaseEstimator, RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\n# Converting Times Series Data to 3D format\\nfrom src.utils.split_sequences import split_sequences\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Plotting\\nimport matplotlib.pyplot as plt\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.model_selection import TimeSeriesSplit\\nfrom sklearn.model_selection import RepeatedKFold\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.model_selection import cross_validate\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.preprocessing import RobustScaler\\n\\n# Metrics\\nfrom sklearn.metrics import mean_squared_error\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.metrics import mean_absolute_percentage_error\\nfrom sklearn.metrics import r2_score\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import BaseEstimator, RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\n# Converting Times Series Data to 3D format\\nfrom src.utils.split_sequences import split_sequences\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "# Converting Times Series Data to 3D format\n",
    "from src.utils.split_sequences import split_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee18a63",
   "metadata": {
    "papermill": {
     "duration": 0.020369,
     "end_time": "2024-04-04T21:18:19.957166",
     "exception": false,
     "start_time": "2024-04-04T21:18:19.936797",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890592b0",
   "metadata": {
    "papermill": {
     "duration": 0.012416,
     "end_time": "2024-04-04T21:18:19.985288",
     "exception": false,
     "start_time": "2024-04-04T21:18:19.972872",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions for blocked time series cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994992ef",
   "metadata": {
    "papermill": {
     "duration": 0.008298,
     "end_time": "2024-04-04T21:18:20.003491",
     "exception": false,
     "start_time": "2024-04-04T21:18:19.995193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Convert train/test data to 3D format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2867cf6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:18:20.020981Z",
     "iopub.status.busy": "2024-04-04T21:18:20.020434Z",
     "iopub.status.idle": "2024-04-04T21:18:20.034262Z",
     "shell.execute_reply": "2024-04-04T21:18:20.033450Z"
    },
    "papermill": {
     "duration": 0.024544,
     "end_time": "2024-04-04T21:18:20.035942",
     "exception": false,
     "start_time": "2024-04-04T21:18:20.011398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def generate_sequences_helper(\\n    dataset, cement_types, dates=None, timesteps=None, split_by_cement_type=False\\n):\\n    index_train = dataset[\\\"y_train\\\"].index\\n    index_test = dataset[\\\"y_test\\\"].index\\n\\n    dataset[\\\"y_train\\\"] = dataset[\\\"y_train\\\"].reset_index(drop=True)\\n    dataset[\\\"y_test\\\"] = dataset[\\\"y_test\\\"].reset_index(drop=True)\\n\\n    if dates is not None:\\n        dataset[\\\"dates_train\\\"] = dates[index_train].reset_index(drop=True)\\n        dataset[\\\"dates_test\\\"] = dates[index_test].reset_index(drop=True)\\n\\n    dataset[\\\"cement_types_train\\\"] = cement_types.loc[index_train].reset_index(drop=True)\\n    dataset[\\\"cement_types_test\\\"] = cement_types.loc[index_test].reset_index(drop=True)\\n\\n    dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\\n\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def generate_sequences_helper(\\n    dataset, cement_types, dates=None, timesteps=None, split_by_cement_type=False\\n):\\n    index_train = dataset[\\\"y_train\\\"].index\\n    index_test = dataset[\\\"y_test\\\"].index\\n\\n    dataset[\\\"y_train\\\"] = dataset[\\\"y_train\\\"].reset_index(drop=True)\\n    dataset[\\\"y_test\\\"] = dataset[\\\"y_test\\\"].reset_index(drop=True)\\n\\n    if dates is not None:\\n        dataset[\\\"dates_train\\\"] = dates[index_train].reset_index(drop=True)\\n        dataset[\\\"dates_test\\\"] = dates[index_test].reset_index(drop=True)\\n\\n    dataset[\\\"cement_types_train\\\"] = cement_types.loc[index_train].reset_index(drop=True)\\n    dataset[\\\"cement_types_test\\\"] = cement_types.loc[index_test].reset_index(drop=True)\\n\\n    dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\\n\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_sequences_helper(\n",
    "    dataset, cement_types, dates=None, timesteps=None, split_by_cement_type=False\n",
    "):\n",
    "    index_train = dataset[\"y_train\"].index\n",
    "    index_test = dataset[\"y_test\"].index\n",
    "\n",
    "    dataset[\"y_train\"] = dataset[\"y_train\"].reset_index(drop=True)\n",
    "    dataset[\"y_test\"] = dataset[\"y_test\"].reset_index(drop=True)\n",
    "\n",
    "    if dates is not None:\n",
    "        dataset[\"dates_train\"] = dates[index_train].reset_index(drop=True)\n",
    "        dataset[\"dates_test\"] = dates[index_test].reset_index(drop=True)\n",
    "\n",
    "    dataset[\"cement_types_train\"] = cement_types.loc[index_train].reset_index(drop=True)\n",
    "    dataset[\"cement_types_test\"] = cement_types.loc[index_test].reset_index(drop=True)\n",
    "\n",
    "    dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "077eaaaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:18:20.081317Z",
     "iopub.status.busy": "2024-04-04T21:18:20.080309Z",
     "iopub.status.idle": "2024-04-04T21:18:20.273524Z",
     "shell.execute_reply": "2024-04-04T21:18:20.271613Z"
    },
    "papermill": {
     "duration": 0.233122,
     "end_time": "2024-04-04T21:18:20.277442",
     "exception": false,
     "start_time": "2024-04-04T21:18:20.044320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"def generate_sequences(dataset, timesteps, split_by_cement_type=False):\\n    if split_by_cement_type:\\n        dataset[\\\"x_train\\\"], dataset[\\\"y_train\\\"] = split_sequences_per_cement_type(\\n            pd.concat(\\n                [\\n                    dataset[\\\"dates_train\\\"],\\n                    pd.DataFrame(dataset[\\\"x_train\\\"], columns=x.columns),\\n                    dataset[\\\"cement_types_train\\\"],\\n                    dataset[\\\"y_train\\\"],\\n                ],\\n                axis=1,\\n            ),\\n            timesteps,\\n        )\\n\\n        dataset[\\\"x_test\\\"], dataset[\\\"y_test\\\"] = split_sequences_per_cement_type(\\n            pd.concat(\\n                [\\n                    dataset[\\\"dates_test\\\"],\\n                    pd.DataFrame(dataset[\\\"x_test\\\"], columns=x.columns),\\n                    dataset[\\\"cement_types_test\\\"],\\n                    dataset[\\\"y_test\\\"],\\n                ],\\n                axis=1,\\n            ),\\n            timesteps,\\n        )\\n    else:\\n        dataset[\\\"x_train\\\"], dataset[\\\"y_train\\\"] = split_sequences(\\n            pd.concat(\\n                [\\n                    pd.DataFrame(dataset[\\\"x_train\\\"], columns=x.columns),\\n                    dataset[\\\"y_train\\\"],\\n                ],\\n                axis=1,\\n            ).values,\\n            timesteps,\\n        )\\n\\n        dataset[\\\"x_test\\\"], dataset[\\\"y_test\\\"] = split_sequences(\\n            pd.concat(\\n                [\\n                    pd.DataFrame(dataset[\\\"x_test\\\"], columns=x.columns),\\n                    dataset[\\\"y_test\\\"],\\n                ],\\n                axis=1,\\n            ).values,\\n            timesteps,\\n        )\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def generate_sequences(dataset, timesteps, split_by_cement_type=False):\\n    if split_by_cement_type:\\n        dataset[\\\"x_train\\\"], dataset[\\\"y_train\\\"] = split_sequences_per_cement_type(\\n            pd.concat(\\n                [\\n                    dataset[\\\"dates_train\\\"],\\n                    pd.DataFrame(dataset[\\\"x_train\\\"], columns=x.columns),\\n                    dataset[\\\"cement_types_train\\\"],\\n                    dataset[\\\"y_train\\\"],\\n                ],\\n                axis=1,\\n            ),\\n            timesteps,\\n        )\\n\\n        dataset[\\\"x_test\\\"], dataset[\\\"y_test\\\"] = split_sequences_per_cement_type(\\n            pd.concat(\\n                [\\n                    dataset[\\\"dates_test\\\"],\\n                    pd.DataFrame(dataset[\\\"x_test\\\"], columns=x.columns),\\n                    dataset[\\\"cement_types_test\\\"],\\n                    dataset[\\\"y_test\\\"],\\n                ],\\n                axis=1,\\n            ),\\n            timesteps,\\n        )\\n    else:\\n        dataset[\\\"x_train\\\"], dataset[\\\"y_train\\\"] = split_sequences(\\n            pd.concat(\\n                [\\n                    pd.DataFrame(dataset[\\\"x_train\\\"], columns=x.columns),\\n                    dataset[\\\"y_train\\\"],\\n                ],\\n                axis=1,\\n            ).values,\\n            timesteps,\\n        )\\n\\n        dataset[\\\"x_test\\\"], dataset[\\\"y_test\\\"] = split_sequences(\\n            pd.concat(\\n                [\\n                    pd.DataFrame(dataset[\\\"x_test\\\"], columns=x.columns),\\n                    dataset[\\\"y_test\\\"],\\n                ],\\n                axis=1,\\n            ).values,\\n            timesteps,\\n        )\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_sequences(dataset, timesteps, split_by_cement_type=False):\n",
    "    if split_by_cement_type:\n",
    "        dataset[\"x_train\"], dataset[\"y_train\"] = split_sequences_per_cement_type(\n",
    "            pd.concat(\n",
    "                [\n",
    "                    dataset[\"dates_train\"],\n",
    "                    pd.DataFrame(dataset[\"x_train\"], columns=x.columns),\n",
    "                    dataset[\"cement_types_train\"],\n",
    "                    dataset[\"y_train\"],\n",
    "                ],\n",
    "                axis=1,\n",
    "            ),\n",
    "            timesteps,\n",
    "        )\n",
    "\n",
    "        dataset[\"x_test\"], dataset[\"y_test\"] = split_sequences_per_cement_type(\n",
    "            pd.concat(\n",
    "                [\n",
    "                    dataset[\"dates_test\"],\n",
    "                    pd.DataFrame(dataset[\"x_test\"], columns=x.columns),\n",
    "                    dataset[\"cement_types_test\"],\n",
    "                    dataset[\"y_test\"],\n",
    "                ],\n",
    "                axis=1,\n",
    "            ),\n",
    "            timesteps,\n",
    "        )\n",
    "    else:\n",
    "        dataset[\"x_train\"], dataset[\"y_train\"] = split_sequences(\n",
    "            pd.concat(\n",
    "                [\n",
    "                    pd.DataFrame(dataset[\"x_train\"], columns=x.columns),\n",
    "                    dataset[\"y_train\"],\n",
    "                ],\n",
    "                axis=1,\n",
    "            ).values,\n",
    "            timesteps,\n",
    "        )\n",
    "\n",
    "        dataset[\"x_test\"], dataset[\"y_test\"] = split_sequences(\n",
    "            pd.concat(\n",
    "                [\n",
    "                    pd.DataFrame(dataset[\"x_test\"], columns=x.columns),\n",
    "                    dataset[\"y_test\"],\n",
    "                ],\n",
    "                axis=1,\n",
    "            ).values,\n",
    "            timesteps,\n",
    "        )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f477d8",
   "metadata": {
    "papermill": {
     "duration": 0.016445,
     "end_time": "2024-04-04T21:18:20.313640",
     "exception": false,
     "start_time": "2024-04-04T21:18:20.297195",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a08b2d03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:18:20.360278Z",
     "iopub.status.busy": "2024-04-04T21:18:20.359510Z",
     "iopub.status.idle": "2024-04-04T21:18:20.485107Z",
     "shell.execute_reply": "2024-04-04T21:18:20.483706Z"
    },
    "papermill": {
     "duration": 0.157826,
     "end_time": "2024-04-04T21:18:20.488325",
     "exception": false,
     "start_time": "2024-04-04T21:18:20.330499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"def impute_data(dataset, imputer=None, imputer_params=None):\\n    x_train = dataset[\\\"x_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n\\n    # Apply imputation to the data\\n    if imputer is not None:\\n        imputer = imputer() if imputer_params is None else imputer(**imputer_params)\\n        x_train = imputer.fit_transform(x_train)\\n        x_test = imputer.transform(x_test)\\n\\n    dataset[\\\"x_train\\\"] = x_train\\n    dataset[\\\"x_test\\\"] = x_test\\n\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def impute_data(dataset, imputer=None, imputer_params=None):\\n    x_train = dataset[\\\"x_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n\\n    # Apply imputation to the data\\n    if imputer is not None:\\n        imputer = imputer() if imputer_params is None else imputer(**imputer_params)\\n        x_train = imputer.fit_transform(x_train)\\n        x_test = imputer.transform(x_test)\\n\\n    dataset[\\\"x_train\\\"] = x_train\\n    dataset[\\\"x_test\\\"] = x_test\\n\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def impute_data(dataset, imputer=None, imputer_params=None):\n",
    "    x_train = dataset[\"x_train\"]\n",
    "    x_test = dataset[\"x_test\"]\n",
    "\n",
    "    # Apply imputation to the data\n",
    "    if imputer is not None:\n",
    "        imputer = imputer() if imputer_params is None else imputer(**imputer_params)\n",
    "        x_train = imputer.fit_transform(x_train)\n",
    "        x_test = imputer.transform(x_test)\n",
    "\n",
    "    dataset[\"x_train\"] = x_train\n",
    "    dataset[\"x_test\"] = x_test\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "648bb166",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:18:20.525900Z",
     "iopub.status.busy": "2024-04-04T21:18:20.524620Z",
     "iopub.status.idle": "2024-04-04T21:18:20.684819Z",
     "shell.execute_reply": "2024-04-04T21:18:20.683316Z"
    },
    "papermill": {
     "duration": 0.182828,
     "end_time": "2024-04-04T21:18:20.688430",
     "exception": false,
     "start_time": "2024-04-04T21:18:20.505602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"def transform_data(dataset, transformer=None):\\n    x_train = dataset[\\\"x_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n\\n    # Apply data normalization/standardization to the data\\n    if transformer is not None:\\n        scaler = transformer()\\n        x_train = scaler.fit_transform(x_train)\\n        x_test = scaler.transform(x_test)\\n\\n    dataset[\\\"x_train\\\"] = x_train\\n    dataset[\\\"x_test\\\"] = x_test\\n\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def transform_data(dataset, transformer=None):\\n    x_train = dataset[\\\"x_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n\\n    # Apply data normalization/standardization to the data\\n    if transformer is not None:\\n        scaler = transformer()\\n        x_train = scaler.fit_transform(x_train)\\n        x_test = scaler.transform(x_test)\\n\\n    dataset[\\\"x_train\\\"] = x_train\\n    dataset[\\\"x_test\\\"] = x_test\\n\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def transform_data(dataset, transformer=None):\n",
    "    x_train = dataset[\"x_train\"]\n",
    "    x_test = dataset[\"x_test\"]\n",
    "\n",
    "    # Apply data normalization/standardization to the data\n",
    "    if transformer is not None:\n",
    "        scaler = transformer()\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "    dataset[\"x_train\"] = x_train\n",
    "    dataset[\"x_test\"] = x_test\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b911e5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:18:20.733076Z",
     "iopub.status.busy": "2024-04-04T21:18:20.732295Z",
     "iopub.status.idle": "2024-04-04T21:18:20.861497Z",
     "shell.execute_reply": "2024-04-04T21:18:20.859633Z"
    },
    "papermill": {
     "duration": 0.155051,
     "end_time": "2024-04-04T21:18:20.865107",
     "exception": false,
     "start_time": "2024-04-04T21:18:20.710056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"def preprocess_data(dataset, transformer=None, imputer=None, imputer_params=None):\\n    dataset = impute_data(dataset, imputer, imputer_params)\\n    dataset = transform_data(dataset, transformer)\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def preprocess_data(dataset, transformer=None, imputer=None, imputer_params=None):\\n    dataset = impute_data(dataset, imputer, imputer_params)\\n    dataset = transform_data(dataset, transformer)\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_data(dataset, transformer=None, imputer=None, imputer_params=None):\n",
    "    dataset = impute_data(dataset, imputer, imputer_params)\n",
    "    dataset = transform_data(dataset, transformer)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae2b5a6",
   "metadata": {
    "papermill": {
     "duration": 0.021282,
     "end_time": "2024-04-04T21:18:20.909920",
     "exception": false,
     "start_time": "2024-04-04T21:18:20.888638",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1003e019",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:18:20.973661Z",
     "iopub.status.busy": "2024-04-04T21:18:20.972895Z",
     "iopub.status.idle": "2024-04-04T21:18:21.089495Z",
     "shell.execute_reply": "2024-04-04T21:18:21.087571Z"
    },
    "papermill": {
     "duration": 0.153152,
     "end_time": "2024-04-04T21:18:21.093411",
     "exception": false,
     "start_time": "2024-04-04T21:18:20.940259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"def train_and_evaluate_model(Estimator, dataset, estimator_params=None):\\n    \\\"\\\"\\\"\\n    Purpose: Helper function to be used in conjunction with\\n    blocked time_series cross validation function\\n    \\\"\\\"\\\"\\n    x_train = dataset[\\\"x_train\\\"]\\n    y_train = dataset[\\\"y_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n    y_test = dataset[\\\"y_test\\\"]\\n\\n    # Instantiate the model\\n    model = Estimator() if estimator_params is None else Estimator(**estimator_params)\\n\\n    # Fitting the model\\n    model.fit(x_train, y_train)\\n\\n    # Making predictions on train/test sets\\n    y_train_pred = model.predict(x_train)\\n    y_test_pred = model.predict(x_test)\\n\\n    # Return regression metrics\\n    return score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"def train_and_evaluate_model(Estimator, dataset, estimator_params=None):\\n    \\\"\\\"\\\"\\n    Purpose: Helper function to be used in conjunction with\\n    blocked time_series cross validation function\\n    \\\"\\\"\\\"\\n    x_train = dataset[\\\"x_train\\\"]\\n    y_train = dataset[\\\"y_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n    y_test = dataset[\\\"y_test\\\"]\\n\\n    # Instantiate the model\\n    model = Estimator() if estimator_params is None else Estimator(**estimator_params)\\n\\n    # Fitting the model\\n    model.fit(x_train, y_train)\\n\\n    # Making predictions on train/test sets\\n    y_train_pred = model.predict(x_train)\\n    y_test_pred = model.predict(x_test)\\n\\n    # Return regression metrics\\n    return score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_and_evaluate_model(Estimator, dataset, estimator_params=None):\n",
    "    \"\"\"\n",
    "    Purpose: Helper function to be used in conjunction with\n",
    "    blocked time_series cross validation function\n",
    "    \"\"\"\n",
    "    x_train = dataset[\"x_train\"]\n",
    "    y_train = dataset[\"y_train\"]\n",
    "    x_test = dataset[\"x_test\"]\n",
    "    y_test = dataset[\"y_test\"]\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = Estimator() if estimator_params is None else Estimator(**estimator_params)\n",
    "\n",
    "    # Fitting the model\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Making predictions on train/test sets\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "\n",
    "    # Return regression metrics\n",
    "    return score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c7568e",
   "metadata": {
    "papermill": {
     "duration": 0.021872,
     "end_time": "2024-04-04T21:18:21.138523",
     "exception": false,
     "start_time": "2024-04-04T21:18:21.116651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Custom Cross Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3713ce2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:18:21.185070Z",
     "iopub.status.busy": "2024-04-04T21:18:21.184468Z",
     "iopub.status.idle": "2024-04-04T21:18:21.332205Z",
     "shell.execute_reply": "2024-04-04T21:18:21.330524Z"
    },
    "papermill": {
     "duration": 0.17357,
     "end_time": "2024-04-04T21:18:21.335796",
     "exception": false,
     "start_time": "2024-04-04T21:18:21.162226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"def custom_cross_validate(\\n    Estimator,\\n    Imputer,\\n    Transform,\\n    x,\\n    y,\\n    cv,\\n    timesteps,\\n    dates=None,\\n    cement_types=None,\\n    estimator_params=None,\\n    imputer_params=None,\\n    split_by_cement_type=True,\\n):\\n    results = []\\n    scores = []\\n\\n    for train_index, test_index in cv.split(x):\\n        dataset = {\\n            \\\"dates_train\\\": dates[train_index].reset_index(drop=True),\\n            \\\"cement_types_train\\\": cement_types.loc[train_index].reset_index(drop=True),\\n            \\\"x_train\\\": x.loc[train_index].reset_index(drop=True),\\n            \\\"y_train\\\": y[train_index].reset_index(drop=True),\\n            \\\"dates_test\\\": dates[test_index].reset_index(drop=True),\\n            \\\"cement_types_test\\\": cement_types.loc[test_index].reset_index(drop=True),\\n            \\\"x_test\\\": x.loc[test_index].reset_index(drop=True),\\n            \\\"y_test\\\": y[test_index].reset_index(drop=True),\\n        }\\n\\n        # Preprocess the dataset\\n        dataset = preprocess_data(dataset, Transform, Imputer, imputer_params)\\n\\n        # generate sequences (3D format)\\n        dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\\n\\n        # Train and Evaluate the model\\n        score = train_and_evaluate_model(Estimator, dataset, estimator_params)\\n        scores.append(score)\\n\\n    # After every iteration metrics results are appended together\\n    scores_final = {key: [] for key, _ in scores[0].items()}\\n    for scores_dict in scores:\\n        for key, value in scores_dict.items():\\n            scores_final[key] += [value]\\n    results.append(scores_final)\\n    return results\";\n",
       "                var nbb_formatted_code = \"def custom_cross_validate(\\n    Estimator,\\n    Imputer,\\n    Transform,\\n    x,\\n    y,\\n    cv,\\n    timesteps,\\n    dates=None,\\n    cement_types=None,\\n    estimator_params=None,\\n    imputer_params=None,\\n    split_by_cement_type=True,\\n):\\n    results = []\\n    scores = []\\n\\n    for train_index, test_index in cv.split(x):\\n        dataset = {\\n            \\\"dates_train\\\": dates[train_index].reset_index(drop=True),\\n            \\\"cement_types_train\\\": cement_types.loc[train_index].reset_index(drop=True),\\n            \\\"x_train\\\": x.loc[train_index].reset_index(drop=True),\\n            \\\"y_train\\\": y[train_index].reset_index(drop=True),\\n            \\\"dates_test\\\": dates[test_index].reset_index(drop=True),\\n            \\\"cement_types_test\\\": cement_types.loc[test_index].reset_index(drop=True),\\n            \\\"x_test\\\": x.loc[test_index].reset_index(drop=True),\\n            \\\"y_test\\\": y[test_index].reset_index(drop=True),\\n        }\\n\\n        # Preprocess the dataset\\n        dataset = preprocess_data(dataset, Transform, Imputer, imputer_params)\\n\\n        # generate sequences (3D format)\\n        dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\\n\\n        # Train and Evaluate the model\\n        score = train_and_evaluate_model(Estimator, dataset, estimator_params)\\n        scores.append(score)\\n\\n    # After every iteration metrics results are appended together\\n    scores_final = {key: [] for key, _ in scores[0].items()}\\n    for scores_dict in scores:\\n        for key, value in scores_dict.items():\\n            scores_final[key] += [value]\\n    results.append(scores_final)\\n    return results\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def custom_cross_validate(\n",
    "    Estimator,\n",
    "    Imputer,\n",
    "    Transform,\n",
    "    x,\n",
    "    y,\n",
    "    cv,\n",
    "    timesteps,\n",
    "    dates=None,\n",
    "    cement_types=None,\n",
    "    estimator_params=None,\n",
    "    imputer_params=None,\n",
    "    split_by_cement_type=True,\n",
    "):\n",
    "    results = []\n",
    "    scores = []\n",
    "\n",
    "    for train_index, test_index in cv.split(x):\n",
    "        dataset = {\n",
    "            \"dates_train\": dates[train_index].reset_index(drop=True),\n",
    "            \"cement_types_train\": cement_types.loc[train_index].reset_index(drop=True),\n",
    "            \"x_train\": x.loc[train_index].reset_index(drop=True),\n",
    "            \"y_train\": y[train_index].reset_index(drop=True),\n",
    "            \"dates_test\": dates[test_index].reset_index(drop=True),\n",
    "            \"cement_types_test\": cement_types.loc[test_index].reset_index(drop=True),\n",
    "            \"x_test\": x.loc[test_index].reset_index(drop=True),\n",
    "            \"y_test\": y[test_index].reset_index(drop=True),\n",
    "        }\n",
    "\n",
    "        # Preprocess the dataset\n",
    "        dataset = preprocess_data(dataset, Transform, Imputer, imputer_params)\n",
    "\n",
    "        # generate sequences (3D format)\n",
    "        dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\n",
    "\n",
    "        # Train and Evaluate the model\n",
    "        score = train_and_evaluate_model(Estimator, dataset, estimator_params)\n",
    "        scores.append(score)\n",
    "\n",
    "    # After every iteration metrics results are appended together\n",
    "    scores_final = {key: [] for key, _ in scores[0].items()}\n",
    "    for scores_dict in scores:\n",
    "        for key, value in scores_dict.items():\n",
    "            scores_final[key] += [value]\n",
    "    results.append(scores_final)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f2af59",
   "metadata": {
    "papermill": {
     "duration": 0.02163,
     "end_time": "2024-04-04T21:18:21.382235",
     "exception": false,
     "start_time": "2024-04-04T21:18:21.360605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0a65a4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:18:21.431382Z",
     "iopub.status.busy": "2024-04-04T21:18:21.430780Z",
     "iopub.status.idle": "2024-04-04T21:18:21.591441Z",
     "shell.execute_reply": "2024-04-04T21:18:21.590043Z"
    },
    "papermill": {
     "duration": 0.18787,
     "end_time": "2024-04-04T21:18:21.594415",
     "exception": false,
     "start_time": "2024-04-04T21:18:21.406545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class GRU(BaseEstimator, RegressorMixin):\\n    def __init__(self):\\n        self.model = self.get_model()\\n        self.batch_size = 16\\n        self.epochs = 300\\n        self.verbose = 0\\n\\n    def fit(self, X=None, y=None):\\n        self.model.fit(\\n            X, y, batch_size=self.batch_size, epochs=self.epochs, verbose=self.verbose\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.GRU(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            # optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class GRU(BaseEstimator, RegressorMixin):\\n    def __init__(self):\\n        self.model = self.get_model()\\n        self.batch_size = 16\\n        self.epochs = 300\\n        self.verbose = 0\\n\\n    def fit(self, X=None, y=None):\\n        self.model.fit(\\n            X, y, batch_size=self.batch_size, epochs=self.epochs, verbose=self.verbose\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.GRU(units=16, activation=\\\"relu\\\"))\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            # optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class GRU(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 16\n",
    "        self.epochs = 300\n",
    "        self.verbose = 0\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.model.fit(\n",
    "            X, y, batch_size=self.batch_size, epochs=self.epochs, verbose=self.verbose\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.GRU(units=16, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            # optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dfcf2b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:18:21.632759Z",
     "iopub.status.busy": "2024-04-04T21:18:21.632176Z",
     "iopub.status.idle": "2024-04-04T21:18:21.814909Z",
     "shell.execute_reply": "2024-04-04T21:18:21.813258Z"
    },
    "papermill": {
     "duration": 0.205642,
     "end_time": "2024-04-04T21:18:21.818281",
     "exception": false,
     "start_time": "2024-04-04T21:18:21.612639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"def pad_time_series(dataframe, timesteps):\\n    \\\"\\\"\\\"\\n    Pad timeseries with zeros\\n    \\\"\\\"\\\"\\n    df_tmp = pd.DataFrame(\\n        dict(\\n            zip(\\n                dataframe.columns,\\n                [[0 for _ in range(timesteps - 1)] for _ in range(dataframe.shape[1])],\\n            )\\n        )\\n    )\\n    df_tmp[DATE] = dataframe[DATE].iloc[0]\\n    return pd.concat([df_tmp, dataframe], axis=0).reset_index(drop=True)\";\n",
       "                var nbb_formatted_code = \"def pad_time_series(dataframe, timesteps):\\n    \\\"\\\"\\\"\\n    Pad timeseries with zeros\\n    \\\"\\\"\\\"\\n    df_tmp = pd.DataFrame(\\n        dict(\\n            zip(\\n                dataframe.columns,\\n                [[0 for _ in range(timesteps - 1)] for _ in range(dataframe.shape[1])],\\n            )\\n        )\\n    )\\n    df_tmp[DATE] = dataframe[DATE].iloc[0]\\n    return pd.concat([df_tmp, dataframe], axis=0).reset_index(drop=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pad_time_series(dataframe, timesteps):\n",
    "    \"\"\"\n",
    "    Pad timeseries with zeros\n",
    "    \"\"\"\n",
    "    df_tmp = pd.DataFrame(\n",
    "        dict(\n",
    "            zip(\n",
    "                dataframe.columns,\n",
    "                [[0 for _ in range(timesteps - 1)] for _ in range(dataframe.shape[1])],\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    df_tmp[DATE] = dataframe[DATE].iloc[0]\n",
    "    return pd.concat([df_tmp, dataframe], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51a54d06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:18:21.862993Z",
     "iopub.status.busy": "2024-04-04T21:18:21.862390Z",
     "iopub.status.idle": "2024-04-04T21:18:22.019212Z",
     "shell.execute_reply": "2024-04-04T21:18:22.017530Z"
    },
    "papermill": {
     "duration": 0.183524,
     "end_time": "2024-04-04T21:18:22.023093",
     "exception": false,
     "start_time": "2024-04-04T21:18:21.839569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"def split_sequences_per_cement_type(dataframe, timesteps, pad=False):\\n    \\\"\\\"\\\"\\n    Create sequences per cement time\\n    to avoid having parts of the sequence\\n    of different types of cement.\\n    \\\"\\\"\\\"\\n    if timesteps == 1:\\n        return split_sequences(\\n            dataframe.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps\\n        )\\n\\n    dates = dataframe[DATE][timesteps - 1 :]\\n    data = []\\n    dataframes = []\\n\\n    for cement_type in CEMENT_TYPES:\\n        data.append(dataframe[dataframe[cement_type] == 1])\\n    data.append(dataframe[(dataframe[CEMENT_TYPES] == 0).all(axis=1)])\\n\\n    for df in data:\\n        if pad:\\n            dates = df[DATE].reset_index(drop=True)\\n            df = pad_time_series(df, timesteps).reset_index(drop=True)\\n        else:\\n            dates = df[DATE][timesteps - 1 :].reset_index(drop=True)\\n        x, y = split_sequences(df.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps)\\n        x = pd.DataFrame({\\\"Sequences\\\": [sample.tolist() for sample in x]})\\n        y = pd.DataFrame({\\\"Target\\\": y})\\n        dataframes.append(pd.concat([dates, x, y], axis=1))\\n\\n    data = pd.concat(dataframes, axis=0)\\n    data[DATE] = pd.to_datetime(data[DATE])\\n    data = data.sort_values(by=DATE).reset_index(drop=True)\\n    x = data[\\\"Sequences\\\"]\\n    y = data[\\\"Target\\\"].values\\n    x = np.array(x.tolist())\\n\\n    return x, y\";\n",
       "                var nbb_formatted_code = \"def split_sequences_per_cement_type(dataframe, timesteps, pad=False):\\n    \\\"\\\"\\\"\\n    Create sequences per cement time\\n    to avoid having parts of the sequence\\n    of different types of cement.\\n    \\\"\\\"\\\"\\n    if timesteps == 1:\\n        return split_sequences(\\n            dataframe.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps\\n        )\\n\\n    dates = dataframe[DATE][timesteps - 1 :]\\n    data = []\\n    dataframes = []\\n\\n    for cement_type in CEMENT_TYPES:\\n        data.append(dataframe[dataframe[cement_type] == 1])\\n    data.append(dataframe[(dataframe[CEMENT_TYPES] == 0).all(axis=1)])\\n\\n    for df in data:\\n        if pad:\\n            dates = df[DATE].reset_index(drop=True)\\n            df = pad_time_series(df, timesteps).reset_index(drop=True)\\n        else:\\n            dates = df[DATE][timesteps - 1 :].reset_index(drop=True)\\n        x, y = split_sequences(df.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps)\\n        x = pd.DataFrame({\\\"Sequences\\\": [sample.tolist() for sample in x]})\\n        y = pd.DataFrame({\\\"Target\\\": y})\\n        dataframes.append(pd.concat([dates, x, y], axis=1))\\n\\n    data = pd.concat(dataframes, axis=0)\\n    data[DATE] = pd.to_datetime(data[DATE])\\n    data = data.sort_values(by=DATE).reset_index(drop=True)\\n    x = data[\\\"Sequences\\\"]\\n    y = data[\\\"Target\\\"].values\\n    x = np.array(x.tolist())\\n\\n    return x, y\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def split_sequences_per_cement_type(dataframe, timesteps, pad=False):\n",
    "    \"\"\"\n",
    "    Create sequences per cement time\n",
    "    to avoid having parts of the sequence\n",
    "    of different types of cement.\n",
    "    \"\"\"\n",
    "    if timesteps == 1:\n",
    "        return split_sequences(\n",
    "            dataframe.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps\n",
    "        )\n",
    "\n",
    "    dates = dataframe[DATE][timesteps - 1 :]\n",
    "    data = []\n",
    "    dataframes = []\n",
    "\n",
    "    for cement_type in CEMENT_TYPES:\n",
    "        data.append(dataframe[dataframe[cement_type] == 1])\n",
    "    data.append(dataframe[(dataframe[CEMENT_TYPES] == 0).all(axis=1)])\n",
    "\n",
    "    for df in data:\n",
    "        if pad:\n",
    "            dates = df[DATE].reset_index(drop=True)\n",
    "            df = pad_time_series(df, timesteps).reset_index(drop=True)\n",
    "        else:\n",
    "            dates = df[DATE][timesteps - 1 :].reset_index(drop=True)\n",
    "        x, y = split_sequences(df.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps)\n",
    "        x = pd.DataFrame({\"Sequences\": [sample.tolist() for sample in x]})\n",
    "        y = pd.DataFrame({\"Target\": y})\n",
    "        dataframes.append(pd.concat([dates, x, y], axis=1))\n",
    "\n",
    "    data = pd.concat(dataframes, axis=0)\n",
    "    data[DATE] = pd.to_datetime(data[DATE])\n",
    "    data = data.sort_values(by=DATE).reset_index(drop=True)\n",
    "    x = data[\"Sequences\"]\n",
    "    y = data[\"Target\"].values\n",
    "    x = np.array(x.tolist())\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45abe932",
   "metadata": {
    "papermill": {
     "duration": 0.022308,
     "end_time": "2024-04-04T21:18:22.073442",
     "exception": false,
     "start_time": "2024-04-04T21:18:22.051134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8bde1cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:18:22.123036Z",
     "iopub.status.busy": "2024-04-04T21:18:22.122430Z",
     "iopub.status.idle": "2024-04-04T21:18:22.265872Z",
     "shell.execute_reply": "2024-04-04T21:18:22.264547Z"
    },
    "papermill": {
     "duration": 0.176855,
     "end_time": "2024-04-04T21:18:22.268526",
     "exception": false,
     "start_time": "2024-04-04T21:18:22.091671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6a58773",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:18:22.302639Z",
     "iopub.status.busy": "2024-04-04T21:18:22.302041Z",
     "iopub.status.idle": "2024-04-04T21:18:22.462376Z",
     "shell.execute_reply": "2024-04-04T21:18:22.460988Z"
    },
    "papermill": {
     "duration": 0.181943,
     "end_time": "2024-04-04T21:18:22.465802",
     "exception": false,
     "start_time": "2024-04-04T21:18:22.283859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"def set_global_determinism():\\n    set_seeds(seed=SEED)\\n\\n    os.environ[\\\"TF_DETERMINISTIC_OPS\\\"] = \\\"1\\\"\\n    os.environ[\\\"TF_CUDNN_DETERMINISTIC\\\"] = \\\"1\\\"\\n\\n    tf.config.threading.set_inter_op_parallelism_threads(1)\\n    tf.config.threading.set_intra_op_parallelism_threads(1)\";\n",
       "                var nbb_formatted_code = \"def set_global_determinism():\\n    set_seeds(seed=SEED)\\n\\n    os.environ[\\\"TF_DETERMINISTIC_OPS\\\"] = \\\"1\\\"\\n    os.environ[\\\"TF_CUDNN_DETERMINISTIC\\\"] = \\\"1\\\"\\n\\n    tf.config.threading.set_inter_op_parallelism_threads(1)\\n    tf.config.threading.set_intra_op_parallelism_threads(1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_global_determinism():\n",
    "    set_seeds(seed=SEED)\n",
    "\n",
    "    os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "    os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd9b93f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:18:22.512704Z",
     "iopub.status.busy": "2024-04-04T21:18:22.512023Z",
     "iopub.status.idle": "2024-04-04T21:18:22.657484Z",
     "shell.execute_reply": "2024-04-04T21:18:22.655960Z"
    },
    "papermill": {
     "duration": 0.174628,
     "end_time": "2024-04-04T21:18:22.661556",
     "exception": false,
     "start_time": "2024-04-04T21:18:22.486928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"index_to_save = 10\";\n",
       "                var nbb_formatted_code = \"index_to_save = 10\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91ad05ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:18:22.712572Z",
     "iopub.status.busy": "2024-04-04T21:18:22.711262Z",
     "iopub.status.idle": "2024-04-04T21:18:22.854590Z",
     "shell.execute_reply": "2024-04-04T21:18:22.852976Z"
    },
    "papermill": {
     "duration": 0.17191,
     "end_time": "2024-04-04T21:18:22.858216",
     "exception": false,
     "start_time": "2024-04-04T21:18:22.686306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\\nDATE = \\\"Date\\\"\\nCEMENT_TYPES = [\\n    \\\"Cement_Type_CP III32\\\",\\n    \\\"Cement_Type_CP III40\\\",\\n    \\\"Cement_Type_CP VARI\\\",\\n    \\\"Cement_Type_Fibrocimento\\\",\\n]\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\\nDATE = \\\"Date\\\"\\nCEMENT_TYPES = [\\n    \\\"Cement_Type_CP III32\\\",\\n    \\\"Cement_Type_CP III40\\\",\\n    \\\"Cement_Type_CP VARI\\\",\\n    \\\"Cement_Type_Fibrocimento\\\",\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}\n",
    "DATE = \"Date\"\n",
    "CEMENT_TYPES = [\n",
    "    \"Cement_Type_CP III32\",\n",
    "    \"Cement_Type_CP III40\",\n",
    "    \"Cement_Type_CP VARI\",\n",
    "    \"Cement_Type_Fibrocimento\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2af03af",
   "metadata": {
    "papermill": {
     "duration": 0.01964,
     "end_time": "2024-04-04T21:18:22.898083",
     "exception": false,
     "start_time": "2024-04-04T21:18:22.878443",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67067392",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:18:22.958269Z",
     "iopub.status.busy": "2024-04-04T21:18:22.957449Z",
     "iopub.status.idle": "2024-04-04T21:18:23.097880Z",
     "shell.execute_reply": "2024-04-04T21:18:23.096533Z"
    },
    "papermill": {
     "duration": 0.17676,
     "end_time": "2024-04-04T21:18:23.101797",
     "exception": false,
     "start_time": "2024-04-04T21:18:22.925037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Local Model\\\",\\n    \\\"Company\\\": \\\"203\\\",\\n    \\\"Plant\\\": \\\"Y\\\",\\n    \\\"Features\\\": \\\"Chemical + Properties CS Less\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"GRU\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Local Model\\\",\\n    \\\"Company\\\": \\\"203\\\",\\n    \\\"Plant\\\": \\\"Y\\\",\\n    \\\"Features\\\": \\\"Chemical + Properties CS Less\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"GRU\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Local Model\",\n",
    "    \"Company\": \"203\",\n",
    "    \"Plant\": \"Y\",\n",
    "    \"Features\": \"Chemical + Properties CS Less\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"GRU\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823d1414",
   "metadata": {
    "papermill": {
     "duration": 0.023616,
     "end_time": "2024-04-04T21:18:23.154343",
     "exception": false,
     "start_time": "2024-04-04T21:18:23.130727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62a8f34d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:18:23.203686Z",
     "iopub.status.busy": "2024-04-04T21:18:23.202867Z",
     "iopub.status.idle": "2024-04-04T21:18:23.287940Z",
     "shell.execute_reply": "2024-04-04T21:18:23.286529Z"
    },
    "papermill": {
     "duration": 0.110731,
     "end_time": "2024-04-04T21:18:23.291157",
     "exception": false,
     "start_time": "2024-04-04T21:18:23.180426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../data/processed/203/y.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../data/processed/203/y.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../data/processed/203/y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365e3aaf",
   "metadata": {
    "papermill": {
     "duration": 0.019975,
     "end_time": "2024-04-04T21:18:23.331907",
     "exception": false,
     "start_time": "2024-04-04T21:18:23.311932",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we keep only chemical and mineralogical features yielded by the same testing method/procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bda6cdce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:18:23.382210Z",
     "iopub.status.busy": "2024-04-04T21:18:23.381155Z",
     "iopub.status.idle": "2024-04-04T21:18:23.519064Z",
     "shell.execute_reply": "2024-04-04T21:18:23.517365Z"
    },
    "papermill": {
     "duration": 0.167794,
     "end_time": "2024-04-04T21:18:23.522439",
     "exception": false,
     "start_time": "2024-04-04T21:18:23.354645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy()\\ndf_copy = pd.get_dummies(data=df_copy, columns=[\\\"Cement_Type\\\"], drop_first=True)\\n\\ndf_copy = df_copy.drop(\\n    [\\n        \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy()\\ndf_copy = pd.get_dummies(data=df_copy, columns=[\\\"Cement_Type\\\"], drop_first=True)\\n\\ndf_copy = df_copy.drop(\\n    [\\n        \\\"CS1\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy()\n",
    "df_copy = pd.get_dummies(data=df_copy, columns=[\"Cement_Type\"], drop_first=True)\n",
    "\n",
    "df_copy = df_copy.drop(\n",
    "    [\n",
    "        \"CS1\",\n",
    "        \"CS3\",\n",
    "        \"CS7\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7bfa62",
   "metadata": {
    "papermill": {
     "duration": 0.023263,
     "end_time": "2024-04-04T21:18:23.569569",
     "exception": false,
     "start_time": "2024-04-04T21:18:23.546306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d70dc97",
   "metadata": {
    "papermill": {
     "duration": 0.021099,
     "end_time": "2024-04-04T21:18:23.612816",
     "exception": false,
     "start_time": "2024-04-04T21:18:23.591717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2>1. Dataset: df_no_cs</h2> <br>In this dataset the CS1, CS3  and CS7 variables are not considered. Only Chemical and mineralogical features measured by the same method. For this particular dataset, all chemical features, with the exception of LOI were measured by XRF and XRD methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97440219",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:18:23.663872Z",
     "iopub.status.busy": "2024-04-04T21:18:23.663253Z",
     "iopub.status.idle": "2024-04-04T21:18:23.686131Z",
     "shell.execute_reply": "2024-04-04T21:18:23.684822Z"
    },
    "papermill": {
     "duration": 0.042253,
     "end_time": "2024-04-04T21:18:23.688716",
     "exception": false,
     "start_time": "2024-04-04T21:18:23.646463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"df_copy[CEMENT_TYPES] = df_copy[CEMENT_TYPES].astype(int)\\ndates = df[\\\"Date\\\"].copy()\\ny = df_copy.pop(\\\"CS28\\\")\\nx = df_copy\\ndf_copy = pd.concat([x, y], axis=1)\";\n",
       "                var nbb_formatted_code = \"df_copy[CEMENT_TYPES] = df_copy[CEMENT_TYPES].astype(int)\\ndates = df[\\\"Date\\\"].copy()\\ny = df_copy.pop(\\\"CS28\\\")\\nx = df_copy\\ndf_copy = pd.concat([x, y], axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy[CEMENT_TYPES] = df_copy[CEMENT_TYPES].astype(int)\n",
    "dates = df[\"Date\"].copy()\n",
    "y = df_copy.pop(\"CS28\")\n",
    "x = df_copy\n",
    "df_copy = pd.concat([x, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4ff4ef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:18:23.744480Z",
     "iopub.status.busy": "2024-04-04T21:18:23.743640Z",
     "iopub.status.idle": "2024-04-04T21:18:23.869656Z",
     "shell.execute_reply": "2024-04-04T21:18:23.868016Z"
    },
    "papermill": {
     "duration": 0.16723,
     "end_time": "2024-04-04T21:18:23.872371",
     "exception": false,
     "start_time": "2024-04-04T21:18:23.705141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"TIMESTEPS_LIST = [1, 7, 14]\";\n",
       "                var nbb_formatted_code = \"TIMESTEPS_LIST = [1, 7, 14]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TIMESTEPS_LIST = [1, 7, 14]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee695b4",
   "metadata": {
    "papermill": {
     "duration": 0.028784,
     "end_time": "2024-04-04T21:18:23.917601",
     "exception": false,
     "start_time": "2024-04-04T21:18:23.888817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Long Short Term Memory - GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0caf91",
   "metadata": {
    "papermill": {
     "duration": 0.036287,
     "end_time": "2024-04-04T21:18:23.992269",
     "exception": false,
     "start_time": "2024-04-04T21:18:23.955982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.1 Repeated KFold Cross validation\n",
    "\n",
    "<b>Dataset shape:</b> (1234, 38)<br>\n",
    "<b>Timesteps:</b> 1, 3, 5, 7, 10, 15, 20<br>\n",
    "<b>Repeats:</b>10<br>\n",
    "<b>Splits:</b>10<br>\n",
    "    1. 10 folds of 123 samples each\n",
    "    2. 90% train (1111 samples each fold)\n",
    "    3. 10% test (123 samples each fold)\n",
    "<b>Total:</b> 100 models<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8cabd32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:18:24.054134Z",
     "iopub.status.busy": "2024-04-04T21:18:24.052727Z",
     "iopub.status.idle": "2024-04-04T22:17:05.699949Z",
     "shell.execute_reply": "2024-04-04T22:17:05.698255Z"
    },
    "papermill": {
     "duration": 3521.722027,
     "end_time": "2024-04-04T22:17:05.740398",
     "exception": false,
     "start_time": "2024-04-04T21:18:24.018371",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated Cross Validation:\n",
      "Repeats: 3\n",
      "n_splits: 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-04 18:18:24.220472: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-04-04 18:18:24.220522: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: inspirada\n",
      "2024-04-04 18:18:24.220530: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: inspirada\n",
      "2024-04-04 18:18:24.220735: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 525.147.5\n",
      "2024-04-04 18:18:24.220777: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 525.147.5\n",
      "2024-04-04 18:18:24.220788: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 525.147.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 1 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.075 (0.086)\n",
      "MAE: 1.624 (0.066)\n",
      "MAPE: 0.037 (0.001)\n",
      "R2: 0.813 (0.017)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.215 (0.131)\n",
      "MAE: 1.734 (0.098)\n",
      "MAPE: 0.040 (0.002)\n",
      "R2: 0.785 (0.026)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 7 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.912 (0.075)\n",
      "MAE: 1.518 (0.060)\n",
      "MAPE: 0.035 (0.001)\n",
      "R2: 0.839 (0.012)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.450 (0.281)\n",
      "MAE: 1.921 (0.167)\n",
      "MAPE: 0.044 (0.004)\n",
      "R2: 0.718 (0.066)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 14 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.957 (0.183)\n",
      "MAE: 1.547 (0.150)\n",
      "MAPE: 0.035 (0.003)\n",
      "R2: 0.826 (0.032)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.429 (0.203)\n",
      "MAE: 1.917 (0.178)\n",
      "MAPE: 0.044 (0.004)\n",
      "R2: 0.707 (0.037)\n",
      "\n",
      "======================\n",
      "\n",
      "Minutes Elapsed:  58.69278392791748\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"start = time.time()\\n\\nrepeats = 3\\nn_splits = 5\\nTIMESTEPS_LIST = [1, 7, 14]\\n\\nprint(\\\"Repeated Cross Validation:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n    cv = RepeatedKFold(n_splits=n_splits, n_repeats=repeats, random_state=SEED)\\n    x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1)\\n    y = df_copy[\\\"CS28\\\"]\\n    scores = custom_cross_validate(\\n        GRU,\\n        SimpleImputer,\\n        StandardScaler,\\n        x,\\n        y,\\n        cv,\\n        timesteps=timesteps,\\n        dates=dates,\\n        cement_types=df_copy[CEMENT_TYPES],\\n        estimator_params=None,\\n        imputer_params={\\\"strategy\\\": \\\"median\\\"},\\n        split_by_cement_type=True,\\n    )\\n    scores = scores[0]\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores, METRICS, METRICS_DICT)\\n\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Repeated KFold\\\"\\n    results_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(results_dict_copy, scores)\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"start = time.time()\\n\\nrepeats = 3\\nn_splits = 5\\nTIMESTEPS_LIST = [1, 7, 14]\\n\\nprint(\\\"Repeated Cross Validation:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n    cv = RepeatedKFold(n_splits=n_splits, n_repeats=repeats, random_state=SEED)\\n    x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1)\\n    y = df_copy[\\\"CS28\\\"]\\n    scores = custom_cross_validate(\\n        GRU,\\n        SimpleImputer,\\n        StandardScaler,\\n        x,\\n        y,\\n        cv,\\n        timesteps=timesteps,\\n        dates=dates,\\n        cement_types=df_copy[CEMENT_TYPES],\\n        estimator_params=None,\\n        imputer_params={\\\"strategy\\\": \\\"median\\\"},\\n        split_by_cement_type=True,\\n    )\\n    scores = scores[0]\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores, METRICS, METRICS_DICT)\\n\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Repeated KFold\\\"\\n    results_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(results_dict_copy, scores)\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "repeats = 3\n",
    "n_splits = 5\n",
    "TIMESTEPS_LIST = [1, 7, 14]\n",
    "\n",
    "print(\"Repeated Cross Validation:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"n_splits: {n_splits}\")\n",
    "print()\n",
    "\n",
    "for timesteps in TIMESTEPS_LIST:\n",
    "    set_seeds()\n",
    "    cv = RepeatedKFold(n_splits=n_splits, n_repeats=repeats, random_state=SEED)\n",
    "    x = df_copy.drop([\"Date\", \"CS28\"] + CEMENT_TYPES, axis=1)\n",
    "    y = df_copy[\"CS28\"]\n",
    "    scores = custom_cross_validate(\n",
    "        GRU,\n",
    "        SimpleImputer,\n",
    "        StandardScaler,\n",
    "        x,\n",
    "        y,\n",
    "        cv,\n",
    "        timesteps=timesteps,\n",
    "        dates=dates,\n",
    "        cement_types=df_copy[CEMENT_TYPES],\n",
    "        estimator_params=None,\n",
    "        imputer_params={\"strategy\": \"median\"},\n",
    "        split_by_cement_type=True,\n",
    "    )\n",
    "    scores = scores[0]\n",
    "    print(\"TIMESTEPS: %d \" % timesteps)\n",
    "    print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "    results_dict_copy = results_dict.copy()\n",
    "    results_dict_copy[\"Timesteps\"] = timesteps\n",
    "    results_dict_copy[\"Cross Validation\"] = \"Repeated KFold\"\n",
    "    results_dict_copy[\"Cross Validation Params\"] = '{\"N_Splits\": 5, \"Repeats\": 3}'\n",
    "    results_dict_copy[\"Data Shape\"] = x.shape\n",
    "    df_results = fill_results_dict(results_dict_copy, scores)\n",
    "    results_to_save.append(df_results)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b656404d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T22:17:05.782698Z",
     "iopub.status.busy": "2024-04-04T22:17:05.781981Z",
     "iopub.status.idle": "2024-04-04T22:17:05.848861Z",
     "shell.execute_reply": "2024-04-04T22:17:05.848116Z"
    },
    "papermill": {
     "duration": 0.088795,
     "end_time": "2024-04-04T22:17:05.852096",
     "exception": false,
     "start_time": "2024-04-04T22:17:05.763301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RMSE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAPE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R2 Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>1</td>\n",
       "      <td>2.215293</td>\n",
       "      <td>0.130524</td>\n",
       "      <td>1.734022</td>\n",
       "      <td>0.098446</td>\n",
       "      <td>0.040019</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.785492</td>\n",
       "      <td>0.025761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>7</td>\n",
       "      <td>2.450196</td>\n",
       "      <td>0.280959</td>\n",
       "      <td>1.921496</td>\n",
       "      <td>0.167354</td>\n",
       "      <td>0.044479</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>0.718135</td>\n",
       "      <td>0.065752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>14</td>\n",
       "      <td>2.428609</td>\n",
       "      <td>0.203399</td>\n",
       "      <td>1.917467</td>\n",
       "      <td>0.178067</td>\n",
       "      <td>0.043778</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.706559</td>\n",
       "      <td>0.037062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Features Model Cross Validation Timesteps RMSE Test  \\\n",
       "                                                                       mean   \n",
       "0  Chemical + Properties CS Less   GRU   Repeated KFold         1  2.215293   \n",
       "1  Chemical + Properties CS Less   GRU   Repeated KFold         7  2.450196   \n",
       "2  Chemical + Properties CS Less   GRU   Repeated KFold        14  2.428609   \n",
       "\n",
       "             MAE Test           MAPE Test             R2 Test            \n",
       "        std      mean       std      mean       std      mean       std  \n",
       "0  0.130524  1.734022  0.098446  0.040019  0.002141  0.785492  0.025761  \n",
       "1  0.280959  1.921496  0.167354  0.044479  0.004092  0.718135  0.065752  \n",
       "2  0.203399  1.917467  0.178067  0.043778  0.003868  0.706559  0.037062  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Timesteps\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_formatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Timesteps\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat(results_to_save).reset_index().groupby(\n",
    "    [\"Features\", \"Model\", \"Cross Validation\", \"Timesteps\"], dropna=False\n",
    ")[[\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]].agg(\n",
    "    [\"mean\", lambda series: pd.Series(series.std(ddof=0), name=\"std\")]\n",
    ").reset_index().rename(\n",
    "    columns={\"<lambda_0>\": \"std\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a79d502",
   "metadata": {
    "papermill": {
     "duration": 0.040426,
     "end_time": "2024-04-04T22:17:05.918242",
     "exception": false,
     "start_time": "2024-04-04T22:17:05.877816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.2. Blocking Time Series Cross Validation\n",
    "\n",
    "<b>Dataset shape:</b> (1234, 38)<br>\n",
    "<b>Splits:</b>5<br>    \n",
    "    1. 5 folds of 246 samples\n",
    "    2. 50% train (123 samples each fold)\n",
    "    3. 50% test (123 samples each fold)\n",
    "<b>Total:</b> 5 models<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6931e2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T22:17:05.965922Z",
     "iopub.status.busy": "2024-04-04T22:17:05.964847Z",
     "iopub.status.idle": "2024-04-04T22:24:32.992467Z",
     "shell.execute_reply": "2024-04-04T22:24:32.990896Z"
    },
    "papermill": {
     "duration": 447.065397,
     "end_time": "2024-04-04T22:24:33.008385",
     "exception": false,
     "start_time": "2024-04-04T22:17:05.942988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocking Time Series Split:\n",
      "Repeats: 3\n",
      "n_splits: 5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 1 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 3.700 (0.374)\n",
      "MAE: 2.872 (0.292)\n",
      "MAPE: 0.067 (0.006)\n",
      "R2: 0.334 (0.218)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 5.435 (1.417)\n",
      "MAE: 4.174 (1.082)\n",
      "MAPE: 0.098 (0.025)\n",
      "R2: -1.124 (1.646)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 7 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.232 (0.217)\n",
      "MAE: 1.815 (0.198)\n",
      "MAPE: 0.041 (0.004)\n",
      "R2: 0.757 (0.078)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 4.824 (0.977)\n",
      "MAE: 3.728 (0.858)\n",
      "MAPE: 0.087 (0.022)\n",
      "R2: -0.710 (0.782)\n",
      "\n",
      "======================\n",
      "\n",
      "Minutes Elapsed:  7.449705191453298\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"start = time.time()\\n\\nrepeats = 3\\nn_splits = 5\\ntrain_size = 0.8\\nTIMESTEPS_LIST = [1, 7]\\n\\nprint(\\\"Blocking Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n    scores_final = None\\n\\n    for _ in range(repeats):\\n        x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1)\\n        y = df_copy[\\\"CS28\\\"]\\n\\n        cv = BlockingTimeSeriesSplit(n_splits=n_splits, train_size=train_size)\\n\\n        scores = custom_cross_validate(\\n            GRU,\\n            SimpleImputer,\\n            StandardScaler,\\n            x,\\n            y,\\n            cv,\\n            timesteps,\\n            dates=dates,\\n            cement_types=df_copy[CEMENT_TYPES],\\n            estimator_params=None,\\n            imputer_params={\\\"strategy\\\": \\\"median\\\"},\\n            split_by_cement_type=True,\\n        )\\n        scores = scores[0]\\n        if scores_final is None:\\n            scores_final = {key: [] for key, _ in scores.items()}\\n\\n        for key, value in scores.items():\\n            scores_final[key] += [value]\\n\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores_final, METRICS, METRICS_DICT)\\n\\n    # Saving the results\\n    scores = {key: np.array(val).flatten() for key, val in scores_final.items()}\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Blocking Time Series Split\\\"\\n    results_dict_copy[\\n        \\\"Cross Validation Params\\\"\\n    ] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3, \\\"train_size\\\": 0.8}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(results_dict_copy, scores)\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"start = time.time()\\n\\nrepeats = 3\\nn_splits = 5\\ntrain_size = 0.8\\nTIMESTEPS_LIST = [1, 7]\\n\\nprint(\\\"Blocking Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n    scores_final = None\\n\\n    for _ in range(repeats):\\n        x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1)\\n        y = df_copy[\\\"CS28\\\"]\\n\\n        cv = BlockingTimeSeriesSplit(n_splits=n_splits, train_size=train_size)\\n\\n        scores = custom_cross_validate(\\n            GRU,\\n            SimpleImputer,\\n            StandardScaler,\\n            x,\\n            y,\\n            cv,\\n            timesteps,\\n            dates=dates,\\n            cement_types=df_copy[CEMENT_TYPES],\\n            estimator_params=None,\\n            imputer_params={\\\"strategy\\\": \\\"median\\\"},\\n            split_by_cement_type=True,\\n        )\\n        scores = scores[0]\\n        if scores_final is None:\\n            scores_final = {key: [] for key, _ in scores.items()}\\n\\n        for key, value in scores.items():\\n            scores_final[key] += [value]\\n\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores_final, METRICS, METRICS_DICT)\\n\\n    # Saving the results\\n    scores = {key: np.array(val).flatten() for key, val in scores_final.items()}\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Blocking Time Series Split\\\"\\n    results_dict_copy[\\n        \\\"Cross Validation Params\\\"\\n    ] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3, \\\"train_size\\\": 0.8}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(results_dict_copy, scores)\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "repeats = 3\n",
    "n_splits = 5\n",
    "train_size = 0.8\n",
    "TIMESTEPS_LIST = [1, 7]\n",
    "\n",
    "print(\"Blocking Time Series Split:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"n_splits: {n_splits}\")\n",
    "print()\n",
    "\n",
    "for timesteps in TIMESTEPS_LIST:\n",
    "    set_seeds()\n",
    "    scores_final = None\n",
    "\n",
    "    for _ in range(repeats):\n",
    "        x = df_copy.drop([\"Date\", \"CS28\"] + CEMENT_TYPES, axis=1)\n",
    "        y = df_copy[\"CS28\"]\n",
    "\n",
    "        cv = BlockingTimeSeriesSplit(n_splits=n_splits, train_size=train_size)\n",
    "\n",
    "        scores = custom_cross_validate(\n",
    "            GRU,\n",
    "            SimpleImputer,\n",
    "            StandardScaler,\n",
    "            x,\n",
    "            y,\n",
    "            cv,\n",
    "            timesteps,\n",
    "            dates=dates,\n",
    "            cement_types=df_copy[CEMENT_TYPES],\n",
    "            estimator_params=None,\n",
    "            imputer_params={\"strategy\": \"median\"},\n",
    "            split_by_cement_type=True,\n",
    "        )\n",
    "        scores = scores[0]\n",
    "        if scores_final is None:\n",
    "            scores_final = {key: [] for key, _ in scores.items()}\n",
    "\n",
    "        for key, value in scores.items():\n",
    "            scores_final[key] += [value]\n",
    "\n",
    "    print(\"TIMESTEPS: %d \" % timesteps)\n",
    "    print_scores(scores_final, METRICS, METRICS_DICT)\n",
    "\n",
    "    # Saving the results\n",
    "    scores = {key: np.array(val).flatten() for key, val in scores_final.items()}\n",
    "    results_dict_copy = results_dict.copy()\n",
    "    results_dict_copy[\"Timesteps\"] = timesteps\n",
    "    results_dict_copy[\"Cross Validation\"] = \"Blocking Time Series Split\"\n",
    "    results_dict_copy[\n",
    "        \"Cross Validation Params\"\n",
    "    ] = '{\"N_Splits\": 5, \"Repeats\": 3, \"train_size\": 0.8}'\n",
    "    results_dict_copy[\"Data Shape\"] = x.shape\n",
    "    df_results = fill_results_dict(results_dict_copy, scores)\n",
    "    results_to_save.append(df_results)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "909b896d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T22:24:33.041417Z",
     "iopub.status.busy": "2024-04-04T22:24:33.041023Z",
     "iopub.status.idle": "2024-04-04T22:24:33.102922Z",
     "shell.execute_reply": "2024-04-04T22:24:33.101557Z"
    },
    "papermill": {
     "duration": 0.081593,
     "end_time": "2024-04-04T22:24:33.105319",
     "exception": false,
     "start_time": "2024-04-04T22:24:33.023726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RMSE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAPE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R2 Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Blocking Time Series Split</td>\n",
       "      <td>1</td>\n",
       "      <td>5.435389</td>\n",
       "      <td>1.416914</td>\n",
       "      <td>4.174001</td>\n",
       "      <td>1.082374</td>\n",
       "      <td>0.097732</td>\n",
       "      <td>0.025389</td>\n",
       "      <td>-1.124075</td>\n",
       "      <td>1.645617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Blocking Time Series Split</td>\n",
       "      <td>7</td>\n",
       "      <td>4.824142</td>\n",
       "      <td>0.977390</td>\n",
       "      <td>3.727949</td>\n",
       "      <td>0.858341</td>\n",
       "      <td>0.087004</td>\n",
       "      <td>0.022322</td>\n",
       "      <td>-0.709555</td>\n",
       "      <td>0.782145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>1</td>\n",
       "      <td>2.215293</td>\n",
       "      <td>0.130524</td>\n",
       "      <td>1.734022</td>\n",
       "      <td>0.098446</td>\n",
       "      <td>0.040019</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.785492</td>\n",
       "      <td>0.025761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>7</td>\n",
       "      <td>2.450196</td>\n",
       "      <td>0.280959</td>\n",
       "      <td>1.921496</td>\n",
       "      <td>0.167354</td>\n",
       "      <td>0.044479</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>0.718135</td>\n",
       "      <td>0.065752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>14</td>\n",
       "      <td>2.428609</td>\n",
       "      <td>0.203399</td>\n",
       "      <td>1.917467</td>\n",
       "      <td>0.178067</td>\n",
       "      <td>0.043778</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.706559</td>\n",
       "      <td>0.037062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Features Model            Cross Validation Timesteps  \\\n",
       "                                                                               \n",
       "0  Chemical + Properties CS Less   GRU  Blocking Time Series Split         1   \n",
       "1  Chemical + Properties CS Less   GRU  Blocking Time Series Split         7   \n",
       "2  Chemical + Properties CS Less   GRU              Repeated KFold         1   \n",
       "3  Chemical + Properties CS Less   GRU              Repeated KFold         7   \n",
       "4  Chemical + Properties CS Less   GRU              Repeated KFold        14   \n",
       "\n",
       "  RMSE Test            MAE Test           MAPE Test             R2 Test  \\\n",
       "       mean       std      mean       std      mean       std      mean   \n",
       "0  5.435389  1.416914  4.174001  1.082374  0.097732  0.025389 -1.124075   \n",
       "1  4.824142  0.977390  3.727949  0.858341  0.087004  0.022322 -0.709555   \n",
       "2  2.215293  0.130524  1.734022  0.098446  0.040019  0.002141  0.785492   \n",
       "3  2.450196  0.280959  1.921496  0.167354  0.044479  0.004092  0.718135   \n",
       "4  2.428609  0.203399  1.917467  0.178067  0.043778  0.003868  0.706559   \n",
       "\n",
       "             \n",
       "        std  \n",
       "0  1.645617  \n",
       "1  0.782145  \n",
       "2  0.025761  \n",
       "3  0.065752  \n",
       "4  0.037062  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Timesteps\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_formatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Timesteps\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat(results_to_save).reset_index().groupby(\n",
    "    [\"Features\", \"Model\", \"Cross Validation\", \"Timesteps\"], dropna=False\n",
    ")[[\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]].agg(\n",
    "    [\"mean\", lambda series: pd.Series(series.std(ddof=0), name=\"std\")]\n",
    ").reset_index().rename(\n",
    "    columns={\"<lambda_0>\": \"std\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c768d",
   "metadata": {
    "papermill": {
     "duration": 0.018253,
     "end_time": "2024-04-04T22:24:33.144655",
     "exception": false,
     "start_time": "2024-04-04T22:24:33.126402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.3. Time Series Split Cross Validation\n",
    "\n",
    "The training set has size i * n_samples // (n_splits + 1) + n_samples % (n_splits + 1) in the i th split, with a test set of size n_samples//(n_splits + 1) by default, where n_samples is the number of samples.\n",
    "\n",
    "\n",
    "<b>Dataset shape:</b> (1234, 38)<br>\n",
    "<b>Splits:</b>10<br>    \n",
    "    1. Train: 10 folds of 114, 226, 338, 450, 562, 675, 787, 899, 1011, 1123 samples each fold\n",
    "    2. Test: 112 samples each fold\n",
    "<b>Total:</b> 10 models<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ccbc2c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T22:24:33.226826Z",
     "iopub.status.busy": "2024-04-04T22:24:33.226242Z",
     "iopub.status.idle": "2024-04-04T23:09:14.115811Z",
     "shell.execute_reply": "2024-04-04T23:09:14.114743Z"
    },
    "papermill": {
     "duration": 2680.942453,
     "end_time": "2024-04-04T23:09:14.133724",
     "exception": false,
     "start_time": "2024-04-04T22:24:33.191271",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocking Time Series Split:\n",
      "Repeats: 3\n",
      "n_splits: 5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 1 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.535 (0.686)\n",
      "MAE: 1.993 (0.547)\n",
      "MAPE: 0.045 (0.013)\n",
      "R2: 0.643 (0.200)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.118 (1.009)\n",
      "MAE: 2.429 (0.732)\n",
      "MAPE: 0.056 (0.016)\n",
      "R2: 0.423 (0.477)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 7 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.087 (0.409)\n",
      "MAE: 1.658 (0.346)\n",
      "MAPE: 0.037 (0.008)\n",
      "R2: 0.758 (0.105)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.780 (1.185)\n",
      "MAE: 3.091 (0.972)\n",
      "MAPE: 0.071 (0.019)\n",
      "R2: 0.084 (0.732)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 14 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.901 (0.206)\n",
      "MAE: 1.504 (0.175)\n",
      "MAPE: 0.034 (0.004)\n",
      "R2: 0.796 (0.051)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.535 (1.526)\n",
      "MAE: 2.822 (1.215)\n",
      "MAPE: 0.065 (0.025)\n",
      "R2: 0.150 (0.863)\n",
      "\n",
      "======================\n",
      "\n",
      "Minutes Elapsed:  44.67867575486501\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nstart = time.time()\\ngap = 0\\nn_splits = 5\\nrepeats = 3\\nTIMESTEPS_LIST = [1, 7, 14]\\n\\nprint(\\\"Blocking Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n    scores_final = None\\n\\n    for _ in range(repeats):\\n        x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1)\\n        y = df_copy[\\\"CS28\\\"]\\n\\n        cv = TimeSeriesSplit(\\n            gap=gap, max_train_size=None, n_splits=n_splits, test_size=None\\n        )\\n        scores = custom_cross_validate(\\n            GRU,\\n            SimpleImputer,\\n            StandardScaler,\\n            x,\\n            y,\\n            cv,\\n            timesteps,\\n            dates=dates,\\n            cement_types=df_copy[CEMENT_TYPES],\\n            estimator_params=None,\\n            imputer_params={\\\"strategy\\\": \\\"median\\\"},\\n        )\\n        scores = scores[0]\\n        if scores_final is None:\\n            scores_final = {key: [] for key, _ in scores.items()}\\n\\n        for key, value in scores.items():\\n            scores_final[key] += [value]\\n\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores_final, METRICS, METRICS_DICT)\\n\\n    # Saving the results\\n    scores = {key: np.array(val).flatten() for key, val in scores_final.items()}\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Time Series Split\\\"\\n    results_dict_copy[\\n        \\\"Cross Validation Params\\\"\\n    ] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3, \\\"Gap\\\": 0}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(results_dict_copy, scores)\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nstart = time.time()\\ngap = 0\\nn_splits = 5\\nrepeats = 3\\nTIMESTEPS_LIST = [1, 7, 14]\\n\\nprint(\\\"Blocking Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n    scores_final = None\\n\\n    for _ in range(repeats):\\n        x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1)\\n        y = df_copy[\\\"CS28\\\"]\\n\\n        cv = TimeSeriesSplit(\\n            gap=gap, max_train_size=None, n_splits=n_splits, test_size=None\\n        )\\n        scores = custom_cross_validate(\\n            GRU,\\n            SimpleImputer,\\n            StandardScaler,\\n            x,\\n            y,\\n            cv,\\n            timesteps,\\n            dates=dates,\\n            cement_types=df_copy[CEMENT_TYPES],\\n            estimator_params=None,\\n            imputer_params={\\\"strategy\\\": \\\"median\\\"},\\n        )\\n        scores = scores[0]\\n        if scores_final is None:\\n            scores_final = {key: [] for key, _ in scores.items()}\\n\\n        for key, value in scores.items():\\n            scores_final[key] += [value]\\n\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores_final, METRICS, METRICS_DICT)\\n\\n    # Saving the results\\n    scores = {key: np.array(val).flatten() for key, val in scores_final.items()}\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Time Series Split\\\"\\n    results_dict_copy[\\n        \\\"Cross Validation Params\\\"\\n    ] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3, \\\"Gap\\\": 0}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(results_dict_copy, scores)\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "start = time.time()\n",
    "gap = 0\n",
    "n_splits = 5\n",
    "repeats = 3\n",
    "TIMESTEPS_LIST = [1, 7, 14]\n",
    "\n",
    "print(\"Blocking Time Series Split:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"n_splits: {n_splits}\")\n",
    "print()\n",
    "\n",
    "for timesteps in TIMESTEPS_LIST:\n",
    "    set_seeds()\n",
    "    scores_final = None\n",
    "\n",
    "    for _ in range(repeats):\n",
    "        x = df_copy.drop([\"Date\", \"CS28\"] + CEMENT_TYPES, axis=1)\n",
    "        y = df_copy[\"CS28\"]\n",
    "\n",
    "        cv = TimeSeriesSplit(\n",
    "            gap=gap, max_train_size=None, n_splits=n_splits, test_size=None\n",
    "        )\n",
    "        scores = custom_cross_validate(\n",
    "            GRU,\n",
    "            SimpleImputer,\n",
    "            StandardScaler,\n",
    "            x,\n",
    "            y,\n",
    "            cv,\n",
    "            timesteps,\n",
    "            dates=dates,\n",
    "            cement_types=df_copy[CEMENT_TYPES],\n",
    "            estimator_params=None,\n",
    "            imputer_params={\"strategy\": \"median\"},\n",
    "        )\n",
    "        scores = scores[0]\n",
    "        if scores_final is None:\n",
    "            scores_final = {key: [] for key, _ in scores.items()}\n",
    "\n",
    "        for key, value in scores.items():\n",
    "            scores_final[key] += [value]\n",
    "\n",
    "    print(\"TIMESTEPS: %d \" % timesteps)\n",
    "    print_scores(scores_final, METRICS, METRICS_DICT)\n",
    "\n",
    "    # Saving the results\n",
    "    scores = {key: np.array(val).flatten() for key, val in scores_final.items()}\n",
    "    results_dict_copy = results_dict.copy()\n",
    "    results_dict_copy[\"Timesteps\"] = timesteps\n",
    "    results_dict_copy[\"Cross Validation\"] = \"Time Series Split\"\n",
    "    results_dict_copy[\n",
    "        \"Cross Validation Params\"\n",
    "    ] = '{\"N_Splits\": 5, \"Repeats\": 3, \"Gap\": 0}'\n",
    "    results_dict_copy[\"Data Shape\"] = x.shape\n",
    "    df_results = fill_results_dict(results_dict_copy, scores)\n",
    "    results_to_save.append(df_results)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6176dcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T23:09:14.172093Z",
     "iopub.status.busy": "2024-04-04T23:09:14.171781Z",
     "iopub.status.idle": "2024-04-04T23:09:14.223721Z",
     "shell.execute_reply": "2024-04-04T23:09:14.222592Z"
    },
    "papermill": {
     "duration": 0.07249,
     "end_time": "2024-04-04T23:09:14.225740",
     "exception": false,
     "start_time": "2024-04-04T23:09:14.153250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RMSE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAPE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R2 Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Blocking Time Series Split</td>\n",
       "      <td>1</td>\n",
       "      <td>5.435389</td>\n",
       "      <td>1.416914</td>\n",
       "      <td>4.174001</td>\n",
       "      <td>1.082374</td>\n",
       "      <td>0.097732</td>\n",
       "      <td>0.025389</td>\n",
       "      <td>-1.124075</td>\n",
       "      <td>1.645617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Blocking Time Series Split</td>\n",
       "      <td>7</td>\n",
       "      <td>4.824142</td>\n",
       "      <td>0.977390</td>\n",
       "      <td>3.727949</td>\n",
       "      <td>0.858341</td>\n",
       "      <td>0.087004</td>\n",
       "      <td>0.022322</td>\n",
       "      <td>-0.709555</td>\n",
       "      <td>0.782145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>1</td>\n",
       "      <td>2.215293</td>\n",
       "      <td>0.130524</td>\n",
       "      <td>1.734022</td>\n",
       "      <td>0.098446</td>\n",
       "      <td>0.040019</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.785492</td>\n",
       "      <td>0.025761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>7</td>\n",
       "      <td>2.450196</td>\n",
       "      <td>0.280959</td>\n",
       "      <td>1.921496</td>\n",
       "      <td>0.167354</td>\n",
       "      <td>0.044479</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>0.718135</td>\n",
       "      <td>0.065752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>14</td>\n",
       "      <td>2.428609</td>\n",
       "      <td>0.203399</td>\n",
       "      <td>1.917467</td>\n",
       "      <td>0.178067</td>\n",
       "      <td>0.043778</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.706559</td>\n",
       "      <td>0.037062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Time Series Split</td>\n",
       "      <td>1</td>\n",
       "      <td>3.117688</td>\n",
       "      <td>1.008770</td>\n",
       "      <td>2.428842</td>\n",
       "      <td>0.732005</td>\n",
       "      <td>0.056499</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.423121</td>\n",
       "      <td>0.476520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Time Series Split</td>\n",
       "      <td>7</td>\n",
       "      <td>3.780437</td>\n",
       "      <td>1.185397</td>\n",
       "      <td>3.090883</td>\n",
       "      <td>0.972227</td>\n",
       "      <td>0.071009</td>\n",
       "      <td>0.019121</td>\n",
       "      <td>0.084268</td>\n",
       "      <td>0.732410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Time Series Split</td>\n",
       "      <td>14</td>\n",
       "      <td>3.534741</td>\n",
       "      <td>1.526144</td>\n",
       "      <td>2.822377</td>\n",
       "      <td>1.215251</td>\n",
       "      <td>0.064776</td>\n",
       "      <td>0.024984</td>\n",
       "      <td>0.150173</td>\n",
       "      <td>0.863357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Features Model            Cross Validation Timesteps  \\\n",
       "                                                                               \n",
       "0  Chemical + Properties CS Less   GRU  Blocking Time Series Split         1   \n",
       "1  Chemical + Properties CS Less   GRU  Blocking Time Series Split         7   \n",
       "2  Chemical + Properties CS Less   GRU              Repeated KFold         1   \n",
       "3  Chemical + Properties CS Less   GRU              Repeated KFold         7   \n",
       "4  Chemical + Properties CS Less   GRU              Repeated KFold        14   \n",
       "5  Chemical + Properties CS Less   GRU           Time Series Split         1   \n",
       "6  Chemical + Properties CS Less   GRU           Time Series Split         7   \n",
       "7  Chemical + Properties CS Less   GRU           Time Series Split        14   \n",
       "\n",
       "  RMSE Test            MAE Test           MAPE Test             R2 Test  \\\n",
       "       mean       std      mean       std      mean       std      mean   \n",
       "0  5.435389  1.416914  4.174001  1.082374  0.097732  0.025389 -1.124075   \n",
       "1  4.824142  0.977390  3.727949  0.858341  0.087004  0.022322 -0.709555   \n",
       "2  2.215293  0.130524  1.734022  0.098446  0.040019  0.002141  0.785492   \n",
       "3  2.450196  0.280959  1.921496  0.167354  0.044479  0.004092  0.718135   \n",
       "4  2.428609  0.203399  1.917467  0.178067  0.043778  0.003868  0.706559   \n",
       "5  3.117688  1.008770  2.428842  0.732005  0.056499  0.015610  0.423121   \n",
       "6  3.780437  1.185397  3.090883  0.972227  0.071009  0.019121  0.084268   \n",
       "7  3.534741  1.526144  2.822377  1.215251  0.064776  0.024984  0.150173   \n",
       "\n",
       "             \n",
       "        std  \n",
       "0  1.645617  \n",
       "1  0.782145  \n",
       "2  0.025761  \n",
       "3  0.065752  \n",
       "4  0.037062  \n",
       "5  0.476520  \n",
       "6  0.732410  \n",
       "7  0.863357  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Timesteps\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_formatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Timesteps\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat(results_to_save).reset_index().groupby(\n",
    "    [\"Features\", \"Model\", \"Cross Validation\", \"Timesteps\"], dropna=False\n",
    ")[[\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]].agg(\n",
    "    [\"mean\", lambda series: pd.Series(series.std(ddof=0), name=\"std\")]\n",
    ").reset_index().rename(\n",
    "    columns={\"<lambda_0>\": \"std\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0a53b0",
   "metadata": {
    "papermill": {
     "duration": 0.01565,
     "end_time": "2024-04-04T23:09:14.257279",
     "exception": false,
     "start_time": "2024-04-04T23:09:14.241629",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.4. Out of time Split Cross Validation\n",
    "\n",
    "<b>Dataset shape:</b> (1234, 38)<br>\n",
    "<b>Train size: 80%</b><br>\n",
    "<b>Test  size: 20%</b>\n",
    "\n",
    "\n",
    "<b>Splits:</b> 2<br>    \n",
    "    1. Train: 987\n",
    "    2. Test: 247\n",
    "<b>Total:</b> 1 model<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ad4b2b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T23:09:14.351117Z",
     "iopub.status.busy": "2024-04-04T23:09:14.350615Z",
     "iopub.status.idle": "2024-04-04T23:22:27.745232Z",
     "shell.execute_reply": "2024-04-04T23:22:27.744395Z"
    },
    "papermill": {
     "duration": 793.466172,
     "end_time": "2024-04-04T23:22:27.785290",
     "exception": false,
     "start_time": "2024-04-04T23:09:14.319118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of time Cross Val:\n",
      "Repeats: 3\n",
      "Train: 80% Test: 20%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 1 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.088 (0.086)\n",
      "MAE: 1.641 (0.063)\n",
      "MAPE: 0.037 (0.001)\n",
      "R2: 0.793 (0.017)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.626 (0.172)\n",
      "MAE: 2.111 (0.139)\n",
      "MAPE: 0.052 (0.003)\n",
      "R2: 0.726 (0.035)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 7 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.857 (0.152)\n",
      "MAE: 1.477 (0.129)\n",
      "MAPE: 0.034 (0.003)\n",
      "R2: 0.833 (0.026)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.778 (0.926)\n",
      "MAE: 3.052 (0.724)\n",
      "MAPE: 0.076 (0.020)\n",
      "R2: 0.398 (0.302)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 14 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.136 (0.095)\n",
      "MAE: 1.702 (0.089)\n",
      "MAPE: 0.038 (0.002)\n",
      "R2: 0.770 (0.021)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.989 (0.617)\n",
      "MAE: 2.358 (0.430)\n",
      "MAPE: 0.059 (0.012)\n",
      "R2: 0.637 (0.153)\n",
      "\n",
      "======================\n",
      "\n",
      "Minutes Elapsed:  13.2225728114446\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"start = time.time()\\ntest_size = 0.2\\nrepeats = 3\\nTIMESTEPS_LIST = [1, 7, 14]\\n\\nprint(\\\"Out of time Cross Val:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"Train: {80}%\\\", f\\\"Test: {20}%\\\")\\nprint()\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n    scores_final = None\\n\\n    for _ in range(repeats):\\n        # Data Splitting\\n        x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1)\\n        y = df_copy[\\\"CS28\\\"]\\n\\n        x_train, x_test, y_train, y_test = train_test_split(\\n            x, y, test_size=test_size, random_state=SEED, shuffle=False\\n        )\\n\\n        # Preprocessing\\n        imputer = SimpleImputer(strategy=\\\"median\\\")\\n        scaler = StandardScaler()\\n\\n        x_train = imputer.fit_transform(x_train)\\n        x_train = scaler.fit_transform(x_train)\\n        dates_train = dates[: x_train.shape[0]].reset_index(drop=True)\\n        cement_types_train = df_copy[CEMENT_TYPES][: x_train.shape[0]].reset_index(\\n            drop=True\\n        )\\n\\n        x_test = imputer.transform(x_test)\\n        x_test = scaler.transform(x_test)\\n        dates_test = dates[x_train.shape[0] :].reset_index(drop=True)\\n        cement_types_test = df_copy[CEMENT_TYPES][x_train.shape[0] :].reset_index(\\n            drop=True\\n        )\\n\\n        # Sequence Splitting\\n        data_train = pd.concat(\\n            [\\n                dates_train,\\n                pd.DataFrame(x_train, columns=x.columns),\\n                cement_types_train,\\n                y_train.reset_index(drop=True),\\n            ],\\n            axis=1,\\n        )\\n        data_test = pd.concat(\\n            [\\n                dates_test,\\n                pd.DataFrame(x_test, columns=x.columns),\\n                cement_types_test,\\n                y_test.reset_index(drop=True),\\n            ],\\n            axis=1,\\n        )\\n\\n        x_train, y_train = split_sequences_per_cement_type(data_train, timesteps)\\n        x_test, y_test = split_sequences_per_cement_type(data_test, timesteps)\\n\\n        # Train model and test evalutation\\n        # Fit model\\n        pipeline = Pipeline([(\\\"estimator\\\", GRU())])\\n        pipeline.fit(x_train, y_train)\\n\\n        # Make predictions\\n        y_train_pred = pipeline.predict(x_train)\\n        y_test_pred = pipeline.predict(x_test)\\n\\n        # evaluate predictions\\n        scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\\n\\n        if scores_final is None:\\n            scores_final = {key: [] for key, _ in scores.items()}\\n\\n        for key, value in scores.items():\\n            scores_final[key] += [value]\\n\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores_final, METRICS, METRICS_DICT)\\n\\n    # Saving the results\\n    # scores = {key: val[0] for key, val in scores.items()}\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time Split\\\"\\n    results_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"Test Size\\\": 0.2}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(\\n        results_dict_copy, {key: value for key, value in scores_final.items()}\\n    )\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"start = time.time()\\ntest_size = 0.2\\nrepeats = 3\\nTIMESTEPS_LIST = [1, 7, 14]\\n\\nprint(\\\"Out of time Cross Val:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"Train: {80}%\\\", f\\\"Test: {20}%\\\")\\nprint()\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n    scores_final = None\\n\\n    for _ in range(repeats):\\n        # Data Splitting\\n        x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1)\\n        y = df_copy[\\\"CS28\\\"]\\n\\n        x_train, x_test, y_train, y_test = train_test_split(\\n            x, y, test_size=test_size, random_state=SEED, shuffle=False\\n        )\\n\\n        # Preprocessing\\n        imputer = SimpleImputer(strategy=\\\"median\\\")\\n        scaler = StandardScaler()\\n\\n        x_train = imputer.fit_transform(x_train)\\n        x_train = scaler.fit_transform(x_train)\\n        dates_train = dates[: x_train.shape[0]].reset_index(drop=True)\\n        cement_types_train = df_copy[CEMENT_TYPES][: x_train.shape[0]].reset_index(\\n            drop=True\\n        )\\n\\n        x_test = imputer.transform(x_test)\\n        x_test = scaler.transform(x_test)\\n        dates_test = dates[x_train.shape[0] :].reset_index(drop=True)\\n        cement_types_test = df_copy[CEMENT_TYPES][x_train.shape[0] :].reset_index(\\n            drop=True\\n        )\\n\\n        # Sequence Splitting\\n        data_train = pd.concat(\\n            [\\n                dates_train,\\n                pd.DataFrame(x_train, columns=x.columns),\\n                cement_types_train,\\n                y_train.reset_index(drop=True),\\n            ],\\n            axis=1,\\n        )\\n        data_test = pd.concat(\\n            [\\n                dates_test,\\n                pd.DataFrame(x_test, columns=x.columns),\\n                cement_types_test,\\n                y_test.reset_index(drop=True),\\n            ],\\n            axis=1,\\n        )\\n\\n        x_train, y_train = split_sequences_per_cement_type(data_train, timesteps)\\n        x_test, y_test = split_sequences_per_cement_type(data_test, timesteps)\\n\\n        # Train model and test evalutation\\n        # Fit model\\n        pipeline = Pipeline([(\\\"estimator\\\", GRU())])\\n        pipeline.fit(x_train, y_train)\\n\\n        # Make predictions\\n        y_train_pred = pipeline.predict(x_train)\\n        y_test_pred = pipeline.predict(x_test)\\n\\n        # evaluate predictions\\n        scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\\n\\n        if scores_final is None:\\n            scores_final = {key: [] for key, _ in scores.items()}\\n\\n        for key, value in scores.items():\\n            scores_final[key] += [value]\\n\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores_final, METRICS, METRICS_DICT)\\n\\n    # Saving the results\\n    # scores = {key: val[0] for key, val in scores.items()}\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time Split\\\"\\n    results_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"Test Size\\\": 0.2}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(\\n        results_dict_copy, {key: value for key, value in scores_final.items()}\\n    )\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "test_size = 0.2\n",
    "repeats = 3\n",
    "TIMESTEPS_LIST = [1, 7, 14]\n",
    "\n",
    "print(\"Out of time Cross Val:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"Train: {80}%\", f\"Test: {20}%\")\n",
    "print()\n",
    "\n",
    "for timesteps in TIMESTEPS_LIST:\n",
    "    set_seeds()\n",
    "    scores_final = None\n",
    "\n",
    "    for _ in range(repeats):\n",
    "        # Data Splitting\n",
    "        x = df_copy.drop([\"Date\", \"CS28\"] + CEMENT_TYPES, axis=1)\n",
    "        y = df_copy[\"CS28\"]\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(\n",
    "            x, y, test_size=test_size, random_state=SEED, shuffle=False\n",
    "        )\n",
    "\n",
    "        # Preprocessing\n",
    "        imputer = SimpleImputer(strategy=\"median\")\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        x_train = imputer.fit_transform(x_train)\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        dates_train = dates[: x_train.shape[0]].reset_index(drop=True)\n",
    "        cement_types_train = df_copy[CEMENT_TYPES][: x_train.shape[0]].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "\n",
    "        x_test = imputer.transform(x_test)\n",
    "        x_test = scaler.transform(x_test)\n",
    "        dates_test = dates[x_train.shape[0] :].reset_index(drop=True)\n",
    "        cement_types_test = df_copy[CEMENT_TYPES][x_train.shape[0] :].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "\n",
    "        # Sequence Splitting\n",
    "        data_train = pd.concat(\n",
    "            [\n",
    "                dates_train,\n",
    "                pd.DataFrame(x_train, columns=x.columns),\n",
    "                cement_types_train,\n",
    "                y_train.reset_index(drop=True),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        data_test = pd.concat(\n",
    "            [\n",
    "                dates_test,\n",
    "                pd.DataFrame(x_test, columns=x.columns),\n",
    "                cement_types_test,\n",
    "                y_test.reset_index(drop=True),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        x_train, y_train = split_sequences_per_cement_type(data_train, timesteps)\n",
    "        x_test, y_test = split_sequences_per_cement_type(data_test, timesteps)\n",
    "\n",
    "        # Train model and test evalutation\n",
    "        # Fit model\n",
    "        pipeline = Pipeline([(\"estimator\", GRU())])\n",
    "        pipeline.fit(x_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = pipeline.predict(x_train)\n",
    "        y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "        # evaluate predictions\n",
    "        scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\n",
    "\n",
    "        if scores_final is None:\n",
    "            scores_final = {key: [] for key, _ in scores.items()}\n",
    "\n",
    "        for key, value in scores.items():\n",
    "            scores_final[key] += [value]\n",
    "\n",
    "    print(\"TIMESTEPS: %d \" % timesteps)\n",
    "    print_scores(scores_final, METRICS, METRICS_DICT)\n",
    "\n",
    "    # Saving the results\n",
    "    # scores = {key: val[0] for key, val in scores.items()}\n",
    "    results_dict_copy = results_dict.copy()\n",
    "    results_dict_copy[\"Timesteps\"] = timesteps\n",
    "    results_dict_copy[\"Cross Validation\"] = \"Out of time Split\"\n",
    "    results_dict_copy[\"Cross Validation Params\"] = '{\"Test Size\": 0.2}'\n",
    "    results_dict_copy[\"Data Shape\"] = x.shape\n",
    "    df_results = fill_results_dict(\n",
    "        results_dict_copy, {key: value for key, value in scores_final.items()}\n",
    "    )\n",
    "    results_to_save.append(df_results)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aec4b53a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T23:22:28.237899Z",
     "iopub.status.busy": "2024-04-04T23:22:28.237494Z",
     "iopub.status.idle": "2024-04-04T23:22:28.290130Z",
     "shell.execute_reply": "2024-04-04T23:22:28.288796Z"
    },
    "papermill": {
     "duration": 0.079134,
     "end_time": "2024-04-04T23:22:28.293283",
     "exception": false,
     "start_time": "2024-04-04T23:22:28.214149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RMSE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAPE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R2 Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Blocking Time Series Split</td>\n",
       "      <td>1</td>\n",
       "      <td>5.435389</td>\n",
       "      <td>1.416914</td>\n",
       "      <td>4.174001</td>\n",
       "      <td>1.082374</td>\n",
       "      <td>0.097732</td>\n",
       "      <td>0.025389</td>\n",
       "      <td>-1.124075</td>\n",
       "      <td>1.645617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Blocking Time Series Split</td>\n",
       "      <td>7</td>\n",
       "      <td>4.824142</td>\n",
       "      <td>0.977390</td>\n",
       "      <td>3.727949</td>\n",
       "      <td>0.858341</td>\n",
       "      <td>0.087004</td>\n",
       "      <td>0.022322</td>\n",
       "      <td>-0.709555</td>\n",
       "      <td>0.782145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Out of time Split</td>\n",
       "      <td>1</td>\n",
       "      <td>2.625981</td>\n",
       "      <td>0.172311</td>\n",
       "      <td>2.110604</td>\n",
       "      <td>0.138620</td>\n",
       "      <td>0.052221</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.726080</td>\n",
       "      <td>0.035437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Out of time Split</td>\n",
       "      <td>7</td>\n",
       "      <td>3.778109</td>\n",
       "      <td>0.925549</td>\n",
       "      <td>3.051569</td>\n",
       "      <td>0.724458</td>\n",
       "      <td>0.075714</td>\n",
       "      <td>0.020347</td>\n",
       "      <td>0.397542</td>\n",
       "      <td>0.301618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Out of time Split</td>\n",
       "      <td>14</td>\n",
       "      <td>2.988868</td>\n",
       "      <td>0.617306</td>\n",
       "      <td>2.358029</td>\n",
       "      <td>0.429520</td>\n",
       "      <td>0.059035</td>\n",
       "      <td>0.011723</td>\n",
       "      <td>0.636596</td>\n",
       "      <td>0.153032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>1</td>\n",
       "      <td>2.215293</td>\n",
       "      <td>0.130524</td>\n",
       "      <td>1.734022</td>\n",
       "      <td>0.098446</td>\n",
       "      <td>0.040019</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.785492</td>\n",
       "      <td>0.025761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>7</td>\n",
       "      <td>2.450196</td>\n",
       "      <td>0.280959</td>\n",
       "      <td>1.921496</td>\n",
       "      <td>0.167354</td>\n",
       "      <td>0.044479</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>0.718135</td>\n",
       "      <td>0.065752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>14</td>\n",
       "      <td>2.428609</td>\n",
       "      <td>0.203399</td>\n",
       "      <td>1.917467</td>\n",
       "      <td>0.178067</td>\n",
       "      <td>0.043778</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.706559</td>\n",
       "      <td>0.037062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Time Series Split</td>\n",
       "      <td>1</td>\n",
       "      <td>3.117688</td>\n",
       "      <td>1.008770</td>\n",
       "      <td>2.428842</td>\n",
       "      <td>0.732005</td>\n",
       "      <td>0.056499</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.423121</td>\n",
       "      <td>0.476520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Time Series Split</td>\n",
       "      <td>7</td>\n",
       "      <td>3.780437</td>\n",
       "      <td>1.185397</td>\n",
       "      <td>3.090883</td>\n",
       "      <td>0.972227</td>\n",
       "      <td>0.071009</td>\n",
       "      <td>0.019121</td>\n",
       "      <td>0.084268</td>\n",
       "      <td>0.732410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chemical + Properties CS Less</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Time Series Split</td>\n",
       "      <td>14</td>\n",
       "      <td>3.534741</td>\n",
       "      <td>1.526144</td>\n",
       "      <td>2.822377</td>\n",
       "      <td>1.215251</td>\n",
       "      <td>0.064776</td>\n",
       "      <td>0.024984</td>\n",
       "      <td>0.150173</td>\n",
       "      <td>0.863357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Features Model            Cross Validation Timesteps  \\\n",
       "                                                                                \n",
       "0   Chemical + Properties CS Less   GRU  Blocking Time Series Split         1   \n",
       "1   Chemical + Properties CS Less   GRU  Blocking Time Series Split         7   \n",
       "2   Chemical + Properties CS Less   GRU           Out of time Split         1   \n",
       "3   Chemical + Properties CS Less   GRU           Out of time Split         7   \n",
       "4   Chemical + Properties CS Less   GRU           Out of time Split        14   \n",
       "5   Chemical + Properties CS Less   GRU              Repeated KFold         1   \n",
       "6   Chemical + Properties CS Less   GRU              Repeated KFold         7   \n",
       "7   Chemical + Properties CS Less   GRU              Repeated KFold        14   \n",
       "8   Chemical + Properties CS Less   GRU           Time Series Split         1   \n",
       "9   Chemical + Properties CS Less   GRU           Time Series Split         7   \n",
       "10  Chemical + Properties CS Less   GRU           Time Series Split        14   \n",
       "\n",
       "   RMSE Test            MAE Test           MAPE Test             R2 Test  \\\n",
       "        mean       std      mean       std      mean       std      mean   \n",
       "0   5.435389  1.416914  4.174001  1.082374  0.097732  0.025389 -1.124075   \n",
       "1   4.824142  0.977390  3.727949  0.858341  0.087004  0.022322 -0.709555   \n",
       "2   2.625981  0.172311  2.110604  0.138620  0.052221  0.003467  0.726080   \n",
       "3   3.778109  0.925549  3.051569  0.724458  0.075714  0.020347  0.397542   \n",
       "4   2.988868  0.617306  2.358029  0.429520  0.059035  0.011723  0.636596   \n",
       "5   2.215293  0.130524  1.734022  0.098446  0.040019  0.002141  0.785492   \n",
       "6   2.450196  0.280959  1.921496  0.167354  0.044479  0.004092  0.718135   \n",
       "7   2.428609  0.203399  1.917467  0.178067  0.043778  0.003868  0.706559   \n",
       "8   3.117688  1.008770  2.428842  0.732005  0.056499  0.015610  0.423121   \n",
       "9   3.780437  1.185397  3.090883  0.972227  0.071009  0.019121  0.084268   \n",
       "10  3.534741  1.526144  2.822377  1.215251  0.064776  0.024984  0.150173   \n",
       "\n",
       "              \n",
       "         std  \n",
       "0   1.645617  \n",
       "1   0.782145  \n",
       "2   0.035437  \n",
       "3   0.301618  \n",
       "4   0.153032  \n",
       "5   0.025761  \n",
       "6   0.065752  \n",
       "7   0.037062  \n",
       "8   0.476520  \n",
       "9   0.732410  \n",
       "10  0.863357  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Timesteps\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_formatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Timesteps\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat(results_to_save).reset_index().groupby(\n",
    "    [\"Features\", \"Model\", \"Cross Validation\", \"Timesteps\"], dropna=False\n",
    ")[[\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]].agg(\n",
    "    [\"mean\", lambda series: pd.Series(series.std(ddof=0), name=\"std\")]\n",
    ").reset_index().rename(\n",
    "    columns={\"<lambda_0>\": \"std\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc16751",
   "metadata": {
    "papermill": {
     "duration": 0.023494,
     "end_time": "2024-04-04T23:22:28.346355",
     "exception": false,
     "start_time": "2024-04-04T23:22:28.322861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Saving the results Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82445ea7",
   "metadata": {
    "papermill": {
     "duration": 0.030313,
     "end_time": "2024-04-04T23:22:28.440748",
     "exception": false,
     "start_time": "2024-04-04T23:22:28.410435",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Saving the full dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb143b61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T23:22:28.478164Z",
     "iopub.status.busy": "2024-04-04T23:22:28.477602Z",
     "iopub.status.idle": "2024-04-04T23:22:28.501827Z",
     "shell.execute_reply": "2024-04-04T23:22:28.500780Z"
    },
    "papermill": {
     "duration": 0.045433,
     "end_time": "2024-04-04T23:22:28.503934",
     "exception": false,
     "start_time": "2024-04-04T23:22:28.458501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"path = \\\"../../../../../../reports/results/local_models/203/y/full/\\\"\\nfilename = f\\\"gru_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = \\\"../../../../../../reports/results/local_models/203/y/full/\\\"\\nfilename = f\\\"gru_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"../../../../../../reports/results/local_models/203/y/full/\"\n",
    "filename = f\"gru_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "156e7093",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T23:22:28.541177Z",
     "iopub.status.busy": "2024-04-04T23:22:28.539950Z",
     "iopub.status.idle": "2024-04-04T23:22:28.801816Z",
     "shell.execute_reply": "2024-04-04T23:22:28.800439Z"
    },
    "papermill": {
     "duration": 0.282938,
     "end_time": "2024-04-04T23:22:28.804161",
     "exception": false,
     "start_time": "2024-04-04T23:22:28.521223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"cols_groupby = [\\n    \\\"Category\\\",\\n    \\\"Company\\\",\\n    \\\"Data Shape\\\",\\n    \\\"Timesteps\\\",\\n    \\\"Features\\\",\\n    \\\"Model\\\",\\n    \\\"Cross Validation\\\",\\n    \\\"Cross Validation Params\\\",\\n]\\n\\ncols_agg = [\\\"RMSE Train\\\", \\\"MAE Train\\\", \\\"MAPE Train\\\", \\\"R2 Train\\\"] + [\\n    \\\"RMSE Test\\\",\\n    \\\"MAE Test\\\",\\n    \\\"MAPE Test\\\",\\n    \\\"R2 Test\\\",\\n]\\n\\npath = \\\"../../../../../../reports/results/local_models/203/y/grouped/\\\"\\nfilename = f\\\"gru_results_grouped_{index_to_save}.csv\\\"\\n\\n\\ndf_results_to_save = (\\n    pd.concat(results_to_save)\\n    .groupby(cols_groupby, dropna=False)[cols_agg]\\n    .agg([\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")])\\n    .reset_index()\\n    .rename(columns={\\\"<lambda_0>\\\": \\\"std\\\"})\\n)\\n\\ndf_results_to_save.to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"cols_groupby = [\\n    \\\"Category\\\",\\n    \\\"Company\\\",\\n    \\\"Data Shape\\\",\\n    \\\"Timesteps\\\",\\n    \\\"Features\\\",\\n    \\\"Model\\\",\\n    \\\"Cross Validation\\\",\\n    \\\"Cross Validation Params\\\",\\n]\\n\\ncols_agg = [\\\"RMSE Train\\\", \\\"MAE Train\\\", \\\"MAPE Train\\\", \\\"R2 Train\\\"] + [\\n    \\\"RMSE Test\\\",\\n    \\\"MAE Test\\\",\\n    \\\"MAPE Test\\\",\\n    \\\"R2 Test\\\",\\n]\\n\\npath = \\\"../../../../../../reports/results/local_models/203/y/grouped/\\\"\\nfilename = f\\\"gru_results_grouped_{index_to_save}.csv\\\"\\n\\n\\ndf_results_to_save = (\\n    pd.concat(results_to_save)\\n    .groupby(cols_groupby, dropna=False)[cols_agg]\\n    .agg([\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")])\\n    .reset_index()\\n    .rename(columns={\\\"<lambda_0>\\\": \\\"std\\\"})\\n)\\n\\ndf_results_to_save.to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols_groupby = [\n",
    "    \"Category\",\n",
    "    \"Company\",\n",
    "    \"Data Shape\",\n",
    "    \"Timesteps\",\n",
    "    \"Features\",\n",
    "    \"Model\",\n",
    "    \"Cross Validation\",\n",
    "    \"Cross Validation Params\",\n",
    "]\n",
    "\n",
    "cols_agg = [\"RMSE Train\", \"MAE Train\", \"MAPE Train\", \"R2 Train\"] + [\n",
    "    \"RMSE Test\",\n",
    "    \"MAE Test\",\n",
    "    \"MAPE Test\",\n",
    "    \"R2 Test\",\n",
    "]\n",
    "\n",
    "path = \"../../../../../../reports/results/local_models/203/y/grouped/\"\n",
    "filename = f\"gru_results_grouped_{index_to_save}.csv\"\n",
    "\n",
    "\n",
    "df_results_to_save = (\n",
    "    pd.concat(results_to_save)\n",
    "    .groupby(cols_groupby, dropna=False)[cols_agg]\n",
    "    .agg([\"mean\", lambda series: pd.Series(series.std(ddof=0), name=\"std\")])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"<lambda_0>\": \"std\"})\n",
    ")\n",
    "\n",
    "df_results_to_save.to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f461ed22",
   "metadata": {
    "papermill": {
     "duration": 0.043319,
     "end_time": "2024-04-04T23:22:28.871047",
     "exception": false,
     "start_time": "2024-04-04T23:22:28.827728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7454.620717,
   "end_time": "2024-04-04T23:22:30.430126",
   "environment_variables": {},
   "exception": null,
   "input_path": "/home/peressim/projects/ccs28-ml-modelling/notebooks/modelling/local_models/203/gru/y/chemical-properties-csless-ds.ipynb",
   "output_path": "/home/peressim/projects/ccs28-ml-modelling/notebooks/modelling/local_models/203/gru/y/chemical-properties-csless-ds.ipynb",
   "parameters": {},
   "start_time": "2024-04-04T21:18:15.809409",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}