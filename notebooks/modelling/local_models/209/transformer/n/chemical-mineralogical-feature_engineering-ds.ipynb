{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cbf52e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:52.058742Z",
     "iopub.status.busy": "2024-02-29T15:16:52.058224Z",
     "iopub.status.idle": "2024-02-29T15:16:52.187353Z",
     "shell.execute_reply": "2024-02-29T15:16:52.185476Z"
    },
    "papermill": {
     "duration": 0.148961,
     "end_time": "2024-02-29T15:16:52.190698",
     "exception": false,
     "start_time": "2024-02-29T15:16:52.041737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dbf5eb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:52.221346Z",
     "iopub.status.busy": "2024-02-29T15:16:52.220777Z",
     "iopub.status.idle": "2024-02-29T15:16:58.196900Z",
     "shell.execute_reply": "2024-02-29T15:16:58.195091Z"
    },
    "papermill": {
     "duration": 5.996087,
     "end_time": "2024-02-29T15:16:58.200596",
     "exception": false,
     "start_time": "2024-02-29T15:16:52.204509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 12:16:54.497091: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-29 12:16:54.579925: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-29 12:16:54.582641: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 12:16:56.555640: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Plotting\\nimport matplotlib.pyplot as plt\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.model_selection import TimeSeriesSplit\\nfrom sklearn.model_selection import RepeatedKFold\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.model_selection import cross_validate\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.preprocessing import RobustScaler\\n\\n# Metrics\\nfrom sklearn.metrics import mean_squared_error\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.metrics import mean_absolute_percentage_error\\nfrom sklearn.metrics import r2_score\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import BaseEstimator, RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\n# Converting Times Series Data to 3D format\\nfrom src.utils.split_sequences import split_sequences\\n\\n# Transformer Encoder for time series data\\nfrom src.models.transformer_ts_tf import Transformer\\n\\n# To run cross validation parallelized\\nfrom joblib import Parallel, delayed\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Plotting\\nimport matplotlib.pyplot as plt\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.model_selection import TimeSeriesSplit\\nfrom sklearn.model_selection import RepeatedKFold\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.model_selection import cross_validate\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.preprocessing import RobustScaler\\n\\n# Metrics\\nfrom sklearn.metrics import mean_squared_error\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.metrics import mean_absolute_percentage_error\\nfrom sklearn.metrics import r2_score\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import BaseEstimator, RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\n# Converting Times Series Data to 3D format\\nfrom src.utils.split_sequences import split_sequences\\n\\n# Transformer Encoder for time series data\\nfrom src.models.transformer_ts_tf import Transformer\\n\\n# To run cross validation parallelized\\nfrom joblib import Parallel, delayed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "# Converting Times Series Data to 3D format\n",
    "from src.utils.split_sequences import split_sequences\n",
    "\n",
    "# Transformer Encoder for time series data\n",
    "from src.models.transformer_ts_tf import Transformer\n",
    "\n",
    "# To run cross validation parallelized\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80586e02",
   "metadata": {
    "papermill": {
     "duration": 0.014982,
     "end_time": "2024-02-29T15:16:58.230858",
     "exception": false,
     "start_time": "2024-02-29T15:16:58.215876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850e4666",
   "metadata": {
    "papermill": {
     "duration": 0.015873,
     "end_time": "2024-02-29T15:16:58.260724",
     "exception": false,
     "start_time": "2024-02-29T15:16:58.244851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Convert train/test data to 3D format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38bb4589",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:58.291787Z",
     "iopub.status.busy": "2024-02-29T15:16:58.290845Z",
     "iopub.status.idle": "2024-02-29T15:16:58.315650Z",
     "shell.execute_reply": "2024-02-29T15:16:58.313582Z"
    },
    "papermill": {
     "duration": 0.04408,
     "end_time": "2024-02-29T15:16:58.318924",
     "exception": false,
     "start_time": "2024-02-29T15:16:58.274844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def generate_sequences_helper(\\n    dataset, cement_types, dates=None, timesteps=None, split_by_cement_type=False\\n):\\n    index_train = dataset[\\\"y_train\\\"].index\\n    index_test = dataset[\\\"y_test\\\"].index\\n\\n    dataset[\\\"y_train\\\"] = dataset[\\\"y_train\\\"].reset_index(drop=True)\\n    dataset[\\\"y_test\\\"] = dataset[\\\"y_test\\\"].reset_index(drop=True)\\n\\n    if dates is not None:\\n        dataset[\\\"dates_train\\\"] = dates[index_train].reset_index(drop=True)\\n        dataset[\\\"dates_test\\\"] = dates[index_test].reset_index(drop=True)\\n\\n    dataset[\\\"cement_types_train\\\"] = cement_types.loc[index_train].reset_index(drop=True)\\n    dataset[\\\"cement_types_test\\\"] = cement_types.loc[index_test].reset_index(drop=True)\\n\\n    dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\\n\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def generate_sequences_helper(\\n    dataset, cement_types, dates=None, timesteps=None, split_by_cement_type=False\\n):\\n    index_train = dataset[\\\"y_train\\\"].index\\n    index_test = dataset[\\\"y_test\\\"].index\\n\\n    dataset[\\\"y_train\\\"] = dataset[\\\"y_train\\\"].reset_index(drop=True)\\n    dataset[\\\"y_test\\\"] = dataset[\\\"y_test\\\"].reset_index(drop=True)\\n\\n    if dates is not None:\\n        dataset[\\\"dates_train\\\"] = dates[index_train].reset_index(drop=True)\\n        dataset[\\\"dates_test\\\"] = dates[index_test].reset_index(drop=True)\\n\\n    dataset[\\\"cement_types_train\\\"] = cement_types.loc[index_train].reset_index(drop=True)\\n    dataset[\\\"cement_types_test\\\"] = cement_types.loc[index_test].reset_index(drop=True)\\n\\n    dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\\n\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_sequences_helper(\n",
    "    dataset, cement_types, dates=None, timesteps=None, split_by_cement_type=False\n",
    "):\n",
    "    index_train = dataset[\"y_train\"].index\n",
    "    index_test = dataset[\"y_test\"].index\n",
    "\n",
    "    dataset[\"y_train\"] = dataset[\"y_train\"].reset_index(drop=True)\n",
    "    dataset[\"y_test\"] = dataset[\"y_test\"].reset_index(drop=True)\n",
    "\n",
    "    if dates is not None:\n",
    "        dataset[\"dates_train\"] = dates[index_train].reset_index(drop=True)\n",
    "        dataset[\"dates_test\"] = dates[index_test].reset_index(drop=True)\n",
    "\n",
    "    dataset[\"cement_types_train\"] = cement_types.loc[index_train].reset_index(drop=True)\n",
    "    dataset[\"cement_types_test\"] = cement_types.loc[index_test].reset_index(drop=True)\n",
    "\n",
    "    dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff96a24c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:58.351608Z",
     "iopub.status.busy": "2024-02-29T15:16:58.351044Z",
     "iopub.status.idle": "2024-02-29T15:16:58.384286Z",
     "shell.execute_reply": "2024-02-29T15:16:58.382543Z"
    },
    "papermill": {
     "duration": 0.053724,
     "end_time": "2024-02-29T15:16:58.387751",
     "exception": false,
     "start_time": "2024-02-29T15:16:58.334027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"def generate_sequences(dataset, timesteps, split_by_cement_type=False):\\n    if split_by_cement_type:\\n        dataset[\\\"x_train\\\"], dataset[\\\"y_train\\\"] = split_sequences_per_cement_type(\\n            pd.concat(\\n                [\\n                    dataset[\\\"dates_train\\\"],\\n                    pd.DataFrame(dataset[\\\"x_train\\\"], columns=x.columns),\\n                    dataset[\\\"cement_types_train\\\"],\\n                    dataset[\\\"y_train\\\"],\\n                ],\\n                axis=1,\\n            ),\\n            timesteps,\\n        )\\n\\n        dataset[\\\"x_test\\\"], dataset[\\\"y_test\\\"] = split_sequences_per_cement_type(\\n            pd.concat(\\n                [\\n                    dataset[\\\"dates_test\\\"],\\n                    pd.DataFrame(dataset[\\\"x_test\\\"], columns=x.columns),\\n                    dataset[\\\"cement_types_test\\\"],\\n                    dataset[\\\"y_test\\\"],\\n                ],\\n                axis=1,\\n            ),\\n            timesteps,\\n        )\\n    else:\\n        dataset[\\\"x_train\\\"], dataset[\\\"y_train\\\"] = split_sequences(\\n            pd.concat(\\n                [\\n                    pd.DataFrame(dataset[\\\"x_train\\\"], columns=x.columns),\\n                    dataset[\\\"y_train\\\"],\\n                ],\\n                axis=1,\\n            ).values,\\n            timesteps,\\n        )\\n\\n        dataset[\\\"x_test\\\"], dataset[\\\"y_test\\\"] = split_sequences(\\n            pd.concat(\\n                [\\n                    pd.DataFrame(dataset[\\\"x_test\\\"], columns=x.columns),\\n                    dataset[\\\"y_test\\\"],\\n                ],\\n                axis=1,\\n            ).values,\\n            timesteps,\\n        )\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def generate_sequences(dataset, timesteps, split_by_cement_type=False):\\n    if split_by_cement_type:\\n        dataset[\\\"x_train\\\"], dataset[\\\"y_train\\\"] = split_sequences_per_cement_type(\\n            pd.concat(\\n                [\\n                    dataset[\\\"dates_train\\\"],\\n                    pd.DataFrame(dataset[\\\"x_train\\\"], columns=x.columns),\\n                    dataset[\\\"cement_types_train\\\"],\\n                    dataset[\\\"y_train\\\"],\\n                ],\\n                axis=1,\\n            ),\\n            timesteps,\\n        )\\n\\n        dataset[\\\"x_test\\\"], dataset[\\\"y_test\\\"] = split_sequences_per_cement_type(\\n            pd.concat(\\n                [\\n                    dataset[\\\"dates_test\\\"],\\n                    pd.DataFrame(dataset[\\\"x_test\\\"], columns=x.columns),\\n                    dataset[\\\"cement_types_test\\\"],\\n                    dataset[\\\"y_test\\\"],\\n                ],\\n                axis=1,\\n            ),\\n            timesteps,\\n        )\\n    else:\\n        dataset[\\\"x_train\\\"], dataset[\\\"y_train\\\"] = split_sequences(\\n            pd.concat(\\n                [\\n                    pd.DataFrame(dataset[\\\"x_train\\\"], columns=x.columns),\\n                    dataset[\\\"y_train\\\"],\\n                ],\\n                axis=1,\\n            ).values,\\n            timesteps,\\n        )\\n\\n        dataset[\\\"x_test\\\"], dataset[\\\"y_test\\\"] = split_sequences(\\n            pd.concat(\\n                [\\n                    pd.DataFrame(dataset[\\\"x_test\\\"], columns=x.columns),\\n                    dataset[\\\"y_test\\\"],\\n                ],\\n                axis=1,\\n            ).values,\\n            timesteps,\\n        )\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_sequences(dataset, timesteps, split_by_cement_type=False):\n",
    "    if split_by_cement_type:\n",
    "        dataset[\"x_train\"], dataset[\"y_train\"] = split_sequences_per_cement_type(\n",
    "            pd.concat(\n",
    "                [\n",
    "                    dataset[\"dates_train\"],\n",
    "                    pd.DataFrame(dataset[\"x_train\"], columns=x.columns),\n",
    "                    dataset[\"cement_types_train\"],\n",
    "                    dataset[\"y_train\"],\n",
    "                ],\n",
    "                axis=1,\n",
    "            ),\n",
    "            timesteps,\n",
    "        )\n",
    "\n",
    "        dataset[\"x_test\"], dataset[\"y_test\"] = split_sequences_per_cement_type(\n",
    "            pd.concat(\n",
    "                [\n",
    "                    dataset[\"dates_test\"],\n",
    "                    pd.DataFrame(dataset[\"x_test\"], columns=x.columns),\n",
    "                    dataset[\"cement_types_test\"],\n",
    "                    dataset[\"y_test\"],\n",
    "                ],\n",
    "                axis=1,\n",
    "            ),\n",
    "            timesteps,\n",
    "        )\n",
    "    else:\n",
    "        dataset[\"x_train\"], dataset[\"y_train\"] = split_sequences(\n",
    "            pd.concat(\n",
    "                [\n",
    "                    pd.DataFrame(dataset[\"x_train\"], columns=x.columns),\n",
    "                    dataset[\"y_train\"],\n",
    "                ],\n",
    "                axis=1,\n",
    "            ).values,\n",
    "            timesteps,\n",
    "        )\n",
    "\n",
    "        dataset[\"x_test\"], dataset[\"y_test\"] = split_sequences(\n",
    "            pd.concat(\n",
    "                [\n",
    "                    pd.DataFrame(dataset[\"x_test\"], columns=x.columns),\n",
    "                    dataset[\"y_test\"],\n",
    "                ],\n",
    "                axis=1,\n",
    "            ).values,\n",
    "            timesteps,\n",
    "        )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee226d13",
   "metadata": {
    "papermill": {
     "duration": 0.014205,
     "end_time": "2024-02-29T15:16:58.416470",
     "exception": false,
     "start_time": "2024-02-29T15:16:58.402265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f727819",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:58.447890Z",
     "iopub.status.busy": "2024-02-29T15:16:58.447335Z",
     "iopub.status.idle": "2024-02-29T15:16:58.465882Z",
     "shell.execute_reply": "2024-02-29T15:16:58.464282Z"
    },
    "papermill": {
     "duration": 0.038865,
     "end_time": "2024-02-29T15:16:58.469842",
     "exception": false,
     "start_time": "2024-02-29T15:16:58.430977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"def impute_data(dataset, imputer=None, imputer_params=None):\\n    x_train = dataset[\\\"x_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n\\n    # Apply imputation to the data\\n    if imputer is not None:\\n        imputer = imputer() if imputer_params is None else imputer(**imputer_params)\\n        x_train = imputer.fit_transform(x_train)\\n        x_test = imputer.transform(x_test)\\n\\n    dataset[\\\"x_train\\\"] = x_train\\n    dataset[\\\"x_test\\\"] = x_test\\n\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def impute_data(dataset, imputer=None, imputer_params=None):\\n    x_train = dataset[\\\"x_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n\\n    # Apply imputation to the data\\n    if imputer is not None:\\n        imputer = imputer() if imputer_params is None else imputer(**imputer_params)\\n        x_train = imputer.fit_transform(x_train)\\n        x_test = imputer.transform(x_test)\\n\\n    dataset[\\\"x_train\\\"] = x_train\\n    dataset[\\\"x_test\\\"] = x_test\\n\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def impute_data(dataset, imputer=None, imputer_params=None):\n",
    "    x_train = dataset[\"x_train\"]\n",
    "    x_test = dataset[\"x_test\"]\n",
    "\n",
    "    # Apply imputation to the data\n",
    "    if imputer is not None:\n",
    "        imputer = imputer() if imputer_params is None else imputer(**imputer_params)\n",
    "        x_train = imputer.fit_transform(x_train)\n",
    "        x_test = imputer.transform(x_test)\n",
    "\n",
    "    dataset[\"x_train\"] = x_train\n",
    "    dataset[\"x_test\"] = x_test\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c598dba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:58.502851Z",
     "iopub.status.busy": "2024-02-29T15:16:58.502312Z",
     "iopub.status.idle": "2024-02-29T15:16:58.518393Z",
     "shell.execute_reply": "2024-02-29T15:16:58.516789Z"
    },
    "papermill": {
     "duration": 0.036664,
     "end_time": "2024-02-29T15:16:58.521487",
     "exception": false,
     "start_time": "2024-02-29T15:16:58.484823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"def transform_data(dataset, transformer=None):\\n    x_train = dataset[\\\"x_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n\\n    # Apply data normalization/standardization to the data\\n    if transformer is not None:\\n        scaler = transformer()\\n        x_train = scaler.fit_transform(x_train)\\n        x_test = scaler.transform(x_test)\\n\\n    dataset[\\\"x_train\\\"] = x_train\\n    dataset[\\\"x_test\\\"] = x_test\\n\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def transform_data(dataset, transformer=None):\\n    x_train = dataset[\\\"x_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n\\n    # Apply data normalization/standardization to the data\\n    if transformer is not None:\\n        scaler = transformer()\\n        x_train = scaler.fit_transform(x_train)\\n        x_test = scaler.transform(x_test)\\n\\n    dataset[\\\"x_train\\\"] = x_train\\n    dataset[\\\"x_test\\\"] = x_test\\n\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def transform_data(dataset, transformer=None):\n",
    "    x_train = dataset[\"x_train\"]\n",
    "    x_test = dataset[\"x_test\"]\n",
    "\n",
    "    # Apply data normalization/standardization to the data\n",
    "    if transformer is not None:\n",
    "        scaler = transformer()\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "    dataset[\"x_train\"] = x_train\n",
    "    dataset[\"x_test\"] = x_test\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f39fc76e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:58.556046Z",
     "iopub.status.busy": "2024-02-29T15:16:58.555451Z",
     "iopub.status.idle": "2024-02-29T15:16:58.569415Z",
     "shell.execute_reply": "2024-02-29T15:16:58.567848Z"
    },
    "papermill": {
     "duration": 0.035618,
     "end_time": "2024-02-29T15:16:58.572817",
     "exception": false,
     "start_time": "2024-02-29T15:16:58.537199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"def preprocess_data(dataset, transformer=None, imputer=None, imputer_params=None):\\n    dataset = impute_data(dataset, imputer, imputer_params)\\n    dataset = transform_data(dataset, transformer)\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def preprocess_data(dataset, transformer=None, imputer=None, imputer_params=None):\\n    dataset = impute_data(dataset, imputer, imputer_params)\\n    dataset = transform_data(dataset, transformer)\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_data(dataset, transformer=None, imputer=None, imputer_params=None):\n",
    "    dataset = impute_data(dataset, imputer, imputer_params)\n",
    "    dataset = transform_data(dataset, transformer)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7043c814",
   "metadata": {
    "papermill": {
     "duration": 0.01572,
     "end_time": "2024-02-29T15:16:58.604444",
     "exception": false,
     "start_time": "2024-02-29T15:16:58.588724",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "065c6426",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:58.637062Z",
     "iopub.status.busy": "2024-02-29T15:16:58.636547Z",
     "iopub.status.idle": "2024-02-29T15:16:58.655345Z",
     "shell.execute_reply": "2024-02-29T15:16:58.653607Z"
    },
    "papermill": {
     "duration": 0.040166,
     "end_time": "2024-02-29T15:16:58.659800",
     "exception": false,
     "start_time": "2024-02-29T15:16:58.619634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"def train_and_evaluate_model(Estimator, dataset, estimator_params=None):\\n    \\\"\\\"\\\"\\n    Purpose: Helper function to be used in conjunction with\\n    blocked time_series cross validation function\\n    \\\"\\\"\\\"\\n    x_train = dataset[\\\"x_train\\\"]\\n    y_train = dataset[\\\"y_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n    y_test = dataset[\\\"y_test\\\"]\\n\\n    # Instantiate the model\\n    model = Estimator() if estimator_params is None else Estimator(**estimator_params)\\n\\n    # Fitting the model\\n    model.fit(x_train, y_train)\\n\\n    # Making predictions on train/test sets\\n    y_train_pred = model.predict(x_train)\\n    y_test_pred = model.predict(x_test)\\n\\n    # Return regression metrics\\n    return score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"def train_and_evaluate_model(Estimator, dataset, estimator_params=None):\\n    \\\"\\\"\\\"\\n    Purpose: Helper function to be used in conjunction with\\n    blocked time_series cross validation function\\n    \\\"\\\"\\\"\\n    x_train = dataset[\\\"x_train\\\"]\\n    y_train = dataset[\\\"y_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n    y_test = dataset[\\\"y_test\\\"]\\n\\n    # Instantiate the model\\n    model = Estimator() if estimator_params is None else Estimator(**estimator_params)\\n\\n    # Fitting the model\\n    model.fit(x_train, y_train)\\n\\n    # Making predictions on train/test sets\\n    y_train_pred = model.predict(x_train)\\n    y_test_pred = model.predict(x_test)\\n\\n    # Return regression metrics\\n    return score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_and_evaluate_model(Estimator, dataset, estimator_params=None):\n",
    "    \"\"\"\n",
    "    Purpose: Helper function to be used in conjunction with\n",
    "    blocked time_series cross validation function\n",
    "    \"\"\"\n",
    "    x_train = dataset[\"x_train\"]\n",
    "    y_train = dataset[\"y_train\"]\n",
    "    x_test = dataset[\"x_test\"]\n",
    "    y_test = dataset[\"y_test\"]\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = Estimator() if estimator_params is None else Estimator(**estimator_params)\n",
    "\n",
    "    # Fitting the model\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Making predictions on train/test sets\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "\n",
    "    # Return regression metrics\n",
    "    return score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc149e80",
   "metadata": {
    "papermill": {
     "duration": 0.017044,
     "end_time": "2024-02-29T15:16:58.692196",
     "exception": false,
     "start_time": "2024-02-29T15:16:58.675152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Custom Cross Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7250629c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:58.728714Z",
     "iopub.status.busy": "2024-02-29T15:16:58.728116Z",
     "iopub.status.idle": "2024-02-29T15:16:58.776528Z",
     "shell.execute_reply": "2024-02-29T15:16:58.774623Z"
    },
    "papermill": {
     "duration": 0.071465,
     "end_time": "2024-02-29T15:16:58.779595",
     "exception": false,
     "start_time": "2024-02-29T15:16:58.708130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"def custom_cross_validate_parallelized(\\n   Estimator,\\n   Imputer,\\n   Transform,\\n   x,\\n   y,\\n   cv,\\n   timesteps,\\n   dates=None,\\n   cement_types=None,\\n   estimator_params=None,\\n   imputer_params=None,\\n   split_by_cement_type=True,\\n   n_jobs=5,  # Set the number of parallel jobs, -1 for using all available cores\\n):\\n    def process_fold(train_index, test_index, dates, cement_types, x, y):\\n        dataset = {\\n           \\\"dates_train\\\": dates[train_index].reset_index(drop=True),\\n           \\\"cement_types_train\\\": cement_types.loc[train_index].reset_index(drop=True),\\n           \\\"x_train\\\": x.loc[train_index].reset_index(drop=True),\\n           \\\"y_train\\\": y[train_index].reset_index(drop=True),\\n           \\\"dates_test\\\": dates[test_index].reset_index(drop=True),\\n           \\\"cement_types_test\\\": cement_types.loc[test_index].reset_index(drop=True),\\n           \\\"x_test\\\": x.loc[test_index].reset_index(drop=True),\\n           \\\"y_test\\\": y[test_index].reset_index(drop=True),\\n        }\\n\\n\\n        set_seeds()\\n\\n        # Preprocess the dataset\\n        dataset = preprocess_data(dataset, Transform, Imputer, imputer_params)\\n\\n        # generate sequences (3D format)\\n        dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\\n\\n        # Train and Evaluate the model\\n        score = train_and_evaluate_model(Estimator, dataset, estimator_params)\\n        return score\\n\\n    scores = Parallel(n_jobs=n_jobs)(\\n    delayed(process_fold)(train_index, test_index, dates, cement_types, x, y)\\n    for train_index, test_index in cv.split(x)\\n    )\\n\\n    # After every iteration metrics results are appended together\\n    scores_final = {key: [] for key, _ in scores[0].items()}\\n    for scores_dict in scores:\\n        for key, value in scores_dict.items():\\n            scores_final[key] += [value]\\n\\n    results = [scores_final]\\n    return results\";\n",
       "                var nbb_formatted_code = \"def custom_cross_validate_parallelized(\\n    Estimator,\\n    Imputer,\\n    Transform,\\n    x,\\n    y,\\n    cv,\\n    timesteps,\\n    dates=None,\\n    cement_types=None,\\n    estimator_params=None,\\n    imputer_params=None,\\n    split_by_cement_type=True,\\n    n_jobs=5,  # Set the number of parallel jobs, -1 for using all available cores\\n):\\n    def process_fold(train_index, test_index, dates, cement_types, x, y):\\n        dataset = {\\n            \\\"dates_train\\\": dates[train_index].reset_index(drop=True),\\n            \\\"cement_types_train\\\": cement_types.loc[train_index].reset_index(drop=True),\\n            \\\"x_train\\\": x.loc[train_index].reset_index(drop=True),\\n            \\\"y_train\\\": y[train_index].reset_index(drop=True),\\n            \\\"dates_test\\\": dates[test_index].reset_index(drop=True),\\n            \\\"cement_types_test\\\": cement_types.loc[test_index].reset_index(drop=True),\\n            \\\"x_test\\\": x.loc[test_index].reset_index(drop=True),\\n            \\\"y_test\\\": y[test_index].reset_index(drop=True),\\n        }\\n\\n        set_seeds()\\n\\n        # Preprocess the dataset\\n        dataset = preprocess_data(dataset, Transform, Imputer, imputer_params)\\n\\n        # generate sequences (3D format)\\n        dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\\n\\n        # Train and Evaluate the model\\n        score = train_and_evaluate_model(Estimator, dataset, estimator_params)\\n        return score\\n\\n    scores = Parallel(n_jobs=n_jobs)(\\n        delayed(process_fold)(train_index, test_index, dates, cement_types, x, y)\\n        for train_index, test_index in cv.split(x)\\n    )\\n\\n    # After every iteration metrics results are appended together\\n    scores_final = {key: [] for key, _ in scores[0].items()}\\n    for scores_dict in scores:\\n        for key, value in scores_dict.items():\\n            scores_final[key] += [value]\\n\\n    results = [scores_final]\\n    return results\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def custom_cross_validate_parallelized(\n",
    "   Estimator,\n",
    "   Imputer,\n",
    "   Transform,\n",
    "   x,\n",
    "   y,\n",
    "   cv,\n",
    "   timesteps,\n",
    "   dates=None,\n",
    "   cement_types=None,\n",
    "   estimator_params=None,\n",
    "   imputer_params=None,\n",
    "   split_by_cement_type=True,\n",
    "   n_jobs=5,  # Set the number of parallel jobs, -1 for using all available cores\n",
    "):\n",
    "    def process_fold(train_index, test_index, dates, cement_types, x, y):\n",
    "        dataset = {\n",
    "           \"dates_train\": dates[train_index].reset_index(drop=True),\n",
    "           \"cement_types_train\": cement_types.loc[train_index].reset_index(drop=True),\n",
    "           \"x_train\": x.loc[train_index].reset_index(drop=True),\n",
    "           \"y_train\": y[train_index].reset_index(drop=True),\n",
    "           \"dates_test\": dates[test_index].reset_index(drop=True),\n",
    "           \"cement_types_test\": cement_types.loc[test_index].reset_index(drop=True),\n",
    "           \"x_test\": x.loc[test_index].reset_index(drop=True),\n",
    "           \"y_test\": y[test_index].reset_index(drop=True),\n",
    "        }\n",
    "\n",
    "\n",
    "        set_seeds()\n",
    "\n",
    "        # Preprocess the dataset\n",
    "        dataset = preprocess_data(dataset, Transform, Imputer, imputer_params)\n",
    "\n",
    "        # generate sequences (3D format)\n",
    "        dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\n",
    "\n",
    "        # Train and Evaluate the model\n",
    "        score = train_and_evaluate_model(Estimator, dataset, estimator_params)\n",
    "        return score\n",
    "\n",
    "    scores = Parallel(n_jobs=n_jobs)(\n",
    "    delayed(process_fold)(train_index, test_index, dates, cement_types, x, y)\n",
    "    for train_index, test_index in cv.split(x)\n",
    "    )\n",
    "\n",
    "    # After every iteration metrics results are appended together\n",
    "    scores_final = {key: [] for key, _ in scores[0].items()}\n",
    "    for scores_dict in scores:\n",
    "        for key, value in scores_dict.items():\n",
    "            scores_final[key] += [value]\n",
    "\n",
    "    results = [scores_final]\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eb2428",
   "metadata": {
    "papermill": {
     "duration": 0.015881,
     "end_time": "2024-02-29T15:16:58.812281",
     "exception": false,
     "start_time": "2024-02-29T15:16:58.796400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a41952e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:58.851012Z",
     "iopub.status.busy": "2024-02-29T15:16:58.850459Z",
     "iopub.status.idle": "2024-02-29T15:16:58.877812Z",
     "shell.execute_reply": "2024-02-29T15:16:58.875860Z"
    },
    "papermill": {
     "duration": 0.050793,
     "end_time": "2024-02-29T15:16:58.881634",
     "exception": false,
     "start_time": "2024-02-29T15:16:58.830841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class TransformerWrapper(RegressorMixin):\\n    def __init__(self, params):\\n        self.params = params\\n        self.model = self.get_model()\\n        self.batch_size = 16\\n        self.epochs = 300\\n        self.verbose = 0\\n\\n    def fit(self, X=None, y=None):\\n        self.model.fit(\\n            X, y, batch_size=self.batch_size, epochs=self.epochs, verbose=self.verbose\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = Transformer(\\n            num_hid=self.params[\\\"num_features\\\"],\\n            time_steps=self.params[\\\"timesteps\\\"],\\n            num_head=self.params[\\\"num_heads\\\"],\\n            num_layers_enc=self.params[\\\"num_layers_enc\\\"],\\n            num_feed_forward=self.params[\\\"num_feed_forward\\\"],\\n        )\\n        model.compile(\\n            tf.keras.optimizers.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class TransformerWrapper(RegressorMixin):\\n    def __init__(self, params):\\n        self.params = params\\n        self.model = self.get_model()\\n        self.batch_size = 16\\n        self.epochs = 300\\n        self.verbose = 0\\n\\n    def fit(self, X=None, y=None):\\n        self.model.fit(\\n            X, y, batch_size=self.batch_size, epochs=self.epochs, verbose=self.verbose\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = Transformer(\\n            num_hid=self.params[\\\"num_features\\\"],\\n            time_steps=self.params[\\\"timesteps\\\"],\\n            num_head=self.params[\\\"num_heads\\\"],\\n            num_layers_enc=self.params[\\\"num_layers_enc\\\"],\\n            num_feed_forward=self.params[\\\"num_feed_forward\\\"],\\n        )\\n        model.compile(\\n            tf.keras.optimizers.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class TransformerWrapper(RegressorMixin):\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 16\n",
    "        self.epochs = 300\n",
    "        self.verbose = 0\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.model.fit(\n",
    "            X, y, batch_size=self.batch_size, epochs=self.epochs, verbose=self.verbose\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = Transformer(\n",
    "            num_hid=self.params[\"num_features\"],\n",
    "            time_steps=self.params[\"timesteps\"],\n",
    "            num_head=self.params[\"num_heads\"],\n",
    "            num_layers_enc=self.params[\"num_layers_enc\"],\n",
    "            num_feed_forward=self.params[\"num_feed_forward\"],\n",
    "        )\n",
    "        model.compile(\n",
    "            tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75ed37f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:58.916814Z",
     "iopub.status.busy": "2024-02-29T15:16:58.916271Z",
     "iopub.status.idle": "2024-02-29T15:16:58.934980Z",
     "shell.execute_reply": "2024-02-29T15:16:58.933130Z"
    },
    "papermill": {
     "duration": 0.041552,
     "end_time": "2024-02-29T15:16:58.939669",
     "exception": false,
     "start_time": "2024-02-29T15:16:58.898117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"def pad_time_series(dataframe, timesteps):\\n    \\\"\\\"\\\"\\n    Pad timeseries with zeros\\n    \\\"\\\"\\\"\\n    df_tmp = pd.DataFrame(\\n        dict(\\n            zip(\\n                dataframe.columns,\\n                [[0 for _ in range(timesteps - 1)] for _ in range(dataframe.shape[1])],\\n            )\\n        )\\n    )\\n    df_tmp[DATE] = dataframe[DATE].iloc[0]\\n    return pd.concat([df_tmp, dataframe], axis=0).reset_index(drop=True)\";\n",
       "                var nbb_formatted_code = \"def pad_time_series(dataframe, timesteps):\\n    \\\"\\\"\\\"\\n    Pad timeseries with zeros\\n    \\\"\\\"\\\"\\n    df_tmp = pd.DataFrame(\\n        dict(\\n            zip(\\n                dataframe.columns,\\n                [[0 for _ in range(timesteps - 1)] for _ in range(dataframe.shape[1])],\\n            )\\n        )\\n    )\\n    df_tmp[DATE] = dataframe[DATE].iloc[0]\\n    return pd.concat([df_tmp, dataframe], axis=0).reset_index(drop=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pad_time_series(dataframe, timesteps):\n",
    "    \"\"\"\n",
    "    Pad timeseries with zeros\n",
    "    \"\"\"\n",
    "    df_tmp = pd.DataFrame(\n",
    "        dict(\n",
    "            zip(\n",
    "                dataframe.columns,\n",
    "                [[0 for _ in range(timesteps - 1)] for _ in range(dataframe.shape[1])],\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    df_tmp[DATE] = dataframe[DATE].iloc[0]\n",
    "    return pd.concat([df_tmp, dataframe], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e31ace72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:58.981757Z",
     "iopub.status.busy": "2024-02-29T15:16:58.979401Z",
     "iopub.status.idle": "2024-02-29T15:16:59.012098Z",
     "shell.execute_reply": "2024-02-29T15:16:59.010027Z"
    },
    "papermill": {
     "duration": 0.058424,
     "end_time": "2024-02-29T15:16:59.016111",
     "exception": false,
     "start_time": "2024-02-29T15:16:58.957687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"def split_sequences_per_cement_type(dataframe, timesteps, pad=False):\\n    \\\"\\\"\\\"\\n    Create sequences per cement time\\n    to avoid having parts of the sequence\\n    of different types of cement.\\n    \\\"\\\"\\\"\\n    if timesteps == 1:\\n        return split_sequences(\\n            dataframe.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps\\n        )\\n\\n    dates = dataframe[DATE][timesteps - 1 :]\\n    data = []\\n    dataframes = []\\n\\n    for cement_type in CEMENT_TYPES:\\n        data.append(dataframe[dataframe[cement_type] == 1])\\n    data.append(dataframe[(dataframe[CEMENT_TYPES] == 0).all(axis=1)])\\n\\n    for df in data:\\n        if pad:\\n            dates = df[DATE].reset_index(drop=True)\\n            df = pad_time_series(df, timesteps).reset_index(drop=True)\\n        else:\\n            dates = df[DATE][timesteps - 1 :].reset_index(drop=True)\\n        x, y = split_sequences(df.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps)\\n        x = pd.DataFrame({\\\"Sequences\\\": [sample.tolist() for sample in x]})\\n        y = pd.DataFrame({\\\"Target\\\": y})\\n        dataframes.append(pd.concat([dates, x, y], axis=1))\\n\\n    data = pd.concat(dataframes, axis=0)\\n    data[DATE] = pd.to_datetime(data[DATE])\\n    data = data.sort_values(by=DATE).reset_index(drop=True)\\n    x = data[\\\"Sequences\\\"]\\n    y = data[\\\"Target\\\"].values\\n    x = np.array(x.tolist())\\n\\n    return x, y\";\n",
       "                var nbb_formatted_code = \"def split_sequences_per_cement_type(dataframe, timesteps, pad=False):\\n    \\\"\\\"\\\"\\n    Create sequences per cement time\\n    to avoid having parts of the sequence\\n    of different types of cement.\\n    \\\"\\\"\\\"\\n    if timesteps == 1:\\n        return split_sequences(\\n            dataframe.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps\\n        )\\n\\n    dates = dataframe[DATE][timesteps - 1 :]\\n    data = []\\n    dataframes = []\\n\\n    for cement_type in CEMENT_TYPES:\\n        data.append(dataframe[dataframe[cement_type] == 1])\\n    data.append(dataframe[(dataframe[CEMENT_TYPES] == 0).all(axis=1)])\\n\\n    for df in data:\\n        if pad:\\n            dates = df[DATE].reset_index(drop=True)\\n            df = pad_time_series(df, timesteps).reset_index(drop=True)\\n        else:\\n            dates = df[DATE][timesteps - 1 :].reset_index(drop=True)\\n        x, y = split_sequences(df.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps)\\n        x = pd.DataFrame({\\\"Sequences\\\": [sample.tolist() for sample in x]})\\n        y = pd.DataFrame({\\\"Target\\\": y})\\n        dataframes.append(pd.concat([dates, x, y], axis=1))\\n\\n    data = pd.concat(dataframes, axis=0)\\n    data[DATE] = pd.to_datetime(data[DATE])\\n    data = data.sort_values(by=DATE).reset_index(drop=True)\\n    x = data[\\\"Sequences\\\"]\\n    y = data[\\\"Target\\\"].values\\n    x = np.array(x.tolist())\\n\\n    return x, y\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def split_sequences_per_cement_type(dataframe, timesteps, pad=False):\n",
    "    \"\"\"\n",
    "    Create sequences per cement time\n",
    "    to avoid having parts of the sequence\n",
    "    of different types of cement.\n",
    "    \"\"\"\n",
    "    if timesteps == 1:\n",
    "        return split_sequences(\n",
    "            dataframe.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps\n",
    "        )\n",
    "\n",
    "    dates = dataframe[DATE][timesteps - 1 :]\n",
    "    data = []\n",
    "    dataframes = []\n",
    "\n",
    "    for cement_type in CEMENT_TYPES:\n",
    "        data.append(dataframe[dataframe[cement_type] == 1])\n",
    "    data.append(dataframe[(dataframe[CEMENT_TYPES] == 0).all(axis=1)])\n",
    "\n",
    "    for df in data:\n",
    "        if pad:\n",
    "            dates = df[DATE].reset_index(drop=True)\n",
    "            df = pad_time_series(df, timesteps).reset_index(drop=True)\n",
    "        else:\n",
    "            dates = df[DATE][timesteps - 1 :].reset_index(drop=True)\n",
    "        x, y = split_sequences(df.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps)\n",
    "        x = pd.DataFrame({\"Sequences\": [sample.tolist() for sample in x]})\n",
    "        y = pd.DataFrame({\"Target\": y})\n",
    "        dataframes.append(pd.concat([dates, x, y], axis=1))\n",
    "\n",
    "    data = pd.concat(dataframes, axis=0)\n",
    "    data[DATE] = pd.to_datetime(data[DATE])\n",
    "    data = data.sort_values(by=DATE).reset_index(drop=True)\n",
    "    x = data[\"Sequences\"]\n",
    "    y = data[\"Target\"].values\n",
    "    x = np.array(x.tolist())\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1910b713",
   "metadata": {
    "papermill": {
     "duration": 0.015612,
     "end_time": "2024-02-29T15:16:59.049805",
     "exception": false,
     "start_time": "2024-02-29T15:16:59.034193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d939ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:59.084951Z",
     "iopub.status.busy": "2024-02-29T15:16:59.084374Z",
     "iopub.status.idle": "2024-02-29T15:16:59.094777Z",
     "shell.execute_reply": "2024-02-29T15:16:59.093442Z"
    },
    "papermill": {
     "duration": 0.030863,
     "end_time": "2024-02-29T15:16:59.098247",
     "exception": false,
     "start_time": "2024-02-29T15:16:59.067384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"SEED = 47\";\n",
       "                var nbb_formatted_code = \"SEED = 47\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f474de7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:59.127416Z",
     "iopub.status.busy": "2024-02-29T15:16:59.126849Z",
     "iopub.status.idle": "2024-02-29T15:16:59.140746Z",
     "shell.execute_reply": "2024-02-29T15:16:59.138997Z"
    },
    "papermill": {
     "duration": 0.032414,
     "end_time": "2024-02-29T15:16:59.143979",
     "exception": false,
     "start_time": "2024-02-29T15:16:59.111565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"def set_seeds(seed=SEED):\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(seed)\\n    tf.random.set_seed(seed)\\n    np.random.seed(seed)\\n    random.seed(seed)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds(seed=SEED):\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(seed)\\n    tf.random.set_seed(seed)\\n    np.random.seed(seed)\\n    random.seed(seed)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds(seed=SEED):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c57f1ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:59.181119Z",
     "iopub.status.busy": "2024-02-29T15:16:59.180555Z",
     "iopub.status.idle": "2024-02-29T15:16:59.195185Z",
     "shell.execute_reply": "2024-02-29T15:16:59.193591Z"
    },
    "papermill": {
     "duration": 0.037868,
     "end_time": "2024-02-29T15:16:59.198712",
     "exception": false,
     "start_time": "2024-02-29T15:16:59.160844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"def set_global_determinism():\\n    set_seeds(seed=SEED)\\n\\n    os.environ[\\\"TF_DETERMINISTIC_OPS\\\"] = \\\"1\\\"\\n    os.environ[\\\"TF_CUDNN_DETERMINISTIC\\\"] = \\\"1\\\"\\n\\n    tf.config.threading.set_inter_op_parallelism_threads(1)\\n    tf.config.threading.set_intra_op_parallelism_threads(1)\";\n",
       "                var nbb_formatted_code = \"def set_global_determinism():\\n    set_seeds(seed=SEED)\\n\\n    os.environ[\\\"TF_DETERMINISTIC_OPS\\\"] = \\\"1\\\"\\n    os.environ[\\\"TF_CUDNN_DETERMINISTIC\\\"] = \\\"1\\\"\\n\\n    tf.config.threading.set_inter_op_parallelism_threads(1)\\n    tf.config.threading.set_intra_op_parallelism_threads(1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_global_determinism():\n",
    "    set_seeds(seed=SEED)\n",
    "\n",
    "    os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "    os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91c656c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:59.300179Z",
     "iopub.status.busy": "2024-02-29T15:16:59.299690Z",
     "iopub.status.idle": "2024-02-29T15:16:59.311115Z",
     "shell.execute_reply": "2024-02-29T15:16:59.309588Z"
    },
    "papermill": {
     "duration": 0.031624,
     "end_time": "2024-02-29T15:16:59.314824",
     "exception": false,
     "start_time": "2024-02-29T15:16:59.283200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"def suppress_warnings():\\n    os.environ[\\\"TF_CPP_MIN_LOG_LEVEL\\\"] = \\\"3\\\"\";\n",
       "                var nbb_formatted_code = \"def suppress_warnings():\\n    os.environ[\\\"TF_CPP_MIN_LOG_LEVEL\\\"] = \\\"3\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def suppress_warnings():\n",
    "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24ceb1cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:59.350923Z",
     "iopub.status.busy": "2024-02-29T15:16:59.350392Z",
     "iopub.status.idle": "2024-02-29T15:16:59.361743Z",
     "shell.execute_reply": "2024-02-29T15:16:59.360011Z"
    },
    "papermill": {
     "duration": 0.032008,
     "end_time": "2024-02-29T15:16:59.364569",
     "exception": false,
     "start_time": "2024-02-29T15:16:59.332561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def supress_other_stuff():\\n    os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    # os.environ[\\\"TF_ENABLE_ONEDNN_OPTS\\\"] = \\\"0\\\"\";\n",
       "                var nbb_formatted_code = \"def supress_other_stuff():\\n    os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    # os.environ[\\\"TF_ENABLE_ONEDNN_OPTS\\\"] = \\\"0\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def supress_other_stuff():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    # os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "108fefd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:59.402095Z",
     "iopub.status.busy": "2024-02-29T15:16:59.401535Z",
     "iopub.status.idle": "2024-02-29T15:16:59.412345Z",
     "shell.execute_reply": "2024-02-29T15:16:59.410653Z"
    },
    "papermill": {
     "duration": 0.032673,
     "end_time": "2024-02-29T15:16:59.415453",
     "exception": false,
     "start_time": "2024-02-29T15:16:59.382780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"suppress_warnings()\\nsupress_other_stuff()\";\n",
       "                var nbb_formatted_code = \"suppress_warnings()\\nsupress_other_stuff()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suppress_warnings()\n",
    "supress_other_stuff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5e20189",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:59.452887Z",
     "iopub.status.busy": "2024-02-29T15:16:59.451231Z",
     "iopub.status.idle": "2024-02-29T15:16:59.462305Z",
     "shell.execute_reply": "2024-02-29T15:16:59.460603Z"
    },
    "papermill": {
     "duration": 0.033798,
     "end_time": "2024-02-29T15:16:59.465719",
     "exception": false,
     "start_time": "2024-02-29T15:16:59.431921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"index_to_save = 9\";\n",
       "                var nbb_formatted_code = \"index_to_save = 9\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38d45168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:59.504229Z",
     "iopub.status.busy": "2024-02-29T15:16:59.503684Z",
     "iopub.status.idle": "2024-02-29T15:16:59.520039Z",
     "shell.execute_reply": "2024-02-29T15:16:59.518196Z"
    },
    "papermill": {
     "duration": 0.039929,
     "end_time": "2024-02-29T15:16:59.523957",
     "exception": false,
     "start_time": "2024-02-29T15:16:59.484028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"METRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\\nDATE = \\\"Date\\\"\\nCEMENT_TYPES = [\\\"Cement_Type_CP II-F-40\\\", \\\"Cement_Type_CP V-ARI\\\"]\";\n",
       "                var nbb_formatted_code = \"METRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\\nDATE = \\\"Date\\\"\\nCEMENT_TYPES = [\\\"Cement_Type_CP II-F-40\\\", \\\"Cement_Type_CP V-ARI\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}\n",
    "DATE = \"Date\"\n",
    "CEMENT_TYPES = [\"Cement_Type_CP II-F-40\", \"Cement_Type_CP V-ARI\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77216327",
   "metadata": {
    "papermill": {
     "duration": 0.015043,
     "end_time": "2024-02-29T15:16:59.556884",
     "exception": false,
     "start_time": "2024-02-29T15:16:59.541841",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18ebf780",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:59.591627Z",
     "iopub.status.busy": "2024-02-29T15:16:59.591107Z",
     "iopub.status.idle": "2024-02-29T15:16:59.611464Z",
     "shell.execute_reply": "2024-02-29T15:16:59.609667Z"
    },
    "papermill": {
     "duration": 0.04289,
     "end_time": "2024-02-29T15:16:59.614951",
     "exception": false,
     "start_time": "2024-02-29T15:16:59.572061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Local Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"N\\\",\\n    \\\"Features\\\": \\\"Chemical + Feature Engineering\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"Transformer\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Local Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"N\\\",\\n    \\\"Features\\\": \\\"Chemical + Feature Engineering\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"Transformer\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Local Model\",\n",
    "    \"Company\": \"209\",\n",
    "    \"Plant\": \"N\",\n",
    "    \"Features\": \"Chemical + Feature Engineering\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"Transformer\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11582c03",
   "metadata": {
    "papermill": {
     "duration": 0.014496,
     "end_time": "2024-02-29T15:16:59.644190",
     "exception": false,
     "start_time": "2024-02-29T15:16:59.629694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32505981",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:59.677480Z",
     "iopub.status.busy": "2024-02-29T15:16:59.676821Z",
     "iopub.status.idle": "2024-02-29T15:16:59.705283Z",
     "shell.execute_reply": "2024-02-29T15:16:59.703637Z"
    },
    "papermill": {
     "duration": 0.048712,
     "end_time": "2024-02-29T15:16:59.708665",
     "exception": false,
     "start_time": "2024-02-29T15:16:59.659953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../data/processed/209/n.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../data/processed/209/n.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../data/processed/209/n.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a16a2fb",
   "metadata": {
    "papermill": {
     "duration": 0.016833,
     "end_time": "2024-02-29T15:16:59.741346",
     "exception": false,
     "start_time": "2024-02-29T15:16:59.724513",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab035c31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:59.778890Z",
     "iopub.status.busy": "2024-02-29T15:16:59.777621Z",
     "iopub.status.idle": "2024-02-29T15:16:59.800893Z",
     "shell.execute_reply": "2024-02-29T15:16:59.799190Z"
    },
    "papermill": {
     "duration": 0.045922,
     "end_time": "2024-02-29T15:16:59.803846",
     "exception": false,
     "start_time": "2024-02-29T15:16:59.757924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy()\\ndf_copy = pd.get_dummies(data=df_copy, columns=[\\\"Cement_Type\\\"], drop_first=True)\\n\\ndf_copy = df_copy.drop(\\n    [\\n        \\\"Blaine\\\",\\n        \\\"#400\\\",\\n        \\\"#325\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy()\\ndf_copy = pd.get_dummies(data=df_copy, columns=[\\\"Cement_Type\\\"], drop_first=True)\\n\\ndf_copy = df_copy.drop(\\n    [\\n        \\\"Blaine\\\",\\n        \\\"#400\\\",\\n        \\\"#325\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy()\n",
    "df_copy = pd.get_dummies(data=df_copy, columns=[\"Cement_Type\"], drop_first=True)\n",
    "\n",
    "df_copy = df_copy.drop(\n",
    "    [\n",
    "        \"Blaine\",\n",
    "        \"#400\",\n",
    "        \"#325\",\n",
    "        \"Final setting time\",\n",
    "        \"Initial setting time\",\n",
    "        \"CS3\",\n",
    "        \"CS7\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ba73d0",
   "metadata": {
    "papermill": {
     "duration": 0.015606,
     "end_time": "2024-02-29T15:16:59.834523",
     "exception": false,
     "start_time": "2024-02-29T15:16:59.818917",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6cc29a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:59.869509Z",
     "iopub.status.busy": "2024-02-29T15:16:59.868458Z",
     "iopub.status.idle": "2024-02-29T15:16:59.903222Z",
     "shell.execute_reply": "2024-02-29T15:16:59.901774Z"
    },
    "papermill": {
     "duration": 0.055459,
     "end_time": "2024-02-29T15:16:59.906837",
     "exception": false,
     "start_time": "2024-02-29T15:16:59.851378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# Feature Engineering over Chemical Features\\nch_features = [\\\"CaO\\\", \\\"MgO\\\", \\\"Na2O\\\", \\\"Al2O3\\\", \\\"SiO2\\\", \\\"SO3\\\", \\\"K2O\\\", \\\"Fe2O3\\\", \\\"TiO2\\\"]\\n\\ndf_copy[\\\"std_ch_feats\\\"] = df_copy[ch_features].std(ddof=0, axis=1)\\n\\ndf_copy[\\\"ratio_CaO_to_SiO2\\\"] = df_copy[\\\"CaO\\\"] / df_copy[\\\"SiO2\\\"]\\ndf_copy[\\\"ratio_MgO_to_CaO\\\"] = df_copy[\\\"MgO\\\"] / df_copy[\\\"CaO\\\"]\\n\\n\\n# Feature Engineering over Mineralogical Features\\nmi_features_set1 = [\\n    # Set 1\\n    \\\"C4AF\\\",\\n    \\\"Cubic C3A\\\",\\n    \\\"Orthorhombic C3A\\\",\\n    \\\"Free CaO\\\",\\n    # Set 2\\n    \\\"Portlandite\\\",\\n    \\\"Periclase\\\",\\n    \\\"Bassanite\\\",\\n    \\\"Calcite\\\",\\n    \\\"Arcanite\\\",\\n    \\\"Aphthitalite\\\",\\n]\\n\\ndf_copy[\\\"mean_mi_set1_feats\\\"] = df_copy[mi_features_set1].mean(axis=1)\\n# Feature Engineering over Mineralogical Features\\nmi_features_set1 = [\\n    # Set 1\\n    \\\"C4AF\\\",\\n    \\\"Cubic C3A\\\",\\n    \\\"Orthorhombic C3A\\\",\\n    \\\"Free CaO\\\",\\n    # Set 2\\n    \\\"Portlandite\\\",\\n    \\\"Periclase\\\",\\n    \\\"Bassanite\\\",\\n    \\\"Calcite\\\",\\n    \\\"Arcanite\\\",\\n    \\\"Aphthitalite\\\",\\n]\\n\\ndf_copy[\\\"mean_mi_set1_feats\\\"] = df_copy[mi_features_set1].mean(axis=1)\";\n",
       "                var nbb_formatted_code = \"# Feature Engineering over Chemical Features\\nch_features = [\\\"CaO\\\", \\\"MgO\\\", \\\"Na2O\\\", \\\"Al2O3\\\", \\\"SiO2\\\", \\\"SO3\\\", \\\"K2O\\\", \\\"Fe2O3\\\", \\\"TiO2\\\"]\\n\\ndf_copy[\\\"std_ch_feats\\\"] = df_copy[ch_features].std(ddof=0, axis=1)\\n\\ndf_copy[\\\"ratio_CaO_to_SiO2\\\"] = df_copy[\\\"CaO\\\"] / df_copy[\\\"SiO2\\\"]\\ndf_copy[\\\"ratio_MgO_to_CaO\\\"] = df_copy[\\\"MgO\\\"] / df_copy[\\\"CaO\\\"]\\n\\n\\n# Feature Engineering over Mineralogical Features\\nmi_features_set1 = [\\n    # Set 1\\n    \\\"C4AF\\\",\\n    \\\"Cubic C3A\\\",\\n    \\\"Orthorhombic C3A\\\",\\n    \\\"Free CaO\\\",\\n    # Set 2\\n    \\\"Portlandite\\\",\\n    \\\"Periclase\\\",\\n    \\\"Bassanite\\\",\\n    \\\"Calcite\\\",\\n    \\\"Arcanite\\\",\\n    \\\"Aphthitalite\\\",\\n]\\n\\ndf_copy[\\\"mean_mi_set1_feats\\\"] = df_copy[mi_features_set1].mean(axis=1)\\n# Feature Engineering over Mineralogical Features\\nmi_features_set1 = [\\n    # Set 1\\n    \\\"C4AF\\\",\\n    \\\"Cubic C3A\\\",\\n    \\\"Orthorhombic C3A\\\",\\n    \\\"Free CaO\\\",\\n    # Set 2\\n    \\\"Portlandite\\\",\\n    \\\"Periclase\\\",\\n    \\\"Bassanite\\\",\\n    \\\"Calcite\\\",\\n    \\\"Arcanite\\\",\\n    \\\"Aphthitalite\\\",\\n]\\n\\ndf_copy[\\\"mean_mi_set1_feats\\\"] = df_copy[mi_features_set1].mean(axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature Engineering over Chemical Features\n",
    "ch_features = [\"CaO\", \"MgO\", \"Na2O\", \"Al2O3\", \"SiO2\", \"SO3\", \"K2O\", \"Fe2O3\", \"TiO2\"]\n",
    "\n",
    "df_copy[\"std_ch_feats\"] = df_copy[ch_features].std(ddof=0, axis=1)\n",
    "\n",
    "df_copy[\"ratio_CaO_to_SiO2\"] = df_copy[\"CaO\"] / df_copy[\"SiO2\"]\n",
    "df_copy[\"ratio_MgO_to_CaO\"] = df_copy[\"MgO\"] / df_copy[\"CaO\"]\n",
    "\n",
    "\n",
    "# Feature Engineering over Mineralogical Features\n",
    "mi_features_set1 = [\n",
    "    # Set 1\n",
    "    \"C4AF\",\n",
    "    \"Cubic C3A\",\n",
    "    \"Orthorhombic C3A\",\n",
    "    \"Free CaO\",\n",
    "    # Set 2\n",
    "    \"Portlandite\",\n",
    "    \"Periclase\",\n",
    "    \"Bassanite\",\n",
    "    \"Calcite\",\n",
    "    \"Arcanite\",\n",
    "    \"Aphthitalite\",\n",
    "]\n",
    "\n",
    "df_copy[\"mean_mi_set1_feats\"] = df_copy[mi_features_set1].mean(axis=1)\n",
    "# Feature Engineering over Mineralogical Features\n",
    "mi_features_set1 = [\n",
    "    # Set 1\n",
    "    \"C4AF\",\n",
    "    \"Cubic C3A\",\n",
    "    \"Orthorhombic C3A\",\n",
    "    \"Free CaO\",\n",
    "    # Set 2\n",
    "    \"Portlandite\",\n",
    "    \"Periclase\",\n",
    "    \"Bassanite\",\n",
    "    \"Calcite\",\n",
    "    \"Arcanite\",\n",
    "    \"Aphthitalite\",\n",
    "]\n",
    "\n",
    "df_copy[\"mean_mi_set1_feats\"] = df_copy[mi_features_set1].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c231ab19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:16:59.951558Z",
     "iopub.status.busy": "2024-02-29T15:16:59.950937Z",
     "iopub.status.idle": "2024-02-29T15:16:59.971341Z",
     "shell.execute_reply": "2024-02-29T15:16:59.969567Z"
    },
    "papermill": {
     "duration": 0.047051,
     "end_time": "2024-02-29T15:16:59.974968",
     "exception": false,
     "start_time": "2024-02-29T15:16:59.927917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                       0.000000\n",
       "C4AF                      14.030916\n",
       "Cubic C3A                 14.030916\n",
       "Orthorhombic C3A          14.030916\n",
       "Free CaO                  14.030916\n",
       "Portlandite               14.625446\n",
       "Periclase                 32.580262\n",
       "Arcanite                  14.030916\n",
       "Aphthitalite              15.933413\n",
       "Bassanite                 22.592152\n",
       "Calcite                   14.030916\n",
       "CaO                        0.237812\n",
       "MgO                        0.237812\n",
       "Na2O                       0.237812\n",
       "Al2O3                      0.237812\n",
       "SiO2                       0.237812\n",
       "SO3                        0.237812\n",
       "K2O                        0.237812\n",
       "TiO2                       0.237812\n",
       "Fe2O3                      0.237812\n",
       "Loss on Ignition           0.356718\n",
       "Insoluble Residue          0.356718\n",
       "CS28                       0.000000\n",
       "Cement_Type_CP II-F-40     0.000000\n",
       "Cement_Type_CP V-ARI       0.000000\n",
       "std_ch_feats               0.237812\n",
       "ratio_CaO_to_SiO2          0.237812\n",
       "ratio_MgO_to_CaO           0.237812\n",
       "mean_mi_set1_feats        13.793103\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"df_copy.isna().sum() / df_copy.shape[0] * 100\";\n",
       "                var nbb_formatted_code = \"df_copy.isna().sum() / df_copy.shape[0] * 100\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy.isna().sum() / df_copy.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b460f7b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:17:00.011472Z",
     "iopub.status.busy": "2024-02-29T15:17:00.010806Z",
     "iopub.status.idle": "2024-02-29T15:17:00.027905Z",
     "shell.execute_reply": "2024-02-29T15:17:00.026037Z"
    },
    "papermill": {
     "duration": 0.042738,
     "end_time": "2024-02-29T15:17:00.035560",
     "exception": false,
     "start_time": "2024-02-29T15:16:59.992822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"df_copy = df_copy.drop([\\\"Periclase\\\"], axis=1)\";\n",
       "                var nbb_formatted_code = \"df_copy = df_copy.drop([\\\"Periclase\\\"], axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df_copy.drop([\"Periclase\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb33630",
   "metadata": {
    "papermill": {
     "duration": 0.022295,
     "end_time": "2024-02-29T15:17:00.081410",
     "exception": false,
     "start_time": "2024-02-29T15:17:00.059115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "201a1bc6",
   "metadata": {
    "papermill": {
     "duration": 0.019422,
     "end_time": "2024-02-29T15:17:00.121602",
     "exception": false,
     "start_time": "2024-02-29T15:17:00.102180",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3fce4454",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:17:00.167735Z",
     "iopub.status.busy": "2024-02-29T15:17:00.167231Z",
     "iopub.status.idle": "2024-02-29T15:17:00.188573Z",
     "shell.execute_reply": "2024-02-29T15:17:00.186960Z"
    },
    "papermill": {
     "duration": 0.048898,
     "end_time": "2024-02-29T15:17:00.192451",
     "exception": false,
     "start_time": "2024-02-29T15:17:00.143553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"df_copy[CEMENT_TYPES] = df_copy[CEMENT_TYPES].astype(int)\\ndates = df[\\\"Date\\\"].copy()\\ny = df_copy.pop(\\\"CS28\\\")\\nx = df_copy\\ndf_copy = pd.concat([x, y], axis=1)\";\n",
       "                var nbb_formatted_code = \"df_copy[CEMENT_TYPES] = df_copy[CEMENT_TYPES].astype(int)\\ndates = df[\\\"Date\\\"].copy()\\ny = df_copy.pop(\\\"CS28\\\")\\nx = df_copy\\ndf_copy = pd.concat([x, y], axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy[CEMENT_TYPES] = df_copy[CEMENT_TYPES].astype(int)\n",
    "dates = df[\"Date\"].copy()\n",
    "y = df_copy.pop(\"CS28\")\n",
    "x = df_copy\n",
    "df_copy = pd.concat([x, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3644210a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:17:00.236771Z",
     "iopub.status.busy": "2024-02-29T15:17:00.236187Z",
     "iopub.status.idle": "2024-02-29T15:17:00.249197Z",
     "shell.execute_reply": "2024-02-29T15:17:00.247361Z"
    },
    "papermill": {
     "duration": 0.040711,
     "end_time": "2024-02-29T15:17:00.253757",
     "exception": false,
     "start_time": "2024-02-29T15:17:00.213046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"TIMESTEPS_LIST = [1, 7, 14]\";\n",
       "                var nbb_formatted_code = \"TIMESTEPS_LIST = [1, 7, 14]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TIMESTEPS_LIST = [1, 7, 14]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d033ae4e",
   "metadata": {
    "papermill": {
     "duration": 0.02274,
     "end_time": "2024-02-29T15:17:00.302864",
     "exception": false,
     "start_time": "2024-02-29T15:17:00.280124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transformer Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cb90a7",
   "metadata": {
    "papermill": {
     "duration": 0.020224,
     "end_time": "2024-02-29T15:17:00.343828",
     "exception": false,
     "start_time": "2024-02-29T15:17:00.323604",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configs:\n",
    "\n",
    "1. TIMESTEPS: 1, 3, 5, 7, 10, 15, 20\n",
    "\n",
    "2. Epochs: 300\n",
    "\n",
    "3. Batch size: 16\n",
    "\n",
    "4. num heads: 1\n",
    "\n",
    "5. FF Layers enc: 1\n",
    "\n",
    "      5.1 Units 16\n",
    "\n",
    "6. Optimization Algorithm: Adam\n",
    "    \n",
    "    6.1. Learning Rate: 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed561297",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:17:00.390130Z",
     "iopub.status.busy": "2024-02-29T15:17:00.389428Z",
     "iopub.status.idle": "2024-02-29T15:17:00.405618Z",
     "shell.execute_reply": "2024-02-29T15:17:00.403616Z"
    },
    "papermill": {
     "duration": 0.044582,
     "end_time": "2024-02-29T15:17:00.409045",
     "exception": false,
     "start_time": "2024-02-29T15:17:00.364463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"params = {}\\nparams[\\\"timesteps\\\"] = None\\nparams[\\\"num_features\\\"] = None\\nparams[\\\"num_heads\\\"] = 1\\nparams[\\\"num_layers_enc\\\"] = 1\\nparams[\\\"num_feed_forward\\\"] = 16\";\n",
       "                var nbb_formatted_code = \"params = {}\\nparams[\\\"timesteps\\\"] = None\\nparams[\\\"num_features\\\"] = None\\nparams[\\\"num_heads\\\"] = 1\\nparams[\\\"num_layers_enc\\\"] = 1\\nparams[\\\"num_feed_forward\\\"] = 16\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {}\n",
    "params[\"timesteps\"] = None\n",
    "params[\"num_features\"] = None\n",
    "params[\"num_heads\"] = 1\n",
    "params[\"num_layers_enc\"] = 1\n",
    "params[\"num_feed_forward\"] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ec90e8",
   "metadata": {
    "papermill": {
     "duration": 0.022467,
     "end_time": "2024-02-29T15:17:00.455710",
     "exception": false,
     "start_time": "2024-02-29T15:17:00.433243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.1 Repeated KFold Cross validation\n",
    "\n",
    "<b>Dataset shape:</b> (1234, 38)<br>\n",
    "<b>Timesteps:</b> 1, 3, 5, 7, 10, 15, 20<br>\n",
    "<b>Repeats:</b>10<br>\n",
    "<b>Splits:</b>10<br>\n",
    "    1. 10 folds of 123 samples each\n",
    "    2. 90% train (1111 samples each fold)\n",
    "    3. 10% test (123 samples each fold)\n",
    "<b>Total:</b> 100 models<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bec25015",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:17:00.500653Z",
     "iopub.status.busy": "2024-02-29T15:17:00.500062Z",
     "iopub.status.idle": "2024-02-29T15:38:12.995227Z",
     "shell.execute_reply": "2024-02-29T15:38:12.992338Z"
    },
    "papermill": {
     "duration": 1272.538678,
     "end_time": "2024-02-29T15:38:13.015929",
     "exception": false,
     "start_time": "2024-02-29T15:17:00.477251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated Cross Validation:\n",
      "Repeats: 3\n",
      "n_splits: 5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 1 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.203 (0.106)\n",
      "MAE: 0.964 (0.093)\n",
      "MAPE: 0.023 (0.002)\n",
      "R2: 0.971 (0.005)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.632 (0.139)\n",
      "MAE: 1.301 (0.124)\n",
      "MAPE: 0.031 (0.003)\n",
      "R2: 0.947 (0.009)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 7 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.043 (0.084)\n",
      "MAE: 0.841 (0.079)\n",
      "MAPE: 0.020 (0.002)\n",
      "R2: 0.978 (0.003)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.101 (0.168)\n",
      "MAE: 1.692 (0.124)\n",
      "MAPE: 0.040 (0.004)\n",
      "R2: 0.910 (0.015)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 14 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.221 (0.109)\n",
      "MAE: 0.999 (0.103)\n",
      "MAPE: 0.023 (0.002)\n",
      "R2: 0.970 (0.006)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.333 (0.345)\n",
      "MAE: 1.878 (0.309)\n",
      "MAPE: 0.044 (0.008)\n",
      "R2: 0.885 (0.036)\n",
      "\n",
      "======================\n",
      "\n",
      "Minutes Elapsed:  21.207604523499807\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"start = time.time()\\n\\nrepeats = 3\\nn_splits = 5\\nTIMESTEPS_LIST = [1, 7, 14]\\n\\nprint(\\\"Repeated Cross Validation:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n    cv = RepeatedKFold(n_splits=n_splits, n_repeats=repeats, random_state=SEED)\\n    x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1)\\n    y = df_copy[\\\"CS28\\\"]\\n\\n    params[\\\"timesteps\\\"] = timesteps\\n    params[\\\"num_features\\\"] = x.shape[-1]\\n\\n    scores = custom_cross_validate_parallelized(\\n        TransformerWrapper,\\n        SimpleImputer,\\n        StandardScaler,\\n        x,\\n        y,\\n        cv,\\n        timesteps=timesteps,\\n        dates=dates,\\n        cement_types=df_copy[CEMENT_TYPES],\\n        estimator_params={\\\"params\\\": params},\\n        imputer_params={\\\"strategy\\\": \\\"median\\\"},\\n        split_by_cement_type=True,\\n    )\\n    scores = scores[0]\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores, METRICS, METRICS_DICT)\\n\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Repeated KFold\\\"\\n    results_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(results_dict_copy, scores)\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"start = time.time()\\n\\nrepeats = 3\\nn_splits = 5\\nTIMESTEPS_LIST = [1, 7, 14]\\n\\nprint(\\\"Repeated Cross Validation:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n    cv = RepeatedKFold(n_splits=n_splits, n_repeats=repeats, random_state=SEED)\\n    x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1)\\n    y = df_copy[\\\"CS28\\\"]\\n\\n    params[\\\"timesteps\\\"] = timesteps\\n    params[\\\"num_features\\\"] = x.shape[-1]\\n\\n    scores = custom_cross_validate_parallelized(\\n        TransformerWrapper,\\n        SimpleImputer,\\n        StandardScaler,\\n        x,\\n        y,\\n        cv,\\n        timesteps=timesteps,\\n        dates=dates,\\n        cement_types=df_copy[CEMENT_TYPES],\\n        estimator_params={\\\"params\\\": params},\\n        imputer_params={\\\"strategy\\\": \\\"median\\\"},\\n        split_by_cement_type=True,\\n    )\\n    scores = scores[0]\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores, METRICS, METRICS_DICT)\\n\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Repeated KFold\\\"\\n    results_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(results_dict_copy, scores)\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "repeats = 3\n",
    "n_splits = 5\n",
    "TIMESTEPS_LIST = [1, 7, 14]\n",
    "\n",
    "print(\"Repeated Cross Validation:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"n_splits: {n_splits}\")\n",
    "print()\n",
    "\n",
    "for timesteps in TIMESTEPS_LIST:\n",
    "    set_seeds()\n",
    "    cv = RepeatedKFold(n_splits=n_splits, n_repeats=repeats, random_state=SEED)\n",
    "    x = df_copy.drop([\"Date\", \"CS28\"] + CEMENT_TYPES, axis=1)\n",
    "    y = df_copy[\"CS28\"]\n",
    "\n",
    "    params[\"timesteps\"] = timesteps\n",
    "    params[\"num_features\"] = x.shape[-1]\n",
    "\n",
    "    scores = custom_cross_validate_parallelized(\n",
    "        TransformerWrapper,\n",
    "        SimpleImputer,\n",
    "        StandardScaler,\n",
    "        x,\n",
    "        y,\n",
    "        cv,\n",
    "        timesteps=timesteps,\n",
    "        dates=dates,\n",
    "        cement_types=df_copy[CEMENT_TYPES],\n",
    "        estimator_params={\"params\": params},\n",
    "        imputer_params={\"strategy\": \"median\"},\n",
    "        split_by_cement_type=True,\n",
    "    )\n",
    "    scores = scores[0]\n",
    "    print(\"TIMESTEPS: %d \" % timesteps)\n",
    "    print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "    results_dict_copy = results_dict.copy()\n",
    "    results_dict_copy[\"Timesteps\"] = timesteps\n",
    "    results_dict_copy[\"Cross Validation\"] = \"Repeated KFold\"\n",
    "    results_dict_copy[\"Cross Validation Params\"] = '{\"N_Splits\": 5, \"Repeats\": 3}'\n",
    "    results_dict_copy[\"Data Shape\"] = x.shape\n",
    "    df_results = fill_results_dict(results_dict_copy, scores)\n",
    "    results_to_save.append(df_results)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555294bf",
   "metadata": {
    "papermill": {
     "duration": 0.019918,
     "end_time": "2024-02-29T15:38:13.055773",
     "exception": false,
     "start_time": "2024-02-29T15:38:13.035855",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.2. Blocking Time Series Cross Validation\n",
    "\n",
    "<b>Dataset shape:</b> (1234, 38)<br>\n",
    "<b>Splits:</b>5<br>    \n",
    "    1. 5 folds of 246 samples\n",
    "    2. 50% train (123 samples each fold)\n",
    "    3. 50% test (123 samples each fold)\n",
    "<b>Total:</b> 5 models<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a699b7d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:38:13.099212Z",
     "iopub.status.busy": "2024-02-29T15:38:13.098571Z",
     "iopub.status.idle": "2024-02-29T15:42:04.306241Z",
     "shell.execute_reply": "2024-02-29T15:42:04.304095Z"
    },
    "papermill": {
     "duration": 231.246351,
     "end_time": "2024-02-29T15:42:04.322082",
     "exception": false,
     "start_time": "2024-02-29T15:38:13.075731",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocking Time Series Split:\n",
      "Repeats: 3\n",
      "n_splits: 5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 1 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.323 (0.068)\n",
      "MAE: 1.081 (0.039)\n",
      "MAPE: 0.025 (0.001)\n",
      "R2: 0.965 (0.006)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.915 (0.317)\n",
      "MAE: 1.569 (0.277)\n",
      "MAPE: 0.037 (0.006)\n",
      "R2: 0.920 (0.031)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 7 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.411 (0.144)\n",
      "MAE: 1.180 (0.142)\n",
      "MAPE: 0.028 (0.004)\n",
      "R2: 0.958 (0.013)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.470 (0.920)\n",
      "MAE: 1.972 (0.744)\n",
      "MAPE: 0.048 (0.021)\n",
      "R2: 0.858 (0.076)\n",
      "\n",
      "======================\n",
      "\n",
      "Minutes Elapsed:  3.852808113892873\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"start = time.time()\\n\\nrepeats = 3\\nn_splits = 5\\ntrain_size = 0.8\\n# TIMESTEPS_LIST = [1, 7, 14]\\nTIMESTEPS_LIST = [1, 7]\\nprint(\\\"Blocking Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n    scores_final = None\\n\\n    params[\\\"timesteps\\\"] = timesteps\\n\\n    for _ in range(repeats):\\n        x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1)\\n        y = df_copy[\\\"CS28\\\"]\\n        params[\\\"num_features\\\"] = x.shape[-1]\\n\\n        cv = BlockingTimeSeriesSplit(n_splits=n_splits, train_size=train_size)\\n\\n        scores = custom_cross_validate_parallelized(\\n            TransformerWrapper,\\n            SimpleImputer,\\n            StandardScaler,\\n            x,\\n            y,\\n            cv,\\n            timesteps,\\n            dates=dates,\\n            cement_types=df_copy[CEMENT_TYPES],\\n            estimator_params={\\\"params\\\": params},\\n            imputer_params={\\\"strategy\\\": \\\"median\\\"},\\n            split_by_cement_type=True,\\n        )\\n        scores = scores[0]\\n        if scores_final is None:\\n            scores_final = {key: [] for key, _ in scores.items()}\\n\\n        for key, value in scores.items():\\n            scores_final[key] += [value]\\n\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores_final, METRICS, METRICS_DICT)\\n\\n    # Saving the results\\n    scores = {key: np.array(val).flatten() for key, val in scores_final.items()}\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Blocking Time Series Split\\\"\\n    results_dict_copy[\\n        \\\"Cross Validation Params\\\"\\n    ] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3, \\\"train_size\\\": 0.8}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(results_dict_copy, scores)\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"start = time.time()\\n\\nrepeats = 3\\nn_splits = 5\\ntrain_size = 0.8\\n# TIMESTEPS_LIST = [1, 7, 14]\\nTIMESTEPS_LIST = [1, 7]\\nprint(\\\"Blocking Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n    scores_final = None\\n\\n    params[\\\"timesteps\\\"] = timesteps\\n\\n    for _ in range(repeats):\\n        x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1)\\n        y = df_copy[\\\"CS28\\\"]\\n        params[\\\"num_features\\\"] = x.shape[-1]\\n\\n        cv = BlockingTimeSeriesSplit(n_splits=n_splits, train_size=train_size)\\n\\n        scores = custom_cross_validate_parallelized(\\n            TransformerWrapper,\\n            SimpleImputer,\\n            StandardScaler,\\n            x,\\n            y,\\n            cv,\\n            timesteps,\\n            dates=dates,\\n            cement_types=df_copy[CEMENT_TYPES],\\n            estimator_params={\\\"params\\\": params},\\n            imputer_params={\\\"strategy\\\": \\\"median\\\"},\\n            split_by_cement_type=True,\\n        )\\n        scores = scores[0]\\n        if scores_final is None:\\n            scores_final = {key: [] for key, _ in scores.items()}\\n\\n        for key, value in scores.items():\\n            scores_final[key] += [value]\\n\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores_final, METRICS, METRICS_DICT)\\n\\n    # Saving the results\\n    scores = {key: np.array(val).flatten() for key, val in scores_final.items()}\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Blocking Time Series Split\\\"\\n    results_dict_copy[\\n        \\\"Cross Validation Params\\\"\\n    ] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3, \\\"train_size\\\": 0.8}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(results_dict_copy, scores)\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "repeats = 3\n",
    "n_splits = 5\n",
    "train_size = 0.8\n",
    "# TIMESTEPS_LIST = [1, 7, 14]\n",
    "TIMESTEPS_LIST = [1, 7]\n",
    "print(\"Blocking Time Series Split:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"n_splits: {n_splits}\")\n",
    "print()\n",
    "\n",
    "for timesteps in TIMESTEPS_LIST:\n",
    "    set_seeds()\n",
    "    scores_final = None\n",
    "\n",
    "    params[\"timesteps\"] = timesteps\n",
    "\n",
    "    for _ in range(repeats):\n",
    "        x = df_copy.drop([\"Date\", \"CS28\"] + CEMENT_TYPES, axis=1)\n",
    "        y = df_copy[\"CS28\"]\n",
    "        params[\"num_features\"] = x.shape[-1]\n",
    "\n",
    "        cv = BlockingTimeSeriesSplit(n_splits=n_splits, train_size=train_size)\n",
    "\n",
    "        scores = custom_cross_validate_parallelized(\n",
    "            TransformerWrapper,\n",
    "            SimpleImputer,\n",
    "            StandardScaler,\n",
    "            x,\n",
    "            y,\n",
    "            cv,\n",
    "            timesteps,\n",
    "            dates=dates,\n",
    "            cement_types=df_copy[CEMENT_TYPES],\n",
    "            estimator_params={\"params\": params},\n",
    "            imputer_params={\"strategy\": \"median\"},\n",
    "            split_by_cement_type=True,\n",
    "        )\n",
    "        scores = scores[0]\n",
    "        if scores_final is None:\n",
    "            scores_final = {key: [] for key, _ in scores.items()}\n",
    "\n",
    "        for key, value in scores.items():\n",
    "            scores_final[key] += [value]\n",
    "\n",
    "    print(\"TIMESTEPS: %d \" % timesteps)\n",
    "    print_scores(scores_final, METRICS, METRICS_DICT)\n",
    "\n",
    "    # Saving the results\n",
    "    scores = {key: np.array(val).flatten() for key, val in scores_final.items()}\n",
    "    results_dict_copy = results_dict.copy()\n",
    "    results_dict_copy[\"Timesteps\"] = timesteps\n",
    "    results_dict_copy[\"Cross Validation\"] = \"Blocking Time Series Split\"\n",
    "    results_dict_copy[\n",
    "        \"Cross Validation Params\"\n",
    "    ] = '{\"N_Splits\": 5, \"Repeats\": 3, \"train_size\": 0.8}'\n",
    "    results_dict_copy[\"Data Shape\"] = x.shape\n",
    "    df_results = fill_results_dict(results_dict_copy, scores)\n",
    "    results_to_save.append(df_results)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c598584",
   "metadata": {
    "papermill": {
     "duration": 0.017799,
     "end_time": "2024-02-29T15:42:04.355548",
     "exception": false,
     "start_time": "2024-02-29T15:42:04.337749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.3. Time Series Split Cross Validation\n",
    "\n",
    "The training set has size i * n_samples // (n_splits + 1) + n_samples % (n_splits + 1) in the i th split, with a test set of size n_samples//(n_splits + 1) by default, where n_samples is the number of samples.\n",
    "\n",
    "\n",
    "<b>Dataset shape:</b> (1234, 38)<br>\n",
    "<b>Splits:</b>10<br>    \n",
    "    1. Train: 10 folds of 114, 226, 338, 450, 562, 675, 787, 899, 1011, 1123 samples each fold\n",
    "    2. Test: 112 samples each fold\n",
    "<b>Total:</b> 10 models<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7001ba3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:42:04.389688Z",
     "iopub.status.busy": "2024-02-29T15:42:04.388075Z",
     "iopub.status.idle": "2024-02-29T15:58:38.365367Z",
     "shell.execute_reply": "2024-02-29T15:58:38.363648Z"
    },
    "papermill": {
     "duration": 994.015726,
     "end_time": "2024-02-29T15:58:38.386420",
     "exception": false,
     "start_time": "2024-02-29T15:42:04.370694",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocking Time Series Split:\n",
      "Repeats: 3\n",
      "n_splits: 5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 1 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.259 (0.153)\n",
      "MAE: 1.018 (0.117)\n",
      "MAPE: 0.024 (0.003)\n",
      "R2: 0.970 (0.008)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.316 (0.268)\n",
      "MAE: 1.858 (0.246)\n",
      "MAPE: 0.043 (0.006)\n",
      "R2: 0.890 (0.020)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 7 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.128 (0.126)\n",
      "MAE: 0.927 (0.111)\n",
      "MAPE: 0.021 (0.003)\n",
      "R2: 0.976 (0.005)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.919 (0.931)\n",
      "MAE: 2.293 (0.694)\n",
      "MAPE: 0.054 (0.017)\n",
      "R2: 0.819 (0.089)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 14 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.159 (0.087)\n",
      "MAE: 0.922 (0.075)\n",
      "MAPE: 0.021 (0.002)\n",
      "R2: 0.974 (0.005)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 4.202 (1.752)\n",
      "MAE: 3.221 (1.023)\n",
      "MAPE: 0.079 (0.025)\n",
      "R2: 0.617 (0.248)\n",
      "\n",
      "======================\n",
      "\n",
      "Minutes Elapsed:  16.565701655546825\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nstart = time.time()\\ngap = 0\\nn_splits = 5\\nrepeats = 3\\nTIMESTEPS_LIST = [1, 7, 14]\\n\\nprint(\\\"Blocking Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n    scores_final = None\\n    params[\\\"timesteps\\\"] = timesteps\\n\\n    for _ in range(repeats):\\n        x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1)\\n        y = df_copy[\\\"CS28\\\"]\\n        params[\\\"num_features\\\"] = x.shape[-1]\\n\\n        cv = TimeSeriesSplit(\\n            gap=gap, max_train_size=None, n_splits=n_splits, test_size=None\\n        )\\n        scores = custom_cross_validate_parallelized(\\n            TransformerWrapper,\\n            SimpleImputer,\\n            StandardScaler,\\n            x,\\n            y,\\n            cv,\\n            timesteps,\\n            dates=dates,\\n            cement_types=df_copy[CEMENT_TYPES],\\n            estimator_params={\\\"params\\\": params},\\n            imputer_params={\\\"strategy\\\": \\\"median\\\"},\\n        )\\n        scores = scores[0]\\n        if scores_final is None:\\n            scores_final = {key: [] for key, _ in scores.items()}\\n\\n        for key, value in scores.items():\\n            scores_final[key] += [value]\\n\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores_final, METRICS, METRICS_DICT)\\n\\n    # Saving the results\\n    scores = {key: np.array(val).flatten() for key, val in scores_final.items()}\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Time Series Split\\\"\\n    results_dict_copy[\\n        \\\"Cross Validation Params\\\"\\n    ] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3, \\\"Gap\\\": 0}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(results_dict_copy, scores)\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nstart = time.time()\\ngap = 0\\nn_splits = 5\\nrepeats = 3\\nTIMESTEPS_LIST = [1, 7, 14]\\n\\nprint(\\\"Blocking Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n    scores_final = None\\n    params[\\\"timesteps\\\"] = timesteps\\n\\n    for _ in range(repeats):\\n        x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1)\\n        y = df_copy[\\\"CS28\\\"]\\n        params[\\\"num_features\\\"] = x.shape[-1]\\n\\n        cv = TimeSeriesSplit(\\n            gap=gap, max_train_size=None, n_splits=n_splits, test_size=None\\n        )\\n        scores = custom_cross_validate_parallelized(\\n            TransformerWrapper,\\n            SimpleImputer,\\n            StandardScaler,\\n            x,\\n            y,\\n            cv,\\n            timesteps,\\n            dates=dates,\\n            cement_types=df_copy[CEMENT_TYPES],\\n            estimator_params={\\\"params\\\": params},\\n            imputer_params={\\\"strategy\\\": \\\"median\\\"},\\n        )\\n        scores = scores[0]\\n        if scores_final is None:\\n            scores_final = {key: [] for key, _ in scores.items()}\\n\\n        for key, value in scores.items():\\n            scores_final[key] += [value]\\n\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores_final, METRICS, METRICS_DICT)\\n\\n    # Saving the results\\n    scores = {key: np.array(val).flatten() for key, val in scores_final.items()}\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Time Series Split\\\"\\n    results_dict_copy[\\n        \\\"Cross Validation Params\\\"\\n    ] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3, \\\"Gap\\\": 0}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(results_dict_copy, scores)\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "start = time.time()\n",
    "gap = 0\n",
    "n_splits = 5\n",
    "repeats = 3\n",
    "TIMESTEPS_LIST = [1, 7, 14]\n",
    "\n",
    "print(\"Blocking Time Series Split:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"n_splits: {n_splits}\")\n",
    "print()\n",
    "\n",
    "for timesteps in TIMESTEPS_LIST:\n",
    "    set_seeds()\n",
    "    scores_final = None\n",
    "    params[\"timesteps\"] = timesteps\n",
    "\n",
    "    for _ in range(repeats):\n",
    "        x = df_copy.drop([\"Date\", \"CS28\"] + CEMENT_TYPES, axis=1)\n",
    "        y = df_copy[\"CS28\"]\n",
    "        params[\"num_features\"] = x.shape[-1]\n",
    "\n",
    "        cv = TimeSeriesSplit(\n",
    "            gap=gap, max_train_size=None, n_splits=n_splits, test_size=None\n",
    "        )\n",
    "        scores = custom_cross_validate_parallelized(\n",
    "            TransformerWrapper,\n",
    "            SimpleImputer,\n",
    "            StandardScaler,\n",
    "            x,\n",
    "            y,\n",
    "            cv,\n",
    "            timesteps,\n",
    "            dates=dates,\n",
    "            cement_types=df_copy[CEMENT_TYPES],\n",
    "            estimator_params={\"params\": params},\n",
    "            imputer_params={\"strategy\": \"median\"},\n",
    "        )\n",
    "        scores = scores[0]\n",
    "        if scores_final is None:\n",
    "            scores_final = {key: [] for key, _ in scores.items()}\n",
    "\n",
    "        for key, value in scores.items():\n",
    "            scores_final[key] += [value]\n",
    "\n",
    "    print(\"TIMESTEPS: %d \" % timesteps)\n",
    "    print_scores(scores_final, METRICS, METRICS_DICT)\n",
    "\n",
    "    # Saving the results\n",
    "    scores = {key: np.array(val).flatten() for key, val in scores_final.items()}\n",
    "    results_dict_copy = results_dict.copy()\n",
    "    results_dict_copy[\"Timesteps\"] = timesteps\n",
    "    results_dict_copy[\"Cross Validation\"] = \"Time Series Split\"\n",
    "    results_dict_copy[\n",
    "        \"Cross Validation Params\"\n",
    "    ] = '{\"N_Splits\": 5, \"Repeats\": 3, \"Gap\": 0}'\n",
    "    results_dict_copy[\"Data Shape\"] = x.shape\n",
    "    df_results = fill_results_dict(results_dict_copy, scores)\n",
    "    results_to_save.append(df_results)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d3fdc8",
   "metadata": {
    "papermill": {
     "duration": 0.019533,
     "end_time": "2024-02-29T15:58:38.426274",
     "exception": false,
     "start_time": "2024-02-29T15:58:38.406741",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.4. Out of time Split Cross Validation\n",
    "\n",
    "<b>Dataset shape:</b> (1234, 38)<br>\n",
    "<b>Train size: 80%</b><br>\n",
    "<b>Test  size: 20%</b>\n",
    "\n",
    "\n",
    "<b>Splits:</b> 2<br>    \n",
    "    1. Train: 987\n",
    "    2. Test: 247\n",
    "<b>Total:</b> 1 model<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4091da64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:58:38.475918Z",
     "iopub.status.busy": "2024-02-29T15:58:38.475342Z",
     "iopub.status.idle": "2024-02-29T16:03:35.864955Z",
     "shell.execute_reply": "2024-02-29T16:03:35.863271Z"
    },
    "papermill": {
     "duration": 297.439709,
     "end_time": "2024-02-29T16:03:35.885338",
     "exception": false,
     "start_time": "2024-02-29T15:58:38.445629",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of time Cross Val:\n",
      "Repeats: 3\n",
      "Train: 80% Test: 20%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 1 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.217 (0.083)\n",
      "MAE: 0.977 (0.082)\n",
      "MAPE: 0.024 (0.002)\n",
      "R2: 0.972 (0.004)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.101 (0.065)\n",
      "MAE: 1.639 (0.095)\n",
      "MAPE: 0.037 (0.002)\n",
      "R2: 0.888 (0.007)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 7 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.065 (0.038)\n",
      "MAE: 0.859 (0.044)\n",
      "MAPE: 0.020 (0.001)\n",
      "R2: 0.979 (0.002)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.749 (0.221)\n",
      "MAE: 2.168 (0.212)\n",
      "MAPE: 0.050 (0.004)\n",
      "R2: 0.807 (0.031)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 14 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.208 (0.097)\n",
      "MAE: 0.983 (0.075)\n",
      "MAPE: 0.023 (0.001)\n",
      "R2: 0.972 (0.004)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.356 (0.139)\n",
      "MAE: 1.908 (0.123)\n",
      "MAPE: 0.045 (0.004)\n",
      "R2: 0.853 (0.017)\n",
      "\n",
      "======================\n",
      "\n",
      "Minutes Elapsed:  4.955532912413279\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"start = time.time()\\ntest_size = 0.2\\nrepeats = 3\\nTIMESTEPS_LIST = [1, 7, 14]\\n\\nprint(\\\"Out of time Cross Val:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"Train: {80}%\\\", f\\\"Test: {20}%\\\")\\nprint()\\nresults = []\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n    params[\\\"timesteps\\\"] = timesteps\\n\\n    def parallel_repeats(repeat):\\n        set_seeds(SEED + repeat)\\n\\n        scores_final = None\\n\\n        # Data Splitting\\n        x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1).copy()\\n        y = df_copy[\\\"CS28\\\"].copy()\\n        params[\\\"num_features\\\"] = x.shape[-1]\\n\\n        x_train, x_test, y_train, y_test = train_test_split(\\n            x, y, test_size=test_size, random_state=SEED, shuffle=False\\n        )\\n\\n        # Preprocessing\\n        imputer = SimpleImputer(strategy=\\\"median\\\")\\n        scaler = StandardScaler()\\n\\n        x_train = imputer.fit_transform(x_train)\\n        x_train = scaler.fit_transform(x_train)\\n        dates_train = dates[: x_train.shape[0]].reset_index(drop=True)\\n        cement_types_train = df_copy[CEMENT_TYPES][: x_train.shape[0]].reset_index(\\n            drop=True\\n        )\\n\\n        x_test = imputer.transform(x_test)\\n        x_test = scaler.transform(x_test)\\n        dates_test = dates[x_train.shape[0] :].reset_index(drop=True)\\n        cement_types_test = df_copy[CEMENT_TYPES][x_train.shape[0] :].reset_index(\\n            drop=True\\n        )\\n\\n        # Sequence Splitting\\n        data_train = pd.concat(\\n            [\\n                dates_train,\\n                pd.DataFrame(x_train, columns=x.columns),\\n                cement_types_train,\\n                y_train.reset_index(drop=True),\\n            ],\\n            axis=1,\\n        )\\n        data_test = pd.concat(\\n            [\\n                dates_test,\\n                pd.DataFrame(x_test, columns=x.columns),\\n                cement_types_test,\\n                y_test.reset_index(drop=True),\\n            ],\\n            axis=1,\\n        )\\n\\n        x_train, y_train = split_sequences_per_cement_type(data_train, timesteps)\\n        x_test, y_test = split_sequences_per_cement_type(data_test, timesteps)\\n\\n        # Train model and test evalutation\\n        # Fit model\\n        pipeline = Pipeline([(\\\"estimator\\\", TransformerWrapper(params))])\\n        pipeline.fit(x_train, y_train)\\n\\n        # Make predictions\\n        y_train_pred = pipeline.predict(x_train)\\n        y_test_pred = pipeline.predict(x_test)\\n\\n        # evaluate predictions\\n        scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\\n\\n        if scores_final is None:\\n            scores_final = {key: [] for key, _ in scores.items()}\\n\\n        for key, value in scores.items():\\n            scores_final[key] += [value]\\n\\n        return scores_final\\n\\n    scores = Parallel(n_jobs=5)(\\n        delayed(parallel_repeats)(repeat) for repeat in range(repeats)\\n    )\\n    results.append(scores)\\n    scores_final = {key: [] for key, _ in scores[0].items()}\\n    for scores_dict in scores:\\n        for key, value in scores_dict.items():\\n            scores_final[key] += value\\n\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores_final, METRICS, METRICS_DICT)\\n\\n    # Saving the results\\n    # scores = {key: val[0] for key, val in scores.items()}\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time Split\\\"\\n    results_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"Test Size\\\": 0.2}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(\\n        results_dict_copy, {key: value for key, value in scores_final.items()}\\n    )\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"start = time.time()\\ntest_size = 0.2\\nrepeats = 3\\nTIMESTEPS_LIST = [1, 7, 14]\\n\\nprint(\\\"Out of time Cross Val:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"Train: {80}%\\\", f\\\"Test: {20}%\\\")\\nprint()\\nresults = []\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n    params[\\\"timesteps\\\"] = timesteps\\n\\n    def parallel_repeats(repeat):\\n        set_seeds(SEED + repeat)\\n\\n        scores_final = None\\n\\n        # Data Splitting\\n        x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1).copy()\\n        y = df_copy[\\\"CS28\\\"].copy()\\n        params[\\\"num_features\\\"] = x.shape[-1]\\n\\n        x_train, x_test, y_train, y_test = train_test_split(\\n            x, y, test_size=test_size, random_state=SEED, shuffle=False\\n        )\\n\\n        # Preprocessing\\n        imputer = SimpleImputer(strategy=\\\"median\\\")\\n        scaler = StandardScaler()\\n\\n        x_train = imputer.fit_transform(x_train)\\n        x_train = scaler.fit_transform(x_train)\\n        dates_train = dates[: x_train.shape[0]].reset_index(drop=True)\\n        cement_types_train = df_copy[CEMENT_TYPES][: x_train.shape[0]].reset_index(\\n            drop=True\\n        )\\n\\n        x_test = imputer.transform(x_test)\\n        x_test = scaler.transform(x_test)\\n        dates_test = dates[x_train.shape[0] :].reset_index(drop=True)\\n        cement_types_test = df_copy[CEMENT_TYPES][x_train.shape[0] :].reset_index(\\n            drop=True\\n        )\\n\\n        # Sequence Splitting\\n        data_train = pd.concat(\\n            [\\n                dates_train,\\n                pd.DataFrame(x_train, columns=x.columns),\\n                cement_types_train,\\n                y_train.reset_index(drop=True),\\n            ],\\n            axis=1,\\n        )\\n        data_test = pd.concat(\\n            [\\n                dates_test,\\n                pd.DataFrame(x_test, columns=x.columns),\\n                cement_types_test,\\n                y_test.reset_index(drop=True),\\n            ],\\n            axis=1,\\n        )\\n\\n        x_train, y_train = split_sequences_per_cement_type(data_train, timesteps)\\n        x_test, y_test = split_sequences_per_cement_type(data_test, timesteps)\\n\\n        # Train model and test evalutation\\n        # Fit model\\n        pipeline = Pipeline([(\\\"estimator\\\", TransformerWrapper(params))])\\n        pipeline.fit(x_train, y_train)\\n\\n        # Make predictions\\n        y_train_pred = pipeline.predict(x_train)\\n        y_test_pred = pipeline.predict(x_test)\\n\\n        # evaluate predictions\\n        scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\\n\\n        if scores_final is None:\\n            scores_final = {key: [] for key, _ in scores.items()}\\n\\n        for key, value in scores.items():\\n            scores_final[key] += [value]\\n\\n        return scores_final\\n\\n    scores = Parallel(n_jobs=5)(\\n        delayed(parallel_repeats)(repeat) for repeat in range(repeats)\\n    )\\n    results.append(scores)\\n    scores_final = {key: [] for key, _ in scores[0].items()}\\n    for scores_dict in scores:\\n        for key, value in scores_dict.items():\\n            scores_final[key] += value\\n\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores_final, METRICS, METRICS_DICT)\\n\\n    # Saving the results\\n    # scores = {key: val[0] for key, val in scores.items()}\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time Split\\\"\\n    results_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"Test Size\\\": 0.2}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(\\n        results_dict_copy, {key: value for key, value in scores_final.items()}\\n    )\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "test_size = 0.2\n",
    "repeats = 3\n",
    "TIMESTEPS_LIST = [1, 7, 14]\n",
    "\n",
    "print(\"Out of time Cross Val:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"Train: {80}%\", f\"Test: {20}%\")\n",
    "print()\n",
    "results = []\n",
    "\n",
    "for timesteps in TIMESTEPS_LIST:\n",
    "    set_seeds()\n",
    "    params[\"timesteps\"] = timesteps\n",
    "\n",
    "    def parallel_repeats(repeat):\n",
    "        set_seeds(SEED + repeat)\n",
    "\n",
    "        scores_final = None\n",
    "\n",
    "        # Data Splitting\n",
    "        x = df_copy.drop([\"Date\", \"CS28\"] + CEMENT_TYPES, axis=1).copy()\n",
    "        y = df_copy[\"CS28\"].copy()\n",
    "        params[\"num_features\"] = x.shape[-1]\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(\n",
    "            x, y, test_size=test_size, random_state=SEED, shuffle=False\n",
    "        )\n",
    "\n",
    "        # Preprocessing\n",
    "        imputer = SimpleImputer(strategy=\"median\")\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        x_train = imputer.fit_transform(x_train)\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        dates_train = dates[: x_train.shape[0]].reset_index(drop=True)\n",
    "        cement_types_train = df_copy[CEMENT_TYPES][: x_train.shape[0]].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "\n",
    "        x_test = imputer.transform(x_test)\n",
    "        x_test = scaler.transform(x_test)\n",
    "        dates_test = dates[x_train.shape[0] :].reset_index(drop=True)\n",
    "        cement_types_test = df_copy[CEMENT_TYPES][x_train.shape[0] :].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "\n",
    "        # Sequence Splitting\n",
    "        data_train = pd.concat(\n",
    "            [\n",
    "                dates_train,\n",
    "                pd.DataFrame(x_train, columns=x.columns),\n",
    "                cement_types_train,\n",
    "                y_train.reset_index(drop=True),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        data_test = pd.concat(\n",
    "            [\n",
    "                dates_test,\n",
    "                pd.DataFrame(x_test, columns=x.columns),\n",
    "                cement_types_test,\n",
    "                y_test.reset_index(drop=True),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        x_train, y_train = split_sequences_per_cement_type(data_train, timesteps)\n",
    "        x_test, y_test = split_sequences_per_cement_type(data_test, timesteps)\n",
    "\n",
    "        # Train model and test evalutation\n",
    "        # Fit model\n",
    "        pipeline = Pipeline([(\"estimator\", TransformerWrapper(params))])\n",
    "        pipeline.fit(x_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = pipeline.predict(x_train)\n",
    "        y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "        # evaluate predictions\n",
    "        scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\n",
    "\n",
    "        if scores_final is None:\n",
    "            scores_final = {key: [] for key, _ in scores.items()}\n",
    "\n",
    "        for key, value in scores.items():\n",
    "            scores_final[key] += [value]\n",
    "\n",
    "        return scores_final\n",
    "\n",
    "    scores = Parallel(n_jobs=5)(\n",
    "        delayed(parallel_repeats)(repeat) for repeat in range(repeats)\n",
    "    )\n",
    "    results.append(scores)\n",
    "    scores_final = {key: [] for key, _ in scores[0].items()}\n",
    "    for scores_dict in scores:\n",
    "        for key, value in scores_dict.items():\n",
    "            scores_final[key] += value\n",
    "\n",
    "    print(\"TIMESTEPS: %d \" % timesteps)\n",
    "    print_scores(scores_final, METRICS, METRICS_DICT)\n",
    "\n",
    "    # Saving the results\n",
    "    # scores = {key: val[0] for key, val in scores.items()}\n",
    "    results_dict_copy = results_dict.copy()\n",
    "    results_dict_copy[\"Timesteps\"] = timesteps\n",
    "    results_dict_copy[\"Cross Validation\"] = \"Out of time Split\"\n",
    "    results_dict_copy[\"Cross Validation Params\"] = '{\"Test Size\": 0.2}'\n",
    "    results_dict_copy[\"Data Shape\"] = x.shape\n",
    "    df_results = fill_results_dict(\n",
    "        results_dict_copy, {key: value for key, value in scores_final.items()}\n",
    "    )\n",
    "    results_to_save.append(df_results)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7bb60602",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T16:03:35.924525Z",
     "iopub.status.busy": "2024-02-29T16:03:35.924129Z",
     "iopub.status.idle": "2024-02-29T16:03:36.003028Z",
     "shell.execute_reply": "2024-02-29T16:03:36.001440Z"
    },
    "papermill": {
     "duration": 0.103484,
     "end_time": "2024-02-29T16:03:36.006516",
     "exception": false,
     "start_time": "2024-02-29T16:03:35.903032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RMSE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAPE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R2 Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>Blocking Time Series Split</td>\n",
       "      <td>{\"N_Splits\": 5, \"Repeats\": 3, \"train_size\": 0.8}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.915087</td>\n",
       "      <td>0.316656</td>\n",
       "      <td>1.569110</td>\n",
       "      <td>0.277063</td>\n",
       "      <td>0.036958</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>0.920441</td>\n",
       "      <td>0.031452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>Blocking Time Series Split</td>\n",
       "      <td>{\"N_Splits\": 5, \"Repeats\": 3, \"train_size\": 0.8}</td>\n",
       "      <td>7</td>\n",
       "      <td>2.469831</td>\n",
       "      <td>0.919534</td>\n",
       "      <td>1.971785</td>\n",
       "      <td>0.743915</td>\n",
       "      <td>0.048417</td>\n",
       "      <td>0.021029</td>\n",
       "      <td>0.858095</td>\n",
       "      <td>0.075519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>Out of time Split</td>\n",
       "      <td>{\"Test Size\": 0.2}</td>\n",
       "      <td>1</td>\n",
       "      <td>2.100839</td>\n",
       "      <td>0.065366</td>\n",
       "      <td>1.639084</td>\n",
       "      <td>0.094652</td>\n",
       "      <td>0.037046</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>0.888195</td>\n",
       "      <td>0.007013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>Out of time Split</td>\n",
       "      <td>{\"Test Size\": 0.2}</td>\n",
       "      <td>7</td>\n",
       "      <td>2.748974</td>\n",
       "      <td>0.220925</td>\n",
       "      <td>2.167738</td>\n",
       "      <td>0.211845</td>\n",
       "      <td>0.050182</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.806610</td>\n",
       "      <td>0.030888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>Out of time Split</td>\n",
       "      <td>{\"Test Size\": 0.2}</td>\n",
       "      <td>14</td>\n",
       "      <td>2.356184</td>\n",
       "      <td>0.139177</td>\n",
       "      <td>1.907744</td>\n",
       "      <td>0.122781</td>\n",
       "      <td>0.045460</td>\n",
       "      <td>0.004225</td>\n",
       "      <td>0.852829</td>\n",
       "      <td>0.016964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>{\"N_Splits\": 5, \"Repeats\": 3}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.631906</td>\n",
       "      <td>0.139402</td>\n",
       "      <td>1.301411</td>\n",
       "      <td>0.124368</td>\n",
       "      <td>0.030662</td>\n",
       "      <td>0.003324</td>\n",
       "      <td>0.946712</td>\n",
       "      <td>0.009471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>{\"N_Splits\": 5, \"Repeats\": 3}</td>\n",
       "      <td>7</td>\n",
       "      <td>2.101466</td>\n",
       "      <td>0.167968</td>\n",
       "      <td>1.691762</td>\n",
       "      <td>0.123626</td>\n",
       "      <td>0.039824</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>0.909823</td>\n",
       "      <td>0.015425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>{\"N_Splits\": 5, \"Repeats\": 3}</td>\n",
       "      <td>14</td>\n",
       "      <td>2.332644</td>\n",
       "      <td>0.344729</td>\n",
       "      <td>1.877711</td>\n",
       "      <td>0.309477</td>\n",
       "      <td>0.044163</td>\n",
       "      <td>0.007682</td>\n",
       "      <td>0.884810</td>\n",
       "      <td>0.035655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>Time Series Split</td>\n",
       "      <td>{\"N_Splits\": 5, \"Repeats\": 3, \"Gap\": 0}</td>\n",
       "      <td>1</td>\n",
       "      <td>2.315810</td>\n",
       "      <td>0.268071</td>\n",
       "      <td>1.857935</td>\n",
       "      <td>0.245958</td>\n",
       "      <td>0.043340</td>\n",
       "      <td>0.006319</td>\n",
       "      <td>0.890175</td>\n",
       "      <td>0.020033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>Time Series Split</td>\n",
       "      <td>{\"N_Splits\": 5, \"Repeats\": 3, \"Gap\": 0}</td>\n",
       "      <td>7</td>\n",
       "      <td>2.919045</td>\n",
       "      <td>0.931379</td>\n",
       "      <td>2.293321</td>\n",
       "      <td>0.693877</td>\n",
       "      <td>0.054264</td>\n",
       "      <td>0.016562</td>\n",
       "      <td>0.818672</td>\n",
       "      <td>0.089182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>Time Series Split</td>\n",
       "      <td>{\"N_Splits\": 5, \"Repeats\": 3, \"Gap\": 0}</td>\n",
       "      <td>14</td>\n",
       "      <td>4.201766</td>\n",
       "      <td>1.752202</td>\n",
       "      <td>3.220910</td>\n",
       "      <td>1.023048</td>\n",
       "      <td>0.079132</td>\n",
       "      <td>0.024576</td>\n",
       "      <td>0.616902</td>\n",
       "      <td>0.247866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Features        Model            Cross Validation  \\\n",
       "                                                                              \n",
       "0   Chemical + Feature Engineering  Transformer  Blocking Time Series Split   \n",
       "1   Chemical + Feature Engineering  Transformer  Blocking Time Series Split   \n",
       "2   Chemical + Feature Engineering  Transformer           Out of time Split   \n",
       "3   Chemical + Feature Engineering  Transformer           Out of time Split   \n",
       "4   Chemical + Feature Engineering  Transformer           Out of time Split   \n",
       "5   Chemical + Feature Engineering  Transformer              Repeated KFold   \n",
       "6   Chemical + Feature Engineering  Transformer              Repeated KFold   \n",
       "7   Chemical + Feature Engineering  Transformer              Repeated KFold   \n",
       "8   Chemical + Feature Engineering  Transformer           Time Series Split   \n",
       "9   Chemical + Feature Engineering  Transformer           Time Series Split   \n",
       "10  Chemical + Feature Engineering  Transformer           Time Series Split   \n",
       "\n",
       "                             Cross Validation Params Timesteps RMSE Test  \\\n",
       "                                                                    mean   \n",
       "0   {\"N_Splits\": 5, \"Repeats\": 3, \"train_size\": 0.8}         1  1.915087   \n",
       "1   {\"N_Splits\": 5, \"Repeats\": 3, \"train_size\": 0.8}         7  2.469831   \n",
       "2                                 {\"Test Size\": 0.2}         1  2.100839   \n",
       "3                                 {\"Test Size\": 0.2}         7  2.748974   \n",
       "4                                 {\"Test Size\": 0.2}        14  2.356184   \n",
       "5                      {\"N_Splits\": 5, \"Repeats\": 3}         1  1.631906   \n",
       "6                      {\"N_Splits\": 5, \"Repeats\": 3}         7  2.101466   \n",
       "7                      {\"N_Splits\": 5, \"Repeats\": 3}        14  2.332644   \n",
       "8            {\"N_Splits\": 5, \"Repeats\": 3, \"Gap\": 0}         1  2.315810   \n",
       "9            {\"N_Splits\": 5, \"Repeats\": 3, \"Gap\": 0}         7  2.919045   \n",
       "10           {\"N_Splits\": 5, \"Repeats\": 3, \"Gap\": 0}        14  4.201766   \n",
       "\n",
       "              MAE Test           MAPE Test             R2 Test            \n",
       "         std      mean       std      mean       std      mean       std  \n",
       "0   0.316656  1.569110  0.277063  0.036958  0.005777  0.920441  0.031452  \n",
       "1   0.919534  1.971785  0.743915  0.048417  0.021029  0.858095  0.075519  \n",
       "2   0.065366  1.639084  0.094652  0.037046  0.001826  0.888195  0.007013  \n",
       "3   0.220925  2.167738  0.211845  0.050182  0.004097  0.806610  0.030888  \n",
       "4   0.139177  1.907744  0.122781  0.045460  0.004225  0.852829  0.016964  \n",
       "5   0.139402  1.301411  0.124368  0.030662  0.003324  0.946712  0.009471  \n",
       "6   0.167968  1.691762  0.123626  0.039824  0.003503  0.909823  0.015425  \n",
       "7   0.344729  1.877711  0.309477  0.044163  0.007682  0.884810  0.035655  \n",
       "8   0.268071  1.857935  0.245958  0.043340  0.006319  0.890175  0.020033  \n",
       "9   0.931379  2.293321  0.693877  0.054264  0.016562  0.818672  0.089182  \n",
       "10  1.752202  3.220910  1.023048  0.079132  0.024576  0.616902  0.247866  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Cross Validation Params\\\", \\\"Timesteps\\\"],\\n    dropna=False,\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_formatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Cross Validation Params\\\", \\\"Timesteps\\\"],\\n    dropna=False,\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat(results_to_save).reset_index().groupby(\n",
    "    [\"Features\", \"Model\", \"Cross Validation\", \"Cross Validation Params\", \"Timesteps\"],\n",
    "    dropna=False,\n",
    ")[[\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]].agg(\n",
    "    [\"mean\", lambda series: pd.Series(series.std(ddof=0), name=\"std\")]\n",
    ").reset_index().rename(\n",
    "    columns={\"<lambda_0>\": \"std\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d30e71",
   "metadata": {
    "papermill": {
     "duration": 0.022753,
     "end_time": "2024-02-29T16:03:36.051681",
     "exception": false,
     "start_time": "2024-02-29T16:03:36.028928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Saving the results Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d0b32c",
   "metadata": {
    "papermill": {
     "duration": 0.022429,
     "end_time": "2024-02-29T16:03:36.096277",
     "exception": false,
     "start_time": "2024-02-29T16:03:36.073848",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Saving the full dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb03e3c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T16:03:36.145960Z",
     "iopub.status.busy": "2024-02-29T16:03:36.144625Z",
     "iopub.status.idle": "2024-02-29T16:03:36.170538Z",
     "shell.execute_reply": "2024-02-29T16:03:36.169037Z"
    },
    "papermill": {
     "duration": 0.054061,
     "end_time": "2024-02-29T16:03:36.173587",
     "exception": false,
     "start_time": "2024-02-29T16:03:36.119526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"path = \\\"../../../../../reports/results/local_models/209/n/full/\\\"\\nfilename = f\\\"transformer_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = \\\"../../../../../reports/results/local_models/209/n/full/\\\"\\nfilename = f\\\"transformer_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"../../../../../reports/results/local_models/209/n/full/\"\n",
    "filename = f\"transformer_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60cafbe",
   "metadata": {
    "papermill": {
     "duration": 0.022689,
     "end_time": "2024-02-29T16:03:36.219715",
     "exception": false,
     "start_time": "2024-02-29T16:03:36.197026",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Saving the grouped dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e96211b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T16:03:36.273085Z",
     "iopub.status.busy": "2024-02-29T16:03:36.271832Z",
     "iopub.status.idle": "2024-02-29T16:03:36.348962Z",
     "shell.execute_reply": "2024-02-29T16:03:36.347343Z"
    },
    "papermill": {
     "duration": 0.104274,
     "end_time": "2024-02-29T16:03:36.352018",
     "exception": false,
     "start_time": "2024-02-29T16:03:36.247744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"cols_groupby = [\\n    \\\"Category\\\",\\n    \\\"Company\\\",\\n    \\\"Data Shape\\\",\\n    \\\"Timesteps\\\",\\n    \\\"Features\\\",\\n    \\\"Model\\\",\\n    \\\"Cross Validation\\\",\\n    \\\"Cross Validation Params\\\",\\n]\\n\\ncols_agg = [\\\"RMSE Train\\\", \\\"MAE Train\\\", \\\"MAPE Train\\\", \\\"R2 Train\\\"] + [\\n    \\\"RMSE Test\\\",\\n    \\\"MAE Test\\\",\\n    \\\"MAPE Test\\\",\\n    \\\"R2 Test\\\",\\n]\\n\\npath = \\\"../../../../../reports/results/local_models/209/n/grouped/\\\"\\nfilename = f\\\"transformer_results_grouped_{index_to_save}.csv\\\"\\n\\n\\ndf_results_to_save = (\\n    pd.concat(results_to_save)\\n    .groupby(cols_groupby, dropna=False)[cols_agg]\\n    .agg([\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")])\\n    .reset_index()\\n    .rename(columns={\\\"<lambda_0>\\\": \\\"std\\\"})\\n)\\n\\ndf_results_to_save.to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"cols_groupby = [\\n    \\\"Category\\\",\\n    \\\"Company\\\",\\n    \\\"Data Shape\\\",\\n    \\\"Timesteps\\\",\\n    \\\"Features\\\",\\n    \\\"Model\\\",\\n    \\\"Cross Validation\\\",\\n    \\\"Cross Validation Params\\\",\\n]\\n\\ncols_agg = [\\\"RMSE Train\\\", \\\"MAE Train\\\", \\\"MAPE Train\\\", \\\"R2 Train\\\"] + [\\n    \\\"RMSE Test\\\",\\n    \\\"MAE Test\\\",\\n    \\\"MAPE Test\\\",\\n    \\\"R2 Test\\\",\\n]\\n\\npath = \\\"../../../../../reports/results/local_models/209/n/grouped/\\\"\\nfilename = f\\\"transformer_results_grouped_{index_to_save}.csv\\\"\\n\\n\\ndf_results_to_save = (\\n    pd.concat(results_to_save)\\n    .groupby(cols_groupby, dropna=False)[cols_agg]\\n    .agg([\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")])\\n    .reset_index()\\n    .rename(columns={\\\"<lambda_0>\\\": \\\"std\\\"})\\n)\\n\\ndf_results_to_save.to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols_groupby = [\n",
    "    \"Category\",\n",
    "    \"Company\",\n",
    "    \"Data Shape\",\n",
    "    \"Timesteps\",\n",
    "    \"Features\",\n",
    "    \"Model\",\n",
    "    \"Cross Validation\",\n",
    "    \"Cross Validation Params\",\n",
    "]\n",
    "\n",
    "cols_agg = [\"RMSE Train\", \"MAE Train\", \"MAPE Train\", \"R2 Train\"] + [\n",
    "    \"RMSE Test\",\n",
    "    \"MAE Test\",\n",
    "    \"MAPE Test\",\n",
    "    \"R2 Test\",\n",
    "]\n",
    "\n",
    "path = \"../../../../../reports/results/local_models/209/n/grouped/\"\n",
    "filename = f\"transformer_results_grouped_{index_to_save}.csv\"\n",
    "\n",
    "\n",
    "df_results_to_save = (\n",
    "    pd.concat(results_to_save)\n",
    "    .groupby(cols_groupby, dropna=False)[cols_agg]\n",
    "    .agg([\"mean\", lambda series: pd.Series(series.std(ddof=0), name=\"std\")])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"<lambda_0>\": \"std\"})\n",
    ")\n",
    "\n",
    "df_results_to_save.to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e655c",
   "metadata": {
    "papermill": {
     "duration": 0.023376,
     "end_time": "2024-02-29T16:03:36.397101",
     "exception": false,
     "start_time": "2024-02-29T16:03:36.373725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2808.647121,
   "end_time": "2024-02-29T16:03:39.062869",
   "environment_variables": {},
   "exception": null,
   "input_path": "/home/peressim/projects/ccs28-ml-modelling/notebooks/modelling/209/transformer/n/chemical-mineralogical-feature_engineering-ds.ipynb",
   "output_path": "/home/peressim/projects/ccs28-ml-modelling/notebooks/modelling/209/transformer/n/chemical-mineralogical-feature_engineering-ds.ipynb",
   "parameters": {},
   "start_time": "2024-02-29T15:16:50.415748",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}