{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6edb92e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:36.908628Z",
     "iopub.status.busy": "2024-03-01T09:23:36.908148Z",
     "iopub.status.idle": "2024-03-01T09:23:37.020189Z",
     "shell.execute_reply": "2024-03-01T09:23:37.018881Z"
    },
    "papermill": {
     "duration": 0.129163,
     "end_time": "2024-03-01T09:23:37.023349",
     "exception": false,
     "start_time": "2024-03-01T09:23:36.894186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b04ff56f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:37.056208Z",
     "iopub.status.busy": "2024-03-01T09:23:37.055736Z",
     "iopub.status.idle": "2024-03-01T09:23:41.742962Z",
     "shell.execute_reply": "2024-03-01T09:23:41.741261Z"
    },
    "papermill": {
     "duration": 4.708291,
     "end_time": "2024-03-01T09:23:41.746396",
     "exception": false,
     "start_time": "2024-03-01T09:23:37.038105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 06:23:38.786287: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-01 06:23:38.855792: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-01 06:23:38.857342: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 06:23:40.454769: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Plotting\\nimport matplotlib.pyplot as plt\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.model_selection import TimeSeriesSplit\\nfrom sklearn.model_selection import RepeatedKFold\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.model_selection import cross_validate\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.preprocessing import RobustScaler\\n\\n# Metrics\\nfrom sklearn.metrics import mean_squared_error\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.metrics import mean_absolute_percentage_error\\nfrom sklearn.metrics import r2_score\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import BaseEstimator, RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\n# Converting Times Series Data to 3D format\\nfrom src.utils.split_sequences import split_sequences\\n\\n# To run cross validation parallelized\\nfrom joblib import Parallel, delayed\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Plotting\\nimport matplotlib.pyplot as plt\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.model_selection import TimeSeriesSplit\\nfrom sklearn.model_selection import RepeatedKFold\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.model_selection import cross_validate\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.preprocessing import RobustScaler\\n\\n# Metrics\\nfrom sklearn.metrics import mean_squared_error\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.metrics import mean_absolute_percentage_error\\nfrom sklearn.metrics import r2_score\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import BaseEstimator, RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\n# Converting Times Series Data to 3D format\\nfrom src.utils.split_sequences import split_sequences\\n\\n# To run cross validation parallelized\\nfrom joblib import Parallel, delayed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "# Converting Times Series Data to 3D format\n",
    "from src.utils.split_sequences import split_sequences\n",
    "\n",
    "# To run cross validation parallelized\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a9c188",
   "metadata": {
    "papermill": {
     "duration": 0.014197,
     "end_time": "2024-03-01T09:23:41.776767",
     "exception": false,
     "start_time": "2024-03-01T09:23:41.762570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe10aff1",
   "metadata": {
    "papermill": {
     "duration": 0.013214,
     "end_time": "2024-03-01T09:23:41.804892",
     "exception": false,
     "start_time": "2024-03-01T09:23:41.791678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions for blocked time series cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d93ad1",
   "metadata": {
    "papermill": {
     "duration": 0.012844,
     "end_time": "2024-03-01T09:23:41.831674",
     "exception": false,
     "start_time": "2024-03-01T09:23:41.818830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Convert train/test data to 3D format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0da93cb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:41.864857Z",
     "iopub.status.busy": "2024-03-01T09:23:41.862973Z",
     "iopub.status.idle": "2024-03-01T09:23:41.884617Z",
     "shell.execute_reply": "2024-03-01T09:23:41.882626Z"
    },
    "papermill": {
     "duration": 0.043076,
     "end_time": "2024-03-01T09:23:41.888154",
     "exception": false,
     "start_time": "2024-03-01T09:23:41.845078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def generate_sequences_helper(\\n    dataset, cement_types, dates=None, timesteps=None, split_by_cement_type=False\\n):\\n    index_train = dataset[\\\"y_train\\\"].index\\n    index_test = dataset[\\\"y_test\\\"].index\\n\\n    dataset[\\\"y_train\\\"] = dataset[\\\"y_train\\\"].reset_index(drop=True)\\n    dataset[\\\"y_test\\\"] = dataset[\\\"y_test\\\"].reset_index(drop=True)\\n\\n    if dates is not None:\\n        dataset[\\\"dates_train\\\"] = dates[index_train].reset_index(drop=True)\\n        dataset[\\\"dates_test\\\"] = dates[index_test].reset_index(drop=True)\\n\\n    dataset[\\\"cement_types_train\\\"] = cement_types.loc[index_train].reset_index(drop=True)\\n    dataset[\\\"cement_types_test\\\"] = cement_types.loc[index_test].reset_index(drop=True)\\n\\n    dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\\n\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def generate_sequences_helper(\\n    dataset, cement_types, dates=None, timesteps=None, split_by_cement_type=False\\n):\\n    index_train = dataset[\\\"y_train\\\"].index\\n    index_test = dataset[\\\"y_test\\\"].index\\n\\n    dataset[\\\"y_train\\\"] = dataset[\\\"y_train\\\"].reset_index(drop=True)\\n    dataset[\\\"y_test\\\"] = dataset[\\\"y_test\\\"].reset_index(drop=True)\\n\\n    if dates is not None:\\n        dataset[\\\"dates_train\\\"] = dates[index_train].reset_index(drop=True)\\n        dataset[\\\"dates_test\\\"] = dates[index_test].reset_index(drop=True)\\n\\n    dataset[\\\"cement_types_train\\\"] = cement_types.loc[index_train].reset_index(drop=True)\\n    dataset[\\\"cement_types_test\\\"] = cement_types.loc[index_test].reset_index(drop=True)\\n\\n    dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\\n\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_sequences_helper(\n",
    "    dataset, cement_types, dates=None, timesteps=None, split_by_cement_type=False\n",
    "):\n",
    "    index_train = dataset[\"y_train\"].index\n",
    "    index_test = dataset[\"y_test\"].index\n",
    "\n",
    "    dataset[\"y_train\"] = dataset[\"y_train\"].reset_index(drop=True)\n",
    "    dataset[\"y_test\"] = dataset[\"y_test\"].reset_index(drop=True)\n",
    "\n",
    "    if dates is not None:\n",
    "        dataset[\"dates_train\"] = dates[index_train].reset_index(drop=True)\n",
    "        dataset[\"dates_test\"] = dates[index_test].reset_index(drop=True)\n",
    "\n",
    "    dataset[\"cement_types_train\"] = cement_types.loc[index_train].reset_index(drop=True)\n",
    "    dataset[\"cement_types_test\"] = cement_types.loc[index_test].reset_index(drop=True)\n",
    "\n",
    "    dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e3c0d28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:41.926809Z",
     "iopub.status.busy": "2024-03-01T09:23:41.926301Z",
     "iopub.status.idle": "2024-03-01T09:23:41.958203Z",
     "shell.execute_reply": "2024-03-01T09:23:41.956232Z"
    },
    "papermill": {
     "duration": 0.051574,
     "end_time": "2024-03-01T09:23:41.961260",
     "exception": false,
     "start_time": "2024-03-01T09:23:41.909686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"def generate_sequences(dataset, timesteps, split_by_cement_type=False):\\n    if split_by_cement_type:\\n        dataset[\\\"x_train\\\"], dataset[\\\"y_train\\\"] = split_sequences_per_cement_type(\\n            pd.concat(\\n                [\\n                    dataset[\\\"dates_train\\\"],\\n                    pd.DataFrame(dataset[\\\"x_train\\\"], columns=x.columns),\\n                    dataset[\\\"cement_types_train\\\"],\\n                    dataset[\\\"y_train\\\"],\\n                ],\\n                axis=1,\\n            ),\\n            timesteps,\\n        )\\n\\n        dataset[\\\"x_test\\\"], dataset[\\\"y_test\\\"] = split_sequences_per_cement_type(\\n            pd.concat(\\n                [\\n                    dataset[\\\"dates_test\\\"],\\n                    pd.DataFrame(dataset[\\\"x_test\\\"], columns=x.columns),\\n                    dataset[\\\"cement_types_test\\\"],\\n                    dataset[\\\"y_test\\\"],\\n                ],\\n                axis=1,\\n            ),\\n            timesteps,\\n        )\\n    else:\\n        dataset[\\\"x_train\\\"], dataset[\\\"y_train\\\"] = split_sequences(\\n            pd.concat(\\n                [\\n                    pd.DataFrame(dataset[\\\"x_train\\\"], columns=x.columns),\\n                    dataset[\\\"y_train\\\"],\\n                ],\\n                axis=1,\\n            ).values,\\n            timesteps,\\n        )\\n\\n        dataset[\\\"x_test\\\"], dataset[\\\"y_test\\\"] = split_sequences(\\n            pd.concat(\\n                [\\n                    pd.DataFrame(dataset[\\\"x_test\\\"], columns=x.columns),\\n                    dataset[\\\"y_test\\\"],\\n                ],\\n                axis=1,\\n            ).values,\\n            timesteps,\\n        )\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def generate_sequences(dataset, timesteps, split_by_cement_type=False):\\n    if split_by_cement_type:\\n        dataset[\\\"x_train\\\"], dataset[\\\"y_train\\\"] = split_sequences_per_cement_type(\\n            pd.concat(\\n                [\\n                    dataset[\\\"dates_train\\\"],\\n                    pd.DataFrame(dataset[\\\"x_train\\\"], columns=x.columns),\\n                    dataset[\\\"cement_types_train\\\"],\\n                    dataset[\\\"y_train\\\"],\\n                ],\\n                axis=1,\\n            ),\\n            timesteps,\\n        )\\n\\n        dataset[\\\"x_test\\\"], dataset[\\\"y_test\\\"] = split_sequences_per_cement_type(\\n            pd.concat(\\n                [\\n                    dataset[\\\"dates_test\\\"],\\n                    pd.DataFrame(dataset[\\\"x_test\\\"], columns=x.columns),\\n                    dataset[\\\"cement_types_test\\\"],\\n                    dataset[\\\"y_test\\\"],\\n                ],\\n                axis=1,\\n            ),\\n            timesteps,\\n        )\\n    else:\\n        dataset[\\\"x_train\\\"], dataset[\\\"y_train\\\"] = split_sequences(\\n            pd.concat(\\n                [\\n                    pd.DataFrame(dataset[\\\"x_train\\\"], columns=x.columns),\\n                    dataset[\\\"y_train\\\"],\\n                ],\\n                axis=1,\\n            ).values,\\n            timesteps,\\n        )\\n\\n        dataset[\\\"x_test\\\"], dataset[\\\"y_test\\\"] = split_sequences(\\n            pd.concat(\\n                [\\n                    pd.DataFrame(dataset[\\\"x_test\\\"], columns=x.columns),\\n                    dataset[\\\"y_test\\\"],\\n                ],\\n                axis=1,\\n            ).values,\\n            timesteps,\\n        )\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_sequences(dataset, timesteps, split_by_cement_type=False):\n",
    "    if split_by_cement_type:\n",
    "        dataset[\"x_train\"], dataset[\"y_train\"] = split_sequences_per_cement_type(\n",
    "            pd.concat(\n",
    "                [\n",
    "                    dataset[\"dates_train\"],\n",
    "                    pd.DataFrame(dataset[\"x_train\"], columns=x.columns),\n",
    "                    dataset[\"cement_types_train\"],\n",
    "                    dataset[\"y_train\"],\n",
    "                ],\n",
    "                axis=1,\n",
    "            ),\n",
    "            timesteps,\n",
    "        )\n",
    "\n",
    "        dataset[\"x_test\"], dataset[\"y_test\"] = split_sequences_per_cement_type(\n",
    "            pd.concat(\n",
    "                [\n",
    "                    dataset[\"dates_test\"],\n",
    "                    pd.DataFrame(dataset[\"x_test\"], columns=x.columns),\n",
    "                    dataset[\"cement_types_test\"],\n",
    "                    dataset[\"y_test\"],\n",
    "                ],\n",
    "                axis=1,\n",
    "            ),\n",
    "            timesteps,\n",
    "        )\n",
    "    else:\n",
    "        dataset[\"x_train\"], dataset[\"y_train\"] = split_sequences(\n",
    "            pd.concat(\n",
    "                [\n",
    "                    pd.DataFrame(dataset[\"x_train\"], columns=x.columns),\n",
    "                    dataset[\"y_train\"],\n",
    "                ],\n",
    "                axis=1,\n",
    "            ).values,\n",
    "            timesteps,\n",
    "        )\n",
    "\n",
    "        dataset[\"x_test\"], dataset[\"y_test\"] = split_sequences(\n",
    "            pd.concat(\n",
    "                [\n",
    "                    pd.DataFrame(dataset[\"x_test\"], columns=x.columns),\n",
    "                    dataset[\"y_test\"],\n",
    "                ],\n",
    "                axis=1,\n",
    "            ).values,\n",
    "            timesteps,\n",
    "        )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d3f38f",
   "metadata": {
    "papermill": {
     "duration": 0.014734,
     "end_time": "2024-03-01T09:23:41.990553",
     "exception": false,
     "start_time": "2024-03-01T09:23:41.975819",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d361eeee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:42.024134Z",
     "iopub.status.busy": "2024-03-01T09:23:42.023498Z",
     "iopub.status.idle": "2024-03-01T09:23:42.041083Z",
     "shell.execute_reply": "2024-03-01T09:23:42.039568Z"
    },
    "papermill": {
     "duration": 0.038163,
     "end_time": "2024-03-01T09:23:42.044277",
     "exception": false,
     "start_time": "2024-03-01T09:23:42.006114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"def impute_data(dataset, imputer=None, imputer_params=None):\\n    x_train = dataset[\\\"x_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n\\n    # Apply imputation to the data\\n    if imputer is not None:\\n        imputer = imputer() if imputer_params is None else imputer(**imputer_params)\\n        x_train = imputer.fit_transform(x_train)\\n        x_test = imputer.transform(x_test)\\n\\n    dataset[\\\"x_train\\\"] = x_train\\n    dataset[\\\"x_test\\\"] = x_test\\n\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def impute_data(dataset, imputer=None, imputer_params=None):\\n    x_train = dataset[\\\"x_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n\\n    # Apply imputation to the data\\n    if imputer is not None:\\n        imputer = imputer() if imputer_params is None else imputer(**imputer_params)\\n        x_train = imputer.fit_transform(x_train)\\n        x_test = imputer.transform(x_test)\\n\\n    dataset[\\\"x_train\\\"] = x_train\\n    dataset[\\\"x_test\\\"] = x_test\\n\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def impute_data(dataset, imputer=None, imputer_params=None):\n",
    "    x_train = dataset[\"x_train\"]\n",
    "    x_test = dataset[\"x_test\"]\n",
    "\n",
    "    # Apply imputation to the data\n",
    "    if imputer is not None:\n",
    "        imputer = imputer() if imputer_params is None else imputer(**imputer_params)\n",
    "        x_train = imputer.fit_transform(x_train)\n",
    "        x_test = imputer.transform(x_test)\n",
    "\n",
    "    dataset[\"x_train\"] = x_train\n",
    "    dataset[\"x_test\"] = x_test\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03a1bf6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:42.078881Z",
     "iopub.status.busy": "2024-03-01T09:23:42.077181Z",
     "iopub.status.idle": "2024-03-01T09:23:42.095149Z",
     "shell.execute_reply": "2024-03-01T09:23:42.093352Z"
    },
    "papermill": {
     "duration": 0.038693,
     "end_time": "2024-03-01T09:23:42.099137",
     "exception": false,
     "start_time": "2024-03-01T09:23:42.060444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"def transform_data(dataset, transformer=None):\\n    x_train = dataset[\\\"x_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n\\n    # Apply data normalization/standardization to the data\\n    if transformer is not None:\\n        scaler = transformer()\\n        x_train = scaler.fit_transform(x_train)\\n        x_test = scaler.transform(x_test)\\n\\n    dataset[\\\"x_train\\\"] = x_train\\n    dataset[\\\"x_test\\\"] = x_test\\n\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def transform_data(dataset, transformer=None):\\n    x_train = dataset[\\\"x_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n\\n    # Apply data normalization/standardization to the data\\n    if transformer is not None:\\n        scaler = transformer()\\n        x_train = scaler.fit_transform(x_train)\\n        x_test = scaler.transform(x_test)\\n\\n    dataset[\\\"x_train\\\"] = x_train\\n    dataset[\\\"x_test\\\"] = x_test\\n\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def transform_data(dataset, transformer=None):\n",
    "    x_train = dataset[\"x_train\"]\n",
    "    x_test = dataset[\"x_test\"]\n",
    "\n",
    "    # Apply data normalization/standardization to the data\n",
    "    if transformer is not None:\n",
    "        scaler = transformer()\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "    dataset[\"x_train\"] = x_train\n",
    "    dataset[\"x_test\"] = x_test\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5904da04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:42.130794Z",
     "iopub.status.busy": "2024-03-01T09:23:42.130236Z",
     "iopub.status.idle": "2024-03-01T09:23:42.145349Z",
     "shell.execute_reply": "2024-03-01T09:23:42.143371Z"
    },
    "papermill": {
     "duration": 0.035153,
     "end_time": "2024-03-01T09:23:42.148977",
     "exception": false,
     "start_time": "2024-03-01T09:23:42.113824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"def preprocess_data(dataset, transformer=None, imputer=None, imputer_params=None):\\n    dataset = impute_data(dataset, imputer, imputer_params)\\n    dataset = transform_data(dataset, transformer)\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def preprocess_data(dataset, transformer=None, imputer=None, imputer_params=None):\\n    dataset = impute_data(dataset, imputer, imputer_params)\\n    dataset = transform_data(dataset, transformer)\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_data(dataset, transformer=None, imputer=None, imputer_params=None):\n",
    "    dataset = impute_data(dataset, imputer, imputer_params)\n",
    "    dataset = transform_data(dataset, transformer)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff03e2fa",
   "metadata": {
    "papermill": {
     "duration": 0.014684,
     "end_time": "2024-03-01T09:23:42.180919",
     "exception": false,
     "start_time": "2024-03-01T09:23:42.166235",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1edfee4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:42.213869Z",
     "iopub.status.busy": "2024-03-01T09:23:42.213333Z",
     "iopub.status.idle": "2024-03-01T09:23:42.232232Z",
     "shell.execute_reply": "2024-03-01T09:23:42.229959Z"
    },
    "papermill": {
     "duration": 0.040761,
     "end_time": "2024-03-01T09:23:42.236422",
     "exception": false,
     "start_time": "2024-03-01T09:23:42.195661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"def train_and_evaluate_model(Estimator, dataset, estimator_params=None):\\n    \\\"\\\"\\\"\\n    Purpose: Helper function to be used in conjunction with\\n    blocked time_series cross validation function\\n    \\\"\\\"\\\"\\n    x_train = dataset[\\\"x_train\\\"]\\n    y_train = dataset[\\\"y_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n    y_test = dataset[\\\"y_test\\\"]\\n\\n    # Instantiate the model\\n    model = Estimator() if estimator_params is None else Estimator(**estimator_params)\\n\\n    # Fitting the model\\n    model.fit(x_train, y_train)\\n\\n    # Making predictions on train/test sets\\n    y_train_pred = model.predict(x_train)\\n    y_test_pred = model.predict(x_test)\\n\\n    # Return regression metrics\\n    return score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"def train_and_evaluate_model(Estimator, dataset, estimator_params=None):\\n    \\\"\\\"\\\"\\n    Purpose: Helper function to be used in conjunction with\\n    blocked time_series cross validation function\\n    \\\"\\\"\\\"\\n    x_train = dataset[\\\"x_train\\\"]\\n    y_train = dataset[\\\"y_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n    y_test = dataset[\\\"y_test\\\"]\\n\\n    # Instantiate the model\\n    model = Estimator() if estimator_params is None else Estimator(**estimator_params)\\n\\n    # Fitting the model\\n    model.fit(x_train, y_train)\\n\\n    # Making predictions on train/test sets\\n    y_train_pred = model.predict(x_train)\\n    y_test_pred = model.predict(x_test)\\n\\n    # Return regression metrics\\n    return score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_and_evaluate_model(Estimator, dataset, estimator_params=None):\n",
    "    \"\"\"\n",
    "    Purpose: Helper function to be used in conjunction with\n",
    "    blocked time_series cross validation function\n",
    "    \"\"\"\n",
    "    x_train = dataset[\"x_train\"]\n",
    "    y_train = dataset[\"y_train\"]\n",
    "    x_test = dataset[\"x_test\"]\n",
    "    y_test = dataset[\"y_test\"]\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = Estimator() if estimator_params is None else Estimator(**estimator_params)\n",
    "\n",
    "    # Fitting the model\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Making predictions on train/test sets\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "\n",
    "    # Return regression metrics\n",
    "    return score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8880cb1d",
   "metadata": {
    "papermill": {
     "duration": 0.017605,
     "end_time": "2024-03-01T09:23:42.270590",
     "exception": false,
     "start_time": "2024-03-01T09:23:42.252985",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Custom Cross Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d91a1541",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:42.307213Z",
     "iopub.status.busy": "2024-03-01T09:23:42.306683Z",
     "iopub.status.idle": "2024-03-01T09:23:42.354546Z",
     "shell.execute_reply": "2024-03-01T09:23:42.352643Z"
    },
    "papermill": {
     "duration": 0.070757,
     "end_time": "2024-03-01T09:23:42.357779",
     "exception": false,
     "start_time": "2024-03-01T09:23:42.287022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"def custom_cross_validate_parallelized(\\n   Estimator,\\n   Imputer,\\n   Transform,\\n   x,\\n   y,\\n   cv,\\n   timesteps,\\n   dates=None,\\n   cement_types=None,\\n   estimator_params=None,\\n   imputer_params=None,\\n   split_by_cement_type=True,\\n   n_jobs=-1,  # Set the number of parallel jobs, -1 for using all available cores\\n):\\n    def process_fold(train_index, test_index, dates, cement_types, x, y):\\n        dataset = {\\n           \\\"dates_train\\\": dates[train_index].reset_index(drop=True),\\n           \\\"cement_types_train\\\": cement_types.loc[train_index].reset_index(drop=True),\\n           \\\"x_train\\\": x.loc[train_index].reset_index(drop=True),\\n           \\\"y_train\\\": y[train_index].reset_index(drop=True),\\n           \\\"dates_test\\\": dates[test_index].reset_index(drop=True),\\n           \\\"cement_types_test\\\": cement_types.loc[test_index].reset_index(drop=True),\\n           \\\"x_test\\\": x.loc[test_index].reset_index(drop=True),\\n           \\\"y_test\\\": y[test_index].reset_index(drop=True),\\n        }\\n\\n\\n        set_seeds()\\n\\n        # Preprocess the dataset\\n        dataset = preprocess_data(dataset, Transform, Imputer, imputer_params)\\n\\n        # generate sequences (3D format)\\n        dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\\n\\n        # Train and Evaluate the model\\n        score = train_and_evaluate_model(Estimator, dataset, estimator_params)\\n        return score\\n\\n    scores = Parallel(n_jobs=n_jobs)(\\n    delayed(process_fold)(train_index, test_index, dates, cement_types, x, y)\\n    for train_index, test_index in cv.split(x)\\n    )\\n\\n    # After every iteration metrics results are appended together\\n    scores_final = {key: [] for key, _ in scores[0].items()}\\n    for scores_dict in scores:\\n        for key, value in scores_dict.items():\\n            scores_final[key] += [value]\\n\\n    results = [scores_final]\\n    return results\";\n",
       "                var nbb_formatted_code = \"def custom_cross_validate_parallelized(\\n    Estimator,\\n    Imputer,\\n    Transform,\\n    x,\\n    y,\\n    cv,\\n    timesteps,\\n    dates=None,\\n    cement_types=None,\\n    estimator_params=None,\\n    imputer_params=None,\\n    split_by_cement_type=True,\\n    n_jobs=-1,  # Set the number of parallel jobs, -1 for using all available cores\\n):\\n    def process_fold(train_index, test_index, dates, cement_types, x, y):\\n        dataset = {\\n            \\\"dates_train\\\": dates[train_index].reset_index(drop=True),\\n            \\\"cement_types_train\\\": cement_types.loc[train_index].reset_index(drop=True),\\n            \\\"x_train\\\": x.loc[train_index].reset_index(drop=True),\\n            \\\"y_train\\\": y[train_index].reset_index(drop=True),\\n            \\\"dates_test\\\": dates[test_index].reset_index(drop=True),\\n            \\\"cement_types_test\\\": cement_types.loc[test_index].reset_index(drop=True),\\n            \\\"x_test\\\": x.loc[test_index].reset_index(drop=True),\\n            \\\"y_test\\\": y[test_index].reset_index(drop=True),\\n        }\\n\\n        set_seeds()\\n\\n        # Preprocess the dataset\\n        dataset = preprocess_data(dataset, Transform, Imputer, imputer_params)\\n\\n        # generate sequences (3D format)\\n        dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\\n\\n        # Train and Evaluate the model\\n        score = train_and_evaluate_model(Estimator, dataset, estimator_params)\\n        return score\\n\\n    scores = Parallel(n_jobs=n_jobs)(\\n        delayed(process_fold)(train_index, test_index, dates, cement_types, x, y)\\n        for train_index, test_index in cv.split(x)\\n    )\\n\\n    # After every iteration metrics results are appended together\\n    scores_final = {key: [] for key, _ in scores[0].items()}\\n    for scores_dict in scores:\\n        for key, value in scores_dict.items():\\n            scores_final[key] += [value]\\n\\n    results = [scores_final]\\n    return results\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def custom_cross_validate_parallelized(\n",
    "   Estimator,\n",
    "   Imputer,\n",
    "   Transform,\n",
    "   x,\n",
    "   y,\n",
    "   cv,\n",
    "   timesteps,\n",
    "   dates=None,\n",
    "   cement_types=None,\n",
    "   estimator_params=None,\n",
    "   imputer_params=None,\n",
    "   split_by_cement_type=True,\n",
    "   n_jobs=-1,  # Set the number of parallel jobs, -1 for using all available cores\n",
    "):\n",
    "    def process_fold(train_index, test_index, dates, cement_types, x, y):\n",
    "        dataset = {\n",
    "           \"dates_train\": dates[train_index].reset_index(drop=True),\n",
    "           \"cement_types_train\": cement_types.loc[train_index].reset_index(drop=True),\n",
    "           \"x_train\": x.loc[train_index].reset_index(drop=True),\n",
    "           \"y_train\": y[train_index].reset_index(drop=True),\n",
    "           \"dates_test\": dates[test_index].reset_index(drop=True),\n",
    "           \"cement_types_test\": cement_types.loc[test_index].reset_index(drop=True),\n",
    "           \"x_test\": x.loc[test_index].reset_index(drop=True),\n",
    "           \"y_test\": y[test_index].reset_index(drop=True),\n",
    "        }\n",
    "\n",
    "\n",
    "        set_seeds()\n",
    "\n",
    "        # Preprocess the dataset\n",
    "        dataset = preprocess_data(dataset, Transform, Imputer, imputer_params)\n",
    "\n",
    "        # generate sequences (3D format)\n",
    "        dataset = generate_sequences(dataset, timesteps, split_by_cement_type)\n",
    "\n",
    "        # Train and Evaluate the model\n",
    "        score = train_and_evaluate_model(Estimator, dataset, estimator_params)\n",
    "        return score\n",
    "\n",
    "    scores = Parallel(n_jobs=n_jobs)(\n",
    "    delayed(process_fold)(train_index, test_index, dates, cement_types, x, y)\n",
    "    for train_index, test_index in cv.split(x)\n",
    "    )\n",
    "\n",
    "    # After every iteration metrics results are appended together\n",
    "    scores_final = {key: [] for key, _ in scores[0].items()}\n",
    "    for scores_dict in scores:\n",
    "        for key, value in scores_dict.items():\n",
    "            scores_final[key] += [value]\n",
    "\n",
    "    results = [scores_final]\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1c3da2",
   "metadata": {
    "papermill": {
     "duration": 0.015613,
     "end_time": "2024-03-01T09:23:42.389694",
     "exception": false,
     "start_time": "2024-03-01T09:23:42.374081",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b0052e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:42.423677Z",
     "iopub.status.busy": "2024-03-01T09:23:42.423138Z",
     "iopub.status.idle": "2024-03-01T09:23:42.449079Z",
     "shell.execute_reply": "2024-03-01T09:23:42.447122Z"
    },
    "papermill": {
     "duration": 0.046797,
     "end_time": "2024-03-01T09:23:42.452615",
     "exception": false,
     "start_time": "2024-03-01T09:23:42.405818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class BidirectionalGRU(BaseEstimator, RegressorMixin):\\n    def __init__(self):\\n        self.model = self.get_model()\\n        self.batch_size = 16\\n        self.epochs = 300\\n        self.verbose = 0\\n\\n    def fit(self, X=None, y=None):\\n        self.model.fit(\\n            X, y, batch_size=self.batch_size, epochs=self.epochs, verbose=self.verbose\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(\\n            tf.keras.layers.Bidirectional(\\n                tf.keras.layers.GRU(units=16, activation=\\\"relu\\\")\\n            )\\n        ),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class BidirectionalGRU(BaseEstimator, RegressorMixin):\\n    def __init__(self):\\n        self.model = self.get_model()\\n        self.batch_size = 16\\n        self.epochs = 300\\n        self.verbose = 0\\n\\n    def fit(self, X=None, y=None):\\n        self.model.fit(\\n            X, y, batch_size=self.batch_size, epochs=self.epochs, verbose=self.verbose\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(\\n            tf.keras.layers.Bidirectional(\\n                tf.keras.layers.GRU(units=16, activation=\\\"relu\\\")\\n            )\\n        ),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class BidirectionalGRU(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 16\n",
    "        self.epochs = 300\n",
    "        self.verbose = 0\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.model.fit(\n",
    "            X, y, batch_size=self.batch_size, epochs=self.epochs, verbose=self.verbose\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(\n",
    "            tf.keras.layers.Bidirectional(\n",
    "                tf.keras.layers.GRU(units=16, activation=\"relu\")\n",
    "            )\n",
    "        ),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0de36c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:42.489143Z",
     "iopub.status.busy": "2024-03-01T09:23:42.488564Z",
     "iopub.status.idle": "2024-03-01T09:23:42.506535Z",
     "shell.execute_reply": "2024-03-01T09:23:42.504936Z"
    },
    "papermill": {
     "duration": 0.039921,
     "end_time": "2024-03-01T09:23:42.509597",
     "exception": false,
     "start_time": "2024-03-01T09:23:42.469676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"def pad_time_series(dataframe, timesteps):\\n    \\\"\\\"\\\"\\n    Pad timeseries with zeros\\n    \\\"\\\"\\\"\\n    df_tmp = pd.DataFrame(\\n        dict(\\n            zip(\\n                dataframe.columns,\\n                [[0 for _ in range(timesteps - 1)] for _ in range(dataframe.shape[1])],\\n            )\\n        )\\n    )\\n    df_tmp[DATE] = dataframe[DATE].iloc[0]\\n    return pd.concat([df_tmp, dataframe], axis=0).reset_index(drop=True)\";\n",
       "                var nbb_formatted_code = \"def pad_time_series(dataframe, timesteps):\\n    \\\"\\\"\\\"\\n    Pad timeseries with zeros\\n    \\\"\\\"\\\"\\n    df_tmp = pd.DataFrame(\\n        dict(\\n            zip(\\n                dataframe.columns,\\n                [[0 for _ in range(timesteps - 1)] for _ in range(dataframe.shape[1])],\\n            )\\n        )\\n    )\\n    df_tmp[DATE] = dataframe[DATE].iloc[0]\\n    return pd.concat([df_tmp, dataframe], axis=0).reset_index(drop=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pad_time_series(dataframe, timesteps):\n",
    "    \"\"\"\n",
    "    Pad timeseries with zeros\n",
    "    \"\"\"\n",
    "    df_tmp = pd.DataFrame(\n",
    "        dict(\n",
    "            zip(\n",
    "                dataframe.columns,\n",
    "                [[0 for _ in range(timesteps - 1)] for _ in range(dataframe.shape[1])],\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    df_tmp[DATE] = dataframe[DATE].iloc[0]\n",
    "    return pd.concat([df_tmp, dataframe], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7c0c701",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:42.544985Z",
     "iopub.status.busy": "2024-03-01T09:23:42.544438Z",
     "iopub.status.idle": "2024-03-01T09:23:42.578003Z",
     "shell.execute_reply": "2024-03-01T09:23:42.576233Z"
    },
    "papermill": {
     "duration": 0.055092,
     "end_time": "2024-03-01T09:23:42.581343",
     "exception": false,
     "start_time": "2024-03-01T09:23:42.526251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"def split_sequences_per_cement_type(dataframe, timesteps, pad=False):\\n    \\\"\\\"\\\"\\n    Create sequences per cement time\\n    to avoid having parts of the sequence\\n    of different types of cement.\\n    \\\"\\\"\\\"\\n    if timesteps == 1:\\n        return split_sequences(\\n            dataframe.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps\\n        )\\n\\n    dates = dataframe[DATE][timesteps - 1 :]\\n    data = []\\n    dataframes = []\\n\\n    for cement_type in CEMENT_TYPES:\\n        data.append(dataframe[dataframe[cement_type] == 1])\\n    data.append(dataframe[(dataframe[CEMENT_TYPES] == 0).all(axis=1)])\\n\\n    for df in data:\\n        if pad:\\n            dates = df[DATE].reset_index(drop=True)\\n            df = pad_time_series(df, timesteps).reset_index(drop=True)\\n        else:\\n            dates = df[DATE][timesteps - 1 :].reset_index(drop=True)\\n        x, y = split_sequences(df.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps)\\n        x = pd.DataFrame({\\\"Sequences\\\": [sample.tolist() for sample in x]})\\n        y = pd.DataFrame({\\\"Target\\\": y})\\n        dataframes.append(pd.concat([dates, x, y], axis=1))\\n\\n    data = pd.concat(dataframes, axis=0)\\n    data[DATE] = pd.to_datetime(data[DATE])\\n    data = data.sort_values(by=DATE).reset_index(drop=True)\\n    x = data[\\\"Sequences\\\"]\\n    y = data[\\\"Target\\\"].values\\n    x = np.array(x.tolist())\\n\\n    return x, y\";\n",
       "                var nbb_formatted_code = \"def split_sequences_per_cement_type(dataframe, timesteps, pad=False):\\n    \\\"\\\"\\\"\\n    Create sequences per cement time\\n    to avoid having parts of the sequence\\n    of different types of cement.\\n    \\\"\\\"\\\"\\n    if timesteps == 1:\\n        return split_sequences(\\n            dataframe.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps\\n        )\\n\\n    dates = dataframe[DATE][timesteps - 1 :]\\n    data = []\\n    dataframes = []\\n\\n    for cement_type in CEMENT_TYPES:\\n        data.append(dataframe[dataframe[cement_type] == 1])\\n    data.append(dataframe[(dataframe[CEMENT_TYPES] == 0).all(axis=1)])\\n\\n    for df in data:\\n        if pad:\\n            dates = df[DATE].reset_index(drop=True)\\n            df = pad_time_series(df, timesteps).reset_index(drop=True)\\n        else:\\n            dates = df[DATE][timesteps - 1 :].reset_index(drop=True)\\n        x, y = split_sequences(df.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps)\\n        x = pd.DataFrame({\\\"Sequences\\\": [sample.tolist() for sample in x]})\\n        y = pd.DataFrame({\\\"Target\\\": y})\\n        dataframes.append(pd.concat([dates, x, y], axis=1))\\n\\n    data = pd.concat(dataframes, axis=0)\\n    data[DATE] = pd.to_datetime(data[DATE])\\n    data = data.sort_values(by=DATE).reset_index(drop=True)\\n    x = data[\\\"Sequences\\\"]\\n    y = data[\\\"Target\\\"].values\\n    x = np.array(x.tolist())\\n\\n    return x, y\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def split_sequences_per_cement_type(dataframe, timesteps, pad=False):\n",
    "    \"\"\"\n",
    "    Create sequences per cement time\n",
    "    to avoid having parts of the sequence\n",
    "    of different types of cement.\n",
    "    \"\"\"\n",
    "    if timesteps == 1:\n",
    "        return split_sequences(\n",
    "            dataframe.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps\n",
    "        )\n",
    "\n",
    "    dates = dataframe[DATE][timesteps - 1 :]\n",
    "    data = []\n",
    "    dataframes = []\n",
    "\n",
    "    for cement_type in CEMENT_TYPES:\n",
    "        data.append(dataframe[dataframe[cement_type] == 1])\n",
    "    data.append(dataframe[(dataframe[CEMENT_TYPES] == 0).all(axis=1)])\n",
    "\n",
    "    for df in data:\n",
    "        if pad:\n",
    "            dates = df[DATE].reset_index(drop=True)\n",
    "            df = pad_time_series(df, timesteps).reset_index(drop=True)\n",
    "        else:\n",
    "            dates = df[DATE][timesteps - 1 :].reset_index(drop=True)\n",
    "        x, y = split_sequences(df.drop([DATE] + CEMENT_TYPES, axis=1).values, timesteps)\n",
    "        x = pd.DataFrame({\"Sequences\": [sample.tolist() for sample in x]})\n",
    "        y = pd.DataFrame({\"Target\": y})\n",
    "        dataframes.append(pd.concat([dates, x, y], axis=1))\n",
    "\n",
    "    data = pd.concat(dataframes, axis=0)\n",
    "    data[DATE] = pd.to_datetime(data[DATE])\n",
    "    data = data.sort_values(by=DATE).reset_index(drop=True)\n",
    "    x = data[\"Sequences\"]\n",
    "    y = data[\"Target\"].values\n",
    "    x = np.array(x.tolist())\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb139be5",
   "metadata": {
    "papermill": {
     "duration": 0.013642,
     "end_time": "2024-03-01T09:23:42.610517",
     "exception": false,
     "start_time": "2024-03-01T09:23:42.596875",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1a7dfb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:42.643592Z",
     "iopub.status.busy": "2024-03-01T09:23:42.643029Z",
     "iopub.status.idle": "2024-03-01T09:23:42.653684Z",
     "shell.execute_reply": "2024-03-01T09:23:42.652190Z"
    },
    "papermill": {
     "duration": 0.032274,
     "end_time": "2024-03-01T09:23:42.656712",
     "exception": false,
     "start_time": "2024-03-01T09:23:42.624438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"SEED = 47\";\n",
       "                var nbb_formatted_code = \"SEED = 47\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "667baa5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:42.692732Z",
     "iopub.status.busy": "2024-03-01T09:23:42.692226Z",
     "iopub.status.idle": "2024-03-01T09:23:42.705707Z",
     "shell.execute_reply": "2024-03-01T09:23:42.703960Z"
    },
    "papermill": {
     "duration": 0.034247,
     "end_time": "2024-03-01T09:23:42.708919",
     "exception": false,
     "start_time": "2024-03-01T09:23:42.674672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"def set_seeds(seed=SEED):\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(seed)\\n    tf.random.set_seed(seed)\\n    np.random.seed(seed)\\n    random.seed(seed)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds(seed=SEED):\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(seed)\\n    tf.random.set_seed(seed)\\n    np.random.seed(seed)\\n    random.seed(seed)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds(seed=SEED):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39497c31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:42.744168Z",
     "iopub.status.busy": "2024-03-01T09:23:42.743602Z",
     "iopub.status.idle": "2024-03-01T09:23:42.759330Z",
     "shell.execute_reply": "2024-03-01T09:23:42.757386Z"
    },
    "papermill": {
     "duration": 0.036831,
     "end_time": "2024-03-01T09:23:42.762270",
     "exception": false,
     "start_time": "2024-03-01T09:23:42.725439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"def set_global_determinism():\\n    set_seeds(seed=SEED)\\n\\n    os.environ[\\\"TF_DETERMINISTIC_OPS\\\"] = \\\"1\\\"\\n    os.environ[\\\"TF_CUDNN_DETERMINISTIC\\\"] = \\\"1\\\"\\n\\n    tf.config.threading.set_inter_op_parallelism_threads(1)\\n    tf.config.threading.set_intra_op_parallelism_threads(1)\";\n",
       "                var nbb_formatted_code = \"def set_global_determinism():\\n    set_seeds(seed=SEED)\\n\\n    os.environ[\\\"TF_DETERMINISTIC_OPS\\\"] = \\\"1\\\"\\n    os.environ[\\\"TF_CUDNN_DETERMINISTIC\\\"] = \\\"1\\\"\\n\\n    tf.config.threading.set_inter_op_parallelism_threads(1)\\n    tf.config.threading.set_intra_op_parallelism_threads(1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_global_determinism():\n",
    "    set_seeds(seed=SEED)\n",
    "\n",
    "    os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "    os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4aa9d78e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:42.796848Z",
     "iopub.status.busy": "2024-03-01T09:23:42.796285Z",
     "iopub.status.idle": "2024-03-01T09:23:42.808292Z",
     "shell.execute_reply": "2024-03-01T09:23:42.806532Z"
    },
    "papermill": {
     "duration": 0.033961,
     "end_time": "2024-03-01T09:23:42.811531",
     "exception": false,
     "start_time": "2024-03-01T09:23:42.777570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"def suppress_warnings():\\n    os.environ[\\\"TF_CPP_MIN_LOG_LEVEL\\\"] = \\\"3\\\"\";\n",
       "                var nbb_formatted_code = \"def suppress_warnings():\\n    os.environ[\\\"TF_CPP_MIN_LOG_LEVEL\\\"] = \\\"3\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def suppress_warnings():\n",
    "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "292ba354",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:42.848270Z",
     "iopub.status.busy": "2024-03-01T09:23:42.847730Z",
     "iopub.status.idle": "2024-03-01T09:23:42.859483Z",
     "shell.execute_reply": "2024-03-01T09:23:42.858071Z"
    },
    "papermill": {
     "duration": 0.034412,
     "end_time": "2024-03-01T09:23:42.862218",
     "exception": false,
     "start_time": "2024-03-01T09:23:42.827806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def supress_other_stuff():\\n    os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    # os.environ[\\\"TF_ENABLE_ONEDNN_OPTS\\\"] = \\\"0\\\"\";\n",
       "                var nbb_formatted_code = \"def supress_other_stuff():\\n    os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    # os.environ[\\\"TF_ENABLE_ONEDNN_OPTS\\\"] = \\\"0\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def supress_other_stuff():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    # os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3adda02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:42.899093Z",
     "iopub.status.busy": "2024-03-01T09:23:42.898466Z",
     "iopub.status.idle": "2024-03-01T09:23:42.909577Z",
     "shell.execute_reply": "2024-03-01T09:23:42.907674Z"
    },
    "papermill": {
     "duration": 0.033608,
     "end_time": "2024-03-01T09:23:42.913033",
     "exception": false,
     "start_time": "2024-03-01T09:23:42.879425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"suppress_warnings()\\nsupress_other_stuff()\";\n",
       "                var nbb_formatted_code = \"suppress_warnings()\\nsupress_other_stuff()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suppress_warnings()\n",
    "supress_other_stuff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dc18e96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:42.951910Z",
     "iopub.status.busy": "2024-03-01T09:23:42.951386Z",
     "iopub.status.idle": "2024-03-01T09:23:42.965386Z",
     "shell.execute_reply": "2024-03-01T09:23:42.963563Z"
    },
    "papermill": {
     "duration": 0.037122,
     "end_time": "2024-03-01T09:23:42.968633",
     "exception": false,
     "start_time": "2024-03-01T09:23:42.931511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"index_to_save = 9\";\n",
       "                var nbb_formatted_code = \"index_to_save = 9\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_save = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc1084ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:43.006297Z",
     "iopub.status.busy": "2024-03-01T09:23:43.005791Z",
     "iopub.status.idle": "2024-03-01T09:23:43.024628Z",
     "shell.execute_reply": "2024-03-01T09:23:43.022426Z"
    },
    "papermill": {
     "duration": 0.04287,
     "end_time": "2024-03-01T09:23:43.028924",
     "exception": false,
     "start_time": "2024-03-01T09:23:42.986054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"METRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\\nDATE = \\\"Date\\\"\\nCEMENT_TYPES = [\\\"Cement_Type_CP II-F-40\\\", \\\"Cement_Type_CP V-ARI\\\"]\";\n",
       "                var nbb_formatted_code = \"METRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\\nDATE = \\\"Date\\\"\\nCEMENT_TYPES = [\\\"Cement_Type_CP II-F-40\\\", \\\"Cement_Type_CP V-ARI\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}\n",
    "DATE = \"Date\"\n",
    "CEMENT_TYPES = [\"Cement_Type_CP II-F-40\", \"Cement_Type_CP V-ARI\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1380f512",
   "metadata": {
    "papermill": {
     "duration": 0.020801,
     "end_time": "2024-03-01T09:23:43.068965",
     "exception": false,
     "start_time": "2024-03-01T09:23:43.048164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f965fc82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:43.108432Z",
     "iopub.status.busy": "2024-03-01T09:23:43.107964Z",
     "iopub.status.idle": "2024-03-01T09:23:43.126989Z",
     "shell.execute_reply": "2024-03-01T09:23:43.125381Z"
    },
    "papermill": {
     "duration": 0.046626,
     "end_time": "2024-03-01T09:23:43.131986",
     "exception": false,
     "start_time": "2024-03-01T09:23:43.085360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Local Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"N\\\",\\n    \\\"Features\\\": \\\"Chemical + Feature Engineering\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"BidirectionalGRU\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Local Model\\\",\\n    \\\"Company\\\": \\\"209\\\",\\n    \\\"Plant\\\": \\\"N\\\",\\n    \\\"Features\\\": \\\"Chemical + Feature Engineering\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"BidirectionalGRU\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Local Model\",\n",
    "    \"Company\": \"209\",\n",
    "    \"Plant\": \"N\",\n",
    "    \"Features\": \"Chemical + Feature Engineering\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"BidirectionalGRU\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b848df",
   "metadata": {
    "papermill": {
     "duration": 0.021562,
     "end_time": "2024-03-01T09:23:43.171915",
     "exception": false,
     "start_time": "2024-03-01T09:23:43.150353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff3b0fc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:43.216576Z",
     "iopub.status.busy": "2024-03-01T09:23:43.216068Z",
     "iopub.status.idle": "2024-03-01T09:23:43.244707Z",
     "shell.execute_reply": "2024-03-01T09:23:43.242829Z"
    },
    "papermill": {
     "duration": 0.05866,
     "end_time": "2024-03-01T09:23:43.248325",
     "exception": false,
     "start_time": "2024-03-01T09:23:43.189665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../data/processed/209/n.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../data/processed/209/n.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../data/processed/209/n.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ec9fd0",
   "metadata": {
    "papermill": {
     "duration": 0.017546,
     "end_time": "2024-03-01T09:23:43.286496",
     "exception": false,
     "start_time": "2024-03-01T09:23:43.268950",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we keep only chemical and mineralogical features yielded by the same testing method/procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ea7294b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:43.326042Z",
     "iopub.status.busy": "2024-03-01T09:23:43.325552Z",
     "iopub.status.idle": "2024-03-01T09:23:43.358225Z",
     "shell.execute_reply": "2024-03-01T09:23:43.356601Z"
    },
    "papermill": {
     "duration": 0.062795,
     "end_time": "2024-03-01T09:23:43.368153",
     "exception": false,
     "start_time": "2024-03-01T09:23:43.305358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df_copy = df.copy()\\ndf_copy = pd.get_dummies(data=df_copy, columns=[\\\"Cement_Type\\\"], drop_first=True)\\n\\ndf_copy = df_copy.drop(\\n    [\\n        \\\"Blaine\\\",\\n        \\n        \\\"#400\\\",\\n\\t\\t\\\"#325\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_formatted_code = \"df_copy = df.copy()\\ndf_copy = pd.get_dummies(data=df_copy, columns=[\\\"Cement_Type\\\"], drop_first=True)\\n\\ndf_copy = df_copy.drop(\\n    [\\n        \\\"Blaine\\\",\\n        \\\"#400\\\",\\n        \\\"#325\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Initial setting time\\\",\\n        \\\"CS3\\\",\\n        \\\"CS7\\\",\\n    ],\\n    axis=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.copy()\n",
    "df_copy = pd.get_dummies(data=df_copy, columns=[\"Cement_Type\"], drop_first=True)\n",
    "\n",
    "df_copy = df_copy.drop(\n",
    "    [\n",
    "        \"Blaine\",\n",
    "        \n",
    "        \"#400\",\n",
    "\t\t\"#325\",\n",
    "        \"Final setting time\",\n",
    "        \"Initial setting time\",\n",
    "        \"CS3\",\n",
    "        \"CS7\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03864f35",
   "metadata": {
    "papermill": {
     "duration": 0.023956,
     "end_time": "2024-03-01T09:23:43.410996",
     "exception": false,
     "start_time": "2024-03-01T09:23:43.387040",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f5c31a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:43.457846Z",
     "iopub.status.busy": "2024-03-01T09:23:43.457350Z",
     "iopub.status.idle": "2024-03-01T09:23:43.502360Z",
     "shell.execute_reply": "2024-03-01T09:23:43.500132Z"
    },
    "papermill": {
     "duration": 0.071305,
     "end_time": "2024-03-01T09:23:43.505904",
     "exception": false,
     "start_time": "2024-03-01T09:23:43.434599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# Feature Engineering over Chemical Features\\nch_features = [\\\"CaO\\\", \\\"MgO\\\", \\\"Na2O\\\", \\\"Al2O3\\\", \\\"SiO2\\\", \\\"SO3\\\", \\\"K2O\\\", \\\"Fe2O3\\\", \\\"TiO2\\\"]\\n\\ndf_copy[\\\"std_ch_feats\\\"] = df_copy[ch_features].std(ddof=0, axis=1)\\n\\ndf_copy[\\\"ratio_CaO_to_SiO2\\\"] = df_copy[\\\"CaO\\\"] / df_copy[\\\"SiO2\\\"]\\ndf_copy[\\\"ratio_MgO_to_CaO\\\"] = df_copy[\\\"MgO\\\"] / df_copy[\\\"CaO\\\"]\\n\\n\\n# Feature Engineering over Mineralogical Features\\nmi_features_set1 = [\\n    # Set 1\\n    \\\"C4AF\\\",\\n    \\\"Cubic C3A\\\",\\n    \\\"Orthorhombic C3A\\\",\\n\\t\\t\\\"Free CaO\\\",\\n    # Set 2\\n    \\\"Portlandite\\\",\\n    \\\"Periclase\\\",\\n    \\\"Bassanite\\\",\\n    \\\"Calcite\\\",\\n    \\\"Arcanite\\\",\\n    \\\"Aphthitalite\\\",\\n]\\n\\ndf_copy[\\\"mean_mi_set1_feats\\\"] = df_copy[mi_features_set1].mean(axis=1) \\n# Feature Engineering over Mineralogical Features\\nmi_features_set1 = [\\n    # Set 1\\n    \\\"C4AF\\\",\\n    \\\"Cubic C3A\\\",\\n    \\\"Orthorhombic C3A\\\",\\n\\t\\t\\\"Free CaO\\\",\\n    # Set 2\\n    \\\"Portlandite\\\",\\n    \\\"Periclase\\\",\\n    \\\"Bassanite\\\",\\n    \\\"Calcite\\\",\\n    \\\"Arcanite\\\",\\n    \\\"Aphthitalite\\\",\\n]\\n\\ndf_copy[\\\"mean_mi_set1_feats\\\"] = df_copy[mi_features_set1].mean(axis=1)\";\n",
       "                var nbb_formatted_code = \"# Feature Engineering over Chemical Features\\nch_features = [\\\"CaO\\\", \\\"MgO\\\", \\\"Na2O\\\", \\\"Al2O3\\\", \\\"SiO2\\\", \\\"SO3\\\", \\\"K2O\\\", \\\"Fe2O3\\\", \\\"TiO2\\\"]\\n\\ndf_copy[\\\"std_ch_feats\\\"] = df_copy[ch_features].std(ddof=0, axis=1)\\n\\ndf_copy[\\\"ratio_CaO_to_SiO2\\\"] = df_copy[\\\"CaO\\\"] / df_copy[\\\"SiO2\\\"]\\ndf_copy[\\\"ratio_MgO_to_CaO\\\"] = df_copy[\\\"MgO\\\"] / df_copy[\\\"CaO\\\"]\\n\\n\\n# Feature Engineering over Mineralogical Features\\nmi_features_set1 = [\\n    # Set 1\\n    \\\"C4AF\\\",\\n    \\\"Cubic C3A\\\",\\n    \\\"Orthorhombic C3A\\\",\\n    \\\"Free CaO\\\",\\n    # Set 2\\n    \\\"Portlandite\\\",\\n    \\\"Periclase\\\",\\n    \\\"Bassanite\\\",\\n    \\\"Calcite\\\",\\n    \\\"Arcanite\\\",\\n    \\\"Aphthitalite\\\",\\n]\\n\\ndf_copy[\\\"mean_mi_set1_feats\\\"] = df_copy[mi_features_set1].mean(axis=1)\\n# Feature Engineering over Mineralogical Features\\nmi_features_set1 = [\\n    # Set 1\\n    \\\"C4AF\\\",\\n    \\\"Cubic C3A\\\",\\n    \\\"Orthorhombic C3A\\\",\\n    \\\"Free CaO\\\",\\n    # Set 2\\n    \\\"Portlandite\\\",\\n    \\\"Periclase\\\",\\n    \\\"Bassanite\\\",\\n    \\\"Calcite\\\",\\n    \\\"Arcanite\\\",\\n    \\\"Aphthitalite\\\",\\n]\\n\\ndf_copy[\\\"mean_mi_set1_feats\\\"] = df_copy[mi_features_set1].mean(axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature Engineering over Chemical Features\n",
    "ch_features = [\"CaO\", \"MgO\", \"Na2O\", \"Al2O3\", \"SiO2\", \"SO3\", \"K2O\", \"Fe2O3\", \"TiO2\"]\n",
    "\n",
    "df_copy[\"std_ch_feats\"] = df_copy[ch_features].std(ddof=0, axis=1)\n",
    "\n",
    "df_copy[\"ratio_CaO_to_SiO2\"] = df_copy[\"CaO\"] / df_copy[\"SiO2\"]\n",
    "df_copy[\"ratio_MgO_to_CaO\"] = df_copy[\"MgO\"] / df_copy[\"CaO\"]\n",
    "\n",
    "\n",
    "# Feature Engineering over Mineralogical Features\n",
    "mi_features_set1 = [\n",
    "    # Set 1\n",
    "    \"C4AF\",\n",
    "    \"Cubic C3A\",\n",
    "    \"Orthorhombic C3A\",\n",
    "\t\t\"Free CaO\",\n",
    "    # Set 2\n",
    "    \"Portlandite\",\n",
    "    \"Periclase\",\n",
    "    \"Bassanite\",\n",
    "    \"Calcite\",\n",
    "    \"Arcanite\",\n",
    "    \"Aphthitalite\",\n",
    "]\n",
    "\n",
    "df_copy[\"mean_mi_set1_feats\"] = df_copy[mi_features_set1].mean(axis=1) \n",
    "# Feature Engineering over Mineralogical Features\n",
    "mi_features_set1 = [\n",
    "    # Set 1\n",
    "    \"C4AF\",\n",
    "    \"Cubic C3A\",\n",
    "    \"Orthorhombic C3A\",\n",
    "\t\t\"Free CaO\",\n",
    "    # Set 2\n",
    "    \"Portlandite\",\n",
    "    \"Periclase\",\n",
    "    \"Bassanite\",\n",
    "    \"Calcite\",\n",
    "    \"Arcanite\",\n",
    "    \"Aphthitalite\",\n",
    "]\n",
    "\n",
    "df_copy[\"mean_mi_set1_feats\"] = df_copy[mi_features_set1].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb9667f",
   "metadata": {
    "papermill": {
     "duration": 0.020987,
     "end_time": "2024-03-01T09:23:43.547123",
     "exception": false,
     "start_time": "2024-03-01T09:23:43.526136",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e348a91",
   "metadata": {
    "papermill": {
     "duration": 0.023534,
     "end_time": "2024-03-01T09:23:43.600695",
     "exception": false,
     "start_time": "2024-03-01T09:23:43.577161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2>1. Dataset: df_no_cs</h2> <br>In this dataset the CS1, CS3  and CS7 variables are not considered. Only Chemical and mineralogical features measured by the same method. For this particular dataset, all chemical features, with the exception of LOI were measured by XRF and XRD methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e0b698c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:43.643930Z",
     "iopub.status.busy": "2024-03-01T09:23:43.643382Z",
     "iopub.status.idle": "2024-03-01T09:23:43.665692Z",
     "shell.execute_reply": "2024-03-01T09:23:43.663678Z"
    },
    "papermill": {
     "duration": 0.050363,
     "end_time": "2024-03-01T09:23:43.669774",
     "exception": false,
     "start_time": "2024-03-01T09:23:43.619411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"df_copy[CEMENT_TYPES] = df_copy[CEMENT_TYPES].astype(int)\\ndates = df[\\\"Date\\\"].copy()\\ny = df_copy.pop(\\\"CS28\\\")\\nx = df_copy\\ndf_copy = pd.concat([x, y], axis=1)\";\n",
       "                var nbb_formatted_code = \"df_copy[CEMENT_TYPES] = df_copy[CEMENT_TYPES].astype(int)\\ndates = df[\\\"Date\\\"].copy()\\ny = df_copy.pop(\\\"CS28\\\")\\nx = df_copy\\ndf_copy = pd.concat([x, y], axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy[CEMENT_TYPES] = df_copy[CEMENT_TYPES].astype(int)\n",
    "dates = df[\"Date\"].copy()\n",
    "y = df_copy.pop(\"CS28\")\n",
    "x = df_copy\n",
    "df_copy = pd.concat([x, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a1218d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:43.711207Z",
     "iopub.status.busy": "2024-03-01T09:23:43.710634Z",
     "iopub.status.idle": "2024-03-01T09:23:43.720989Z",
     "shell.execute_reply": "2024-03-01T09:23:43.719650Z"
    },
    "papermill": {
     "duration": 0.034899,
     "end_time": "2024-03-01T09:23:43.723820",
     "exception": false,
     "start_time": "2024-03-01T09:23:43.688921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"TIMESTEPS_LIST = [1, 7, 14]\";\n",
       "                var nbb_formatted_code = \"TIMESTEPS_LIST = [1, 7, 14]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TIMESTEPS_LIST = [1, 7, 14]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fc518f",
   "metadata": {
    "papermill": {
     "duration": 0.023531,
     "end_time": "2024-03-01T09:23:43.766248",
     "exception": false,
     "start_time": "2024-03-01T09:23:43.742717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Bidirectional Long Short Term Memory - Bi-GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9ae728",
   "metadata": {
    "papermill": {
     "duration": 0.024601,
     "end_time": "2024-03-01T09:23:43.809319",
     "exception": false,
     "start_time": "2024-03-01T09:23:43.784718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.1 Repeated KFold Cross validation\n",
    "\n",
    "<b>Dataset shape:</b> (1234, 38)<br>\n",
    "<b>Timesteps:</b> 1, 3, 5, 7, 10, 15, 20<br>\n",
    "<b>Repeats:</b>10<br>\n",
    "<b>Splits:</b>10<br>\n",
    "    1. 10 folds of 123 samples each\n",
    "    2. 90% train (1111 samples each fold)\n",
    "    3. 10% test (123 samples each fold)\n",
    "<b>Total:</b> 100 models<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2efc3f3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:23:43.857740Z",
     "iopub.status.busy": "2024-03-01T09:23:43.857181Z",
     "iopub.status.idle": "2024-03-01T09:53:16.413004Z",
     "shell.execute_reply": "2024-03-01T09:53:16.411645Z"
    },
    "papermill": {
     "duration": 1772.602542,
     "end_time": "2024-03-01T09:53:16.436469",
     "exception": false,
     "start_time": "2024-03-01T09:23:43.833927",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated Cross Validation:\n",
      "Repeats: 3\n",
      "n_splits: 5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 1 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.267 (0.040)\n",
      "MAE: 0.996 (0.029)\n",
      "MAPE: 0.023 (0.001)\n",
      "R2: 0.968 (0.002)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.548 (0.107)\n",
      "MAE: 1.210 (0.080)\n",
      "MAPE: 0.028 (0.002)\n",
      "R2: 0.952 (0.007)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 7 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 0.999 (0.102)\n",
      "MAE: 0.791 (0.082)\n",
      "MAPE: 0.018 (0.002)\n",
      "R2: 0.980 (0.004)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.037 (0.141)\n",
      "MAE: 1.621 (0.110)\n",
      "MAPE: 0.038 (0.003)\n",
      "R2: 0.915 (0.013)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 14 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 0.969 (0.043)\n",
      "MAE: 0.769 (0.036)\n",
      "MAPE: 0.018 (0.001)\n",
      "R2: 0.981 (0.002)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.043 (0.200)\n",
      "MAE: 1.615 (0.173)\n",
      "MAPE: 0.038 (0.004)\n",
      "R2: 0.912 (0.018)\n",
      "\n",
      "======================\n",
      "\n",
      "Minutes Elapsed:  29.54214958747228\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"start = time.time()\\n\\nrepeats = 3\\nn_splits = 5\\nTIMESTEPS_LIST = [1, 7, 14]\\n\\nprint(\\\"Repeated Cross Validation:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n    cv = RepeatedKFold(n_splits=n_splits, n_repeats=repeats, random_state=SEED)\\n    x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1)\\n    y = df_copy[\\\"CS28\\\"]\\n    scores = custom_cross_validate_parallelized(\\n        BidirectionalGRU,\\n        SimpleImputer,\\n        StandardScaler,\\n        x,\\n        y,\\n        cv,\\n        timesteps=timesteps,\\n        dates=dates,\\n        cement_types=df_copy[CEMENT_TYPES],\\n        estimator_params=None,\\n        imputer_params={\\\"strategy\\\": \\\"median\\\"},\\n        split_by_cement_type=True,\\n    )\\n    scores = scores[0]\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores, METRICS, METRICS_DICT)\\n\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Repeated KFold\\\"\\n    results_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(results_dict_copy, scores)\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"start = time.time()\\n\\nrepeats = 3\\nn_splits = 5\\nTIMESTEPS_LIST = [1, 7, 14]\\n\\nprint(\\\"Repeated Cross Validation:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n    cv = RepeatedKFold(n_splits=n_splits, n_repeats=repeats, random_state=SEED)\\n    x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1)\\n    y = df_copy[\\\"CS28\\\"]\\n    scores = custom_cross_validate_parallelized(\\n        BidirectionalGRU,\\n        SimpleImputer,\\n        StandardScaler,\\n        x,\\n        y,\\n        cv,\\n        timesteps=timesteps,\\n        dates=dates,\\n        cement_types=df_copy[CEMENT_TYPES],\\n        estimator_params=None,\\n        imputer_params={\\\"strategy\\\": \\\"median\\\"},\\n        split_by_cement_type=True,\\n    )\\n    scores = scores[0]\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores, METRICS, METRICS_DICT)\\n\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Repeated KFold\\\"\\n    results_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(results_dict_copy, scores)\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "repeats = 3\n",
    "n_splits = 5\n",
    "TIMESTEPS_LIST = [1, 7, 14]\n",
    "\n",
    "print(\"Repeated Cross Validation:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"n_splits: {n_splits}\")\n",
    "print()\n",
    "\n",
    "for timesteps in TIMESTEPS_LIST:\n",
    "    set_seeds()\n",
    "    cv = RepeatedKFold(n_splits=n_splits, n_repeats=repeats, random_state=SEED)\n",
    "    x = df_copy.drop([\"Date\", \"CS28\"] + CEMENT_TYPES, axis=1)\n",
    "    y = df_copy[\"CS28\"]\n",
    "    scores = custom_cross_validate_parallelized(\n",
    "        BidirectionalGRU,\n",
    "        SimpleImputer,\n",
    "        StandardScaler,\n",
    "        x,\n",
    "        y,\n",
    "        cv,\n",
    "        timesteps=timesteps,\n",
    "        dates=dates,\n",
    "        cement_types=df_copy[CEMENT_TYPES],\n",
    "        estimator_params=None,\n",
    "        imputer_params={\"strategy\": \"median\"},\n",
    "        split_by_cement_type=True,\n",
    "    )\n",
    "    scores = scores[0]\n",
    "    print(\"TIMESTEPS: %d \" % timesteps)\n",
    "    print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "    results_dict_copy = results_dict.copy()\n",
    "    results_dict_copy[\"Timesteps\"] = timesteps\n",
    "    results_dict_copy[\"Cross Validation\"] = \"Repeated KFold\"\n",
    "    results_dict_copy[\"Cross Validation Params\"] = '{\"N_Splits\": 5, \"Repeats\": 3}'\n",
    "    results_dict_copy[\"Data Shape\"] = x.shape\n",
    "    df_results = fill_results_dict(results_dict_copy, scores)\n",
    "    results_to_save.append(df_results)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31706d9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:53:16.469063Z",
     "iopub.status.busy": "2024-03-01T09:53:16.468650Z",
     "iopub.status.idle": "2024-03-01T09:53:16.524409Z",
     "shell.execute_reply": "2024-03-01T09:53:16.523293Z"
    },
    "papermill": {
     "duration": 0.07481,
     "end_time": "2024-03-01T09:53:16.526278",
     "exception": false,
     "start_time": "2024-03-01T09:53:16.451468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RMSE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAPE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R2 Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>1</td>\n",
       "      <td>1.547631</td>\n",
       "      <td>0.107179</td>\n",
       "      <td>1.209918</td>\n",
       "      <td>0.080420</td>\n",
       "      <td>0.028032</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.952184</td>\n",
       "      <td>0.006795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>7</td>\n",
       "      <td>2.037267</td>\n",
       "      <td>0.140557</td>\n",
       "      <td>1.620816</td>\n",
       "      <td>0.110028</td>\n",
       "      <td>0.037983</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.915441</td>\n",
       "      <td>0.012742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>14</td>\n",
       "      <td>2.042778</td>\n",
       "      <td>0.199961</td>\n",
       "      <td>1.615116</td>\n",
       "      <td>0.173376</td>\n",
       "      <td>0.037765</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.912487</td>\n",
       "      <td>0.018175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Features             Model Cross Validation  \\\n",
       "                                                                       \n",
       "0  Chemical + Feature Engineering  BidirectionalGRU   Repeated KFold   \n",
       "1  Chemical + Feature Engineering  BidirectionalGRU   Repeated KFold   \n",
       "2  Chemical + Feature Engineering  BidirectionalGRU   Repeated KFold   \n",
       "\n",
       "  Timesteps RMSE Test            MAE Test           MAPE Test            \\\n",
       "                 mean       std      mean       std      mean       std   \n",
       "0         1  1.547631  0.107179  1.209918  0.080420  0.028032  0.002018   \n",
       "1         7  2.037267  0.140557  1.620816  0.110028  0.037983  0.002901   \n",
       "2        14  2.042778  0.199961  1.615116  0.173376  0.037765  0.004248   \n",
       "\n",
       "    R2 Test            \n",
       "       mean       std  \n",
       "0  0.952184  0.006795  \n",
       "1  0.915441  0.012742  \n",
       "2  0.912487  0.018175  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Timesteps\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_formatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Timesteps\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat(results_to_save).reset_index().groupby(\n",
    "    [\"Features\", \"Model\", \"Cross Validation\", \"Timesteps\"], dropna=False\n",
    ")[[\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]].agg(\n",
    "    [\"mean\", lambda series: pd.Series(series.std(ddof=0), name=\"std\")]\n",
    ").reset_index().rename(\n",
    "    columns={\"<lambda_0>\": \"std\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf414ed1",
   "metadata": {
    "papermill": {
     "duration": 0.012521,
     "end_time": "2024-03-01T09:53:16.551320",
     "exception": false,
     "start_time": "2024-03-01T09:53:16.538799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.2. Blocking Time Series Cross Validation\n",
    "\n",
    "<b>Dataset shape:</b> (1234, 38)<br>\n",
    "<b>Splits:</b>5<br>    \n",
    "    1. 5 folds of 246 samples\n",
    "    2. 50% train (123 samples each fold)\n",
    "    3. 50% test (123 samples each fold)\n",
    "<b>Total:</b> 5 models<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e4022df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:53:16.579221Z",
     "iopub.status.busy": "2024-03-01T09:53:16.578869Z",
     "iopub.status.idle": "2024-03-01T09:58:39.891716Z",
     "shell.execute_reply": "2024-03-01T09:58:39.890236Z"
    },
    "papermill": {
     "duration": 323.34663,
     "end_time": "2024-03-01T09:58:39.910161",
     "exception": false,
     "start_time": "2024-03-01T09:53:16.563531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocking Time Series Split:\n",
      "Repeats: 3\n",
      "n_splits: 5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 1 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 2.514 (0.219)\n",
      "MAE: 1.919 (0.134)\n",
      "MAPE: 0.044 (0.003)\n",
      "R2: 0.871 (0.028)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 6.527 (2.624)\n",
      "MAE: 5.108 (2.167)\n",
      "MAPE: 0.113 (0.044)\n",
      "R2: 0.085 (0.562)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 7 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.793 (0.325)\n",
      "MAE: 1.580 (0.344)\n",
      "MAPE: 0.036 (0.008)\n",
      "R2: 0.933 (0.023)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 8.253 (2.101)\n",
      "MAE: 6.698 (1.368)\n",
      "MAPE: 0.161 (0.037)\n",
      "R2: -0.597 (0.767)\n",
      "\n",
      "======================\n",
      "\n",
      "Minutes Elapsed:  5.388132588068644\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"start = time.time()\\n\\nrepeats = 3\\nn_splits = 5\\ntrain_size = 0.8\\nTIMESTEPS_LIST = [1, 7]\\n\\nprint(\\\"Blocking Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n    scores_final = None\\n\\n    for _ in range(repeats):\\n        x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1)\\n        y = df_copy[\\\"CS28\\\"]\\n\\n        cv = BlockingTimeSeriesSplit(n_splits=n_splits, train_size=train_size)\\n\\n        scores = custom_cross_validate_parallelized(\\n            BidirectionalGRU,\\n            SimpleImputer,\\n            StandardScaler,\\n            x,\\n            y,\\n            cv,\\n            timesteps,\\n            dates=dates,\\n            cement_types=df_copy[CEMENT_TYPES],\\n            estimator_params=None,\\n            imputer_params={\\\"strategy\\\": \\\"median\\\"},\\n            split_by_cement_type=True,\\n        )\\n        scores = scores[0]\\n        if scores_final is None:\\n            scores_final = {key: [] for key, _ in scores.items()}\\n\\n        for key, value in scores.items():\\n            scores_final[key] += [value]\\n\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores_final, METRICS, METRICS_DICT)\\n\\n    # Saving the results\\n    scores = {key: np.array(val).flatten() for key, val in scores_final.items()}\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Blocking Time Series Split\\\"\\n    results_dict_copy[\\n        \\\"Cross Validation Params\\\"\\n    ] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3, \\\"train_size\\\": 0.8}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(results_dict_copy, scores)\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"start = time.time()\\n\\nrepeats = 3\\nn_splits = 5\\ntrain_size = 0.8\\nTIMESTEPS_LIST = [1, 7]\\n\\nprint(\\\"Blocking Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n    scores_final = None\\n\\n    for _ in range(repeats):\\n        x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1)\\n        y = df_copy[\\\"CS28\\\"]\\n\\n        cv = BlockingTimeSeriesSplit(n_splits=n_splits, train_size=train_size)\\n\\n        scores = custom_cross_validate_parallelized(\\n            BidirectionalGRU,\\n            SimpleImputer,\\n            StandardScaler,\\n            x,\\n            y,\\n            cv,\\n            timesteps,\\n            dates=dates,\\n            cement_types=df_copy[CEMENT_TYPES],\\n            estimator_params=None,\\n            imputer_params={\\\"strategy\\\": \\\"median\\\"},\\n            split_by_cement_type=True,\\n        )\\n        scores = scores[0]\\n        if scores_final is None:\\n            scores_final = {key: [] for key, _ in scores.items()}\\n\\n        for key, value in scores.items():\\n            scores_final[key] += [value]\\n\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores_final, METRICS, METRICS_DICT)\\n\\n    # Saving the results\\n    scores = {key: np.array(val).flatten() for key, val in scores_final.items()}\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Blocking Time Series Split\\\"\\n    results_dict_copy[\\n        \\\"Cross Validation Params\\\"\\n    ] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3, \\\"train_size\\\": 0.8}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(results_dict_copy, scores)\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "repeats = 3\n",
    "n_splits = 5\n",
    "train_size = 0.8\n",
    "TIMESTEPS_LIST = [1, 7]\n",
    "\n",
    "print(\"Blocking Time Series Split:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"n_splits: {n_splits}\")\n",
    "print()\n",
    "\n",
    "for timesteps in TIMESTEPS_LIST:\n",
    "    set_seeds()\n",
    "    scores_final = None\n",
    "\n",
    "    for _ in range(repeats):\n",
    "        x = df_copy.drop([\"Date\", \"CS28\"] + CEMENT_TYPES, axis=1)\n",
    "        y = df_copy[\"CS28\"]\n",
    "\n",
    "        cv = BlockingTimeSeriesSplit(n_splits=n_splits, train_size=train_size)\n",
    "\n",
    "        scores = custom_cross_validate_parallelized(\n",
    "            BidirectionalGRU,\n",
    "            SimpleImputer,\n",
    "            StandardScaler,\n",
    "            x,\n",
    "            y,\n",
    "            cv,\n",
    "            timesteps,\n",
    "            dates=dates,\n",
    "            cement_types=df_copy[CEMENT_TYPES],\n",
    "            estimator_params=None,\n",
    "            imputer_params={\"strategy\": \"median\"},\n",
    "            split_by_cement_type=True,\n",
    "        )\n",
    "        scores = scores[0]\n",
    "        if scores_final is None:\n",
    "            scores_final = {key: [] for key, _ in scores.items()}\n",
    "\n",
    "        for key, value in scores.items():\n",
    "            scores_final[key] += [value]\n",
    "\n",
    "    print(\"TIMESTEPS: %d \" % timesteps)\n",
    "    print_scores(scores_final, METRICS, METRICS_DICT)\n",
    "\n",
    "    # Saving the results\n",
    "    scores = {key: np.array(val).flatten() for key, val in scores_final.items()}\n",
    "    results_dict_copy = results_dict.copy()\n",
    "    results_dict_copy[\"Timesteps\"] = timesteps\n",
    "    results_dict_copy[\"Cross Validation\"] = \"Blocking Time Series Split\"\n",
    "    results_dict_copy[\n",
    "        \"Cross Validation Params\"\n",
    "    ] = '{\"N_Splits\": 5, \"Repeats\": 3, \"train_size\": 0.8}'\n",
    "    results_dict_copy[\"Data Shape\"] = x.shape\n",
    "    df_results = fill_results_dict(results_dict_copy, scores)\n",
    "    results_to_save.append(df_results)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a65ecfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:58:39.942679Z",
     "iopub.status.busy": "2024-03-01T09:58:39.942278Z",
     "iopub.status.idle": "2024-03-01T09:58:39.984650Z",
     "shell.execute_reply": "2024-03-01T09:58:39.983705Z"
    },
    "papermill": {
     "duration": 0.062137,
     "end_time": "2024-03-01T09:58:39.986829",
     "exception": false,
     "start_time": "2024-03-01T09:58:39.924692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RMSE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAPE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R2 Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Blocking Time Series Split</td>\n",
       "      <td>1</td>\n",
       "      <td>6.527176</td>\n",
       "      <td>2.623622</td>\n",
       "      <td>5.108403</td>\n",
       "      <td>2.166673</td>\n",
       "      <td>0.112813</td>\n",
       "      <td>0.043884</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>0.562239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Blocking Time Series Split</td>\n",
       "      <td>7</td>\n",
       "      <td>8.253175</td>\n",
       "      <td>2.101136</td>\n",
       "      <td>6.698482</td>\n",
       "      <td>1.367674</td>\n",
       "      <td>0.160623</td>\n",
       "      <td>0.037041</td>\n",
       "      <td>-0.597264</td>\n",
       "      <td>0.766954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>1</td>\n",
       "      <td>1.547631</td>\n",
       "      <td>0.107179</td>\n",
       "      <td>1.209918</td>\n",
       "      <td>0.080420</td>\n",
       "      <td>0.028032</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.952184</td>\n",
       "      <td>0.006795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>7</td>\n",
       "      <td>2.037267</td>\n",
       "      <td>0.140557</td>\n",
       "      <td>1.620816</td>\n",
       "      <td>0.110028</td>\n",
       "      <td>0.037983</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.915441</td>\n",
       "      <td>0.012742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>14</td>\n",
       "      <td>2.042778</td>\n",
       "      <td>0.199961</td>\n",
       "      <td>1.615116</td>\n",
       "      <td>0.173376</td>\n",
       "      <td>0.037765</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.912487</td>\n",
       "      <td>0.018175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Features             Model  \\\n",
       "                                                      \n",
       "0  Chemical + Feature Engineering  BidirectionalGRU   \n",
       "1  Chemical + Feature Engineering  BidirectionalGRU   \n",
       "2  Chemical + Feature Engineering  BidirectionalGRU   \n",
       "3  Chemical + Feature Engineering  BidirectionalGRU   \n",
       "4  Chemical + Feature Engineering  BidirectionalGRU   \n",
       "\n",
       "             Cross Validation Timesteps RMSE Test            MAE Test  \\\n",
       "                                             mean       std      mean   \n",
       "0  Blocking Time Series Split         1  6.527176  2.623622  5.108403   \n",
       "1  Blocking Time Series Split         7  8.253175  2.101136  6.698482   \n",
       "2              Repeated KFold         1  1.547631  0.107179  1.209918   \n",
       "3              Repeated KFold         7  2.037267  0.140557  1.620816   \n",
       "4              Repeated KFold        14  2.042778  0.199961  1.615116   \n",
       "\n",
       "            MAPE Test             R2 Test            \n",
       "        std      mean       std      mean       std  \n",
       "0  2.166673  0.112813  0.043884  0.084968  0.562239  \n",
       "1  1.367674  0.160623  0.037041 -0.597264  0.766954  \n",
       "2  0.080420  0.028032  0.002018  0.952184  0.006795  \n",
       "3  0.110028  0.037983  0.002901  0.915441  0.012742  \n",
       "4  0.173376  0.037765  0.004248  0.912487  0.018175  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Timesteps\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_formatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Timesteps\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat(results_to_save).reset_index().groupby(\n",
    "    [\"Features\", \"Model\", \"Cross Validation\", \"Timesteps\"], dropna=False\n",
    ")[[\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]].agg(\n",
    "    [\"mean\", lambda series: pd.Series(series.std(ddof=0), name=\"std\")]\n",
    ").reset_index().rename(\n",
    "    columns={\"<lambda_0>\": \"std\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89341bff",
   "metadata": {
    "papermill": {
     "duration": 0.019019,
     "end_time": "2024-03-01T09:58:40.027096",
     "exception": false,
     "start_time": "2024-03-01T09:58:40.008077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.3. Time Series Split Cross Validation\n",
    "\n",
    "The training set has size i * n_samples // (n_splits + 1) + n_samples % (n_splits + 1) in the i th split, with a test set of size n_samples//(n_splits + 1) by default, where n_samples is the number of samples.\n",
    "\n",
    "\n",
    "<b>Dataset shape:</b> (1234, 38)<br>\n",
    "<b>Splits:</b>10<br>    \n",
    "    1. Train: 10 folds of 114, 226, 338, 450, 562, 675, 787, 899, 1011, 1123 samples each fold\n",
    "    2. Test: 112 samples each fold\n",
    "<b>Total:</b> 10 models<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7caf41b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T09:58:40.058239Z",
     "iopub.status.busy": "2024-03-01T09:58:40.057757Z",
     "iopub.status.idle": "2024-03-01T10:25:08.593117Z",
     "shell.execute_reply": "2024-03-01T10:25:08.591918Z"
    },
    "papermill": {
     "duration": 1588.568053,
     "end_time": "2024-03-01T10:25:08.610376",
     "exception": false,
     "start_time": "2024-03-01T09:58:40.042323",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocking Time Series Split:\n",
      "Repeats: 3\n",
      "n_splits: 5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 1 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.432 (0.343)\n",
      "MAE: 1.133 (0.269)\n",
      "MAPE: 0.026 (0.006)\n",
      "R2: 0.960 (0.022)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.602 (2.059)\n",
      "MAE: 2.844 (1.708)\n",
      "MAPE: 0.067 (0.040)\n",
      "R2: 0.681 (0.347)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 7 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.316 (0.379)\n",
      "MAE: 1.059 (0.301)\n",
      "MAPE: 0.024 (0.006)\n",
      "R2: 0.965 (0.019)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 6.575 (3.260)\n",
      "MAE: 5.039 (2.308)\n",
      "MAPE: 0.117 (0.050)\n",
      "R2: -0.019 (0.936)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 14 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.138 (0.075)\n",
      "MAE: 0.915 (0.074)\n",
      "MAPE: 0.021 (0.002)\n",
      "R2: 0.975 (0.004)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 4.244 (1.763)\n",
      "MAE: 3.407 (1.434)\n",
      "MAPE: 0.079 (0.031)\n",
      "R2: 0.591 (0.336)\n",
      "\n",
      "======================\n",
      "\n",
      "Minutes Elapsed:  26.47506807645162\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nstart = time.time()\\ngap = 0\\nn_splits = 5\\nrepeats = 3\\nTIMESTEPS_LIST = [1, 7, 14]\\n\\nprint(\\\"Blocking Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n    scores_final = None\\n\\n    for _ in range(repeats):\\n        x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1)\\n        y = df_copy[\\\"CS28\\\"]\\n\\n        cv = TimeSeriesSplit(\\n            gap=gap, max_train_size=None, n_splits=n_splits, test_size=None\\n        )\\n        scores = custom_cross_validate_parallelized(\\n            BidirectionalGRU,\\n            SimpleImputer,\\n            StandardScaler,\\n            x,\\n            y,\\n            cv,\\n            timesteps,\\n            dates=dates,\\n            cement_types=df_copy[CEMENT_TYPES],\\n            estimator_params=None,\\n            imputer_params={\\\"strategy\\\": \\\"median\\\"},\\n        )\\n        scores = scores[0]\\n        if scores_final is None:\\n            scores_final = {key: [] for key, _ in scores.items()}\\n\\n        for key, value in scores.items():\\n            scores_final[key] += [value]\\n\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores_final, METRICS, METRICS_DICT)\\n\\n    # Saving the results\\n    scores = {key: np.array(val).flatten() for key, val in scores_final.items()}\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Time Series Split\\\"\\n    results_dict_copy[\\n        \\\"Cross Validation Params\\\"\\n    ] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3, \\\"Gap\\\": 0}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(results_dict_copy, scores)\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nstart = time.time()\\ngap = 0\\nn_splits = 5\\nrepeats = 3\\nTIMESTEPS_LIST = [1, 7, 14]\\n\\nprint(\\\"Blocking Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n    scores_final = None\\n\\n    for _ in range(repeats):\\n        x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1)\\n        y = df_copy[\\\"CS28\\\"]\\n\\n        cv = TimeSeriesSplit(\\n            gap=gap, max_train_size=None, n_splits=n_splits, test_size=None\\n        )\\n        scores = custom_cross_validate_parallelized(\\n            BidirectionalGRU,\\n            SimpleImputer,\\n            StandardScaler,\\n            x,\\n            y,\\n            cv,\\n            timesteps,\\n            dates=dates,\\n            cement_types=df_copy[CEMENT_TYPES],\\n            estimator_params=None,\\n            imputer_params={\\\"strategy\\\": \\\"median\\\"},\\n        )\\n        scores = scores[0]\\n        if scores_final is None:\\n            scores_final = {key: [] for key, _ in scores.items()}\\n\\n        for key, value in scores.items():\\n            scores_final[key] += [value]\\n\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores_final, METRICS, METRICS_DICT)\\n\\n    # Saving the results\\n    scores = {key: np.array(val).flatten() for key, val in scores_final.items()}\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Time Series Split\\\"\\n    results_dict_copy[\\n        \\\"Cross Validation Params\\\"\\n    ] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3, \\\"Gap\\\": 0}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(results_dict_copy, scores)\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "start = time.time()\n",
    "gap = 0\n",
    "n_splits = 5\n",
    "repeats = 3\n",
    "TIMESTEPS_LIST = [1, 7, 14]\n",
    "\n",
    "print(\"Blocking Time Series Split:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"n_splits: {n_splits}\")\n",
    "print()\n",
    "\n",
    "for timesteps in TIMESTEPS_LIST:\n",
    "    set_seeds()\n",
    "    scores_final = None\n",
    "\n",
    "    for _ in range(repeats):\n",
    "        x = df_copy.drop([\"Date\", \"CS28\"] + CEMENT_TYPES, axis=1)\n",
    "        y = df_copy[\"CS28\"]\n",
    "\n",
    "        cv = TimeSeriesSplit(\n",
    "            gap=gap, max_train_size=None, n_splits=n_splits, test_size=None\n",
    "        )\n",
    "        scores = custom_cross_validate_parallelized(\n",
    "            BidirectionalGRU,\n",
    "            SimpleImputer,\n",
    "            StandardScaler,\n",
    "            x,\n",
    "            y,\n",
    "            cv,\n",
    "            timesteps,\n",
    "            dates=dates,\n",
    "            cement_types=df_copy[CEMENT_TYPES],\n",
    "            estimator_params=None,\n",
    "            imputer_params={\"strategy\": \"median\"},\n",
    "        )\n",
    "        scores = scores[0]\n",
    "        if scores_final is None:\n",
    "            scores_final = {key: [] for key, _ in scores.items()}\n",
    "\n",
    "        for key, value in scores.items():\n",
    "            scores_final[key] += [value]\n",
    "\n",
    "    print(\"TIMESTEPS: %d \" % timesteps)\n",
    "    print_scores(scores_final, METRICS, METRICS_DICT)\n",
    "\n",
    "    # Saving the results\n",
    "    scores = {key: np.array(val).flatten() for key, val in scores_final.items()}\n",
    "    results_dict_copy = results_dict.copy()\n",
    "    results_dict_copy[\"Timesteps\"] = timesteps\n",
    "    results_dict_copy[\"Cross Validation\"] = \"Time Series Split\"\n",
    "    results_dict_copy[\n",
    "        \"Cross Validation Params\"\n",
    "    ] = '{\"N_Splits\": 5, \"Repeats\": 3, \"Gap\": 0}'\n",
    "    results_dict_copy[\"Data Shape\"] = x.shape\n",
    "    df_results = fill_results_dict(results_dict_copy, scores)\n",
    "    results_to_save.append(df_results)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbc53015",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T10:25:08.649851Z",
     "iopub.status.busy": "2024-03-01T10:25:08.648266Z",
     "iopub.status.idle": "2024-03-01T10:25:08.707526Z",
     "shell.execute_reply": "2024-03-01T10:25:08.706791Z"
    },
    "papermill": {
     "duration": 0.080056,
     "end_time": "2024-03-01T10:25:08.709274",
     "exception": false,
     "start_time": "2024-03-01T10:25:08.629218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RMSE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAPE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R2 Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Blocking Time Series Split</td>\n",
       "      <td>1</td>\n",
       "      <td>6.527176</td>\n",
       "      <td>2.623622</td>\n",
       "      <td>5.108403</td>\n",
       "      <td>2.166673</td>\n",
       "      <td>0.112813</td>\n",
       "      <td>0.043884</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>0.562239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Blocking Time Series Split</td>\n",
       "      <td>7</td>\n",
       "      <td>8.253175</td>\n",
       "      <td>2.101136</td>\n",
       "      <td>6.698482</td>\n",
       "      <td>1.367674</td>\n",
       "      <td>0.160623</td>\n",
       "      <td>0.037041</td>\n",
       "      <td>-0.597264</td>\n",
       "      <td>0.766954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>1</td>\n",
       "      <td>1.547631</td>\n",
       "      <td>0.107179</td>\n",
       "      <td>1.209918</td>\n",
       "      <td>0.080420</td>\n",
       "      <td>0.028032</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.952184</td>\n",
       "      <td>0.006795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>7</td>\n",
       "      <td>2.037267</td>\n",
       "      <td>0.140557</td>\n",
       "      <td>1.620816</td>\n",
       "      <td>0.110028</td>\n",
       "      <td>0.037983</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.915441</td>\n",
       "      <td>0.012742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>14</td>\n",
       "      <td>2.042778</td>\n",
       "      <td>0.199961</td>\n",
       "      <td>1.615116</td>\n",
       "      <td>0.173376</td>\n",
       "      <td>0.037765</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.912487</td>\n",
       "      <td>0.018175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Time Series Split</td>\n",
       "      <td>1</td>\n",
       "      <td>3.601535</td>\n",
       "      <td>2.059450</td>\n",
       "      <td>2.844490</td>\n",
       "      <td>1.707720</td>\n",
       "      <td>0.066575</td>\n",
       "      <td>0.040200</td>\n",
       "      <td>0.681299</td>\n",
       "      <td>0.346980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Time Series Split</td>\n",
       "      <td>7</td>\n",
       "      <td>6.575463</td>\n",
       "      <td>3.260244</td>\n",
       "      <td>5.039080</td>\n",
       "      <td>2.308463</td>\n",
       "      <td>0.116744</td>\n",
       "      <td>0.050230</td>\n",
       "      <td>-0.019110</td>\n",
       "      <td>0.936444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Time Series Split</td>\n",
       "      <td>14</td>\n",
       "      <td>4.244235</td>\n",
       "      <td>1.762650</td>\n",
       "      <td>3.407007</td>\n",
       "      <td>1.434067</td>\n",
       "      <td>0.079290</td>\n",
       "      <td>0.031280</td>\n",
       "      <td>0.591086</td>\n",
       "      <td>0.335942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Features             Model  \\\n",
       "                                                      \n",
       "0  Chemical + Feature Engineering  BidirectionalGRU   \n",
       "1  Chemical + Feature Engineering  BidirectionalGRU   \n",
       "2  Chemical + Feature Engineering  BidirectionalGRU   \n",
       "3  Chemical + Feature Engineering  BidirectionalGRU   \n",
       "4  Chemical + Feature Engineering  BidirectionalGRU   \n",
       "5  Chemical + Feature Engineering  BidirectionalGRU   \n",
       "6  Chemical + Feature Engineering  BidirectionalGRU   \n",
       "7  Chemical + Feature Engineering  BidirectionalGRU   \n",
       "\n",
       "             Cross Validation Timesteps RMSE Test            MAE Test  \\\n",
       "                                             mean       std      mean   \n",
       "0  Blocking Time Series Split         1  6.527176  2.623622  5.108403   \n",
       "1  Blocking Time Series Split         7  8.253175  2.101136  6.698482   \n",
       "2              Repeated KFold         1  1.547631  0.107179  1.209918   \n",
       "3              Repeated KFold         7  2.037267  0.140557  1.620816   \n",
       "4              Repeated KFold        14  2.042778  0.199961  1.615116   \n",
       "5           Time Series Split         1  3.601535  2.059450  2.844490   \n",
       "6           Time Series Split         7  6.575463  3.260244  5.039080   \n",
       "7           Time Series Split        14  4.244235  1.762650  3.407007   \n",
       "\n",
       "            MAPE Test             R2 Test            \n",
       "        std      mean       std      mean       std  \n",
       "0  2.166673  0.112813  0.043884  0.084968  0.562239  \n",
       "1  1.367674  0.160623  0.037041 -0.597264  0.766954  \n",
       "2  0.080420  0.028032  0.002018  0.952184  0.006795  \n",
       "3  0.110028  0.037983  0.002901  0.915441  0.012742  \n",
       "4  0.173376  0.037765  0.004248  0.912487  0.018175  \n",
       "5  1.707720  0.066575  0.040200  0.681299  0.346980  \n",
       "6  2.308463  0.116744  0.050230 -0.019110  0.936444  \n",
       "7  1.434067  0.079290  0.031280  0.591086  0.335942  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Timesteps\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_formatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Timesteps\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat(results_to_save).reset_index().groupby(\n",
    "    [\"Features\", \"Model\", \"Cross Validation\", \"Timesteps\"], dropna=False\n",
    ")[[\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]].agg(\n",
    "    [\"mean\", lambda series: pd.Series(series.std(ddof=0), name=\"std\")]\n",
    ").reset_index().rename(\n",
    "    columns={\"<lambda_0>\": \"std\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8136cf8",
   "metadata": {
    "papermill": {
     "duration": 0.01906,
     "end_time": "2024-03-01T10:25:08.746061",
     "exception": false,
     "start_time": "2024-03-01T10:25:08.727001",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.4. Out of time Split Cross Validation\n",
    "\n",
    "<b>Dataset shape:</b> (1234, 38)<br>\n",
    "<b>Train size: 80%</b><br>\n",
    "<b>Test  size: 20%</b>\n",
    "\n",
    "\n",
    "<b>Splits:</b> 2<br>    \n",
    "    1. Train: 987\n",
    "    2. Test: 247\n",
    "<b>Total:</b> 1 model<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1915b42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T10:25:08.792576Z",
     "iopub.status.busy": "2024-03-01T10:25:08.791529Z",
     "iopub.status.idle": "2024-03-01T10:32:57.299066Z",
     "shell.execute_reply": "2024-03-01T10:32:57.297672Z"
    },
    "papermill": {
     "duration": 468.55101,
     "end_time": "2024-03-01T10:32:57.320213",
     "exception": false,
     "start_time": "2024-03-01T10:25:08.769203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of time Cross Val:\n",
      "Repeats: 3\n",
      "Train: 80% Test: 20%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 1 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.216 (0.067)\n",
      "MAE: 0.960 (0.061)\n",
      "MAPE: 0.022 (0.001)\n",
      "R2: 0.972 (0.003)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.528 (0.322)\n",
      "MAE: 2.073 (0.278)\n",
      "MAPE: 0.047 (0.006)\n",
      "R2: 0.836 (0.043)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 7 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.209 (0.192)\n",
      "MAE: 0.995 (0.174)\n",
      "MAPE: 0.023 (0.004)\n",
      "R2: 0.972 (0.008)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.324 (0.313)\n",
      "MAE: 2.721 (0.231)\n",
      "MAPE: 0.062 (0.004)\n",
      "R2: 0.717 (0.051)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS: 14 \n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 0.934 (0.006)\n",
      "MAE: 0.752 (0.002)\n",
      "MAPE: 0.018 (0.000)\n",
      "R2: 0.983 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.789 (0.175)\n",
      "MAE: 2.337 (0.191)\n",
      "MAPE: 0.054 (0.004)\n",
      "R2: 0.794 (0.026)\n",
      "\n",
      "======================\n",
      "\n",
      "Minutes Elapsed:  7.807537833849589\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"start = time.time()\\ntest_size = 0.2\\nrepeats = 3\\nTIMESTEPS_LIST = [1, 7, 14]\\n\\nprint(\\\"Out of time Cross Val:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"Train: {80}%\\\", f\\\"Test: {20}%\\\")\\nprint()\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n\\n    def parallel_repeats(repeat):\\n        set_seeds(SEED + repeat)\\n\\n        scores_final = None\\n\\n        # Data Splitting\\n        x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1).copy()\\n        y = df_copy[\\\"CS28\\\"].copy()\\n\\n        x_train, x_test, y_train, y_test = train_test_split(\\n            x, y, test_size=test_size, random_state=SEED, shuffle=False\\n        )\\n\\n        # Preprocessing\\n        imputer = SimpleImputer(strategy=\\\"median\\\")\\n        scaler = StandardScaler()\\n\\n        x_train = imputer.fit_transform(x_train)\\n        x_train = scaler.fit_transform(x_train)\\n        dates_train = dates[: x_train.shape[0]].reset_index(drop=True)\\n        cement_types_train = df_copy[CEMENT_TYPES][: x_train.shape[0]].reset_index(\\n            drop=True\\n        )\\n\\n        x_test = imputer.transform(x_test)\\n        x_test = scaler.transform(x_test)\\n        dates_test = dates[x_train.shape[0] :].reset_index(drop=True)\\n        cement_types_test = df_copy[CEMENT_TYPES][x_train.shape[0] :].reset_index(\\n            drop=True\\n        )\\n\\n        # Sequence Splitting\\n        data_train = pd.concat(\\n            [\\n                dates_train,\\n                pd.DataFrame(x_train, columns=x.columns),\\n                cement_types_train,\\n                y_train.reset_index(drop=True),\\n            ],\\n            axis=1,\\n        )\\n        data_test = pd.concat(\\n            [\\n                dates_test,\\n                pd.DataFrame(x_test, columns=x.columns),\\n                cement_types_test,\\n                y_test.reset_index(drop=True),\\n            ],\\n            axis=1,\\n        )\\n\\n        x_train, y_train = split_sequences_per_cement_type(data_train, timesteps)\\n        x_test, y_test = split_sequences_per_cement_type(data_test, timesteps)\\n\\n        # Train model and test evalutation\\n        # Fit model\\n        pipeline = Pipeline([(\\\"estimator\\\", BidirectionalGRU())])\\n        pipeline.fit(x_train, y_train)\\n\\n        # Make predictions\\n        y_train_pred = pipeline.predict(x_train)\\n        y_test_pred = pipeline.predict(x_test)\\n\\n        # evaluate predictions\\n        scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\\n\\n        if scores_final is None:\\n            scores_final = {key: [] for key, _ in scores.items()}\\n\\n        for key, value in scores.items():\\n            scores_final[key] += [value]\\n\\n        return scores_final\\n\\n    scores = Parallel(n_jobs=5)(\\n        delayed(parallel_repeats)(repeat) for repeat in range(repeats)\\n    )\\n    scores_final = {key: [] for key, _ in scores[0].items()}\\n    for scores_dict in scores:\\n        for key, value in scores_dict.items():\\n            scores_final[key] += value\\n\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores_final, METRICS, METRICS_DICT)\\n\\n    # Saving the results\\n    # scores = {key: val[0] for key, val in scores.items()}\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time Split\\\"\\n    results_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"Test Size\\\": 0.2}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(\\n        results_dict_copy, {key: value for key, value in scores_final.items()}\\n    )\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"start = time.time()\\ntest_size = 0.2\\nrepeats = 3\\nTIMESTEPS_LIST = [1, 7, 14]\\n\\nprint(\\\"Out of time Cross Val:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"Train: {80}%\\\", f\\\"Test: {20}%\\\")\\nprint()\\n\\nfor timesteps in TIMESTEPS_LIST:\\n    set_seeds()\\n\\n    def parallel_repeats(repeat):\\n        set_seeds(SEED + repeat)\\n\\n        scores_final = None\\n\\n        # Data Splitting\\n        x = df_copy.drop([\\\"Date\\\", \\\"CS28\\\"] + CEMENT_TYPES, axis=1).copy()\\n        y = df_copy[\\\"CS28\\\"].copy()\\n\\n        x_train, x_test, y_train, y_test = train_test_split(\\n            x, y, test_size=test_size, random_state=SEED, shuffle=False\\n        )\\n\\n        # Preprocessing\\n        imputer = SimpleImputer(strategy=\\\"median\\\")\\n        scaler = StandardScaler()\\n\\n        x_train = imputer.fit_transform(x_train)\\n        x_train = scaler.fit_transform(x_train)\\n        dates_train = dates[: x_train.shape[0]].reset_index(drop=True)\\n        cement_types_train = df_copy[CEMENT_TYPES][: x_train.shape[0]].reset_index(\\n            drop=True\\n        )\\n\\n        x_test = imputer.transform(x_test)\\n        x_test = scaler.transform(x_test)\\n        dates_test = dates[x_train.shape[0] :].reset_index(drop=True)\\n        cement_types_test = df_copy[CEMENT_TYPES][x_train.shape[0] :].reset_index(\\n            drop=True\\n        )\\n\\n        # Sequence Splitting\\n        data_train = pd.concat(\\n            [\\n                dates_train,\\n                pd.DataFrame(x_train, columns=x.columns),\\n                cement_types_train,\\n                y_train.reset_index(drop=True),\\n            ],\\n            axis=1,\\n        )\\n        data_test = pd.concat(\\n            [\\n                dates_test,\\n                pd.DataFrame(x_test, columns=x.columns),\\n                cement_types_test,\\n                y_test.reset_index(drop=True),\\n            ],\\n            axis=1,\\n        )\\n\\n        x_train, y_train = split_sequences_per_cement_type(data_train, timesteps)\\n        x_test, y_test = split_sequences_per_cement_type(data_test, timesteps)\\n\\n        # Train model and test evalutation\\n        # Fit model\\n        pipeline = Pipeline([(\\\"estimator\\\", BidirectionalGRU())])\\n        pipeline.fit(x_train, y_train)\\n\\n        # Make predictions\\n        y_train_pred = pipeline.predict(x_train)\\n        y_test_pred = pipeline.predict(x_test)\\n\\n        # evaluate predictions\\n        scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\\n\\n        if scores_final is None:\\n            scores_final = {key: [] for key, _ in scores.items()}\\n\\n        for key, value in scores.items():\\n            scores_final[key] += [value]\\n\\n        return scores_final\\n\\n    scores = Parallel(n_jobs=5)(\\n        delayed(parallel_repeats)(repeat) for repeat in range(repeats)\\n    )\\n    scores_final = {key: [] for key, _ in scores[0].items()}\\n    for scores_dict in scores:\\n        for key, value in scores_dict.items():\\n            scores_final[key] += value\\n\\n    print(\\\"TIMESTEPS: %d \\\" % timesteps)\\n    print_scores(scores_final, METRICS, METRICS_DICT)\\n\\n    # Saving the results\\n    # scores = {key: val[0] for key, val in scores.items()}\\n    results_dict_copy = results_dict.copy()\\n    results_dict_copy[\\\"Timesteps\\\"] = timesteps\\n    results_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time Split\\\"\\n    results_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"Test Size\\\": 0.2}'\\n    results_dict_copy[\\\"Data Shape\\\"] = x.shape\\n    df_results = fill_results_dict(\\n        results_dict_copy, {key: value for key, value in scores_final.items()}\\n    )\\n    results_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "test_size = 0.2\n",
    "repeats = 3\n",
    "TIMESTEPS_LIST = [1, 7, 14]\n",
    "\n",
    "print(\"Out of time Cross Val:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"Train: {80}%\", f\"Test: {20}%\")\n",
    "print()\n",
    "\n",
    "for timesteps in TIMESTEPS_LIST:\n",
    "    set_seeds()\n",
    "\n",
    "    def parallel_repeats(repeat):\n",
    "        set_seeds(SEED + repeat)\n",
    "\n",
    "        scores_final = None\n",
    "\n",
    "        # Data Splitting\n",
    "        x = df_copy.drop([\"Date\", \"CS28\"] + CEMENT_TYPES, axis=1).copy()\n",
    "        y = df_copy[\"CS28\"].copy()\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(\n",
    "            x, y, test_size=test_size, random_state=SEED, shuffle=False\n",
    "        )\n",
    "\n",
    "        # Preprocessing\n",
    "        imputer = SimpleImputer(strategy=\"median\")\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        x_train = imputer.fit_transform(x_train)\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        dates_train = dates[: x_train.shape[0]].reset_index(drop=True)\n",
    "        cement_types_train = df_copy[CEMENT_TYPES][: x_train.shape[0]].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "\n",
    "        x_test = imputer.transform(x_test)\n",
    "        x_test = scaler.transform(x_test)\n",
    "        dates_test = dates[x_train.shape[0] :].reset_index(drop=True)\n",
    "        cement_types_test = df_copy[CEMENT_TYPES][x_train.shape[0] :].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "\n",
    "        # Sequence Splitting\n",
    "        data_train = pd.concat(\n",
    "            [\n",
    "                dates_train,\n",
    "                pd.DataFrame(x_train, columns=x.columns),\n",
    "                cement_types_train,\n",
    "                y_train.reset_index(drop=True),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        data_test = pd.concat(\n",
    "            [\n",
    "                dates_test,\n",
    "                pd.DataFrame(x_test, columns=x.columns),\n",
    "                cement_types_test,\n",
    "                y_test.reset_index(drop=True),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        x_train, y_train = split_sequences_per_cement_type(data_train, timesteps)\n",
    "        x_test, y_test = split_sequences_per_cement_type(data_test, timesteps)\n",
    "\n",
    "        # Train model and test evalutation\n",
    "        # Fit model\n",
    "        pipeline = Pipeline([(\"estimator\", BidirectionalGRU())])\n",
    "        pipeline.fit(x_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = pipeline.predict(x_train)\n",
    "        y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "        # evaluate predictions\n",
    "        scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\n",
    "\n",
    "        if scores_final is None:\n",
    "            scores_final = {key: [] for key, _ in scores.items()}\n",
    "\n",
    "        for key, value in scores.items():\n",
    "            scores_final[key] += [value]\n",
    "\n",
    "        return scores_final\n",
    "\n",
    "    scores = Parallel(n_jobs=5)(\n",
    "        delayed(parallel_repeats)(repeat) for repeat in range(repeats)\n",
    "    )\n",
    "    scores_final = {key: [] for key, _ in scores[0].items()}\n",
    "    for scores_dict in scores:\n",
    "        for key, value in scores_dict.items():\n",
    "            scores_final[key] += value\n",
    "\n",
    "    print(\"TIMESTEPS: %d \" % timesteps)\n",
    "    print_scores(scores_final, METRICS, METRICS_DICT)\n",
    "\n",
    "    # Saving the results\n",
    "    # scores = {key: val[0] for key, val in scores.items()}\n",
    "    results_dict_copy = results_dict.copy()\n",
    "    results_dict_copy[\"Timesteps\"] = timesteps\n",
    "    results_dict_copy[\"Cross Validation\"] = \"Out of time Split\"\n",
    "    results_dict_copy[\"Cross Validation Params\"] = '{\"Test Size\": 0.2}'\n",
    "    results_dict_copy[\"Data Shape\"] = x.shape\n",
    "    df_results = fill_results_dict(\n",
    "        results_dict_copy, {key: value for key, value in scores_final.items()}\n",
    "    )\n",
    "    results_to_save.append(df_results)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a423391",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T10:32:57.360931Z",
     "iopub.status.busy": "2024-03-01T10:32:57.360451Z",
     "iopub.status.idle": "2024-03-01T10:32:57.413089Z",
     "shell.execute_reply": "2024-03-01T10:32:57.412119Z"
    },
    "papermill": {
     "duration": 0.073355,
     "end_time": "2024-03-01T10:32:57.414930",
     "exception": false,
     "start_time": "2024-03-01T10:32:57.341575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RMSE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAPE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R2 Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Blocking Time Series Split</td>\n",
       "      <td>1</td>\n",
       "      <td>6.527176</td>\n",
       "      <td>2.623622</td>\n",
       "      <td>5.108403</td>\n",
       "      <td>2.166673</td>\n",
       "      <td>0.112813</td>\n",
       "      <td>0.043884</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>0.562239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Blocking Time Series Split</td>\n",
       "      <td>7</td>\n",
       "      <td>8.253175</td>\n",
       "      <td>2.101136</td>\n",
       "      <td>6.698482</td>\n",
       "      <td>1.367674</td>\n",
       "      <td>0.160623</td>\n",
       "      <td>0.037041</td>\n",
       "      <td>-0.597264</td>\n",
       "      <td>0.766954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Out of time Split</td>\n",
       "      <td>1</td>\n",
       "      <td>2.528086</td>\n",
       "      <td>0.322334</td>\n",
       "      <td>2.073496</td>\n",
       "      <td>0.277885</td>\n",
       "      <td>0.047332</td>\n",
       "      <td>0.005752</td>\n",
       "      <td>0.835623</td>\n",
       "      <td>0.043083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Out of time Split</td>\n",
       "      <td>7</td>\n",
       "      <td>3.323953</td>\n",
       "      <td>0.312566</td>\n",
       "      <td>2.721097</td>\n",
       "      <td>0.231370</td>\n",
       "      <td>0.062352</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.716581</td>\n",
       "      <td>0.051156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Out of time Split</td>\n",
       "      <td>14</td>\n",
       "      <td>2.789270</td>\n",
       "      <td>0.174971</td>\n",
       "      <td>2.337312</td>\n",
       "      <td>0.191169</td>\n",
       "      <td>0.054238</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.793663</td>\n",
       "      <td>0.025788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>1</td>\n",
       "      <td>1.547631</td>\n",
       "      <td>0.107179</td>\n",
       "      <td>1.209918</td>\n",
       "      <td>0.080420</td>\n",
       "      <td>0.028032</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.952184</td>\n",
       "      <td>0.006795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>7</td>\n",
       "      <td>2.037267</td>\n",
       "      <td>0.140557</td>\n",
       "      <td>1.620816</td>\n",
       "      <td>0.110028</td>\n",
       "      <td>0.037983</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.915441</td>\n",
       "      <td>0.012742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>14</td>\n",
       "      <td>2.042778</td>\n",
       "      <td>0.199961</td>\n",
       "      <td>1.615116</td>\n",
       "      <td>0.173376</td>\n",
       "      <td>0.037765</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.912487</td>\n",
       "      <td>0.018175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Time Series Split</td>\n",
       "      <td>1</td>\n",
       "      <td>3.601535</td>\n",
       "      <td>2.059450</td>\n",
       "      <td>2.844490</td>\n",
       "      <td>1.707720</td>\n",
       "      <td>0.066575</td>\n",
       "      <td>0.040200</td>\n",
       "      <td>0.681299</td>\n",
       "      <td>0.346980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Time Series Split</td>\n",
       "      <td>7</td>\n",
       "      <td>6.575463</td>\n",
       "      <td>3.260244</td>\n",
       "      <td>5.039080</td>\n",
       "      <td>2.308463</td>\n",
       "      <td>0.116744</td>\n",
       "      <td>0.050230</td>\n",
       "      <td>-0.019110</td>\n",
       "      <td>0.936444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chemical + Feature Engineering</td>\n",
       "      <td>BidirectionalGRU</td>\n",
       "      <td>Time Series Split</td>\n",
       "      <td>14</td>\n",
       "      <td>4.244235</td>\n",
       "      <td>1.762650</td>\n",
       "      <td>3.407007</td>\n",
       "      <td>1.434067</td>\n",
       "      <td>0.079290</td>\n",
       "      <td>0.031280</td>\n",
       "      <td>0.591086</td>\n",
       "      <td>0.335942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Features             Model  \\\n",
       "                                                       \n",
       "0   Chemical + Feature Engineering  BidirectionalGRU   \n",
       "1   Chemical + Feature Engineering  BidirectionalGRU   \n",
       "2   Chemical + Feature Engineering  BidirectionalGRU   \n",
       "3   Chemical + Feature Engineering  BidirectionalGRU   \n",
       "4   Chemical + Feature Engineering  BidirectionalGRU   \n",
       "5   Chemical + Feature Engineering  BidirectionalGRU   \n",
       "6   Chemical + Feature Engineering  BidirectionalGRU   \n",
       "7   Chemical + Feature Engineering  BidirectionalGRU   \n",
       "8   Chemical + Feature Engineering  BidirectionalGRU   \n",
       "9   Chemical + Feature Engineering  BidirectionalGRU   \n",
       "10  Chemical + Feature Engineering  BidirectionalGRU   \n",
       "\n",
       "              Cross Validation Timesteps RMSE Test            MAE Test  \\\n",
       "                                              mean       std      mean   \n",
       "0   Blocking Time Series Split         1  6.527176  2.623622  5.108403   \n",
       "1   Blocking Time Series Split         7  8.253175  2.101136  6.698482   \n",
       "2            Out of time Split         1  2.528086  0.322334  2.073496   \n",
       "3            Out of time Split         7  3.323953  0.312566  2.721097   \n",
       "4            Out of time Split        14  2.789270  0.174971  2.337312   \n",
       "5               Repeated KFold         1  1.547631  0.107179  1.209918   \n",
       "6               Repeated KFold         7  2.037267  0.140557  1.620816   \n",
       "7               Repeated KFold        14  2.042778  0.199961  1.615116   \n",
       "8            Time Series Split         1  3.601535  2.059450  2.844490   \n",
       "9            Time Series Split         7  6.575463  3.260244  5.039080   \n",
       "10           Time Series Split        14  4.244235  1.762650  3.407007   \n",
       "\n",
       "             MAPE Test             R2 Test            \n",
       "         std      mean       std      mean       std  \n",
       "0   2.166673  0.112813  0.043884  0.084968  0.562239  \n",
       "1   1.367674  0.160623  0.037041 -0.597264  0.766954  \n",
       "2   0.277885  0.047332  0.005752  0.835623  0.043083  \n",
       "3   0.231370  0.062352  0.004387  0.716581  0.051156  \n",
       "4   0.191169  0.054238  0.004357  0.793663  0.025788  \n",
       "5   0.080420  0.028032  0.002018  0.952184  0.006795  \n",
       "6   0.110028  0.037983  0.002901  0.915441  0.012742  \n",
       "7   0.173376  0.037765  0.004248  0.912487  0.018175  \n",
       "8   1.707720  0.066575  0.040200  0.681299  0.346980  \n",
       "9   2.308463  0.116744  0.050230 -0.019110  0.936444  \n",
       "10  1.434067  0.079290  0.031280  0.591086  0.335942  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Timesteps\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_formatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Timesteps\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat(results_to_save).reset_index().groupby(\n",
    "    [\"Features\", \"Model\", \"Cross Validation\", \"Timesteps\"], dropna=False\n",
    ")[[\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]].agg(\n",
    "    [\"mean\", lambda series: pd.Series(series.std(ddof=0), name=\"std\")]\n",
    ").reset_index().rename(\n",
    "    columns={\"<lambda_0>\": \"std\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b96e153",
   "metadata": {
    "papermill": {
     "duration": 0.018327,
     "end_time": "2024-03-01T10:32:57.450367",
     "exception": false,
     "start_time": "2024-03-01T10:32:57.432040",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Saving the results Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca24eba",
   "metadata": {
    "papermill": {
     "duration": 0.017717,
     "end_time": "2024-03-01T10:32:57.487914",
     "exception": false,
     "start_time": "2024-03-01T10:32:57.470197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Saving the full dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d049b1fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T10:32:57.522074Z",
     "iopub.status.busy": "2024-03-01T10:32:57.521192Z",
     "iopub.status.idle": "2024-03-01T10:32:57.544807Z",
     "shell.execute_reply": "2024-03-01T10:32:57.543386Z"
    },
    "papermill": {
     "duration": 0.043623,
     "end_time": "2024-03-01T10:32:57.547589",
     "exception": false,
     "start_time": "2024-03-01T10:32:57.503966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"path = \\\"../../../../../reports/results/local_models/209/n/full/\\\"\\nfilename = f\\\"BidirectionalGRU_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = \\\"../../../../../reports/results/local_models/209/n/full/\\\"\\nfilename = f\\\"BidirectionalGRU_results_full_{index_to_save}.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"../../../../../reports/results/local_models/209/n/full/\"\n",
    "filename = f\"BidirectionalGRU_results_full_{index_to_save}.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e0d4dda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T10:32:57.585869Z",
     "iopub.status.busy": "2024-03-01T10:32:57.585402Z",
     "iopub.status.idle": "2024-03-01T10:32:57.642556Z",
     "shell.execute_reply": "2024-03-01T10:32:57.641192Z"
    },
    "papermill": {
     "duration": 0.075615,
     "end_time": "2024-03-01T10:32:57.644821",
     "exception": false,
     "start_time": "2024-03-01T10:32:57.569206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"cols_groupby = [\\n    \\\"Category\\\",\\n    \\\"Company\\\",\\n    \\\"Data Shape\\\",\\n    \\\"Timesteps\\\",\\n    \\\"Features\\\",\\n    \\\"Model\\\",\\n    \\\"Cross Validation\\\",\\n    \\\"Cross Validation Params\\\",\\n]\\n\\ncols_agg = [\\\"RMSE Train\\\", \\\"MAE Train\\\", \\\"MAPE Train\\\", \\\"R2 Train\\\"] + [\\n    \\\"RMSE Test\\\",\\n    \\\"MAE Test\\\",\\n    \\\"MAPE Test\\\",\\n    \\\"R2 Test\\\",\\n]\\n\\npath = \\\"../../../../../reports/results/local_models/209/n/grouped/\\\"\\nfilename = f\\\"BidirectionalGRU_results_grouped_{index_to_save}.csv\\\"\\n\\n\\ndf_results_to_save = (\\n    pd.concat(results_to_save)\\n    .groupby(cols_groupby, dropna=False)[cols_agg]\\n    .agg([\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")])\\n    .reset_index()\\n    .rename(columns={\\\"<lambda_0>\\\": \\\"std\\\"})\\n)\\n\\ndf_results_to_save.to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"cols_groupby = [\\n    \\\"Category\\\",\\n    \\\"Company\\\",\\n    \\\"Data Shape\\\",\\n    \\\"Timesteps\\\",\\n    \\\"Features\\\",\\n    \\\"Model\\\",\\n    \\\"Cross Validation\\\",\\n    \\\"Cross Validation Params\\\",\\n]\\n\\ncols_agg = [\\\"RMSE Train\\\", \\\"MAE Train\\\", \\\"MAPE Train\\\", \\\"R2 Train\\\"] + [\\n    \\\"RMSE Test\\\",\\n    \\\"MAE Test\\\",\\n    \\\"MAPE Test\\\",\\n    \\\"R2 Test\\\",\\n]\\n\\npath = \\\"../../../../../reports/results/local_models/209/n/grouped/\\\"\\nfilename = f\\\"BidirectionalGRU_results_grouped_{index_to_save}.csv\\\"\\n\\n\\ndf_results_to_save = (\\n    pd.concat(results_to_save)\\n    .groupby(cols_groupby, dropna=False)[cols_agg]\\n    .agg([\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")])\\n    .reset_index()\\n    .rename(columns={\\\"<lambda_0>\\\": \\\"std\\\"})\\n)\\n\\ndf_results_to_save.to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols_groupby = [\n",
    "    \"Category\",\n",
    "    \"Company\",\n",
    "    \"Data Shape\",\n",
    "    \"Timesteps\",\n",
    "    \"Features\",\n",
    "    \"Model\",\n",
    "    \"Cross Validation\",\n",
    "    \"Cross Validation Params\",\n",
    "]\n",
    "\n",
    "cols_agg = [\"RMSE Train\", \"MAE Train\", \"MAPE Train\", \"R2 Train\"] + [\n",
    "    \"RMSE Test\",\n",
    "    \"MAE Test\",\n",
    "    \"MAPE Test\",\n",
    "    \"R2 Test\",\n",
    "]\n",
    "\n",
    "path = \"../../../../../reports/results/local_models/209/n/grouped/\"\n",
    "filename = f\"BidirectionalGRU_results_grouped_{index_to_save}.csv\"\n",
    "\n",
    "\n",
    "df_results_to_save = (\n",
    "    pd.concat(results_to_save)\n",
    "    .groupby(cols_groupby, dropna=False)[cols_agg]\n",
    "    .agg([\"mean\", lambda series: pd.Series(series.std(ddof=0), name=\"std\")])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"<lambda_0>\": \"std\"})\n",
    ")\n",
    "\n",
    "df_results_to_save.to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bea70c",
   "metadata": {
    "papermill": {
     "duration": 0.016944,
     "end_time": "2024-03-01T10:32:57.678173",
     "exception": false,
     "start_time": "2024-03-01T10:32:57.661229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4164.320315,
   "end_time": "2024-03-01T10:33:00.334621",
   "environment_variables": {},
   "exception": null,
   "input_path": "/home/peressim/projects/ccs28-ml-modelling/notebooks/modelling/209/bi-gru/n/chemical-mineralogical-feature_engineering-ds.ipynb",
   "output_path": "/home/peressim/projects/ccs28-ml-modelling/notebooks/modelling/209/bi-gru/n/chemical-mineralogical-feature_engineering-ds.ipynb",
   "parameters": {},
   "start_time": "2024-03-01T09:23:36.014306",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}