{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from src.utils.time_series_procs import split_sequences\n",
    "from src.models.transformer_ts_tf import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler3DShape:\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        X_new = self.scaler.fit_transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)\n",
    "        return X_new\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_new = X.reshape(-1, X.shape[-1])\n",
    "        self.scaler.fit(X_new)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_new = self.scaler.transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline_model(\n",
    "    num_features, time_steps, num_heads=2, num_layers_enc=1, num_feed_forward=32\n",
    "):\n",
    "    model = Transformer(\n",
    "        num_hid=num_features,\n",
    "        time_steps=time_steps,\n",
    "        num_head=num_heads,\n",
    "        num_layers_enc=num_layers_enc,\n",
    "        num_feed_forward=num_feed_forward,\n",
    "    )\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=\"mse\",\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_repeated_time_series_k_fold(\n",
    "    x,\n",
    "    y,\n",
    "    train_period,\n",
    "    test_period,\n",
    "    repeats=10,\n",
    "    show_individual_results=True,\n",
    "    show_final_result=True,\n",
    "):\n",
    "    results = []\n",
    "    max_samples = x.shape[0]\n",
    "\n",
    "    for _ in range(repeats):\n",
    "        i = 0\n",
    "        scores = []\n",
    "        for _ in range(0, max_samples // train_period):\n",
    "            x_train = x[i : i + train_period]\n",
    "            y_train = y[i : i + train_period]\n",
    "            x_test = x[i + train_period : i + train_period + test_period]\n",
    "            y_test = y[i + train_period : i + train_period + test_period]\n",
    "            i += train_period\n",
    "            x_train = scaler.fit_transform(\n",
    "                x_train.reshape(-1, x_train.shape[-1])\n",
    "            ).reshape(x_train.shape)\n",
    "            x_test = scaler.transform(x_test.reshape(-1, x_test.shape[-1])).reshape(\n",
    "                x_test.shape\n",
    "            )\n",
    "            model = get_baseline_model(\n",
    "                num_features=x_train.shape[-1], time_steps=x_train.shape[-2]\n",
    "            )\n",
    "            model.fit(x_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "            rmse = model.evaluate(x_test, y_test, verbose=0)\n",
    "            scores.append(rmse[1])\n",
    "        results.append(scores)\n",
    "        if show_individual_results:\n",
    "            print(\"RMSE: %.3f (%.3f)\" % (np.mean(scores), np.std(scores)))\n",
    "    if show_final_result:\n",
    "        print(\"\\nRMSE: %.3f (%.3f)\" % (np.mean(results), np.std(results)))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timesteps_repeated_time_series_k_fold(\n",
    "    df, train_period, test_period, repeats=10, timesteps_list=[3], show_results=True\n",
    "):\n",
    "    results = {}\n",
    "\n",
    "    for timesteps in timesteps_list:\n",
    "        x, y = split_sequences(df.values, timesteps)\n",
    "        scores = make_repeated_time_series_k_fold(\n",
    "            x,\n",
    "            y,\n",
    "            train_period,\n",
    "            test_period,\n",
    "            repeats=10,\n",
    "            show_individual_results=False,\n",
    "            show_final_result=False,\n",
    "        )\n",
    "        results[timesteps] = scores\n",
    "        if show_results:\n",
    "            print(\n",
    "                \"TIMESTEPS: %d RMSE: %.3f (%.3f)\"\n",
    "                % (timesteps, np.mean(scores), np.std(scores))\n",
    "            )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Disable Tensorflow Warnings</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../../../data/interim/partner_iii/Dati CADD 2020-2022_with_fillna.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 47\n",
    "scaler = StandardScaler()\n",
    "\n",
    "timesteps_list = [1, 3, 5, 7, 10, 15, 20]\n",
    "repeats = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs:\n",
    "\n",
    "1. TIMESTEPS: [1, 3, 5, 7, 10, 15, 20]\n",
    "\n",
    "2. Epochs: 100\n",
    "\n",
    "3. Batch size: 32\n",
    "\n",
    "4. num heads: 2\n",
    "\n",
    "5. FF Layers enc: 1\n",
    "\n",
    "      5.1 Units 32\n",
    "\n",
    "6. Optimization Algorithm: Adam\n",
    "    \n",
    "    6.1. Learning Rate: 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Times Series Repeated KFold Cross validation - different Timesteps values\n",
    "\n",
    "Here we will make a Times Series KFold Cross validation. We are using the Blocking Time Series Split method. And with timeseries Split method. We also do it with different number of timesteps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Time Series Repeated KFold Cross Validation with vary timesteps</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Experiment 1</h4>\n",
    "    \n",
    "<b>Train 80 of that data and test with 20%</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_period = 200\n",
    "test_period = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f29bc1da488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f29a46c4f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "TIMESTEPS: 1 RMSE: 5.847 (0.762)\n",
      "TIMESTEPS: 3 RMSE: 6.162 (1.411)\n",
      "TIMESTEPS: 5 RMSE: 6.423 (2.168)\n",
      "TIMESTEPS: 7 RMSE: 6.843 (2.526)\n",
      "TIMESTEPS: 10 RMSE: 7.304 (2.746)\n",
      "TIMESTEPS: 15 RMSE: 6.759 (1.909)\n",
      "TIMESTEPS: 20 RMSE: 7.077 (2.336)\n"
     ]
    }
   ],
   "source": [
    "results = make_timesteps_repeated_time_series_k_fold(\n",
    "    df, train_period, test_period, repeats, timesteps_list, True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ccs28-venv)",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
