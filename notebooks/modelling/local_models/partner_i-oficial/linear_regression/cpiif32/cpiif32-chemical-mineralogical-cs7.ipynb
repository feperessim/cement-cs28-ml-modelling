{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Plotting\\nimport matplotlib.pyplot as plt\\n\\n# Processing results\\nimport json\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.model_selection import TimeSeriesSplit\\nfrom sklearn.model_selection import RepeatedKFold\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.model_selection import cross_validate\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\n# Modeling\\nfrom sklearn.linear_model import LinearRegression\\n\\n# Preprocessing - Data standardization\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Metrics\\nfrom sklearn.metrics import mean_squared_error\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.metrics import mean_absolute_percentage_error\\nfrom sklearn.metrics import r2_score\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Plotting\\nimport matplotlib.pyplot as plt\\n\\n# Processing results\\nimport json\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.model_selection import TimeSeriesSplit\\nfrom sklearn.model_selection import RepeatedKFold\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.model_selection import cross_validate\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\\n\\n# Modeling\\nfrom sklearn.linear_model import LinearRegression\\n\\n# Preprocessing - Data standardization\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Metrics\\nfrom sklearn.metrics import mean_squared_error\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.metrics import mean_absolute_percentage_error\\nfrom sklearn.metrics import r2_score\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Processing results\n",
    "import json\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict\n",
    "\n",
    "# Modeling\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Preprocessing - Data standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Local Model\\\",\\n    \\\"Company\\\": \\\"partner_i\\\",\\n    \\\"Features\\\": \\\"Chemical + Mineralogical + CS7\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"Linear Regression\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Local Model\\\",\\n    \\\"Company\\\": \\\"partner_i\\\",\\n    \\\"Features\\\": \\\"Chemical + Mineralogical + CS7\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"Linear Regression\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Local Model\",\n",
    "    \"Company\": \"partner_i\",\n",
    "    \"Features\": \"Chemical + Mineralogical + CS7\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"Linear Regression\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../data/processed/partner_i-Oficial/cpiif32.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../data/processed/partner_i-Oficial/cpiif32.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../data/processed/partner_i-Oficial/cpiif32.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"df_copy = df.drop(\\n    [\\n        # Properties\\n        \\\"Blaine\\\",\\n        \\\"Initial setting time\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Density\\\",\\n        \\\"#200\\\",\\n        \\\"#325\\\",\\n        \\\"CS3\\\",       \\n       \\n        # Chemical Composition\\n        # Reason: Loss on Ignition is the only feature\\n        # that belongs to chemical composition in which was \\n        # measured by a different method, namely manual\\n        \\\"LOI\\\"\\n    ],\\n    axis=1,\\n).copy()\";\n",
       "                var nbb_formatted_code = \"df_copy = df.drop(\\n    [\\n        # Properties\\n        \\\"Blaine\\\",\\n        \\\"Initial setting time\\\",\\n        \\\"Final setting time\\\",\\n        \\\"Density\\\",\\n        \\\"#200\\\",\\n        \\\"#325\\\",\\n        \\\"CS3\\\",\\n        # Chemical Composition\\n        # Reason: Loss on Ignition is the only feature\\n        # that belongs to chemical composition in which was\\n        # measured by a different method, namely manual\\n        \\\"LOI\\\",\\n    ],\\n    axis=1,\\n).copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.drop(\n",
    "    [\n",
    "        # Properties\n",
    "        \"Blaine\",\n",
    "        \"Initial setting time\",\n",
    "        \"Final setting time\",\n",
    "        \"Density\",\n",
    "        \"#200\",\n",
    "        \"#325\",\n",
    "        \"CS3\",       \n",
    "       \n",
    "        # Chemical Composition\n",
    "        # Reason: Loss on Ignition is the only feature\n",
    "        # that belongs to chemical composition in which was \n",
    "        # measured by a different method, namely manual\n",
    "        \"LOI\"\n",
    "    ],\n",
    "    axis=1,\n",
    ").copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Repeated KFold Cross validation\n",
    "\n",
    "<b>Dataset shape:</b> (410, 37)<br>\n",
    "<b>Repeats:</b>10<br>\n",
    "<b>Splits:</b>5<br>\n",
    "    1. 5 folds of 246 samples each\n",
    "    2. 80% train (988 samples each fold)\n",
    "    3. 20% test (246 samples each fold)\n",
    "<b>Total:</b> 100 models<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated Cross Validation:\n",
      "Repeats: 3\n",
      "n_splits: 5\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: -0.703 (0.012)\n",
      "MAE: -0.549 (0.012)\n",
      "MAPE: -0.015 (0.000)\n",
      "R2: 0.588 (0.022)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: -0.787 (0.055)\n",
      "MAE: -0.616 (0.042)\n",
      "MAPE: -0.017 (0.001)\n",
      "R2: 0.463 (0.123)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"repeats = 3\\nn_splits = 5\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", LinearRegression()),\\n    ]\\n)\\ncv = RepeatedKFold(n_splits=n_splits, n_repeats=repeats, random_state=SEED)\\nscores = cross_validate(\\n    pipeline,\\n    x,\\n    y,\\n    scoring=METRICS,\\n    cv=cv,\\n    n_jobs=-1,\\n    return_train_score=True,\\n)\\nprint(\\\"Repeated Cross Validation:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Repeated KFold\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\";\n",
       "                var nbb_formatted_code = \"repeats = 3\\nn_splits = 5\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", LinearRegression()),\\n    ]\\n)\\ncv = RepeatedKFold(n_splits=n_splits, n_repeats=repeats, random_state=SEED)\\nscores = cross_validate(\\n    pipeline,\\n    x,\\n    y,\\n    scoring=METRICS,\\n    cv=cv,\\n    n_jobs=-1,\\n    return_train_score=True,\\n)\\nprint(\\\"Repeated Cross Validation:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Repeated KFold\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "repeats = 3\n",
    "n_splits = 5\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", LinearRegression()),\n",
    "    ]\n",
    ")\n",
    "cv = RepeatedKFold(n_splits=n_splits, n_repeats=repeats, random_state=SEED)\n",
    "scores = cross_validate(\n",
    "    pipeline,\n",
    "    x,\n",
    "    y,\n",
    "    scoring=METRICS,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    ")\n",
    "print(\"Repeated Cross Validation:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"n_splits: {n_splits}\")\n",
    "print()\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Repeated KFold\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"N_Splits\": 5, \"Repeats\": 3}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Blocking Time Series Cross Validation\n",
    "\n",
    "<b>Dataset shape:</b> (410, 37)<br>\n",
    "<b>Splits:</b>5<br>    \n",
    "    1. 5 folds of 246 samples\n",
    "    2. 50% train (123 samples each fold)\n",
    "    3. 50% test (123 samples each fold)\n",
    "<b>Total:</b> 5 models<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocking Time Series Split:\n",
      "Repeats: 3\n",
      "n_splits: 5\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: -0.488 (0.078)\n",
      "MAE: -0.389 (0.059)\n",
      "MAPE: -0.011 (0.002)\n",
      "R2: 0.777 (0.056)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: -0.999 (0.327)\n",
      "MAE: -0.744 (0.179)\n",
      "MAPE: -0.020 (0.005)\n",
      "R2: -0.353 (0.653)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"n_splits = 5\\ntrain_size = 0.8\\n\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", LinearRegression()),\\n    ]\\n)\\ncv = BlockingTimeSeriesSplit(n_splits=n_splits, train_size=train_size)\\nscores = cross_validate(\\n    pipeline,\\n    x,\\n    y,\\n    scoring=METRICS,\\n    cv=cv,\\n    n_jobs=-1,\\n    return_train_score=True,\\n)\\nprint(\\\"Blocking Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Blocking Time Series Split\\\"\\nresults_dict_copy[\\n    \\\"Cross Validation Params\\\"\\n] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 1, \\\"train_size\\\": 0.8}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\";\n",
       "                var nbb_formatted_code = \"n_splits = 5\\ntrain_size = 0.8\\n\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", LinearRegression()),\\n    ]\\n)\\ncv = BlockingTimeSeriesSplit(n_splits=n_splits, train_size=train_size)\\nscores = cross_validate(\\n    pipeline,\\n    x,\\n    y,\\n    scoring=METRICS,\\n    cv=cv,\\n    n_jobs=-1,\\n    return_train_score=True,\\n)\\nprint(\\\"Blocking Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Blocking Time Series Split\\\"\\nresults_dict_copy[\\n    \\\"Cross Validation Params\\\"\\n] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 1, \\\"train_size\\\": 0.8}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_splits = 5\n",
    "train_size = 0.8\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", LinearRegression()),\n",
    "    ]\n",
    ")\n",
    "cv = BlockingTimeSeriesSplit(n_splits=n_splits, train_size=train_size)\n",
    "scores = cross_validate(\n",
    "    pipeline,\n",
    "    x,\n",
    "    y,\n",
    "    scoring=METRICS,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    ")\n",
    "print(\"Blocking Time Series Split:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"n_splits: {n_splits}\")\n",
    "print()\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Blocking Time Series Split\"\n",
    "results_dict_copy[\n",
    "    \"Cross Validation Params\"\n",
    "] = '{\"N_Splits\": 5, \"Repeats\": 1, \"train_size\": 0.8}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Time Series Split Cross Validation\n",
    "\n",
    "The training set has size i * n_samples // (n_splits + 1) + n_samples % (n_splits + 1) in the i th split, with a test set of size n_samples//(n_splits + 1) by default, where n_samples is the number of samples.\n",
    "\n",
    "\n",
    "<b>Dataset shape:</b> (410, 37)<br>\n",
    "<b>Splits:</b>10<br>    \n",
    "    1. Train: 10 folds of 40, 77, 114, 152, 189, 226, 263, 301, 338 samples each fold\n",
    "    2. Test: 37 samples each fold\n",
    "<b>Total:</b> 10 models<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series Split:\n",
      "Repeats: 3\n",
      "n_splits: 5\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: -0.617 (0.062)\n",
      "MAE: -0.478 (0.048)\n",
      "MAPE: -0.013 (0.001)\n",
      "R2: 0.669 (0.065)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: -1.255 (0.549)\n",
      "MAE: -0.825 (0.101)\n",
      "MAPE: -0.023 (0.003)\n",
      "R2: -1.135 (2.632)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"n_splits = 5\\ngap = 0\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", LinearRegression()),\\n    ]\\n)\\ncv = TimeSeriesSplit(gap=gap, max_train_size=None, n_splits=n_splits, test_size=None)\\n\\nscores = cross_validate(\\n    pipeline,\\n    x,\\n    y,\\n    scoring=METRICS,\\n    cv=cv,\\n    n_jobs=-1,\\n    return_train_score=True,\\n)\\nprint(\\\"Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Time Series Split\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 1, \\\"Gap\\\": 0}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\";\n",
       "                var nbb_formatted_code = \"n_splits = 5\\ngap = 0\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", LinearRegression()),\\n    ]\\n)\\ncv = TimeSeriesSplit(gap=gap, max_train_size=None, n_splits=n_splits, test_size=None)\\n\\nscores = cross_validate(\\n    pipeline,\\n    x,\\n    y,\\n    scoring=METRICS,\\n    cv=cv,\\n    n_jobs=-1,\\n    return_train_score=True,\\n)\\nprint(\\\"Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Time Series Split\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 1, \\\"Gap\\\": 0}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_splits = 5\n",
    "gap = 0\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", LinearRegression()),\n",
    "    ]\n",
    ")\n",
    "cv = TimeSeriesSplit(gap=gap, max_train_size=None, n_splits=n_splits, test_size=None)\n",
    "\n",
    "scores = cross_validate(\n",
    "    pipeline,\n",
    "    x,\n",
    "    y,\n",
    "    scoring=METRICS,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    ")\n",
    "print(\"Time Series Split:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"n_splits: {n_splits}\")\n",
    "print()\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Time Series Split\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"N_Splits\": 5, \"Repeats\": 1, \"Gap\": 0}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Out of time Split Cross Validation\n",
    "\n",
    "<b>Dataset shape:</b> (410, 37)<br>\n",
    "<b>Train size: 80%</b><br>\n",
    "<b>Test  size: 20%</b>\n",
    "\n",
    "\n",
    "<b>Splits:</b> 2<br>    \n",
    "    1. Train: 328\n",
    "    2. Test: 82\n",
    "<b>Total:</b> 1 model<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 0.690 (0.000)\n",
      "MAE: 0.533 (0.000)\n",
      "MAPE: 0.015 (0.000)\n",
      "R2: 0.626 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 0.873 (0.000)\n",
      "MAE: 0.734 (0.000)\n",
      "MAPE: 0.020 (0.000)\n",
      "R2: 0.087 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"test_size = 0.2\\n\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=test_size, random_state=SEED, shuffle=False\\n)\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", LinearRegression()),\\n    ]\\n)\\n\\npipeline.fit(x_train, y_train)\\n\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\n\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time Split\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"Test Size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(\\n    results_dict_copy, {key: [value] for key, value in scores.items()}\\n)\\nresults_to_save.append(df_results)\";\n",
       "                var nbb_formatted_code = \"test_size = 0.2\\n\\nx_train, x_test, y_train, y_test = train_test_split(\\n    x, y, test_size=test_size, random_state=SEED, shuffle=False\\n)\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", LinearRegression()),\\n    ]\\n)\\n\\npipeline.fit(x_train, y_train)\\n\\ny_train_pred = pipeline.predict(x_train)\\ny_test_pred = pipeline.predict(x_test)\\n\\nscores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time Split\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"Test Size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(\\n    results_dict_copy, {key: [value] for key, value in scores.items()}\\n)\\nresults_to_save.append(df_results)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_size = 0.2\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=test_size, random_state=SEED, shuffle=False\n",
    ")\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", LinearRegression()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred = pipeline.predict(x_train)\n",
    "y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time Split\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"Test Size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "df_results = fill_results_dict(\n",
    "    results_dict_copy, {key: [value] for key, value in scores.items()}\n",
    ")\n",
    "results_to_save.append(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RMSE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAPE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R2 Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chemical + Mineralogical + CS7</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Blocking Time Series Split</td>\n",
       "      <td>{\"N_Splits\": 5, \"Repeats\": 1, \"train_size\": 0.8}</td>\n",
       "      <td>0.999130</td>\n",
       "      <td>0.326906</td>\n",
       "      <td>0.743743</td>\n",
       "      <td>0.178536</td>\n",
       "      <td>0.020031</td>\n",
       "      <td>0.004643</td>\n",
       "      <td>-0.352541</td>\n",
       "      <td>0.653300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chemical + Mineralogical + CS7</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Out of time Split</td>\n",
       "      <td>{\"Test Size\": 0.2}</td>\n",
       "      <td>0.872652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.733607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086545</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chemical + Mineralogical + CS7</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>{\"N_Splits\": 5, \"Repeats\": 3}</td>\n",
       "      <td>0.787350</td>\n",
       "      <td>0.054681</td>\n",
       "      <td>0.616168</td>\n",
       "      <td>0.041767</td>\n",
       "      <td>0.016779</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.462901</td>\n",
       "      <td>0.122543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chemical + Mineralogical + CS7</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Time Series Split</td>\n",
       "      <td>{\"N_Splits\": 5, \"Repeats\": 1, \"Gap\": 0}</td>\n",
       "      <td>1.255252</td>\n",
       "      <td>0.548562</td>\n",
       "      <td>0.825206</td>\n",
       "      <td>0.101005</td>\n",
       "      <td>0.022503</td>\n",
       "      <td>0.002729</td>\n",
       "      <td>-1.134680</td>\n",
       "      <td>2.631911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Features              Model  \\\n",
       "                                                       \n",
       "0  Chemical + Mineralogical + CS7  Linear Regression   \n",
       "1  Chemical + Mineralogical + CS7  Linear Regression   \n",
       "2  Chemical + Mineralogical + CS7  Linear Regression   \n",
       "3  Chemical + Mineralogical + CS7  Linear Regression   \n",
       "\n",
       "             Cross Validation  \\\n",
       "                                \n",
       "0  Blocking Time Series Split   \n",
       "1           Out of time Split   \n",
       "2              Repeated KFold   \n",
       "3           Time Series Split   \n",
       "\n",
       "                            Cross Validation Params RMSE Test            \\\n",
       "                                                         mean       std   \n",
       "0  {\"N_Splits\": 5, \"Repeats\": 1, \"train_size\": 0.8}  0.999130  0.326906   \n",
       "1                                {\"Test Size\": 0.2}  0.872652  0.000000   \n",
       "2                     {\"N_Splits\": 5, \"Repeats\": 3}  0.787350  0.054681   \n",
       "3           {\"N_Splits\": 5, \"Repeats\": 1, \"Gap\": 0}  1.255252  0.548562   \n",
       "\n",
       "   MAE Test           MAPE Test             R2 Test            \n",
       "       mean       std      mean       std      mean       std  \n",
       "0  0.743743  0.178536  0.020031  0.004643 -0.352541  0.653300  \n",
       "1  0.733607  0.000000  0.019887  0.000000  0.086545  0.000000  \n",
       "2  0.616168  0.041767  0.016779  0.001117  0.462901  0.122543  \n",
       "3  0.825206  0.101005  0.022503  0.002729 -1.134680  2.631911  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"pd.concat(results_to_save).groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Cross Validation Params\\\"]\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_formatted_code = \"pd.concat(results_to_save).groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Cross Validation Params\\\"]\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat(results_to_save).groupby(\n",
    "    [\"Features\", \"Model\", \"Cross Validation\", \"Cross Validation Params\"]\n",
    ")[[\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]].agg(\n",
    "    [\"mean\", lambda series: pd.Series(series.std(ddof=0), name=\"std\")]\n",
    ").reset_index().rename(\n",
    "    columns={\"<lambda_0>\": \"std\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"path = \\\"../../../../../reports/results/local_models/partner_i-oficial/cpiif32/full/\\\"\\nfilename = \\\"linear_regression_results_full_4.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = \\\"../../../../../reports/results/local_models/partner_i-oficial/cpiif32/full/\\\"\\nfilename = \\\"linear_regression_results_full_4.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"../../../../../reports/results/local_models/partner_i-oficial/cpiif32/full/\"\n",
    "filename = \"linear_regression_results_full_4.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the grouped dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"cols_groupby = [\\n    \\\"Category\\\",\\n    \\\"Company\\\",\\n    \\\"Data Shape\\\",\\n    \\\"Timesteps\\\",\\n    \\\"Features\\\",\\n    \\\"Model\\\",\\n    \\\"Cross Validation\\\",\\n    \\\"Cross Validation Params\\\",\\n]\\n\\ncols_agg = [\\\"RMSE Train\\\", \\\"MAE Train\\\", \\\"MAPE Train\\\", \\\"R2 Train\\\"] + [\\n    \\\"RMSE Test\\\",\\n    \\\"MAE Test\\\",\\n    \\\"MAPE Test\\\",\\n    \\\"R2 Test\\\",\\n]\\n\\npath = \\\"../../../../../reports/results/local_models/partner_i-oficial/cpiif32/grouped/\\\"\\nfilename = \\\"linear_regression_results_grouped_4.csv\\\"\\n\\n\\ndf_results_to_save = (\\n    pd.concat(results_to_save)\\n    .groupby(cols_groupby, dropna=False)[cols_agg]\\n    .agg([\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")])\\n    .reset_index()\\n    .rename(columns={\\\"<lambda_0>\\\": \\\"std\\\"})\\n)\\n\\ndf_results_to_save.to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"cols_groupby = [\\n    \\\"Category\\\",\\n    \\\"Company\\\",\\n    \\\"Data Shape\\\",\\n    \\\"Timesteps\\\",\\n    \\\"Features\\\",\\n    \\\"Model\\\",\\n    \\\"Cross Validation\\\",\\n    \\\"Cross Validation Params\\\",\\n]\\n\\ncols_agg = [\\\"RMSE Train\\\", \\\"MAE Train\\\", \\\"MAPE Train\\\", \\\"R2 Train\\\"] + [\\n    \\\"RMSE Test\\\",\\n    \\\"MAE Test\\\",\\n    \\\"MAPE Test\\\",\\n    \\\"R2 Test\\\",\\n]\\n\\npath = \\\"../../../../../reports/results/local_models/partner_i-oficial/cpiif32/grouped/\\\"\\nfilename = \\\"linear_regression_results_grouped_4.csv\\\"\\n\\n\\ndf_results_to_save = (\\n    pd.concat(results_to_save)\\n    .groupby(cols_groupby, dropna=False)[cols_agg]\\n    .agg([\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")])\\n    .reset_index()\\n    .rename(columns={\\\"<lambda_0>\\\": \\\"std\\\"})\\n)\\n\\ndf_results_to_save.to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols_groupby = [\n",
    "    \"Category\",\n",
    "    \"Company\",\n",
    "    \"Data Shape\",\n",
    "    \"Timesteps\",\n",
    "    \"Features\",\n",
    "    \"Model\",\n",
    "    \"Cross Validation\",\n",
    "    \"Cross Validation Params\",\n",
    "]\n",
    "\n",
    "cols_agg = [\"RMSE Train\", \"MAE Train\", \"MAPE Train\", \"R2 Train\"] + [\n",
    "    \"RMSE Test\",\n",
    "    \"MAE Test\",\n",
    "    \"MAPE Test\",\n",
    "    \"R2 Test\",\n",
    "]\n",
    "\n",
    "path = \"../../../../../reports/results/local_models/partner_i-oficial/cpiif32/grouped/\"\n",
    "filename = \"linear_regression_results_grouped_4.csv\"\n",
    "\n",
    "\n",
    "df_results_to_save = (\n",
    "    pd.concat(results_to_save)\n",
    "    .groupby(cols_groupby, dropna=False)[cols_agg]\n",
    "    .agg([\"mean\", lambda series: pd.Series(series.std(ddof=0), name=\"std\")])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"<lambda_0>\": \"std\"})\n",
    ")\n",
    "\n",
    "df_results_to_save.to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_721553f0_527e_11ee_bf14_dcfb48751facrow0_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow1_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow2_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow3_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow4_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow5_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow6_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow7_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow8_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow9_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow10_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow11_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow12_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow13_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow14_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow15_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow16_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow17_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow18_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow19_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow20_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow21_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow22_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow23_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow24_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow25_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow26_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow27_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow28_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow29_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow30_col0,#T_721553f0_527e_11ee_bf14_dcfb48751facrow31_col0{\n",
       "            background-color:  #f7fcf5;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_721553f0_527e_11ee_bf14_dcfb48751fac\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Coefficients</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row0\" class=\"row_heading level0 row0\" >CaO</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow0_col0\" class=\"data row0 col0\" >0.062688</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row1\" class=\"row_heading level0 row1\" >MgO</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow1_col0\" class=\"data row1 col0\" >-0.261707</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row2\" class=\"row_heading level0 row2\" >Na2O</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow2_col0\" class=\"data row2 col0\" >-0.074322</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row3\" class=\"row_heading level0 row3\" >Al2O3</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow3_col0\" class=\"data row3 col0\" >0.192661</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row4\" class=\"row_heading level0 row4\" >SiO2</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow4_col0\" class=\"data row4 col0\" >-0.181872</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row5\" class=\"row_heading level0 row5\" >SO3</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow5_col0\" class=\"data row5 col0\" >0.044958</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row6\" class=\"row_heading level0 row6\" >K2O</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow6_col0\" class=\"data row6 col0\" >-0.166403</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row7\" class=\"row_heading level0 row7\" >Fe2O3</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow7_col0\" class=\"data row7 col0\" >0.125457</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row8\" class=\"row_heading level0 row8\" >IR</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow8_col0\" class=\"data row8 col0\" >-0.013219</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row9\" class=\"row_heading level0 row9\" >Alite total</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow9_col0\" class=\"data row9 col0\" >0.104795</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row10\" class=\"row_heading level0 row10\" >Belite alpha</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow10_col0\" class=\"data row10 col0\" >0.127343</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row11\" class=\"row_heading level0 row11\" >Belite beta</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow11_col0\" class=\"data row11 col0\" >0.027923</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row12\" class=\"row_heading level0 row12\" >Belite gamma</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow12_col0\" class=\"data row12 col0\" >-0.121590</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row13\" class=\"row_heading level0 row13\" >Ferrite</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow13_col0\" class=\"data row13 col0\" >0.244275</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row14\" class=\"row_heading level0 row14\" >Aluminate</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow14_col0\" class=\"data row14 col0\" >0.197707</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row15\" class=\"row_heading level0 row15\" >Aluminate cubic</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow15_col0\" class=\"data row15 col0\" >-0.090480</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row16\" class=\"row_heading level0 row16\" >Aluminate orto</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow16_col0\" class=\"data row16 col0\" >0.079115</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row17\" class=\"row_heading level0 row17\" >Free lime</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow17_col0\" class=\"data row17 col0\" >0.012966</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row18\" class=\"row_heading level0 row18\" >Portlandite</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow18_col0\" class=\"data row18 col0\" >-0.115373</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row19\" class=\"row_heading level0 row19\" >Periclase</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow19_col0\" class=\"data row19 col0\" >0.004152</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row20\" class=\"row_heading level0 row20\" >Arcanite</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow20_col0\" class=\"data row20 col0\" >0.195034</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row21\" class=\"row_heading level0 row21\" >Aphthalite</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow21_col0\" class=\"data row21 col0\" >-0.017603</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row22\" class=\"row_heading level0 row22\" >Gypsum</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow22_col0\" class=\"data row22 col0\" >0.163063</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row23\" class=\"row_heading level0 row23\" >Bassanite</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow23_col0\" class=\"data row23 col0\" >0.321342</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row24\" class=\"row_heading level0 row24\" >Anhydrite</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow24_col0\" class=\"data row24 col0\" >-0.110665</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row25\" class=\"row_heading level0 row25\" >Calcite</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow25_col0\" class=\"data row25 col0\" >0.410326</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row26\" class=\"row_heading level0 row26\" >Dolimite</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow26_col0\" class=\"data row26 col0\" >0.059940</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row27\" class=\"row_heading level0 row27\" >Quartz</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow27_col0\" class=\"data row27 col0\" >0.226403</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row28\" class=\"row_heading level0 row28\" >%Gypsum</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow28_col0\" class=\"data row28 col0\" >-0.357107</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row29\" class=\"row_heading level0 row29\" >%Limestone</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow29_col0\" class=\"data row29 col0\" >-1.792895</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row30\" class=\"row_heading level0 row30\" >%Clinker</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow30_col0\" class=\"data row30 col0\" >-1.307693</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_721553f0_527e_11ee_bf14_dcfb48751faclevel0_row31\" class=\"row_heading level0 row31\" >CS7</th>\n",
       "                        <td id=\"T_721553f0_527e_11ee_bf14_dcfb48751facrow31_col0\" class=\"data row31 col0\" >0.627430</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f35a1482e10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"pd.Series(\\n    pipeline.named_steps[\\\"estimator\\\"].coef_,\\n    df_copy.drop([\\\"Date\\\"], axis=1).columns,\\n).to_frame(name=\\\"Coefficients\\\").style.background_gradient(\\n    axis=None, vmin=1, vmax=5, cmap=\\\"Greens\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"pd.Series(\\n    pipeline.named_steps[\\\"estimator\\\"].coef_,\\n    df_copy.drop([\\\"Date\\\"], axis=1).columns,\\n).to_frame(name=\\\"Coefficients\\\").style.background_gradient(\\n    axis=None, vmin=1, vmax=5, cmap=\\\"Greens\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(\n",
    "    pipeline.named_steps[\"estimator\"].coef_,\n",
    "    df_copy.drop([\"Date\"], axis=1).columns,\n",
    ").to_frame(name=\"Coefficients\").style.background_gradient(\n",
    "    axis=None, vmin=1, vmax=5, cmap=\"Greens\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ccs28-venv)",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
