{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b87b59ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:01:57.332515Z",
     "iopub.status.busy": "2024-07-13T22:01:57.330262Z",
     "iopub.status.idle": "2024-07-13T22:01:57.440227Z",
     "shell.execute_reply": "2024-07-13T22:01:57.439235Z"
    },
    "papermill": {
     "duration": 0.123599,
     "end_time": "2024-07-13T22:01:57.442273",
     "exception": false,
     "start_time": "2024-07-13T22:01:57.318674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ea6cf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:01:57.463462Z",
     "iopub.status.busy": "2024-07-13T22:01:57.462896Z",
     "iopub.status.idle": "2024-07-13T22:02:01.959251Z",
     "shell.execute_reply": "2024-07-13T22:02:01.958126Z"
    },
    "papermill": {
     "duration": 4.511497,
     "end_time": "2024-07-13T22:02:01.963262",
     "exception": false,
     "start_time": "2024-07-13T22:01:57.451765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 19:01:59.405622: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-13 19:01:59.409087: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-13 19:01:59.483974: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-13 19:01:59.485177: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 19:02:00.813533: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Plotting\\nimport matplotlib.pyplot as plt\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Processing results\\nimport json\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.model_selection import TimeSeriesSplit\\nfrom sklearn.model_selection import RepeatedKFold\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.model_selection import cross_validate\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.preprocessing import RobustScaler\\n\\n# Metrics\\nfrom sklearn.metrics import mean_squared_error\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.metrics import mean_absolute_percentage_error\\nfrom sklearn.metrics import r2_score\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Plotting\\nimport matplotlib.pyplot as plt\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Processing results\\nimport json\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.model_selection import TimeSeriesSplit\\nfrom sklearn.model_selection import RepeatedKFold\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.model_selection import cross_validate\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.preprocessing import RobustScaler\\n\\n# Metrics\\nfrom sklearn.metrics import mean_squared_error\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.metrics import mean_absolute_percentage_error\\nfrom sklearn.metrics import r2_score\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Processing results\n",
    "import json\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0903c03d",
   "metadata": {
    "papermill": {
     "duration": 0.021141,
     "end_time": "2024-07-13T22:02:02.009142",
     "exception": false,
     "start_time": "2024-07-13T22:02:01.988001",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7d6def2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:02:02.040810Z",
     "iopub.status.busy": "2024-07-13T22:02:02.039970Z",
     "iopub.status.idle": "2024-07-13T22:02:02.063886Z",
     "shell.execute_reply": "2024-07-13T22:02:02.062729Z"
    },
    "papermill": {
     "duration": 0.041094,
     "end_time": "2024-07-13T22:02:02.067234",
     "exception": false,
     "start_time": "2024-07-13T22:02:02.026140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def plot_predictions(model, df, scaler, index, date_column, x, y):\\n    dates = df[date_column].values\\n    test_series = pd.DataFrame({\\\"ccs28\\\": y}, index=pd.to_datetime(dates))\\n    pred_series = model.predict(scaler.transform(x)).squeeze()\\n    pred_series = pd.DataFrame({\\\"ccs28-pred\\\": pred_series}, index=pd.to_datetime(dates))\\n\\n    fig, ax = plt.subplots(1, 1, sharex=True, sharey=True, figsize=(15, 7))\\n\\n    test_series.plot(ax=ax)\\n    ax.axvline(test_series.index[index], color=\\\"r\\\")  # end of train dataset\\n    pred_series[index:].plot(ax=ax)\\n    ax.grid(which=\\\"both\\\")\\n    ax.legend(\\n        [\\\"train and test series\\\", \\\"end of train series\\\", \\\"predicted\\\"], loc=\\\"upper left\\\"\\n    )\\n    ax.set_xlabel(\\\"Dates\\\", labelpad=20, fontsize=15)\\n    ax.set_ylabel(\\\"Compressive Strength - MPa\\\", labelpad=20, fontsize=15)\\n    ax.spines[\\\"top\\\"].set_visible(False)\\n    ax.spines[\\\"right\\\"].set_visible(False)\\n    plt.show()\";\n",
       "                var nbb_formatted_code = \"def plot_predictions(model, df, scaler, index, date_column, x, y):\\n    dates = df[date_column].values\\n    test_series = pd.DataFrame({\\\"ccs28\\\": y}, index=pd.to_datetime(dates))\\n    pred_series = model.predict(scaler.transform(x)).squeeze()\\n    pred_series = pd.DataFrame({\\\"ccs28-pred\\\": pred_series}, index=pd.to_datetime(dates))\\n\\n    fig, ax = plt.subplots(1, 1, sharex=True, sharey=True, figsize=(15, 7))\\n\\n    test_series.plot(ax=ax)\\n    ax.axvline(test_series.index[index], color=\\\"r\\\")  # end of train dataset\\n    pred_series[index:].plot(ax=ax)\\n    ax.grid(which=\\\"both\\\")\\n    ax.legend(\\n        [\\\"train and test series\\\", \\\"end of train series\\\", \\\"predicted\\\"], loc=\\\"upper left\\\"\\n    )\\n    ax.set_xlabel(\\\"Dates\\\", labelpad=20, fontsize=15)\\n    ax.set_ylabel(\\\"Compressive Strength - MPa\\\", labelpad=20, fontsize=15)\\n    ax.spines[\\\"top\\\"].set_visible(False)\\n    ax.spines[\\\"right\\\"].set_visible(False)\\n    plt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_predictions(model, df, scaler, index, date_column, x, y):\n",
    "    dates = df[date_column].values\n",
    "    test_series = pd.DataFrame({\"ccs28\": y}, index=pd.to_datetime(dates))\n",
    "    pred_series = model.predict(scaler.transform(x)).squeeze()\n",
    "    pred_series = pd.DataFrame({\"ccs28-pred\": pred_series}, index=pd.to_datetime(dates))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, sharex=True, sharey=True, figsize=(15, 7))\n",
    "\n",
    "    test_series.plot(ax=ax)\n",
    "    ax.axvline(test_series.index[index], color=\"r\")  # end of train dataset\n",
    "    pred_series[index:].plot(ax=ax)\n",
    "    ax.grid(which=\"both\")\n",
    "    ax.legend(\n",
    "        [\"train and test series\", \"end of train series\", \"predicted\"], loc=\"upper left\"\n",
    "    )\n",
    "    ax.set_xlabel(\"Dates\", labelpad=20, fontsize=15)\n",
    "    ax.set_ylabel(\"Compressive Strength - MPa\", labelpad=20, fontsize=15)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39fc28e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:02:02.100270Z",
     "iopub.status.busy": "2024-07-13T22:02:02.099673Z",
     "iopub.status.idle": "2024-07-13T22:02:02.281256Z",
     "shell.execute_reply": "2024-07-13T22:02:02.279233Z"
    },
    "papermill": {
     "duration": 0.200838,
     "end_time": "2024-07-13T22:02:02.284582",
     "exception": false,
     "start_time": "2024-07-13T22:02:02.083744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"def plot_scores_box_plot(scores, repeats, n_splits):\\n    plt.figure(figsize=(15, 8))\\n    plt.boxplot(\\n        scores.reshape((repeats, n_splits)),\\n        labels=[str(r) for r in range(1, repeats + 1)],\\n        showmeans=True,\\n    )\\n    plt.ylabel(\\\"RMSE\\\", labelpad=20, fontsize=15)\\n    plt.xlabel(\\\"Repeats\\\", labelpad=20, fontsize=15)\\n    plt.show()\";\n",
       "                var nbb_formatted_code = \"def plot_scores_box_plot(scores, repeats, n_splits):\\n    plt.figure(figsize=(15, 8))\\n    plt.boxplot(\\n        scores.reshape((repeats, n_splits)),\\n        labels=[str(r) for r in range(1, repeats + 1)],\\n        showmeans=True,\\n    )\\n    plt.ylabel(\\\"RMSE\\\", labelpad=20, fontsize=15)\\n    plt.xlabel(\\\"Repeats\\\", labelpad=20, fontsize=15)\\n    plt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_scores_box_plot(scores, repeats, n_splits):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.boxplot(\n",
    "        scores.reshape((repeats, n_splits)),\n",
    "        labels=[str(r) for r in range(1, repeats + 1)],\n",
    "        showmeans=True,\n",
    "    )\n",
    "    plt.ylabel(\"RMSE\", labelpad=20, fontsize=15)\n",
    "    plt.xlabel(\"Repeats\", labelpad=20, fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16da23ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:02:02.322002Z",
     "iopub.status.busy": "2024-07-13T22:02:02.320637Z",
     "iopub.status.idle": "2024-07-13T22:02:02.485745Z",
     "shell.execute_reply": "2024-07-13T22:02:02.484104Z"
    },
    "papermill": {
     "duration": 0.187282,
     "end_time": "2024-07-13T22:02:02.488594",
     "exception": false,
     "start_time": "2024-07-13T22:02:02.301312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class BlockingTimeSeriesSplit:\\n    def __init__(self, n_splits, train_size):\\n        self.n_splits = n_splits\\n        self.train_size = train_size\\n\\n    def get_n_splits(self, X, y, groups):\\n        return self.n_splits\\n\\n    def split(self, X, y=None, groups=None):\\n        n_samples = len(X)\\n        k_fold_size = n_samples // self.n_splits\\n        indices = np.arange(n_samples)\\n\\n        margin = 0\\n        for i in range(self.n_splits):\\n            start = i * k_fold_size\\n            stop = start + k_fold_size\\n            mid = int(self.train_size * (stop - start)) + start\\n            yield indices[start:mid], indices[mid + margin : stop]\\n\\n\\n# Reference: https://goldinlocks.github.io/Time-Series-Cross-Validation/\";\n",
       "                var nbb_formatted_code = \"class BlockingTimeSeriesSplit:\\n    def __init__(self, n_splits, train_size):\\n        self.n_splits = n_splits\\n        self.train_size = train_size\\n\\n    def get_n_splits(self, X, y, groups):\\n        return self.n_splits\\n\\n    def split(self, X, y=None, groups=None):\\n        n_samples = len(X)\\n        k_fold_size = n_samples // self.n_splits\\n        indices = np.arange(n_samples)\\n\\n        margin = 0\\n        for i in range(self.n_splits):\\n            start = i * k_fold_size\\n            stop = start + k_fold_size\\n            mid = int(self.train_size * (stop - start)) + start\\n            yield indices[start:mid], indices[mid + margin : stop]\\n\\n\\n# Reference: https://goldinlocks.github.io/Time-Series-Cross-Validation/\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class BlockingTimeSeriesSplit:\n",
    "    def __init__(self, n_splits, train_size):\n",
    "        self.n_splits = n_splits\n",
    "        self.train_size = train_size\n",
    "\n",
    "    def get_n_splits(self, X, y, groups):\n",
    "        return self.n_splits\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        n_samples = len(X)\n",
    "        k_fold_size = n_samples // self.n_splits\n",
    "        indices = np.arange(n_samples)\n",
    "\n",
    "        margin = 0\n",
    "        for i in range(self.n_splits):\n",
    "            start = i * k_fold_size\n",
    "            stop = start + k_fold_size\n",
    "            mid = int(self.train_size * (stop - start)) + start\n",
    "            yield indices[start:mid], indices[mid + margin : stop]\n",
    "\n",
    "\n",
    "# Reference: https://goldinlocks.github.io/Time-Series-Cross-Validation/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc2eded",
   "metadata": {
    "papermill": {
     "duration": 0.018377,
     "end_time": "2024-07-13T22:02:02.527170",
     "exception": false,
     "start_time": "2024-07-13T22:02:02.508793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions for blocked time series cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff03498",
   "metadata": {
    "papermill": {
     "duration": 0.031788,
     "end_time": "2024-07-13T22:02:02.597713",
     "exception": false,
     "start_time": "2024-07-13T22:02:02.565925",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "816a02e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:02:02.666519Z",
     "iopub.status.busy": "2024-07-13T22:02:02.665134Z",
     "iopub.status.idle": "2024-07-13T22:02:02.726389Z",
     "shell.execute_reply": "2024-07-13T22:02:02.725258Z"
    },
    "papermill": {
     "duration": 0.089878,
     "end_time": "2024-07-13T22:02:02.729962",
     "exception": false,
     "start_time": "2024-07-13T22:02:02.640084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"def split_by_periods(x, y, train_period, test_period):\\n    datasets = []\\n    i = 0\\n    max_samples = x.shape[0]\\n\\n    for _ in range(0, max_samples // (train_period + test_period)):\\n        # Splitting the data into train/test sets\\n        x_train = x[i : i + train_period].copy()\\n        y_train = y[i : i + train_period].copy()\\n        x_test = x[i + train_period : i + train_period + test_period].copy()\\n        y_test = y[i + train_period : i + train_period + test_period].copy()\\n\\n        datasets.append(\\n            {\\n                \\\"x_train\\\": x_train,\\n                \\\"y_train\\\": y_train,\\n                \\\"x_test\\\": x_test,\\n                \\\"y_test\\\": y_test,\\n            }\\n        )\\n        # Increments the index for the next period of time\\n        i += train_period + test_period\\n\\n    return datasets\";\n",
       "                var nbb_formatted_code = \"def split_by_periods(x, y, train_period, test_period):\\n    datasets = []\\n    i = 0\\n    max_samples = x.shape[0]\\n\\n    for _ in range(0, max_samples // (train_period + test_period)):\\n        # Splitting the data into train/test sets\\n        x_train = x[i : i + train_period].copy()\\n        y_train = y[i : i + train_period].copy()\\n        x_test = x[i + train_period : i + train_period + test_period].copy()\\n        y_test = y[i + train_period : i + train_period + test_period].copy()\\n\\n        datasets.append(\\n            {\\n                \\\"x_train\\\": x_train,\\n                \\\"y_train\\\": y_train,\\n                \\\"x_test\\\": x_test,\\n                \\\"y_test\\\": y_test,\\n            }\\n        )\\n        # Increments the index for the next period of time\\n        i += train_period + test_period\\n\\n    return datasets\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def split_by_periods(x, y, train_period, test_period):\n",
    "    datasets = []\n",
    "    i = 0\n",
    "    max_samples = x.shape[0]\n",
    "\n",
    "    for _ in range(0, max_samples // (train_period + test_period)):\n",
    "        # Splitting the data into train/test sets\n",
    "        x_train = x[i : i + train_period].copy()\n",
    "        y_train = y[i : i + train_period].copy()\n",
    "        x_test = x[i + train_period : i + train_period + test_period].copy()\n",
    "        y_test = y[i + train_period : i + train_period + test_period].copy()\n",
    "\n",
    "        datasets.append(\n",
    "            {\n",
    "                \"x_train\": x_train,\n",
    "                \"y_train\": y_train,\n",
    "                \"x_test\": x_test,\n",
    "                \"y_test\": y_test,\n",
    "            }\n",
    "        )\n",
    "        # Increments the index for the next period of time\n",
    "        i += train_period + test_period\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd18fa87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:02:02.782854Z",
     "iopub.status.busy": "2024-07-13T22:02:02.781981Z",
     "iopub.status.idle": "2024-07-13T22:02:02.965254Z",
     "shell.execute_reply": "2024-07-13T22:02:02.963717Z"
    },
    "papermill": {
     "duration": 0.218172,
     "end_time": "2024-07-13T22:02:02.968913",
     "exception": false,
     "start_time": "2024-07-13T22:02:02.750741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"def split_by_dates(x, y, train_period, test_period, dates):\\n    datasets = []\\n    dates = dates[: x.shape[0]].copy()\\n    dates_unique = dates.copy().unique()\\n    i = 0\\n    max_samples = dates_unique.shape[0]\\n\\n    for _ in range(0, max_samples // (train_period + test_period)):\\n        # Splitting the Train Set\\n        start_date_train = dates_unique[i]\\n        end_date_train = dates_unique[i + train_period]\\n        idx_train = dates[(dates >= start_date_train) & (dates < end_date_train)].index\\n        x_train = x.loc[idx_train].copy()\\n        y_train = y[idx_train].copy()\\n\\n        # Splitting the Test Set\\n        start_date_test = dates_unique[i + train_period]\\n        end_date_test = dates_unique[i + train_period + test_period]\\n        idx_test = dates[(dates >= start_date_test) & (dates < end_date_test)].index\\n        x_test = x.loc[idx_test].copy()\\n        y_test = y[idx_test].copy()\\n\\n        datasets.append(\\n            {\\n                \\\"x_train\\\": x_train,\\n                \\\"y_train\\\": y_train,\\n                \\\"x_test\\\": x_test,\\n                \\\"y_test\\\": y_test,\\n            }\\n        )\\n\\n        i += train_period + test_period\\n\\n    return datasets\";\n",
       "                var nbb_formatted_code = \"def split_by_dates(x, y, train_period, test_period, dates):\\n    datasets = []\\n    dates = dates[: x.shape[0]].copy()\\n    dates_unique = dates.copy().unique()\\n    i = 0\\n    max_samples = dates_unique.shape[0]\\n\\n    for _ in range(0, max_samples // (train_period + test_period)):\\n        # Splitting the Train Set\\n        start_date_train = dates_unique[i]\\n        end_date_train = dates_unique[i + train_period]\\n        idx_train = dates[(dates >= start_date_train) & (dates < end_date_train)].index\\n        x_train = x.loc[idx_train].copy()\\n        y_train = y[idx_train].copy()\\n\\n        # Splitting the Test Set\\n        start_date_test = dates_unique[i + train_period]\\n        end_date_test = dates_unique[i + train_period + test_period]\\n        idx_test = dates[(dates >= start_date_test) & (dates < end_date_test)].index\\n        x_test = x.loc[idx_test].copy()\\n        y_test = y[idx_test].copy()\\n\\n        datasets.append(\\n            {\\n                \\\"x_train\\\": x_train,\\n                \\\"y_train\\\": y_train,\\n                \\\"x_test\\\": x_test,\\n                \\\"y_test\\\": y_test,\\n            }\\n        )\\n\\n        i += train_period + test_period\\n\\n    return datasets\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def split_by_dates(x, y, train_period, test_period, dates):\n",
    "    datasets = []\n",
    "    dates = dates[: x.shape[0]].copy()\n",
    "    dates_unique = dates.copy().unique()\n",
    "    i = 0\n",
    "    max_samples = dates_unique.shape[0]\n",
    "\n",
    "    for _ in range(0, max_samples // (train_period + test_period)):\n",
    "        # Splitting the Train Set\n",
    "        start_date_train = dates_unique[i]\n",
    "        end_date_train = dates_unique[i + train_period]\n",
    "        idx_train = dates[(dates >= start_date_train) & (dates < end_date_train)].index\n",
    "        x_train = x.loc[idx_train].copy()\n",
    "        y_train = y[idx_train].copy()\n",
    "\n",
    "        # Splitting the Test Set\n",
    "        start_date_test = dates_unique[i + train_period]\n",
    "        end_date_test = dates_unique[i + train_period + test_period]\n",
    "        idx_test = dates[(dates >= start_date_test) & (dates < end_date_test)].index\n",
    "        x_test = x.loc[idx_test].copy()\n",
    "        y_test = y[idx_test].copy()\n",
    "\n",
    "        datasets.append(\n",
    "            {\n",
    "                \"x_train\": x_train,\n",
    "                \"y_train\": y_train,\n",
    "                \"x_test\": x_test,\n",
    "                \"y_test\": y_test,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        i += train_period + test_period\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c65cd24f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:02:03.010801Z",
     "iopub.status.busy": "2024-07-13T22:02:03.009789Z",
     "iopub.status.idle": "2024-07-13T22:02:03.120198Z",
     "shell.execute_reply": "2024-07-13T22:02:03.118516Z"
    },
    "papermill": {
     "duration": 0.135037,
     "end_time": "2024-07-13T22:02:03.124631",
     "exception": false,
     "start_time": "2024-07-13T22:02:02.989594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"def train_test_split_blocked_ts(x, y, train_period, test_period, dates=None):\\n    \\\"\\\"\\\"\\n    Split the input data into train-test datasets based on train and test periods.\\n\\n    Args:\\n        x (pd.DataFrame): Input features.\\n        y (np.Array): Target values.\\n        train_period (int): Length of the training period.\\n        test_period (int): Length of the testing period.\\n        dates (pd.Series): Optional date information.\\n\\n    Returns:\\n        List[dict]: A list of dictionaries, each containing 'x_train', 'y_train', 'x_test', and 'y_test'.\\n    \\\"\\\"\\\"\\n    if dates is None:\\n        return split_by_periods(x, y, train_period, test_period)\\n    else:\\n        return split_by_dates(x, y, train_period, test_period, dates)\";\n",
       "                var nbb_formatted_code = \"def train_test_split_blocked_ts(x, y, train_period, test_period, dates=None):\\n    \\\"\\\"\\\"\\n    Split the input data into train-test datasets based on train and test periods.\\n\\n    Args:\\n        x (pd.DataFrame): Input features.\\n        y (np.Array): Target values.\\n        train_period (int): Length of the training period.\\n        test_period (int): Length of the testing period.\\n        dates (pd.Series): Optional date information.\\n\\n    Returns:\\n        List[dict]: A list of dictionaries, each containing 'x_train', 'y_train', 'x_test', and 'y_test'.\\n    \\\"\\\"\\\"\\n    if dates is None:\\n        return split_by_periods(x, y, train_period, test_period)\\n    else:\\n        return split_by_dates(x, y, train_period, test_period, dates)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_test_split_blocked_ts(x, y, train_period, test_period, dates=None):\n",
    "    \"\"\"\n",
    "    Split the input data into train-test datasets based on train and test periods.\n",
    "\n",
    "    Args:\n",
    "        x (pd.DataFrame): Input features.\n",
    "        y (np.Array): Target values.\n",
    "        train_period (int): Length of the training period.\n",
    "        test_period (int): Length of the testing period.\n",
    "        dates (pd.Series): Optional date information.\n",
    "\n",
    "    Returns:\n",
    "        List[dict]: A list of dictionaries, each containing 'x_train', 'y_train', 'x_test', and 'y_test'.\n",
    "    \"\"\"\n",
    "    if dates is None:\n",
    "        return split_by_periods(x, y, train_period, test_period)\n",
    "    else:\n",
    "        return split_by_dates(x, y, train_period, test_period, dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff925bef",
   "metadata": {
    "papermill": {
     "duration": 0.019585,
     "end_time": "2024-07-13T22:02:03.170332",
     "exception": false,
     "start_time": "2024-07-13T22:02:03.150747",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d24b2535",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:02:03.227550Z",
     "iopub.status.busy": "2024-07-13T22:02:03.226810Z",
     "iopub.status.idle": "2024-07-13T22:02:03.389400Z",
     "shell.execute_reply": "2024-07-13T22:02:03.387326Z"
    },
    "papermill": {
     "duration": 0.192816,
     "end_time": "2024-07-13T22:02:03.393741",
     "exception": false,
     "start_time": "2024-07-13T22:02:03.200925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"def impute_data(dataset, imputer=None, imputer_params=None):\\n    x_train = dataset[\\\"x_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n\\n    # Apply imputation to the data\\n    if imputer is not None:\\n        imputer = imputer() if imputer_params is None else imputer(**imputer_params)\\n        x_train = imputer.fit_transform(x_train)\\n        x_test = imputer.transform(x_test)\\n\\n    dataset[\\\"x_train\\\"] = x_train\\n    dataset[\\\"x_test\\\"] = x_test\\n\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def impute_data(dataset, imputer=None, imputer_params=None):\\n    x_train = dataset[\\\"x_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n\\n    # Apply imputation to the data\\n    if imputer is not None:\\n        imputer = imputer() if imputer_params is None else imputer(**imputer_params)\\n        x_train = imputer.fit_transform(x_train)\\n        x_test = imputer.transform(x_test)\\n\\n    dataset[\\\"x_train\\\"] = x_train\\n    dataset[\\\"x_test\\\"] = x_test\\n\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def impute_data(dataset, imputer=None, imputer_params=None):\n",
    "    x_train = dataset[\"x_train\"]\n",
    "    x_test = dataset[\"x_test\"]\n",
    "\n",
    "    # Apply imputation to the data\n",
    "    if imputer is not None:\n",
    "        imputer = imputer() if imputer_params is None else imputer(**imputer_params)\n",
    "        x_train = imputer.fit_transform(x_train)\n",
    "        x_test = imputer.transform(x_test)\n",
    "\n",
    "    dataset[\"x_train\"] = x_train\n",
    "    dataset[\"x_test\"] = x_test\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc37dfb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:02:03.442912Z",
     "iopub.status.busy": "2024-07-13T22:02:03.442044Z",
     "iopub.status.idle": "2024-07-13T22:02:03.545097Z",
     "shell.execute_reply": "2024-07-13T22:02:03.543223Z"
    },
    "papermill": {
     "duration": 0.130905,
     "end_time": "2024-07-13T22:02:03.548842",
     "exception": false,
     "start_time": "2024-07-13T22:02:03.417937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"def transform_data(dataset, transformer=None):\\n    x_train = dataset[\\\"x_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n\\n    # Apply data normalization/standardization to the data\\n    if transformer is not None:\\n        scaler = transformer()\\n        x_train = scaler.fit_transform(x_train)\\n        x_test = scaler.transform(x_test)\\n\\n    dataset[\\\"x_train\\\"] = x_train\\n    dataset[\\\"x_test\\\"] = x_test\\n\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def transform_data(dataset, transformer=None):\\n    x_train = dataset[\\\"x_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n\\n    # Apply data normalization/standardization to the data\\n    if transformer is not None:\\n        scaler = transformer()\\n        x_train = scaler.fit_transform(x_train)\\n        x_test = scaler.transform(x_test)\\n\\n    dataset[\\\"x_train\\\"] = x_train\\n    dataset[\\\"x_test\\\"] = x_test\\n\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def transform_data(dataset, transformer=None):\n",
    "    x_train = dataset[\"x_train\"]\n",
    "    x_test = dataset[\"x_test\"]\n",
    "\n",
    "    # Apply data normalization/standardization to the data\n",
    "    if transformer is not None:\n",
    "        scaler = transformer()\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "    dataset[\"x_train\"] = x_train\n",
    "    dataset[\"x_test\"] = x_test\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e605c71b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:02:03.596249Z",
     "iopub.status.busy": "2024-07-13T22:02:03.595215Z",
     "iopub.status.idle": "2024-07-13T22:02:03.738460Z",
     "shell.execute_reply": "2024-07-13T22:02:03.736580Z"
    },
    "papermill": {
     "duration": 0.171234,
     "end_time": "2024-07-13T22:02:03.742577",
     "exception": false,
     "start_time": "2024-07-13T22:02:03.571343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"def preprocess_data(dataset, transformer=None, imputer=None, imputer_params=None):\\n    dataset = impute_data(dataset, imputer, imputer_params)\\n    dataset = transform_data(dataset, transformer)\\n    return dataset\";\n",
       "                var nbb_formatted_code = \"def preprocess_data(dataset, transformer=None, imputer=None, imputer_params=None):\\n    dataset = impute_data(dataset, imputer, imputer_params)\\n    dataset = transform_data(dataset, transformer)\\n    return dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_data(dataset, transformer=None, imputer=None, imputer_params=None):\n",
    "    dataset = impute_data(dataset, imputer, imputer_params)\n",
    "    dataset = transform_data(dataset, transformer)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41668a6",
   "metadata": {
    "papermill": {
     "duration": 0.019923,
     "end_time": "2024-07-13T22:02:03.785000",
     "exception": false,
     "start_time": "2024-07-13T22:02:03.765077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5850781",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:02:03.841213Z",
     "iopub.status.busy": "2024-07-13T22:02:03.840182Z",
     "iopub.status.idle": "2024-07-13T22:02:03.962011Z",
     "shell.execute_reply": "2024-07-13T22:02:03.960365Z"
    },
    "papermill": {
     "duration": 0.146567,
     "end_time": "2024-07-13T22:02:03.964903",
     "exception": false,
     "start_time": "2024-07-13T22:02:03.818336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"def train_and_evaluate_model(Estimator, dataset, estimator_params=None):\\n    \\\"\\\"\\\"\\n    Purpose: Helper function to be used in conjunction with\\n    blocked time_series cross validation function\\n    \\\"\\\"\\\"\\n    x_train = dataset[\\\"x_train\\\"]\\n    y_train = dataset[\\\"y_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n    y_test = dataset[\\\"y_test\\\"]\\n\\n    # Instantiate the model\\n    model = Estimator() if estimator_params is None else Estimator(**estimator_params)\\n\\n    # Fitting the model\\n    model.fit(x_train, y_train)\\n\\n    # Making predictions on train/test sets\\n    y_train_pred = model.predict(x_train)\\n    y_test_pred = model.predict(x_test)\\n\\n    # Return regression metrics\\n    return score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_formatted_code = \"def train_and_evaluate_model(Estimator, dataset, estimator_params=None):\\n    \\\"\\\"\\\"\\n    Purpose: Helper function to be used in conjunction with\\n    blocked time_series cross validation function\\n    \\\"\\\"\\\"\\n    x_train = dataset[\\\"x_train\\\"]\\n    y_train = dataset[\\\"y_train\\\"]\\n    x_test = dataset[\\\"x_test\\\"]\\n    y_test = dataset[\\\"y_test\\\"]\\n\\n    # Instantiate the model\\n    model = Estimator() if estimator_params is None else Estimator(**estimator_params)\\n\\n    # Fitting the model\\n    model.fit(x_train, y_train)\\n\\n    # Making predictions on train/test sets\\n    y_train_pred = model.predict(x_train)\\n    y_test_pred = model.predict(x_test)\\n\\n    # Return regression metrics\\n    return score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_and_evaluate_model(Estimator, dataset, estimator_params=None):\n",
    "    \"\"\"\n",
    "    Purpose: Helper function to be used in conjunction with\n",
    "    blocked time_series cross validation function\n",
    "    \"\"\"\n",
    "    x_train = dataset[\"x_train\"]\n",
    "    y_train = dataset[\"y_train\"]\n",
    "    x_test = dataset[\"x_test\"]\n",
    "    y_test = dataset[\"y_test\"]\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = Estimator() if estimator_params is None else Estimator(**estimator_params)\n",
    "\n",
    "    # Fitting the model\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Making predictions on train/test sets\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "\n",
    "    # Return regression metrics\n",
    "    return score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ec5db4",
   "metadata": {
    "papermill": {
     "duration": 0.017804,
     "end_time": "2024-07-13T22:02:04.000552",
     "exception": false,
     "start_time": "2024-07-13T22:02:03.982748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Blocking time series cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55a36976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:02:04.063797Z",
     "iopub.status.busy": "2024-07-13T22:02:04.062906Z",
     "iopub.status.idle": "2024-07-13T22:02:04.234113Z",
     "shell.execute_reply": "2024-07-13T22:02:04.232365Z"
    },
    "papermill": {
     "duration": 0.208314,
     "end_time": "2024-07-13T22:02:04.238510",
     "exception": false,
     "start_time": "2024-07-13T22:02:04.030196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"def repeated_blocking_time_series(\\n    Estimator,\\n    Transform,\\n    Imputer,\\n    x,\\n    y,\\n    train_period,\\n    test_period,\\n    dates=None,\\n    repeats=10,\\n    estimator_params=None,\\n    imputer_params=None,\\n):\\n    \\\"\\\"\\\"\\n    Perform repeated cross-validation with blocked time series data.\\n\\n    Args:\\n        Estimator: Machine learning model class.\\n        Transform: Data transformation method.\\n        Imputer: Data imputation method.\\n        x: Input features.\\n        y: Target values.\\n        train_period: Length of the training period.\\n        test_period: Length of the testing period.\\n        dates: Optional date information.\\n        repeats: Number of repetitions.\\n        estimator_params: Parameters for the model.\\n        imputer_params: Parameters for data imputation.\\n\\n    Returns:\\n        list: List of dictionaries containing evaluation metrics for each repetition.\\n    \\\"\\\"\\\"\\n\\n    results = []\\n    max_samples = x.shape[0]\\n\\n    # Splitting the data into train/test sets\\n    datasets = train_test_split_blocked_ts(x, y, train_period, test_period, dates)\\n\\n    for _ in range(repeats):\\n        scores = []\\n\\n        for dataset in datasets:\\n            dataset = preprocess_data(dataset, Transform, Imputer, imputer_params)\\n            score = train_and_evaluate_model(Estimator, dataset, estimator_params)\\n            scores.append(score)\\n\\n        # After every iteration metrics results are appended together\\n        scores_final = {key: [] for key, _ in scores[0].items()}\\n        for scores_dict in scores:\\n            for key, value in scores_dict.items():\\n                scores_final[key] += [value]\\n        results.append(scores_final)\\n    return results\";\n",
       "                var nbb_formatted_code = \"def repeated_blocking_time_series(\\n    Estimator,\\n    Transform,\\n    Imputer,\\n    x,\\n    y,\\n    train_period,\\n    test_period,\\n    dates=None,\\n    repeats=10,\\n    estimator_params=None,\\n    imputer_params=None,\\n):\\n    \\\"\\\"\\\"\\n    Perform repeated cross-validation with blocked time series data.\\n\\n    Args:\\n        Estimator: Machine learning model class.\\n        Transform: Data transformation method.\\n        Imputer: Data imputation method.\\n        x: Input features.\\n        y: Target values.\\n        train_period: Length of the training period.\\n        test_period: Length of the testing period.\\n        dates: Optional date information.\\n        repeats: Number of repetitions.\\n        estimator_params: Parameters for the model.\\n        imputer_params: Parameters for data imputation.\\n\\n    Returns:\\n        list: List of dictionaries containing evaluation metrics for each repetition.\\n    \\\"\\\"\\\"\\n\\n    results = []\\n    max_samples = x.shape[0]\\n\\n    # Splitting the data into train/test sets\\n    datasets = train_test_split_blocked_ts(x, y, train_period, test_period, dates)\\n\\n    for _ in range(repeats):\\n        scores = []\\n\\n        for dataset in datasets:\\n            dataset = preprocess_data(dataset, Transform, Imputer, imputer_params)\\n            score = train_and_evaluate_model(Estimator, dataset, estimator_params)\\n            scores.append(score)\\n\\n        # After every iteration metrics results are appended together\\n        scores_final = {key: [] for key, _ in scores[0].items()}\\n        for scores_dict in scores:\\n            for key, value in scores_dict.items():\\n                scores_final[key] += [value]\\n        results.append(scores_final)\\n    return results\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def repeated_blocking_time_series(\n",
    "    Estimator,\n",
    "    Transform,\n",
    "    Imputer,\n",
    "    x,\n",
    "    y,\n",
    "    train_period,\n",
    "    test_period,\n",
    "    dates=None,\n",
    "    repeats=10,\n",
    "    estimator_params=None,\n",
    "    imputer_params=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform repeated cross-validation with blocked time series data.\n",
    "\n",
    "    Args:\n",
    "        Estimator: Machine learning model class.\n",
    "        Transform: Data transformation method.\n",
    "        Imputer: Data imputation method.\n",
    "        x: Input features.\n",
    "        y: Target values.\n",
    "        train_period: Length of the training period.\n",
    "        test_period: Length of the testing period.\n",
    "        dates: Optional date information.\n",
    "        repeats: Number of repetitions.\n",
    "        estimator_params: Parameters for the model.\n",
    "        imputer_params: Parameters for data imputation.\n",
    "\n",
    "    Returns:\n",
    "        list: List of dictionaries containing evaluation metrics for each repetition.\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "    max_samples = x.shape[0]\n",
    "\n",
    "    # Splitting the data into train/test sets\n",
    "    datasets = train_test_split_blocked_ts(x, y, train_period, test_period, dates)\n",
    "\n",
    "    for _ in range(repeats):\n",
    "        scores = []\n",
    "\n",
    "        for dataset in datasets:\n",
    "            dataset = preprocess_data(dataset, Transform, Imputer, imputer_params)\n",
    "            score = train_and_evaluate_model(Estimator, dataset, estimator_params)\n",
    "            scores.append(score)\n",
    "\n",
    "        # After every iteration metrics results are appended together\n",
    "        scores_final = {key: [] for key, _ in scores[0].items()}\n",
    "        for scores_dict in scores:\n",
    "            for key, value in scores_dict.items():\n",
    "                scores_final[key] += [value]\n",
    "        results.append(scores_final)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ceacad36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:02:04.286328Z",
     "iopub.status.busy": "2024-07-13T22:02:04.285556Z",
     "iopub.status.idle": "2024-07-13T22:02:04.460332Z",
     "shell.execute_reply": "2024-07-13T22:02:04.458714Z"
    },
    "papermill": {
     "duration": 0.200639,
     "end_time": "2024-07-13T22:02:04.464622",
     "exception": false,
     "start_time": "2024-07-13T22:02:04.263983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"def print_scores(scores, METRICS, METRICS_DICT):\\n    for phase in [\\\"train\\\", \\\"test\\\"]:\\n        print(\\\"******\\\")\\n        print(f\\\"[{phase.upper()}]\\\")\\n        print(\\\"******\\\")\\n        for metric in METRICS:\\n            name = METRICS_DICT[metric]\\n            print(\\n                f\\\"{name}: %.3f (%.3f)\\\"\\n                % (\\n                    np.mean(scores[f\\\"{phase}_\\\" + metric]),\\n                    np.std(scores[f\\\"{phase}_\\\" + metric]),\\n                )\\n            )\\n        print(\\\"\\\\n======================\\\\n\\\")\";\n",
       "                var nbb_formatted_code = \"def print_scores(scores, METRICS, METRICS_DICT):\\n    for phase in [\\\"train\\\", \\\"test\\\"]:\\n        print(\\\"******\\\")\\n        print(f\\\"[{phase.upper()}]\\\")\\n        print(\\\"******\\\")\\n        for metric in METRICS:\\n            name = METRICS_DICT[metric]\\n            print(\\n                f\\\"{name}: %.3f (%.3f)\\\"\\n                % (\\n                    np.mean(scores[f\\\"{phase}_\\\" + metric]),\\n                    np.std(scores[f\\\"{phase}_\\\" + metric]),\\n                )\\n            )\\n        print(\\\"\\\\n======================\\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_scores(scores, METRICS, METRICS_DICT):\n",
    "    for phase in [\"train\", \"test\"]:\n",
    "        print(\"******\")\n",
    "        print(f\"[{phase.upper()}]\")\n",
    "        print(\"******\")\n",
    "        for metric in METRICS:\n",
    "            name = METRICS_DICT[metric]\n",
    "            print(\n",
    "                f\"{name}: %.3f (%.3f)\"\n",
    "                % (\n",
    "                    np.mean(scores[f\"{phase}_\" + metric]),\n",
    "                    np.std(scores[f\"{phase}_\" + metric]),\n",
    "                )\n",
    "            )\n",
    "        print(\"\\n======================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "388d1de2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:02:04.519503Z",
     "iopub.status.busy": "2024-07-13T22:02:04.518667Z",
     "iopub.status.idle": "2024-07-13T22:02:04.690227Z",
     "shell.execute_reply": "2024-07-13T22:02:04.688148Z"
    },
    "papermill": {
     "duration": 0.199905,
     "end_time": "2024-07-13T22:02:04.693828",
     "exception": false,
     "start_time": "2024-07-13T22:02:04.493923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"def score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred):\\n    \\\"\\\"\\\"\\n    Calculate and return regression metrics for both training and testing sets.\\n\\n    Args:\\n        y_train (array-like): True target values for the training set.\\n        y_train_pred (array-like): Predicted target values for the training set.\\n        y_test (array-like): True target values for the testing set.\\n        y_test_pred (array-like): Predicted target values for the testing set.\\n\\n    Returns:\\n        dict: Dictionary containing regression metrics.\\n    \\\"\\\"\\\"\\n    TRAIN_RMSE = mean_squared_error(y_true=y_train, y_pred=y_train_pred, squared=False)\\n    TRAIN_MAE = mean_absolute_error(y_true=y_train, y_pred=y_train_pred)\\n    TRAIN_MAPE = mean_absolute_percentage_error(y_true=y_train, y_pred=y_train_pred)\\n    TRAIN_R2 = r2_score(y_true=y_train, y_pred=y_train_pred)\\n\\n    TEST_RMSE = mean_squared_error(y_true=y_test, y_pred=y_test_pred, squared=False)\\n    TEST_MAE = mean_absolute_error(y_true=y_test, y_pred=y_test_pred)\\n    TEST_MAPE = mean_absolute_percentage_error(y_true=y_test, y_pred=y_test_pred)\\n    TEST_R2 = r2_score(y_true=y_test, y_pred=y_test_pred)\\n\\n    scores = {\\n        \\\"train_neg_root_mean_squared_error\\\": TRAIN_RMSE,\\n        \\\"train_neg_mean_absolute_error\\\": TRAIN_MAE,\\n        \\\"train_neg_mean_absolute_percentage_error\\\": TRAIN_MAPE,\\n        \\\"train_r2\\\": TRAIN_R2,\\n        \\\"test_neg_root_mean_squared_error\\\": TEST_RMSE,\\n        \\\"test_neg_mean_absolute_error\\\": TEST_MAE,\\n        \\\"test_neg_mean_absolute_percentage_error\\\": TEST_MAPE,\\n        \\\"test_r2\\\": TEST_R2,\\n    }\\n    return scores\";\n",
       "                var nbb_formatted_code = \"def score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred):\\n    \\\"\\\"\\\"\\n    Calculate and return regression metrics for both training and testing sets.\\n\\n    Args:\\n        y_train (array-like): True target values for the training set.\\n        y_train_pred (array-like): Predicted target values for the training set.\\n        y_test (array-like): True target values for the testing set.\\n        y_test_pred (array-like): Predicted target values for the testing set.\\n\\n    Returns:\\n        dict: Dictionary containing regression metrics.\\n    \\\"\\\"\\\"\\n    TRAIN_RMSE = mean_squared_error(y_true=y_train, y_pred=y_train_pred, squared=False)\\n    TRAIN_MAE = mean_absolute_error(y_true=y_train, y_pred=y_train_pred)\\n    TRAIN_MAPE = mean_absolute_percentage_error(y_true=y_train, y_pred=y_train_pred)\\n    TRAIN_R2 = r2_score(y_true=y_train, y_pred=y_train_pred)\\n\\n    TEST_RMSE = mean_squared_error(y_true=y_test, y_pred=y_test_pred, squared=False)\\n    TEST_MAE = mean_absolute_error(y_true=y_test, y_pred=y_test_pred)\\n    TEST_MAPE = mean_absolute_percentage_error(y_true=y_test, y_pred=y_test_pred)\\n    TEST_R2 = r2_score(y_true=y_test, y_pred=y_test_pred)\\n\\n    scores = {\\n        \\\"train_neg_root_mean_squared_error\\\": TRAIN_RMSE,\\n        \\\"train_neg_mean_absolute_error\\\": TRAIN_MAE,\\n        \\\"train_neg_mean_absolute_percentage_error\\\": TRAIN_MAPE,\\n        \\\"train_r2\\\": TRAIN_R2,\\n        \\\"test_neg_root_mean_squared_error\\\": TEST_RMSE,\\n        \\\"test_neg_mean_absolute_error\\\": TEST_MAE,\\n        \\\"test_neg_mean_absolute_percentage_error\\\": TEST_MAPE,\\n        \\\"test_r2\\\": TEST_R2,\\n    }\\n    return scores\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred):\n",
    "    \"\"\"\n",
    "    Calculate and return regression metrics for both training and testing sets.\n",
    "\n",
    "    Args:\n",
    "        y_train (array-like): True target values for the training set.\n",
    "        y_train_pred (array-like): Predicted target values for the training set.\n",
    "        y_test (array-like): True target values for the testing set.\n",
    "        y_test_pred (array-like): Predicted target values for the testing set.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing regression metrics.\n",
    "    \"\"\"\n",
    "    TRAIN_RMSE = mean_squared_error(y_true=y_train, y_pred=y_train_pred, squared=False)\n",
    "    TRAIN_MAE = mean_absolute_error(y_true=y_train, y_pred=y_train_pred)\n",
    "    TRAIN_MAPE = mean_absolute_percentage_error(y_true=y_train, y_pred=y_train_pred)\n",
    "    TRAIN_R2 = r2_score(y_true=y_train, y_pred=y_train_pred)\n",
    "\n",
    "    TEST_RMSE = mean_squared_error(y_true=y_test, y_pred=y_test_pred, squared=False)\n",
    "    TEST_MAE = mean_absolute_error(y_true=y_test, y_pred=y_test_pred)\n",
    "    TEST_MAPE = mean_absolute_percentage_error(y_true=y_test, y_pred=y_test_pred)\n",
    "    TEST_R2 = r2_score(y_true=y_test, y_pred=y_test_pred)\n",
    "\n",
    "    scores = {\n",
    "        \"train_neg_root_mean_squared_error\": TRAIN_RMSE,\n",
    "        \"train_neg_mean_absolute_error\": TRAIN_MAE,\n",
    "        \"train_neg_mean_absolute_percentage_error\": TRAIN_MAPE,\n",
    "        \"train_r2\": TRAIN_R2,\n",
    "        \"test_neg_root_mean_squared_error\": TEST_RMSE,\n",
    "        \"test_neg_mean_absolute_error\": TEST_MAE,\n",
    "        \"test_neg_mean_absolute_percentage_error\": TEST_MAPE,\n",
    "        \"test_r2\": TEST_R2,\n",
    "    }\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90b3a50b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:02:04.743453Z",
     "iopub.status.busy": "2024-07-13T22:02:04.742718Z",
     "iopub.status.idle": "2024-07-13T22:02:04.922376Z",
     "shell.execute_reply": "2024-07-13T22:02:04.920115Z"
    },
    "papermill": {
     "duration": 0.207806,
     "end_time": "2024-07-13T22:02:04.925885",
     "exception": false,
     "start_time": "2024-07-13T22:02:04.718079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"def fill_results_dict(results_dict, scores):\\n    num_samples = len(scores[\\\"test_r2\\\"])\\n\\n    # Create a DataFrame by copying the results_dict for each sample\\n    df_results = pd.DataFrame([results_dict.copy()] * num_samples)\\n\\n    # Define a mapping of metric names between the input scores and the DataFrame\\n    metric_mapping = {\\n        \\\"train_neg_root_mean_squared_error\\\": \\\"RMSE Train\\\",\\n        \\\"test_neg_root_mean_squared_error\\\": \\\"RMSE Test\\\",\\n        \\\"train_neg_mean_absolute_error\\\": \\\"MAE Train\\\",\\n        \\\"test_neg_mean_absolute_error\\\": \\\"MAE Test\\\",\\n        \\\"train_neg_mean_absolute_percentage_error\\\": \\\"MAPE Train\\\",\\n        \\\"test_neg_mean_absolute_percentage_error\\\": \\\"MAPE Test\\\",\\n        \\\"train_r2\\\": \\\"R2 Train\\\",\\n        \\\"test_r2\\\": \\\"R2 Test\\\",\\n    }\\n\\n    # Iterate through the mapping and fill the DataFrame\\n    for score_key, df_column_name in metric_mapping.items():\\n        if score_key in scores:\\n            if \\\"R2\\\" not in df_column_name:\\n                df_results[df_column_name] = np.abs(scores[score_key])\\n            else:\\n                df_results[df_column_name] = scores[score_key]\\n\\n    return df_results\";\n",
       "                var nbb_formatted_code = \"def fill_results_dict(results_dict, scores):\\n    num_samples = len(scores[\\\"test_r2\\\"])\\n\\n    # Create a DataFrame by copying the results_dict for each sample\\n    df_results = pd.DataFrame([results_dict.copy()] * num_samples)\\n\\n    # Define a mapping of metric names between the input scores and the DataFrame\\n    metric_mapping = {\\n        \\\"train_neg_root_mean_squared_error\\\": \\\"RMSE Train\\\",\\n        \\\"test_neg_root_mean_squared_error\\\": \\\"RMSE Test\\\",\\n        \\\"train_neg_mean_absolute_error\\\": \\\"MAE Train\\\",\\n        \\\"test_neg_mean_absolute_error\\\": \\\"MAE Test\\\",\\n        \\\"train_neg_mean_absolute_percentage_error\\\": \\\"MAPE Train\\\",\\n        \\\"test_neg_mean_absolute_percentage_error\\\": \\\"MAPE Test\\\",\\n        \\\"train_r2\\\": \\\"R2 Train\\\",\\n        \\\"test_r2\\\": \\\"R2 Test\\\",\\n    }\\n\\n    # Iterate through the mapping and fill the DataFrame\\n    for score_key, df_column_name in metric_mapping.items():\\n        if score_key in scores:\\n            if \\\"R2\\\" not in df_column_name:\\n                df_results[df_column_name] = np.abs(scores[score_key])\\n            else:\\n                df_results[df_column_name] = scores[score_key]\\n\\n    return df_results\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fill_results_dict(results_dict, scores):\n",
    "    num_samples = len(scores[\"test_r2\"])\n",
    "\n",
    "    # Create a DataFrame by copying the results_dict for each sample\n",
    "    df_results = pd.DataFrame([results_dict.copy()] * num_samples)\n",
    "\n",
    "    # Define a mapping of metric names between the input scores and the DataFrame\n",
    "    metric_mapping = {\n",
    "        \"train_neg_root_mean_squared_error\": \"RMSE Train\",\n",
    "        \"test_neg_root_mean_squared_error\": \"RMSE Test\",\n",
    "        \"train_neg_mean_absolute_error\": \"MAE Train\",\n",
    "        \"test_neg_mean_absolute_error\": \"MAE Test\",\n",
    "        \"train_neg_mean_absolute_percentage_error\": \"MAPE Train\",\n",
    "        \"test_neg_mean_absolute_percentage_error\": \"MAPE Test\",\n",
    "        \"train_r2\": \"R2 Train\",\n",
    "        \"test_r2\": \"R2 Test\",\n",
    "    }\n",
    "\n",
    "    # Iterate through the mapping and fill the DataFrame\n",
    "    for score_key, df_column_name in metric_mapping.items():\n",
    "        if score_key in scores:\n",
    "            if \"R2\" not in df_column_name:\n",
    "                df_results[df_column_name] = np.abs(scores[score_key])\n",
    "            else:\n",
    "                df_results[df_column_name] = scores[score_key]\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3ddec0",
   "metadata": {
    "papermill": {
     "duration": 0.024088,
     "end_time": "2024-07-13T22:02:04.974765",
     "exception": false,
     "start_time": "2024-07-13T22:02:04.950677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "707188c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:02:05.045190Z",
     "iopub.status.busy": "2024-07-13T22:02:05.044240Z",
     "iopub.status.idle": "2024-07-13T22:02:05.206638Z",
     "shell.execute_reply": "2024-07-13T22:02:05.205036Z"
    },
    "papermill": {
     "duration": 0.203172,
     "end_time": "2024-07-13T22:02:05.210871",
     "exception": false,
     "start_time": "2024-07-13T22:02:05.007699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"class MLP(RegressorMixin):\\n    def __init__(self):\\n        self.model = self.get_model()\\n        self.batch_size = 16\\n        self.epochs = 300\\n        self.verbose = 0\\n\\n    def fit(self, X=None, y=None):\\n        self.model.fit(\\n            X, y, batch_size=self.batch_size, epochs=self.epochs, verbose=self.verbose\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            # optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP(RegressorMixin):\\n    def __init__(self):\\n        self.model = self.get_model()\\n        self.batch_size = 16\\n        self.epochs = 300\\n        self.verbose = 0\\n\\n    def fit(self, X=None, y=None):\\n        self.model.fit(\\n            X, y, batch_size=self.batch_size, epochs=self.epochs, verbose=self.verbose\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            # optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP(RegressorMixin):\n",
    "    def __init__(self):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 16\n",
    "        self.epochs = 300\n",
    "        self.verbose = 0\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.model.fit(\n",
    "            X, y, batch_size=self.batch_size, epochs=self.epochs, verbose=self.verbose\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            # optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf9dee9",
   "metadata": {
    "papermill": {
     "duration": 0.017691,
     "end_time": "2024-07-13T22:02:05.253256",
     "exception": false,
     "start_time": "2024-07-13T22:02:05.235565",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8730500",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:02:05.323348Z",
     "iopub.status.busy": "2024-07-13T22:02:05.322480Z",
     "iopub.status.idle": "2024-07-13T22:02:05.469362Z",
     "shell.execute_reply": "2024-07-13T22:02:05.467378Z"
    },
    "papermill": {
     "duration": 0.18756,
     "end_time": "2024-07-13T22:02:05.472711",
     "exception": false,
     "start_time": "2024-07-13T22:02:05.285151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b5058a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:02:05.514646Z",
     "iopub.status.busy": "2024-07-13T22:02:05.513723Z",
     "iopub.status.idle": "2024-07-13T22:02:05.665316Z",
     "shell.execute_reply": "2024-07-13T22:02:05.663215Z"
    },
    "papermill": {
     "duration": 0.176085,
     "end_time": "2024-07-13T22:02:05.668500",
     "exception": false,
     "start_time": "2024-07-13T22:02:05.492415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdd8477",
   "metadata": {
    "papermill": {
     "duration": 0.020862,
     "end_time": "2024-07-13T22:02:05.713724",
     "exception": false,
     "start_time": "2024-07-13T22:02:05.692862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4270cb47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:02:05.758361Z",
     "iopub.status.busy": "2024-07-13T22:02:05.757026Z",
     "iopub.status.idle": "2024-07-13T22:02:05.868568Z",
     "shell.execute_reply": "2024-07-13T22:02:05.866999Z"
    },
    "papermill": {
     "duration": 0.140293,
     "end_time": "2024-07-13T22:02:05.871445",
     "exception": false,
     "start_time": "2024-07-13T22:02:05.731152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Local Model\\\",\\n    \\\"Company\\\": \\\"partner_i\\\",\\n    \\\"Features\\\": \\\"Chemical + Mineralogical + Physical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Local Model\\\",\\n    \\\"Company\\\": \\\"partner_i\\\",\\n    \\\"Features\\\": \\\"Chemical + Mineralogical + Physical\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Local Model\",\n",
    "    \"Company\": \"partner_i\",\n",
    "    \"Features\": \"Chemical + Mineralogical + Physical\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06be557",
   "metadata": {
    "papermill": {
     "duration": 0.022531,
     "end_time": "2024-07-13T22:02:05.916959",
     "exception": false,
     "start_time": "2024-07-13T22:02:05.894428",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b81a6af6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:02:05.978034Z",
     "iopub.status.busy": "2024-07-13T22:02:05.976748Z",
     "iopub.status.idle": "2024-07-13T22:02:06.156314Z",
     "shell.execute_reply": "2024-07-13T22:02:06.154636Z"
    },
    "papermill": {
     "duration": 0.215162,
     "end_time": "2024-07-13T22:02:06.159077",
     "exception": false,
     "start_time": "2024-07-13T22:02:05.943915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../data/processed/partner_i-Oficial/cement-shipping.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\n    \\\"../../../../../../data/processed/partner_i-Oficial/cement-shipping.csv\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../data/processed/partner_i-Oficial/cement-shipping.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7025abbf",
   "metadata": {
    "papermill": {
     "duration": 0.018944,
     "end_time": "2024-07-13T22:02:06.197852",
     "exception": false,
     "start_time": "2024-07-13T22:02:06.178908",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ead7bab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:02:06.247332Z",
     "iopub.status.busy": "2024-07-13T22:02:06.246469Z",
     "iopub.status.idle": "2024-07-13T22:02:06.266956Z",
     "shell.execute_reply": "2024-07-13T22:02:06.265713Z"
    },
    "papermill": {
     "duration": 0.040254,
     "end_time": "2024-07-13T22:02:06.269911",
     "exception": false,
     "start_time": "2024-07-13T22:02:06.229657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"df_copy = df.drop(\\n    [  # Removing One-Hot encoding variables\\n        \\\"Cement_Type\\\",\\n        \\n    ],\\n    axis=1,\\n).copy()\";\n",
       "                var nbb_formatted_code = \"df_copy = df.drop(\\n    [  # Removing One-Hot encoding variables\\n        \\\"Cement_Type\\\",\\n    ],\\n    axis=1,\\n).copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.drop(\n",
    "    [  # Removing One-Hot encoding variables\n",
    "        \"Cement_Type\",\n",
    "        \n",
    "    ],\n",
    "    axis=1,\n",
    ").copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c25e39",
   "metadata": {
    "papermill": {
     "duration": 0.017071,
     "end_time": "2024-07-13T22:02:06.307770",
     "exception": false,
     "start_time": "2024-07-13T22:02:06.290699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2>1. Dataset: df_copy</h2> <br>In this dataset all features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f1335cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:02:06.372394Z",
     "iopub.status.busy": "2024-07-13T22:02:06.371136Z",
     "iopub.status.idle": "2024-07-13T22:02:06.477710Z",
     "shell.execute_reply": "2024-07-13T22:02:06.475951Z"
    },
    "papermill": {
     "duration": 0.1342,
     "end_time": "2024-07-13T22:02:06.481231",
     "exception": false,
     "start_time": "2024-07-13T22:02:06.347031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff71ca5",
   "metadata": {
    "papermill": {
     "duration": 0.024289,
     "end_time": "2024-07-13T22:02:06.529143",
     "exception": false,
     "start_time": "2024-07-13T22:02:06.504854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8a38d5",
   "metadata": {
    "papermill": {
     "duration": 0.029411,
     "end_time": "2024-07-13T22:02:06.592306",
     "exception": false,
     "start_time": "2024-07-13T22:02:06.562895",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.1 Repeated KFold Cross validation\n",
    "\n",
    "<b>Dataset shape:</b> (1234, 37)<br>\n",
    "<b>Repeats:</b>10<br>\n",
    "<b>Splits:</b>5<br>\n",
    "    1. 5 folds of 246 samples each\n",
    "    2. 80% train (988 samples each fold)\n",
    "    3. 20% test (246 samples each fold)\n",
    "<b>Total:</b> 100 models<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54c03dbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:02:06.661740Z",
     "iopub.status.busy": "2024-07-13T22:02:06.660936Z",
     "iopub.status.idle": "2024-07-13T22:10:08.639034Z",
     "shell.execute_reply": "2024-07-13T22:10:08.637965Z"
    },
    "papermill": {
     "duration": 482.034059,
     "end_time": "2024-07-13T22:10:08.653118",
     "exception": false,
     "start_time": "2024-07-13T22:02:06.619059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 19:02:06.781540: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-07-13 19:02:06.781586: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: inspirada\n",
      "2024-07-13 19:02:06.781594: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: inspirada\n",
      "2024-07-13 19:02:06.781816: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 535.183.1\n",
      "2024-07-13 19:02:06.781849: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.183.1\n",
      "2024-07-13 19:02:06.781854: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 535.183.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated Cross Validation:\n",
      "Repeats: 3\n",
      "n_splits: 5\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: -1.097 (0.057)\n",
      "MAE: -0.866 (0.047)\n",
      "MAPE: -0.020 (0.001)\n",
      "R2: 0.953 (0.005)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: -1.187 (0.096)\n",
      "MAE: -0.924 (0.075)\n",
      "MAPE: -0.021 (0.002)\n",
      "R2: 0.944 (0.008)\n",
      "\n",
      "======================\n",
      "\n",
      "Minutes Elapsed:  8.031782738367717\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nstart = time.time()\\n\\nrepeats = 3\\nn_splits = 5\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP()),\\n    ]\\n)\\ncv = RepeatedKFold(n_splits=n_splits, n_repeats=repeats, random_state=SEED)\\nscores = cross_validate(\\n    pipeline,\\n    x,\\n    y,\\n    scoring=METRICS,\\n    cv=cv,\\n    n_jobs=1,\\n    return_train_score=True,\\n)\\nprint(\\\"Repeated Cross Validation:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Repeated KFold\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nstart = time.time()\\n\\nrepeats = 3\\nn_splits = 5\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP()),\\n    ]\\n)\\ncv = RepeatedKFold(n_splits=n_splits, n_repeats=repeats, random_state=SEED)\\nscores = cross_validate(\\n    pipeline,\\n    x,\\n    y,\\n    scoring=METRICS,\\n    cv=cv,\\n    n_jobs=1,\\n    return_train_score=True,\\n)\\nprint(\\\"Repeated Cross Validation:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Repeated KFold\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "start = time.time()\n",
    "\n",
    "repeats = 3\n",
    "n_splits = 5\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP()),\n",
    "    ]\n",
    ")\n",
    "cv = RepeatedKFold(n_splits=n_splits, n_repeats=repeats, random_state=SEED)\n",
    "scores = cross_validate(\n",
    "    pipeline,\n",
    "    x,\n",
    "    y,\n",
    "    scoring=METRICS,\n",
    "    cv=cv,\n",
    "    n_jobs=1,\n",
    "    return_train_score=True,\n",
    ")\n",
    "print(\"Repeated Cross Validation:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"n_splits: {n_splits}\")\n",
    "print()\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Repeated KFold\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"N_Splits\": 5, \"Repeats\": 3}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3591a687",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:10:08.680865Z",
     "iopub.status.busy": "2024-07-13T22:10:08.680342Z",
     "iopub.status.idle": "2024-07-13T22:10:08.733278Z",
     "shell.execute_reply": "2024-07-13T22:10:08.732041Z"
    },
    "papermill": {
     "duration": 0.069304,
     "end_time": "2024-07-13T22:10:08.735304",
     "exception": false,
     "start_time": "2024-07-13T22:10:08.666000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th>Timesteps</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RMSE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAPE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R2 Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chemical + Mineralogical + Physical</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.187407</td>\n",
       "      <td>0.095578</td>\n",
       "      <td>0.924239</td>\n",
       "      <td>0.075126</td>\n",
       "      <td>0.021415</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.944114</td>\n",
       "      <td>0.007868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Features Model Cross Validation Timesteps  \\\n",
       "                                                                          \n",
       "0  Chemical + Mineralogical + Physical   MLP   Repeated KFold       NaN   \n",
       "\n",
       "  RMSE Test            MAE Test           MAPE Test             R2 Test  \\\n",
       "       mean       std      mean       std      mean       std      mean   \n",
       "0  1.187407  0.095578  0.924239  0.075126  0.021415  0.001905  0.944114   \n",
       "\n",
       "             \n",
       "        std  \n",
       "0  0.007868  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Timesteps\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_formatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Timesteps\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat(results_to_save).reset_index().groupby(\n",
    "    [\"Features\", \"Model\", \"Cross Validation\", \"Timesteps\"], dropna=False\n",
    ")[[\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]].agg(\n",
    "    [\"mean\", lambda series: pd.Series(series.std(ddof=0), name=\"std\")]\n",
    ").reset_index().rename(\n",
    "    columns={\"<lambda_0>\": \"std\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc249a",
   "metadata": {
    "papermill": {
     "duration": 0.015122,
     "end_time": "2024-07-13T22:10:08.763889",
     "exception": false,
     "start_time": "2024-07-13T22:10:08.748767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.2. Blocking Time Series Cross Validation\n",
    "\n",
    "<b>Dataset shape:</b> (1234, 38)<br>\n",
    "<b>Splits:</b>5<br>    \n",
    "    1. 5 folds of 246 samples\n",
    "    2. 50% train (123 samples each fold)\n",
    "    3. 50% test (123 samples each fold)\n",
    "<b>Total:</b> 5 models<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5488f34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:10:08.809115Z",
     "iopub.status.busy": "2024-07-13T22:10:08.808588Z",
     "iopub.status.idle": "2024-07-13T22:12:12.408722Z",
     "shell.execute_reply": "2024-07-13T22:12:12.406697Z"
    },
    "papermill": {
     "duration": 123.671821,
     "end_time": "2024-07-13T22:12:12.450268",
     "exception": false,
     "start_time": "2024-07-13T22:10:08.778447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocking Time Series Split:\n",
      "Repeats: 3\n",
      "n_splits: 5\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: -3.552 (0.427)\n",
      "MAE: -2.804 (0.330)\n",
      "MAPE: -0.065 (0.007)\n",
      "R2: 0.497 (0.127)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: -6.289 (0.845)\n",
      "MAE: -4.969 (0.769)\n",
      "MAPE: -0.116 (0.018)\n",
      "R2: -0.644 (0.340)\n",
      "\n",
      "======================\n",
      "\n",
      "Minutes Elapsed:  2.0564977407455443\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nstart = time.time()\\n\\nrepeats = 3\\nn_splits = 5\\ntrain_size = 0.8\\nscores_final = None\\n\\nfor _ in range(repeats):\\n    pipeline = Pipeline(\\n        [\\n            (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n            (\\\"transformer\\\", StandardScaler()),\\n            (\\\"estimator\\\", MLP()),\\n        ]\\n    )\\n    cv = BlockingTimeSeriesSplit(n_splits=n_splits, train_size=train_size)\\n    scores = cross_validate(\\n        pipeline,\\n        x,\\n        y,\\n        scoring=METRICS,\\n        cv=cv,\\n        # n_jobs=None,\\n        return_train_score=True,\\n    )\\n    if scores_final is None:\\n        scores_final = {key: [] for key, _ in scores.items()}\\n\\n    for key, value in scores.items():\\n        scores_final[key] += [value]\\n\\n\\nprint(\\\"Blocking Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\nprint_scores(scores_final, METRICS, METRICS_DICT)\\n\\nscores = {key: np.array(val).flatten() for key, val in scores_final.items()}\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Blocking Time Series Split\\\"\\nresults_dict_copy[\\n    \\\"Cross Validation Params\\\"\\n] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3, \\\"train_size\\\": 0.8}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nstart = time.time()\\n\\nrepeats = 3\\nn_splits = 5\\ntrain_size = 0.8\\nscores_final = None\\n\\nfor _ in range(repeats):\\n    pipeline = Pipeline(\\n        [\\n            (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n            (\\\"transformer\\\", StandardScaler()),\\n            (\\\"estimator\\\", MLP()),\\n        ]\\n    )\\n    cv = BlockingTimeSeriesSplit(n_splits=n_splits, train_size=train_size)\\n    scores = cross_validate(\\n        pipeline,\\n        x,\\n        y,\\n        scoring=METRICS,\\n        cv=cv,\\n        # n_jobs=None,\\n        return_train_score=True,\\n    )\\n    if scores_final is None:\\n        scores_final = {key: [] for key, _ in scores.items()}\\n\\n    for key, value in scores.items():\\n        scores_final[key] += [value]\\n\\n\\nprint(\\\"Blocking Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\nprint_scores(scores_final, METRICS, METRICS_DICT)\\n\\nscores = {key: np.array(val).flatten() for key, val in scores_final.items()}\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Blocking Time Series Split\\\"\\nresults_dict_copy[\\n    \\\"Cross Validation Params\\\"\\n] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3, \\\"train_size\\\": 0.8}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "start = time.time()\n",
    "\n",
    "repeats = 3\n",
    "n_splits = 5\n",
    "train_size = 0.8\n",
    "scores_final = None\n",
    "\n",
    "for _ in range(repeats):\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"transformer\", StandardScaler()),\n",
    "            (\"estimator\", MLP()),\n",
    "        ]\n",
    "    )\n",
    "    cv = BlockingTimeSeriesSplit(n_splits=n_splits, train_size=train_size)\n",
    "    scores = cross_validate(\n",
    "        pipeline,\n",
    "        x,\n",
    "        y,\n",
    "        scoring=METRICS,\n",
    "        cv=cv,\n",
    "        # n_jobs=None,\n",
    "        return_train_score=True,\n",
    "    )\n",
    "    if scores_final is None:\n",
    "        scores_final = {key: [] for key, _ in scores.items()}\n",
    "\n",
    "    for key, value in scores.items():\n",
    "        scores_final[key] += [value]\n",
    "\n",
    "\n",
    "print(\"Blocking Time Series Split:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"n_splits: {n_splits}\")\n",
    "print()\n",
    "print_scores(scores_final, METRICS, METRICS_DICT)\n",
    "\n",
    "scores = {key: np.array(val).flatten() for key, val in scores_final.items()}\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Blocking Time Series Split\"\n",
    "results_dict_copy[\n",
    "    \"Cross Validation Params\"\n",
    "] = '{\"N_Splits\": 5, \"Repeats\": 3, \"train_size\": 0.8}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8673485e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:12:12.498750Z",
     "iopub.status.busy": "2024-07-13T22:12:12.498064Z",
     "iopub.status.idle": "2024-07-13T22:12:12.568613Z",
     "shell.execute_reply": "2024-07-13T22:12:12.567474Z"
    },
    "papermill": {
     "duration": 0.093483,
     "end_time": "2024-07-13T22:12:12.570604",
     "exception": false,
     "start_time": "2024-07-13T22:12:12.477121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RMSE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAPE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R2 Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chemical + Mineralogical + Physical</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Blocking Time Series Split</td>\n",
       "      <td>6.288996</td>\n",
       "      <td>0.845163</td>\n",
       "      <td>4.969017</td>\n",
       "      <td>0.769403</td>\n",
       "      <td>0.116256</td>\n",
       "      <td>0.018108</td>\n",
       "      <td>-0.644155</td>\n",
       "      <td>0.339835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chemical + Mineralogical + Physical</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>1.187407</td>\n",
       "      <td>0.095578</td>\n",
       "      <td>0.924239</td>\n",
       "      <td>0.075126</td>\n",
       "      <td>0.021415</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.944114</td>\n",
       "      <td>0.007868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Features Model            Cross Validation  \\\n",
       "                                                                           \n",
       "0  Chemical + Mineralogical + Physical   MLP  Blocking Time Series Split   \n",
       "1  Chemical + Mineralogical + Physical   MLP              Repeated KFold   \n",
       "\n",
       "  RMSE Test            MAE Test           MAPE Test             R2 Test  \\\n",
       "       mean       std      mean       std      mean       std      mean   \n",
       "0  6.288996  0.845163  4.969017  0.769403  0.116256  0.018108 -0.644155   \n",
       "1  1.187407  0.095578  0.924239  0.075126  0.021415  0.001905  0.944114   \n",
       "\n",
       "             \n",
       "        std  \n",
       "0  0.339835  \n",
       "1  0.007868  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_formatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat(results_to_save).reset_index().groupby(\n",
    "    [\"Features\", \"Model\", \"Cross Validation\"], dropna=False\n",
    ")[[\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]].agg(\n",
    "    [\"mean\", lambda series: pd.Series(series.std(ddof=0), name=\"std\")]\n",
    ").reset_index().rename(\n",
    "    columns={\"<lambda_0>\": \"std\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c06000",
   "metadata": {
    "papermill": {
     "duration": 0.014431,
     "end_time": "2024-07-13T22:12:12.600849",
     "exception": false,
     "start_time": "2024-07-13T22:12:12.586418",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.3. Time Series Split Cross Validation\n",
    "\n",
    "The training set has size i * n_samples // (n_splits + 1) + n_samples % (n_splits + 1) in the i th split, with a test set of size n_samples//(n_splits + 1) by default, where n_samples is the number of samples.\n",
    "\n",
    "\n",
    "<b>Dataset shape:</b> (1234, 38)<br>\n",
    "<b>Splits:</b>10<br>    \n",
    "    1. Train: 10 folds of 114, 226, 338, 450, 562, 675, 787, 899, 1011, 1123 samples each fold\n",
    "    2. Test: 112 samples each fold\n",
    "<b>Total:</b> 10 models<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de60bac9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:12:12.662263Z",
     "iopub.status.busy": "2024-07-13T22:12:12.661546Z",
     "iopub.status.idle": "2024-07-13T22:17:27.902131Z",
     "shell.execute_reply": "2024-07-13T22:17:27.900409Z"
    },
    "papermill": {
     "duration": 315.296816,
     "end_time": "2024-07-13T22:17:27.939319",
     "exception": false,
     "start_time": "2024-07-13T22:12:12.642503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocking Time Series Split:\n",
      "Repeats: 3\n",
      "n_splits: 5\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: -1.932 (0.958)\n",
      "MAE: -1.524 (0.762)\n",
      "MAPE: -0.036 (0.018)\n",
      "R2: 0.805 (0.201)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: -3.829 (2.946)\n",
      "MAE: -2.924 (2.143)\n",
      "MAPE: -0.069 (0.051)\n",
      "R2: 0.058 (1.375)\n",
      "\n",
      "======================\n",
      "\n",
      "Minutes Elapsed:  5.2519904255867\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nstart = time.time()\\n\\nscores_final = None\\nrepeats = 3\\nn_splits = 5\\ngap = 0\\n\\nfor _ in range(repeats):\\n    pipeline = Pipeline(\\n        [\\n            (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n            (\\\"transformer\\\", StandardScaler()),\\n            (\\\"estimator\\\", MLP()),\\n        ]\\n    )\\n    cv = TimeSeriesSplit(gap=gap, max_train_size=None, n_splits=n_splits)\\n\\n    scores = cross_validate(\\n        pipeline,\\n        x,\\n        y,\\n        scoring=METRICS,\\n        cv=cv,\\n        # n_jobs=-1,\\n        return_train_score=True,\\n    )\\n    if scores_final is None:\\n        scores_final = {key: [] for key, _ in scores.items()}\\n    for key, value in scores.items():\\n        scores_final[key] += [value]\\n\\nprint(\\\"Blocking Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\nprint_scores(scores_final, METRICS, METRICS_DICT)\\n\\n# Saving the results\\nscores = {key: np.array(val).flatten() for key, val in scores_final.items()}\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Time Series Split\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3, \\\"Gap\\\": 0}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nstart = time.time()\\n\\nscores_final = None\\nrepeats = 3\\nn_splits = 5\\ngap = 0\\n\\nfor _ in range(repeats):\\n    pipeline = Pipeline(\\n        [\\n            (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n            (\\\"transformer\\\", StandardScaler()),\\n            (\\\"estimator\\\", MLP()),\\n        ]\\n    )\\n    cv = TimeSeriesSplit(gap=gap, max_train_size=None, n_splits=n_splits)\\n\\n    scores = cross_validate(\\n        pipeline,\\n        x,\\n        y,\\n        scoring=METRICS,\\n        cv=cv,\\n        # n_jobs=-1,\\n        return_train_score=True,\\n    )\\n    if scores_final is None:\\n        scores_final = {key: [] for key, _ in scores.items()}\\n    for key, value in scores.items():\\n        scores_final[key] += [value]\\n\\nprint(\\\"Blocking Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\nprint_scores(scores_final, METRICS, METRICS_DICT)\\n\\n# Saving the results\\nscores = {key: np.array(val).flatten() for key, val in scores_final.items()}\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Time Series Split\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3, \\\"Gap\\\": 0}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "start = time.time()\n",
    "\n",
    "scores_final = None\n",
    "repeats = 3\n",
    "n_splits = 5\n",
    "gap = 0\n",
    "\n",
    "for _ in range(repeats):\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"transformer\", StandardScaler()),\n",
    "            (\"estimator\", MLP()),\n",
    "        ]\n",
    "    )\n",
    "    cv = TimeSeriesSplit(gap=gap, max_train_size=None, n_splits=n_splits)\n",
    "\n",
    "    scores = cross_validate(\n",
    "        pipeline,\n",
    "        x,\n",
    "        y,\n",
    "        scoring=METRICS,\n",
    "        cv=cv,\n",
    "        # n_jobs=-1,\n",
    "        return_train_score=True,\n",
    "    )\n",
    "    if scores_final is None:\n",
    "        scores_final = {key: [] for key, _ in scores.items()}\n",
    "    for key, value in scores.items():\n",
    "        scores_final[key] += [value]\n",
    "\n",
    "print(\"Blocking Time Series Split:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"n_splits: {n_splits}\")\n",
    "print()\n",
    "print_scores(scores_final, METRICS, METRICS_DICT)\n",
    "\n",
    "# Saving the results\n",
    "scores = {key: np.array(val).flatten() for key, val in scores_final.items()}\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Time Series Split\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"N_Splits\": 5, \"Repeats\": 3, \"Gap\": 0}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0b97be2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:17:27.991900Z",
     "iopub.status.busy": "2024-07-13T22:17:27.991488Z",
     "iopub.status.idle": "2024-07-13T22:17:28.064770Z",
     "shell.execute_reply": "2024-07-13T22:17:28.063155Z"
    },
    "papermill": {
     "duration": 0.101395,
     "end_time": "2024-07-13T22:17:28.067005",
     "exception": false,
     "start_time": "2024-07-13T22:17:27.965610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RMSE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAPE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R2 Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chemical + Mineralogical + Physical</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Blocking Time Series Split</td>\n",
       "      <td>6.288996</td>\n",
       "      <td>0.845163</td>\n",
       "      <td>4.969017</td>\n",
       "      <td>0.769403</td>\n",
       "      <td>0.116256</td>\n",
       "      <td>0.018108</td>\n",
       "      <td>-0.644155</td>\n",
       "      <td>0.339835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chemical + Mineralogical + Physical</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>1.187407</td>\n",
       "      <td>0.095578</td>\n",
       "      <td>0.924239</td>\n",
       "      <td>0.075126</td>\n",
       "      <td>0.021415</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.944114</td>\n",
       "      <td>0.007868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chemical + Mineralogical + Physical</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Time Series Split</td>\n",
       "      <td>3.828779</td>\n",
       "      <td>2.946002</td>\n",
       "      <td>2.923995</td>\n",
       "      <td>2.142933</td>\n",
       "      <td>0.068667</td>\n",
       "      <td>0.050860</td>\n",
       "      <td>0.057774</td>\n",
       "      <td>1.375247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Features Model            Cross Validation  \\\n",
       "                                                                           \n",
       "0  Chemical + Mineralogical + Physical   MLP  Blocking Time Series Split   \n",
       "1  Chemical + Mineralogical + Physical   MLP              Repeated KFold   \n",
       "2  Chemical + Mineralogical + Physical   MLP           Time Series Split   \n",
       "\n",
       "  RMSE Test            MAE Test           MAPE Test             R2 Test  \\\n",
       "       mean       std      mean       std      mean       std      mean   \n",
       "0  6.288996  0.845163  4.969017  0.769403  0.116256  0.018108 -0.644155   \n",
       "1  1.187407  0.095578  0.924239  0.075126  0.021415  0.001905  0.944114   \n",
       "2  3.828779  2.946002  2.923995  2.142933  0.068667  0.050860  0.057774   \n",
       "\n",
       "             \n",
       "        std  \n",
       "0  0.339835  \n",
       "1  0.007868  \n",
       "2  1.375247  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_formatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat(results_to_save).reset_index().groupby(\n",
    "    [\"Features\", \"Model\", \"Cross Validation\"], dropna=False\n",
    ")[[\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]].agg(\n",
    "    [\"mean\", lambda series: pd.Series(series.std(ddof=0), name=\"std\")]\n",
    ").reset_index().rename(\n",
    "    columns={\"<lambda_0>\": \"std\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37516287",
   "metadata": {
    "papermill": {
     "duration": 0.015247,
     "end_time": "2024-07-13T22:17:28.099695",
     "exception": false,
     "start_time": "2024-07-13T22:17:28.084448",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.4. Out of time Split Cross Validation\n",
    "\n",
    "<b>Dataset shape:</b> (1234, 38)<br>\n",
    "<b>Train size: 80%</b><br>\n",
    "<b>Test  size: 20%</b>\n",
    "\n",
    "\n",
    "<b>Splits:</b> 2<br>    \n",
    "    1. Train: 987\n",
    "    2. Test: 247\n",
    "<b>Total:</b> 1 model<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c900489a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:17:28.146523Z",
     "iopub.status.busy": "2024-07-13T22:17:28.145961Z",
     "iopub.status.idle": "2024-07-13T22:19:00.958067Z",
     "shell.execute_reply": "2024-07-13T22:19:00.956556Z"
    },
    "papermill": {
     "duration": 92.884575,
     "end_time": "2024-07-13T22:19:01.002705",
     "exception": false,
     "start_time": "2024-07-13T22:17:28.118130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of time Cross Val:\n",
      "Repeats: 3\n",
      "Train: 80% Test: 20%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.045 (0.028)\n",
      "MAE: 0.815 (0.021)\n",
      "MAPE: 0.019 (0.000)\n",
      "R2: 0.957 (0.002)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 1.277 (0.010)\n",
      "MAE: 1.020 (0.007)\n",
      "MAPE: 0.024 (0.000)\n",
      "R2: 0.934 (0.001)\n",
      "\n",
      "======================\n",
      "\n",
      "Minutes Elapsed:  1.543573053677877\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nstart = time.time()\\n\\ntest_size = 0.2\\nrepeats = 3\\nscores_final = None\\n\\nprint(\\\"Out of time Cross Val:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"Train: {80}%\\\", f\\\"Test: {20}%\\\")\\nprint()\\n\\n\\nfor _ in range(repeats):\\n    x_train, x_test, y_train, y_test = train_test_split(\\n        x, y, test_size=test_size, random_state=SEED, shuffle=False\\n    )\\n\\n    pipeline = Pipeline(\\n        [\\n            (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n            (\\\"transformer\\\", StandardScaler()),\\n            (\\\"estimator\\\", MLP()),\\n        ]\\n    )\\n\\n    pipeline.fit(x_train, y_train)\\n\\n    y_train_pred = pipeline.predict(x_train)\\n    y_test_pred = pipeline.predict(x_test)\\n\\n    scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\\n\\n    if scores_final is None:\\n        scores_final = {key: [] for key, _ in scores.items()}\\n\\n    for key, value in scores.items():\\n        scores_final[key] += [value]\\n\\n# Saving the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time Split\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"Test Size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(\\n    results_dict_copy, {key: value for key, value in scores_final.items()}\\n)\\nresults_to_save.append(df_results)\\n\\nprint_scores(scores_final, METRICS, METRICS_DICT)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nstart = time.time()\\n\\ntest_size = 0.2\\nrepeats = 3\\nscores_final = None\\n\\nprint(\\\"Out of time Cross Val:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"Train: {80}%\\\", f\\\"Test: {20}%\\\")\\nprint()\\n\\n\\nfor _ in range(repeats):\\n    x_train, x_test, y_train, y_test = train_test_split(\\n        x, y, test_size=test_size, random_state=SEED, shuffle=False\\n    )\\n\\n    pipeline = Pipeline(\\n        [\\n            (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n            (\\\"transformer\\\", StandardScaler()),\\n            (\\\"estimator\\\", MLP()),\\n        ]\\n    )\\n\\n    pipeline.fit(x_train, y_train)\\n\\n    y_train_pred = pipeline.predict(x_train)\\n    y_test_pred = pipeline.predict(x_test)\\n\\n    scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\\n\\n    if scores_final is None:\\n        scores_final = {key: [] for key, _ in scores.items()}\\n\\n    for key, value in scores.items():\\n        scores_final[key] += [value]\\n\\n# Saving the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time Split\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"Test Size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(\\n    results_dict_copy, {key: value for key, value in scores_final.items()}\\n)\\nresults_to_save.append(df_results)\\n\\nprint_scores(scores_final, METRICS, METRICS_DICT)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "start = time.time()\n",
    "\n",
    "test_size = 0.2\n",
    "repeats = 3\n",
    "scores_final = None\n",
    "\n",
    "print(\"Out of time Cross Val:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"Train: {80}%\", f\"Test: {20}%\")\n",
    "print()\n",
    "\n",
    "\n",
    "for _ in range(repeats):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=test_size, random_state=SEED, shuffle=False\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"transformer\", StandardScaler()),\n",
    "            (\"estimator\", MLP()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipeline.fit(x_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(x_train)\n",
    "    y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "    scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\n",
    "\n",
    "    if scores_final is None:\n",
    "        scores_final = {key: [] for key, _ in scores.items()}\n",
    "\n",
    "    for key, value in scores.items():\n",
    "        scores_final[key] += [value]\n",
    "\n",
    "# Saving the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time Split\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"Test Size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "df_results = fill_results_dict(\n",
    "    results_dict_copy, {key: value for key, value in scores_final.items()}\n",
    ")\n",
    "results_to_save.append(df_results)\n",
    "\n",
    "print_scores(scores_final, METRICS, METRICS_DICT)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bf62bdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:19:01.052429Z",
     "iopub.status.busy": "2024-07-13T22:19:01.052071Z",
     "iopub.status.idle": "2024-07-13T22:19:01.106881Z",
     "shell.execute_reply": "2024-07-13T22:19:01.106037Z"
    },
    "papermill": {
     "duration": 0.077611,
     "end_time": "2024-07-13T22:19:01.109146",
     "exception": false,
     "start_time": "2024-07-13T22:19:01.031535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RMSE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAPE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R2 Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chemical + Mineralogical + Physical</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Blocking Time Series Split</td>\n",
       "      <td>6.288996</td>\n",
       "      <td>0.845163</td>\n",
       "      <td>4.969017</td>\n",
       "      <td>0.769403</td>\n",
       "      <td>0.116256</td>\n",
       "      <td>0.018108</td>\n",
       "      <td>-0.644155</td>\n",
       "      <td>0.339835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chemical + Mineralogical + Physical</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Out of time Split</td>\n",
       "      <td>1.276626</td>\n",
       "      <td>0.009603</td>\n",
       "      <td>1.019811</td>\n",
       "      <td>0.007371</td>\n",
       "      <td>0.023555</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.934155</td>\n",
       "      <td>0.000991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chemical + Mineralogical + Physical</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>1.187407</td>\n",
       "      <td>0.095578</td>\n",
       "      <td>0.924239</td>\n",
       "      <td>0.075126</td>\n",
       "      <td>0.021415</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.944114</td>\n",
       "      <td>0.007868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chemical + Mineralogical + Physical</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Time Series Split</td>\n",
       "      <td>3.828779</td>\n",
       "      <td>2.946002</td>\n",
       "      <td>2.923995</td>\n",
       "      <td>2.142933</td>\n",
       "      <td>0.068667</td>\n",
       "      <td>0.050860</td>\n",
       "      <td>0.057774</td>\n",
       "      <td>1.375247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Features Model            Cross Validation  \\\n",
       "                                                                           \n",
       "0  Chemical + Mineralogical + Physical   MLP  Blocking Time Series Split   \n",
       "1  Chemical + Mineralogical + Physical   MLP           Out of time Split   \n",
       "2  Chemical + Mineralogical + Physical   MLP              Repeated KFold   \n",
       "3  Chemical + Mineralogical + Physical   MLP           Time Series Split   \n",
       "\n",
       "  RMSE Test            MAE Test           MAPE Test             R2 Test  \\\n",
       "       mean       std      mean       std      mean       std      mean   \n",
       "0  6.288996  0.845163  4.969017  0.769403  0.116256  0.018108 -0.644155   \n",
       "1  1.276626  0.009603  1.019811  0.007371  0.023555  0.000208  0.934155   \n",
       "2  1.187407  0.095578  0.924239  0.075126  0.021415  0.001905  0.944114   \n",
       "3  3.828779  2.946002  2.923995  2.142933  0.068667  0.050860  0.057774   \n",
       "\n",
       "             \n",
       "        std  \n",
       "0  0.339835  \n",
       "1  0.000991  \n",
       "2  0.007868  \n",
       "3  1.375247  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_formatted_code = \"pd.concat(results_to_save).reset_index().groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\"], dropna=False\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat(results_to_save).reset_index().groupby(\n",
    "    [\"Features\", \"Model\", \"Cross Validation\"], dropna=False\n",
    ")[[\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]].agg(\n",
    "    [\"mean\", lambda series: pd.Series(series.std(ddof=0), name=\"std\")]\n",
    ").reset_index().rename(\n",
    "    columns={\"<lambda_0>\": \"std\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3e487f",
   "metadata": {
    "papermill": {
     "duration": 0.022725,
     "end_time": "2024-07-13T22:19:01.155224",
     "exception": false,
     "start_time": "2024-07-13T22:19:01.132499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Saving the results Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1c6dfe",
   "metadata": {
    "papermill": {
     "duration": 0.019367,
     "end_time": "2024-07-13T22:19:01.220353",
     "exception": false,
     "start_time": "2024-07-13T22:19:01.200986",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Saving the full dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bf8d03f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:19:01.260314Z",
     "iopub.status.busy": "2024-07-13T22:19:01.259501Z",
     "iopub.status.idle": "2024-07-13T22:19:01.289627Z",
     "shell.execute_reply": "2024-07-13T22:19:01.287999Z"
    },
    "papermill": {
     "duration": 0.053683,
     "end_time": "2024-07-13T22:19:01.291985",
     "exception": false,
     "start_time": "2024-07-13T22:19:01.238302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"path = (\\n    \\\"../../../../../../reports/results/local_models/partner_i-oficial/all_cements/full/\\\"\\n)\\nfilename = \\\"mlp_results_full_7.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = \\\"../../../../../../reports/results/local_models/partner_i-oficial/all_cements/full/\\\"\\nfilename = \\\"mlp_results_full_7.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = (\n",
    "    \"../../../../../../reports/results/local_models/partner_i-oficial/all_cements/full/\"\n",
    ")\n",
    "filename = \"mlp_results_full_7.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1dabf943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T22:19:01.326985Z",
     "iopub.status.busy": "2024-07-13T22:19:01.325451Z",
     "iopub.status.idle": "2024-07-13T22:19:01.511043Z",
     "shell.execute_reply": "2024-07-13T22:19:01.509633Z"
    },
    "papermill": {
     "duration": 0.205491,
     "end_time": "2024-07-13T22:19:01.513646",
     "exception": false,
     "start_time": "2024-07-13T22:19:01.308155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"cols_groupby = [\\n    \\\"Category\\\",\\n    \\\"Company\\\",\\n    \\\"Data Shape\\\",\\n    \\\"Timesteps\\\",\\n    \\\"Features\\\",\\n    \\\"Model\\\",\\n    \\\"Cross Validation\\\",\\n    \\\"Cross Validation Params\\\",\\n]\\n\\ncols_agg = [\\\"RMSE Train\\\", \\\"MAE Train\\\", \\\"MAPE Train\\\", \\\"R2 Train\\\"] + [\\n    \\\"RMSE Test\\\",\\n    \\\"MAE Test\\\",\\n    \\\"MAPE Test\\\",\\n    \\\"R2 Test\\\",\\n]\\n\\npath = \\\"../../../../../../reports/results/local_models/partner_i-oficial/all_cements/grouped/\\\"\\nfilename = \\\"mlp_results_grouped_7.csv\\\"\\n\\n\\ndf_results_to_save = (\\n    pd.concat(results_to_save)\\n    .groupby(cols_groupby, dropna=False)[cols_agg]\\n    .agg([\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")])\\n    .reset_index()\\n    .rename(columns={\\\"<lambda_0>\\\": \\\"std\\\"})\\n)\\n\\ndf_results_to_save.to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,  # header=df_results_to_save.columns\\n)\";\n",
       "                var nbb_formatted_code = \"cols_groupby = [\\n    \\\"Category\\\",\\n    \\\"Company\\\",\\n    \\\"Data Shape\\\",\\n    \\\"Timesteps\\\",\\n    \\\"Features\\\",\\n    \\\"Model\\\",\\n    \\\"Cross Validation\\\",\\n    \\\"Cross Validation Params\\\",\\n]\\n\\ncols_agg = [\\\"RMSE Train\\\", \\\"MAE Train\\\", \\\"MAPE Train\\\", \\\"R2 Train\\\"] + [\\n    \\\"RMSE Test\\\",\\n    \\\"MAE Test\\\",\\n    \\\"MAPE Test\\\",\\n    \\\"R2 Test\\\",\\n]\\n\\npath = \\\"../../../../../../reports/results/local_models/partner_i-oficial/all_cements/grouped/\\\"\\nfilename = \\\"mlp_results_grouped_7.csv\\\"\\n\\n\\ndf_results_to_save = (\\n    pd.concat(results_to_save)\\n    .groupby(cols_groupby, dropna=False)[cols_agg]\\n    .agg([\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")])\\n    .reset_index()\\n    .rename(columns={\\\"<lambda_0>\\\": \\\"std\\\"})\\n)\\n\\ndf_results_to_save.to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,  # header=df_results_to_save.columns\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols_groupby = [\n",
    "    \"Category\",\n",
    "    \"Company\",\n",
    "    \"Data Shape\",\n",
    "    \"Timesteps\",\n",
    "    \"Features\",\n",
    "    \"Model\",\n",
    "    \"Cross Validation\",\n",
    "    \"Cross Validation Params\",\n",
    "]\n",
    "\n",
    "cols_agg = [\"RMSE Train\", \"MAE Train\", \"MAPE Train\", \"R2 Train\"] + [\n",
    "    \"RMSE Test\",\n",
    "    \"MAE Test\",\n",
    "    \"MAPE Test\",\n",
    "    \"R2 Test\",\n",
    "]\n",
    "\n",
    "path = \"../../../../../../reports/results/local_models/partner_i-oficial/all_cements/grouped/\"\n",
    "filename = \"mlp_results_grouped_7.csv\"\n",
    "\n",
    "\n",
    "df_results_to_save = (\n",
    "    pd.concat(results_to_save)\n",
    "    .groupby(cols_groupby, dropna=False)[cols_agg]\n",
    "    .agg([\"mean\", lambda series: pd.Series(series.std(ddof=0), name=\"std\")])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"<lambda_0>\": \"std\"})\n",
    ")\n",
    "\n",
    "df_results_to_save.to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,  # header=df_results_to_save.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b8ba6a",
   "metadata": {
    "papermill": {
     "duration": 0.024087,
     "end_time": "2024-07-13T22:19:01.561164",
     "exception": false,
     "start_time": "2024-07-13T22:19:01.537077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1026.908349,
   "end_time": "2024-07-13T22:19:03.220995",
   "environment_variables": {},
   "exception": null,
   "input_path": "/home/peressim/projects/ccs28-ml-modelling/notebooks/modelling/local_models/partner_i-oficial/mlp/all_cements/full-ds.ipynb",
   "output_path": "/home/peressim/projects/ccs28-ml-modelling/notebooks/modelling/local_models/partner_i-oficial/mlp/all_cements/full-ds.ipynb",
   "parameters": {},
   "start_time": "2024-07-13T22:01:56.312646",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}