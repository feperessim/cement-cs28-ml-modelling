{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105550b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:47:28.806627Z",
     "iopub.status.busy": "2024-07-17T13:47:28.803722Z",
     "iopub.status.idle": "2024-07-17T13:47:28.925871Z",
     "shell.execute_reply": "2024-07-17T13:47:28.925048Z"
    },
    "papermill": {
     "duration": 0.138701,
     "end_time": "2024-07-17T13:47:28.929427",
     "exception": false,
     "start_time": "2024-07-17T13:47:28.790726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d63805e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:47:28.955370Z",
     "iopub.status.busy": "2024-07-17T13:47:28.954864Z",
     "iopub.status.idle": "2024-07-17T13:47:31.699153Z",
     "shell.execute_reply": "2024-07-17T13:47:31.698253Z"
    },
    "papermill": {
     "duration": 2.761304,
     "end_time": "2024-07-17T13:47:31.702839",
     "exception": false,
     "start_time": "2024-07-17T13:47:28.941535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 10:47:30.191482: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-17 10:47:30.193839: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-17 10:47:30.240576: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-17 10:47:30.241664: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 10:47:31.011027: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Plotting\\nimport matplotlib.pyplot as plt\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Processing results\\nimport json\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.model_selection import TimeSeriesSplit\\nfrom sklearn.model_selection import RepeatedKFold\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.model_selection import cross_validate\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.preprocessing import RobustScaler\\n\\n# Metrics\\nfrom sklearn.metrics import mean_squared_error\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.metrics import mean_absolute_percentage_error\\nfrom sklearn.metrics import r2_score\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\";\n",
       "                var nbb_formatted_code = \"# Database Reading and Manipulation\\nimport pandas as pd\\n\\n# Linear Algebra\\nimport numpy as np\\n\\n# Plotting\\nimport matplotlib.pyplot as plt\\n\\n# Time\\nimport time\\n\\n# Random and os for reproducibility\\nimport random\\nimport os\\n\\n# Processing results\\nimport json\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.model_selection import TimeSeriesSplit\\nfrom sklearn.model_selection import RepeatedKFold\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.model_selection import cross_validate\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# Modeling\\nimport tensorflow as tf\\n\\n# Processing\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.preprocessing import RobustScaler\\n\\n# Metrics\\nfrom sklearn.metrics import mean_squared_error\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.metrics import mean_absolute_percentage_error\\nfrom sklearn.metrics import r2_score\\n\\n# Pipeline\\nfrom sklearn.pipeline import Pipeline\\n\\n# Data imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# Making keras compatible with scikit learn api\\n# https://scikit-learn.org/stable/developers/develop.html\\nfrom sklearn.base import RegressorMixin\\n\\n# Custom modules\\n## Model selection\\nfrom src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\\n\\n## Function to print scores\\nfrom src.utils.print_scores import print_scores\\n\\n## Function to calculate score regression metrics\\nfrom src.utils.score_regression_metrics import score_regression_metrics\\n\\n## Function to fill the results metric dict\\nfrom src.utils.fill_results_dict import fill_results_dict\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Random and os for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Processing results\n",
    "import json\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Making keras compatible with scikit learn api\n",
    "# https://scikit-learn.org/stable/developers/develop.html\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "# Custom modules\n",
    "## Model selection\n",
    "from src.cross_validation.blocking_time_series_split import BlockingTimeSeriesSplit\n",
    "\n",
    "## Function to print scores\n",
    "from src.utils.print_scores import print_scores\n",
    "\n",
    "## Function to calculate score regression metrics\n",
    "from src.utils.score_regression_metrics import score_regression_metrics\n",
    "\n",
    "## Function to fill the results metric dict\n",
    "from src.utils.fill_results_dict import fill_results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305b2303",
   "metadata": {
    "papermill": {
     "duration": 0.0122,
     "end_time": "2024-07-17T13:47:31.727959",
     "exception": false,
     "start_time": "2024-07-17T13:47:31.715759",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions and definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b89f0ea",
   "metadata": {
    "papermill": {
     "duration": 0.011234,
     "end_time": "2024-07-17T13:47:31.751409",
     "exception": false,
     "start_time": "2024-07-17T13:47:31.740175",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb1fe3cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:47:31.770009Z",
     "iopub.status.busy": "2024-07-17T13:47:31.769410Z",
     "iopub.status.idle": "2024-07-17T13:47:31.786014Z",
     "shell.execute_reply": "2024-07-17T13:47:31.785176Z"
    },
    "papermill": {
     "duration": 0.027751,
     "end_time": "2024-07-17T13:47:31.788057",
     "exception": false,
     "start_time": "2024-07-17T13:47:31.760306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"class MLP(RegressorMixin):\\n    def __init__(self):\\n        self.model = self.get_model()\\n        self.batch_size = 16\\n        self.epochs = 300\\n        self.verbose = 0\\n\\n    def fit(self, X=None, y=None):\\n        self.model.fit(\\n            X, y, batch_size=self.batch_size, epochs=self.epochs, verbose=self.verbose\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            # optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_formatted_code = \"class MLP(RegressorMixin):\\n    def __init__(self):\\n        self.model = self.get_model()\\n        self.batch_size = 16\\n        self.epochs = 300\\n        self.verbose = 0\\n\\n    def fit(self, X=None, y=None):\\n        self.model.fit(\\n            X, y, batch_size=self.batch_size, epochs=self.epochs, verbose=self.verbose\\n        )\\n\\n    def predict(self, X=None):\\n        return self.model.predict(X, verbose=self.verbose)\\n\\n    def get_model(self):\\n        model = tf.keras.Sequential()\\n        model.add(tf.keras.layers.Dense(units=16, activation=\\\"relu\\\")),\\n        model.add(tf.keras.layers.Dropout(rate=0.10))\\n        model.add(tf.keras.layers.Dense(units=1))\\n        model.compile(\\n            # optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\\n            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\\n            loss=\\\"mse\\\",\\n            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\\\"RMSE\\\")],\\n        )\\n        return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLP(RegressorMixin):\n",
    "    def __init__(self):\n",
    "        self.model = self.get_model()\n",
    "        self.batch_size = 16\n",
    "        self.epochs = 300\n",
    "        self.verbose = 0\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.model.fit(\n",
    "            X, y, batch_size=self.batch_size, epochs=self.epochs, verbose=self.verbose\n",
    "        )\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self.model.predict(X, verbose=self.verbose)\n",
    "\n",
    "    def get_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(units=16, activation=\"relu\")),\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "        model.compile(\n",
    "            # optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "            loss=\"mse\",\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2767d8d",
   "metadata": {
    "papermill": {
     "duration": 0.024639,
     "end_time": "2024-07-17T13:47:31.819839",
     "exception": false,
     "start_time": "2024-07-17T13:47:31.795200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Settings for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03c0e5bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:47:31.889017Z",
     "iopub.status.busy": "2024-07-17T13:47:31.888495Z",
     "iopub.status.idle": "2024-07-17T13:47:32.032174Z",
     "shell.execute_reply": "2024-07-17T13:47:32.030893Z"
    },
    "papermill": {
     "duration": 0.182128,
     "end_time": "2024-07-17T13:47:32.035617",
     "exception": false,
     "start_time": "2024-07-17T13:47:31.853489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"def set_seeds():\\n    os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_formatted_code = \"def set_seeds():\\n    os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"\\\"\\n    os.environ[\\\"PYTHONHASHSEED\\\"] = str(SEED)\\n    tf.random.set_seed(SEED)\\n    np.random.seed(SEED)\\n    random.seed(SEED)\\n\\n\\n# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seeds():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a71f2b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:47:32.065765Z",
     "iopub.status.busy": "2024-07-17T13:47:32.064577Z",
     "iopub.status.idle": "2024-07-17T13:47:32.230233Z",
     "shell.execute_reply": "2024-07-17T13:47:32.228965Z"
    },
    "papermill": {
     "duration": 0.184775,
     "end_time": "2024-07-17T13:47:32.233570",
     "exception": false,
     "start_time": "2024-07-17T13:47:32.048795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"SEED = 47\\nMETRICS = (\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\",\\n    \\\"r2\\\",\\n)\\nMETRICS_DICT = {\\n    \\\"neg_root_mean_squared_error\\\": \\\"RMSE\\\",\\n    \\\"neg_mean_absolute_error\\\": \\\"MAE\\\",\\n    \\\"neg_mean_absolute_percentage_error\\\": \\\"MAPE\\\",\\n    \\\"r2\\\": \\\"R2\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d749cc2c",
   "metadata": {
    "papermill": {
     "duration": 0.018184,
     "end_time": "2024-07-17T13:47:32.265777",
     "exception": false,
     "start_time": "2024-07-17T13:47:32.247593",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Defining a dataframe structure to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df1333ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:47:32.325158Z",
     "iopub.status.busy": "2024-07-17T13:47:32.323982Z",
     "iopub.status.idle": "2024-07-17T13:47:32.447068Z",
     "shell.execute_reply": "2024-07-17T13:47:32.445798Z"
    },
    "papermill": {
     "duration": 0.161409,
     "end_time": "2024-07-17T13:47:32.450488",
     "exception": false,
     "start_time": "2024-07-17T13:47:32.289079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Local Model\\\",\\n    \\\"Company\\\": \\\"partner_ii\\\",\\n    \\\"Features\\\": \\\"Chemical + Mineralogical + CS3 + CS7\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_formatted_code = \"results_to_save = []\\n\\nresults_dict = {\\n    \\\"Category\\\": \\\"Local Model\\\",\\n    \\\"Company\\\": \\\"partner_ii\\\",\\n    \\\"Features\\\": \\\"Chemical + Mineralogical + CS3 + CS7\\\",\\n    \\\"Data Shape\\\": None,\\n    \\\"Timesteps\\\": None,\\n    \\\"Model\\\": \\\"MLP\\\",\\n    \\\"Model Params\\\": None,\\n    \\\"Scaler\\\": \\\"Standard Scaler\\\",\\n    \\\"Scaler Params\\\": None,\\n    \\\"Imputer\\\": \\\"Median\\\",\\n    \\\"Imputer Params\\\": None,\\n    \\\"Cross Validation\\\": None,\\n    \\\"Cross Validation Params\\\": np.nan,\\n    \\\"RMSE Train\\\": np.nan,\\n    \\\"MAE Train\\\": np.nan,\\n    \\\"MAPE Train\\\": np.nan,\\n    \\\"R2 Train\\\": np.nan,\\n    \\\"RMSE Test\\\": np.nan,\\n    \\\"MAE Test\\\": np.nan,\\n    \\\"MAPE Test\\\": np.nan,\\n    \\\"R2 Test\\\": np.nan,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_to_save = []\n",
    "\n",
    "results_dict = {\n",
    "    \"Category\": \"Local Model\",\n",
    "    \"Company\": \"partner_ii\",\n",
    "    \"Features\": \"Chemical + Mineralogical + CS3 + CS7\",\n",
    "    \"Data Shape\": None,\n",
    "    \"Timesteps\": None,\n",
    "    \"Model\": \"MLP\",\n",
    "    \"Model Params\": None,\n",
    "    \"Scaler\": \"Standard Scaler\",\n",
    "    \"Scaler Params\": None,\n",
    "    \"Imputer\": \"Median\",\n",
    "    \"Imputer Params\": None,\n",
    "    \"Cross Validation\": None,\n",
    "    \"Cross Validation Params\": np.nan,\n",
    "    \"RMSE Train\": np.nan,\n",
    "    \"MAE Train\": np.nan,\n",
    "    \"MAPE Train\": np.nan,\n",
    "    \"R2 Train\": np.nan,\n",
    "    \"RMSE Test\": np.nan,\n",
    "    \"MAE Test\": np.nan,\n",
    "    \"MAPE Test\": np.nan,\n",
    "    \"R2 Test\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69092d1e",
   "metadata": {
    "papermill": {
     "duration": 0.024435,
     "end_time": "2024-07-17T13:47:32.489730",
     "exception": false,
     "start_time": "2024-07-17T13:47:32.465295",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "148f0da6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:47:32.559259Z",
     "iopub.status.busy": "2024-07-17T13:47:32.558529Z",
     "iopub.status.idle": "2024-07-17T13:47:32.699077Z",
     "shell.execute_reply": "2024-07-17T13:47:32.697787Z"
    },
    "papermill": {
     "duration": 0.17977,
     "end_time": "2024-07-17T13:47:32.702496",
     "exception": false,
     "start_time": "2024-07-17T13:47:32.522726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../../../../../../data/processed/partner_ii/cement-shipping.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../../../../../../data/processed/partner_ii/cement-shipping.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../../../../data/processed/partner_ii/cement-shipping.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2751528e",
   "metadata": {
    "papermill": {
     "duration": 0.017377,
     "end_time": "2024-07-17T13:47:32.734999",
     "exception": false,
     "start_time": "2024-07-17T13:47:32.717622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Defining Features\n",
    "\n",
    "In this set of experiments we keep only chemical and mineralogical features yielded by the same testing method/procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e87ec4e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:47:32.805003Z",
     "iopub.status.busy": "2024-07-17T13:47:32.803808Z",
     "iopub.status.idle": "2024-07-17T13:47:32.901340Z",
     "shell.execute_reply": "2024-07-17T13:47:32.900059Z"
    },
    "papermill": {
     "duration": 0.136352,
     "end_time": "2024-07-17T13:47:32.904850",
     "exception": false,
     "start_time": "2024-07-17T13:47:32.768498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"df_copy = df.drop(\\n    [\\n        # Properties\\n                \\n        \\\"Initial setting time\\\",\\n        \\\"Blaine\\\",\\n        \\\"Sieve 32 um\\\",\\n        \\\"Sieve 45 um\\\",\\n        \\\"CS1\\\",\\n        \\\"Cement_Type\\\",\\n    ],\\n    axis=1,\\n).copy()\";\n",
       "                var nbb_formatted_code = \"df_copy = df.drop(\\n    [\\n        # Properties\\n        \\\"Initial setting time\\\",\\n        \\\"Blaine\\\",\\n        \\\"Sieve 32 um\\\",\\n        \\\"Sieve 45 um\\\",\\n        \\\"CS1\\\",\\n        \\\"Cement_Type\\\",\\n    ],\\n    axis=1,\\n).copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy = df.drop(\n",
    "    [\n",
    "        # Properties\n",
    "                \n",
    "        \"Initial setting time\",\n",
    "        \"Blaine\",\n",
    "        \"Sieve 32 um\",\n",
    "        \"Sieve 45 um\",\n",
    "        \"CS1\",\n",
    "        \"Cement_Type\",\n",
    "    ],\n",
    "    axis=1,\n",
    ").copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8234b145",
   "metadata": {
    "papermill": {
     "duration": 0.027428,
     "end_time": "2024-07-17T13:47:32.947489",
     "exception": false,
     "start_time": "2024-07-17T13:47:32.920061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2>Dataset: df_copy</h2> <br>In this dataset all features are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62304406",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:47:33.017850Z",
     "iopub.status.busy": "2024-07-17T13:47:33.016672Z",
     "iopub.status.idle": "2024-07-17T13:47:33.129779Z",
     "shell.execute_reply": "2024-07-17T13:47:33.128509Z"
    },
    "papermill": {
     "duration": 0.153385,
     "end_time": "2024-07-17T13:47:33.133240",
     "exception": false,
     "start_time": "2024-07-17T13:47:32.979855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"y = df_copy.pop(\\\"CS28\\\").values\\nx = df_copy.drop([\\\"Date\\\"], axis=1)\\ndates = df[\\\"Date\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_copy.pop(\"CS28\").values\n",
    "x = df_copy.drop([\"Date\"], axis=1)\n",
    "dates = df[\"Date\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec38f39c",
   "metadata": {
    "papermill": {
     "duration": 0.015356,
     "end_time": "2024-07-17T13:47:33.164261",
     "exception": false,
     "start_time": "2024-07-17T13:47:33.148905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9572b48",
   "metadata": {
    "papermill": {
     "duration": 0.024405,
     "end_time": "2024-07-17T13:47:33.215879",
     "exception": false,
     "start_time": "2024-07-17T13:47:33.191474",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.1 Repeated KFold Cross validation\n",
    "\n",
    "<b>Dataset shape:</b> (1057, 15)<br>\n",
    "<b>Repeats:</b>10<br>\n",
    "<b>Splits:</b>10<br>\n",
    "    1. 10 folds of 105 samples each\n",
    "    2. 90% train (951 samples each fold)\n",
    "    3. 10% test (105 samples each fold)\n",
    "<b>Total:</b> 100 models<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "860a85e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:47:33.273507Z",
     "iopub.status.busy": "2024-07-17T13:47:33.272919Z",
     "iopub.status.idle": "2024-07-17T13:56:25.262576Z",
     "shell.execute_reply": "2024-07-17T13:56:25.261631Z"
    },
    "papermill": {
     "duration": 532.027332,
     "end_time": "2024-07-17T13:56:25.274542",
     "exception": false,
     "start_time": "2024-07-17T13:47:33.247210",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 10:47:33.405843: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-07-17 10:47:33.405900: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: inspirada\n",
      "2024-07-17 10:47:33.405912: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: inspirada\n",
      "2024-07-17 10:47:33.406138: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 535.183.1\n",
      "2024-07-17 10:47:33.406180: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.183.1\n",
      "2024-07-17 10:47:33.406190: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 535.183.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated Cross Validation:\n",
      "Repeats: 3\n",
      "n_splits: 5\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: -1.538 (0.035)\n",
      "MAE: -1.224 (0.031)\n",
      "MAPE: -0.028 (0.001)\n",
      "R2: 0.810 (0.011)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: -1.592 (0.091)\n",
      "MAE: -1.263 (0.077)\n",
      "MAPE: -0.029 (0.002)\n",
      "R2: 0.794 (0.019)\n",
      "\n",
      "======================\n",
      "\n",
      "Minutes Elapsed:  8.865280449390411\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nstart = time.time()\\n\\nrepeats = 3\\nn_splits = 5\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP()),\\n    ]\\n)\\ncv = RepeatedKFold(n_splits=n_splits, n_repeats=repeats, random_state=SEED)\\nscores = cross_validate(\\n    pipeline,\\n    x,\\n    y,\\n    scoring=METRICS,\\n    cv=cv,\\n    n_jobs=1,\\n    return_train_score=True,\\n)\\nprint(\\\"Repeated Cross Validation:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Repeated KFold\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nstart = time.time()\\n\\nrepeats = 3\\nn_splits = 5\\npipeline = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"transformer\\\", StandardScaler()),\\n        (\\\"estimator\\\", MLP()),\\n    ]\\n)\\ncv = RepeatedKFold(n_splits=n_splits, n_repeats=repeats, random_state=SEED)\\nscores = cross_validate(\\n    pipeline,\\n    x,\\n    y,\\n    scoring=METRICS,\\n    cv=cv,\\n    n_jobs=1,\\n    return_train_score=True,\\n)\\nprint(\\\"Repeated Cross Validation:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\nprint_scores(scores, METRICS, METRICS_DICT)\\n\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Repeated KFold\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "start = time.time()\n",
    "\n",
    "repeats = 3\n",
    "n_splits = 5\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"transformer\", StandardScaler()),\n",
    "        (\"estimator\", MLP()),\n",
    "    ]\n",
    ")\n",
    "cv = RepeatedKFold(n_splits=n_splits, n_repeats=repeats, random_state=SEED)\n",
    "scores = cross_validate(\n",
    "    pipeline,\n",
    "    x,\n",
    "    y,\n",
    "    scoring=METRICS,\n",
    "    cv=cv,\n",
    "    n_jobs=1,\n",
    "    return_train_score=True,\n",
    ")\n",
    "print(\"Repeated Cross Validation:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"n_splits: {n_splits}\")\n",
    "print()\n",
    "print_scores(scores, METRICS, METRICS_DICT)\n",
    "\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Repeated KFold\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"N_Splits\": 5, \"Repeats\": 3}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19e7856",
   "metadata": {
    "papermill": {
     "duration": 0.016279,
     "end_time": "2024-07-17T13:56:25.712283",
     "exception": false,
     "start_time": "2024-07-17T13:56:25.696004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.2. Blocking Time Series Cross Validation\n",
    "\n",
    "<b>Dataset shape:</b> (1057, 15)<br>\n",
    "<b>Splits:</b>5<br>    \n",
    "    1. 5 folds of 211 samples\n",
    "    2. 50% train (105 samples each fold)\n",
    "    3. 50% test (105 samples each fold)\n",
    "<b>Total:</b> 5 models<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "818dae1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:56:25.747819Z",
     "iopub.status.busy": "2024-07-17T13:56:25.747501Z",
     "iopub.status.idle": "2024-07-17T13:58:25.029356Z",
     "shell.execute_reply": "2024-07-17T13:58:25.028597Z"
    },
    "papermill": {
     "duration": 119.308585,
     "end_time": "2024-07-17T13:58:25.038261",
     "exception": false,
     "start_time": "2024-07-17T13:56:25.729676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocking Time Series Split:\n",
      "Repeats: 3\n",
      "n_splits: 5\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: -4.527 (0.476)\n",
      "MAE: -3.584 (0.381)\n",
      "MAPE: -0.084 (0.007)\n",
      "R2: -1.137 (0.438)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: -9.564 (3.449)\n",
      "MAE: -7.112 (2.084)\n",
      "MAPE: -0.167 (0.053)\n",
      "R2: -9.433 (6.955)\n",
      "\n",
      "======================\n",
      "\n",
      "Minutes Elapsed:  1.9869576215744018\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nstart = time.time()\\n\\nrepeats = 3\\nn_splits = 5\\ntrain_size = 0.8\\nscores_final = None\\n\\nfor _ in range(repeats):\\n    pipeline = Pipeline(\\n        [\\n            (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n            (\\\"transformer\\\", StandardScaler()),\\n            (\\\"estimator\\\", MLP()),\\n        ]\\n    )\\n    cv = BlockingTimeSeriesSplit(n_splits=n_splits, train_size=train_size)\\n    scores = cross_validate(\\n        pipeline,\\n        x,\\n        y,\\n        scoring=METRICS,\\n        cv=cv,\\n        # n_jobs=None,\\n        return_train_score=True,\\n    )\\n    if scores_final is None:\\n        scores_final = {key: [] for key, _ in scores.items()}\\n\\n    for key, value in scores.items():\\n        scores_final[key] += [value]\\n\\n\\nprint(\\\"Blocking Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\nprint_scores(scores_final, METRICS, METRICS_DICT)\\n\\nscores = {key: np.array(val).flatten() for key, val in scores_final.items()}\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Blocking Time Series Split\\\"\\nresults_dict_copy[\\n    \\\"Cross Validation Params\\\"\\n] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3, \\\"train_size\\\": 0.8}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nstart = time.time()\\n\\nrepeats = 3\\nn_splits = 5\\ntrain_size = 0.8\\nscores_final = None\\n\\nfor _ in range(repeats):\\n    pipeline = Pipeline(\\n        [\\n            (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n            (\\\"transformer\\\", StandardScaler()),\\n            (\\\"estimator\\\", MLP()),\\n        ]\\n    )\\n    cv = BlockingTimeSeriesSplit(n_splits=n_splits, train_size=train_size)\\n    scores = cross_validate(\\n        pipeline,\\n        x,\\n        y,\\n        scoring=METRICS,\\n        cv=cv,\\n        # n_jobs=None,\\n        return_train_score=True,\\n    )\\n    if scores_final is None:\\n        scores_final = {key: [] for key, _ in scores.items()}\\n\\n    for key, value in scores.items():\\n        scores_final[key] += [value]\\n\\n\\nprint(\\\"Blocking Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\nprint_scores(scores_final, METRICS, METRICS_DICT)\\n\\nscores = {key: np.array(val).flatten() for key, val in scores_final.items()}\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Blocking Time Series Split\\\"\\nresults_dict_copy[\\n    \\\"Cross Validation Params\\\"\\n] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3, \\\"train_size\\\": 0.8}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "start = time.time()\n",
    "\n",
    "repeats = 3\n",
    "n_splits = 5\n",
    "train_size = 0.8\n",
    "scores_final = None\n",
    "\n",
    "for _ in range(repeats):\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"transformer\", StandardScaler()),\n",
    "            (\"estimator\", MLP()),\n",
    "        ]\n",
    "    )\n",
    "    cv = BlockingTimeSeriesSplit(n_splits=n_splits, train_size=train_size)\n",
    "    scores = cross_validate(\n",
    "        pipeline,\n",
    "        x,\n",
    "        y,\n",
    "        scoring=METRICS,\n",
    "        cv=cv,\n",
    "        # n_jobs=None,\n",
    "        return_train_score=True,\n",
    "    )\n",
    "    if scores_final is None:\n",
    "        scores_final = {key: [] for key, _ in scores.items()}\n",
    "\n",
    "    for key, value in scores.items():\n",
    "        scores_final[key] += [value]\n",
    "\n",
    "\n",
    "print(\"Blocking Time Series Split:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"n_splits: {n_splits}\")\n",
    "print()\n",
    "print_scores(scores_final, METRICS, METRICS_DICT)\n",
    "\n",
    "scores = {key: np.array(val).flatten() for key, val in scores_final.items()}\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Blocking Time Series Split\"\n",
    "results_dict_copy[\n",
    "    \"Cross Validation Params\"\n",
    "] = '{\"N_Splits\": 5, \"Repeats\": 3, \"train_size\": 0.8}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8262b1a9",
   "metadata": {
    "papermill": {
     "duration": 0.00744,
     "end_time": "2024-07-17T13:58:25.053311",
     "exception": false,
     "start_time": "2024-07-17T13:58:25.045871",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.3. Time Series Split Cross Validation\n",
    "\n",
    "The training set has size i * n_samples // (n_splits + 1) + n_samples % (n_splits + 1) in the i th split, with a test set of size n_samples//(n_splits + 1) by default, where n_samples is the number of samples.\n",
    "\n",
    "\n",
    "<b>Dataset shape:</b> (1057, 15)<br>\n",
    "<b>Splits:</b>10<br>    \n",
    "    1. Train: 10 folds of 97, 193, 289, 385, 481, 577, 673, 769, 865 samples each fold\n",
    "    2. Test:  96 samples each fold\n",
    "<b>Total:</b> 10 models<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d54f45b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:58:25.069127Z",
     "iopub.status.busy": "2024-07-17T13:58:25.068834Z",
     "iopub.status.idle": "2024-07-17T14:03:57.548360Z",
     "shell.execute_reply": "2024-07-17T14:03:57.547317Z"
    },
    "papermill": {
     "duration": 332.494944,
     "end_time": "2024-07-17T14:03:57.555420",
     "exception": false,
     "start_time": "2024-07-17T13:58:25.060476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocking Time Series Split:\n",
      "Repeats: 3\n",
      "n_splits: 5\n",
      "\n",
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: -2.230 (1.132)\n",
      "MAE: -1.765 (0.896)\n",
      "MAPE: -0.040 (0.021)\n",
      "R2: 0.477 (0.513)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: -4.483 (3.910)\n",
      "MAE: -3.300 (2.837)\n",
      "MAPE: -0.077 (0.065)\n",
      "R2: -2.823 (6.191)\n",
      "\n",
      "======================\n",
      "\n",
      "Minutes Elapsed:  5.540388480822245\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nstart = time.time()\\n\\nscores_final = None\\nrepeats = 3\\nn_splits = 5\\ngap = 0\\n\\nfor _ in range(repeats):\\n    pipeline = Pipeline(\\n        [\\n            (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n            (\\\"transformer\\\", StandardScaler()),\\n            (\\\"estimator\\\", MLP()),\\n        ]\\n    )\\n    cv = TimeSeriesSplit(gap=gap, max_train_size=None, n_splits=n_splits)\\n\\n    scores = cross_validate(\\n        pipeline,\\n        x,\\n        y,\\n        scoring=METRICS,\\n        cv=cv,\\n        # n_jobs=-1,\\n        return_train_score=True,\\n    )\\n    if scores_final is None:\\n        scores_final = {key: [] for key, _ in scores.items()}\\n    for key, value in scores.items():\\n        scores_final[key] += [value]\\n\\nprint(\\\"Blocking Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\nprint_scores(scores_final, METRICS, METRICS_DICT)\\n\\n# Saving the results\\nscores = {key: np.array(val).flatten() for key, val in scores_final.items()}\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Time Series Split\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3, \\\"Gap\\\": 0}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nstart = time.time()\\n\\nscores_final = None\\nrepeats = 3\\nn_splits = 5\\ngap = 0\\n\\nfor _ in range(repeats):\\n    pipeline = Pipeline(\\n        [\\n            (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n            (\\\"transformer\\\", StandardScaler()),\\n            (\\\"estimator\\\", MLP()),\\n        ]\\n    )\\n    cv = TimeSeriesSplit(gap=gap, max_train_size=None, n_splits=n_splits)\\n\\n    scores = cross_validate(\\n        pipeline,\\n        x,\\n        y,\\n        scoring=METRICS,\\n        cv=cv,\\n        # n_jobs=-1,\\n        return_train_score=True,\\n    )\\n    if scores_final is None:\\n        scores_final = {key: [] for key, _ in scores.items()}\\n    for key, value in scores.items():\\n        scores_final[key] += [value]\\n\\nprint(\\\"Blocking Time Series Split:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"n_splits: {n_splits}\\\")\\nprint()\\nprint_scores(scores_final, METRICS, METRICS_DICT)\\n\\n# Saving the results\\nscores = {key: np.array(val).flatten() for key, val in scores_final.items()}\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Time Series Split\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"N_Splits\\\": 5, \\\"Repeats\\\": 3, \\\"Gap\\\": 0}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(results_dict_copy, scores)\\nresults_to_save.append(df_results)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "start = time.time()\n",
    "\n",
    "scores_final = None\n",
    "repeats = 3\n",
    "n_splits = 5\n",
    "gap = 0\n",
    "\n",
    "for _ in range(repeats):\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"transformer\", StandardScaler()),\n",
    "            (\"estimator\", MLP()),\n",
    "        ]\n",
    "    )\n",
    "    cv = TimeSeriesSplit(gap=gap, max_train_size=None, n_splits=n_splits)\n",
    "\n",
    "    scores = cross_validate(\n",
    "        pipeline,\n",
    "        x,\n",
    "        y,\n",
    "        scoring=METRICS,\n",
    "        cv=cv,\n",
    "        # n_jobs=-1,\n",
    "        return_train_score=True,\n",
    "    )\n",
    "    if scores_final is None:\n",
    "        scores_final = {key: [] for key, _ in scores.items()}\n",
    "    for key, value in scores.items():\n",
    "        scores_final[key] += [value]\n",
    "\n",
    "print(\"Blocking Time Series Split:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"n_splits: {n_splits}\")\n",
    "print()\n",
    "print_scores(scores_final, METRICS, METRICS_DICT)\n",
    "\n",
    "# Saving the results\n",
    "scores = {key: np.array(val).flatten() for key, val in scores_final.items()}\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Time Series Split\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"N_Splits\": 5, \"Repeats\": 3, \"Gap\": 0}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "df_results = fill_results_dict(results_dict_copy, scores)\n",
    "results_to_save.append(df_results)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd51657",
   "metadata": {
    "papermill": {
     "duration": 0.015919,
     "end_time": "2024-07-17T14:03:58.012847",
     "exception": false,
     "start_time": "2024-07-17T14:03:57.996928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.4. Out of time Split Cross Validation\n",
    "\n",
    "<b>Dataset shape:</b> (1057, 15)<br>\n",
    "<b>Train size: 80%</b><br>\n",
    "<b>Test  size: 20%</b>\n",
    "\n",
    "\n",
    "<b>Splits:</b> 2<br>    \n",
    "    1. Train: 845\n",
    "    2. Test: 211\n",
    "<b>Total:</b> 1 model<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5e09f90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T14:03:58.046270Z",
     "iopub.status.busy": "2024-07-17T14:03:58.045809Z",
     "iopub.status.idle": "2024-07-17T14:05:45.290697Z",
     "shell.execute_reply": "2024-07-17T14:05:45.289898Z"
    },
    "papermill": {
     "duration": 107.272763,
     "end_time": "2024-07-17T14:05:45.301469",
     "exception": false,
     "start_time": "2024-07-17T14:03:58.028706",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of time Cross Val:\n",
      "Repeats: 3\n",
      "Train: 80% Test: 20%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 1.431 (0.034)\n",
      "MAE: 1.133 (0.032)\n",
      "MAPE: 0.026 (0.001)\n",
      "R2: 0.807 (0.009)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 2.063 (0.133)\n",
      "MAE: 1.653 (0.112)\n",
      "MAPE: 0.043 (0.003)\n",
      "R2: 0.448 (0.069)\n",
      "\n",
      "======================\n",
      "\n",
      "Minutes Elapsed:  1.7860751787821452\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"set_seeds()\\nstart = time.time()\\n\\ntest_size = 0.2\\nrepeats = 3\\nscores_final = None\\n\\nprint(\\\"Out of time Cross Val:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"Train: {80}%\\\", f\\\"Test: {20}%\\\")\\nprint()\\n\\n\\nfor _ in range(repeats):\\n    x_train, x_test, y_train, y_test = train_test_split(\\n        x, y, test_size=test_size, random_state=SEED, shuffle=False\\n    )\\n\\n    pipeline = Pipeline(\\n        [\\n            (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n            (\\\"transformer\\\", StandardScaler()),\\n            (\\\"estimator\\\", MLP()),\\n        ]\\n    )\\n\\n    pipeline.fit(x_train, y_train)\\n\\n    y_train_pred = pipeline.predict(x_train)\\n    y_test_pred = pipeline.predict(x_test)\\n\\n    scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\\n\\n    if scores_final is None:\\n        scores_final = {key: [] for key, _ in scores.items()}\\n\\n    for key, value in scores.items():\\n        scores_final[key] += [value]\\n\\n# Saving the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time Split\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"Test Size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(\\n    results_dict_copy, {key: value for key, value in scores_final.items()}\\n)\\nresults_to_save.append(df_results)\\n\\nprint_scores(scores_final, METRICS, METRICS_DICT)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_formatted_code = \"set_seeds()\\nstart = time.time()\\n\\ntest_size = 0.2\\nrepeats = 3\\nscores_final = None\\n\\nprint(\\\"Out of time Cross Val:\\\")\\nprint(f\\\"Repeats: {repeats}\\\")\\nprint(f\\\"Train: {80}%\\\", f\\\"Test: {20}%\\\")\\nprint()\\n\\n\\nfor _ in range(repeats):\\n    x_train, x_test, y_train, y_test = train_test_split(\\n        x, y, test_size=test_size, random_state=SEED, shuffle=False\\n    )\\n\\n    pipeline = Pipeline(\\n        [\\n            (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n            (\\\"transformer\\\", StandardScaler()),\\n            (\\\"estimator\\\", MLP()),\\n        ]\\n    )\\n\\n    pipeline.fit(x_train, y_train)\\n\\n    y_train_pred = pipeline.predict(x_train)\\n    y_test_pred = pipeline.predict(x_test)\\n\\n    scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\\n\\n    if scores_final is None:\\n        scores_final = {key: [] for key, _ in scores.items()}\\n\\n    for key, value in scores.items():\\n        scores_final[key] += [value]\\n\\n# Saving the results\\nresults_dict_copy = results_dict.copy()\\nresults_dict_copy[\\\"Cross Validation\\\"] = \\\"Out of time Split\\\"\\nresults_dict_copy[\\\"Cross Validation Params\\\"] = '{\\\"Test Size\\\": 0.2}'\\nresults_dict_copy[\\\"Data Shape\\\"] = x.shape\\ndf_results = fill_results_dict(\\n    results_dict_copy, {key: value for key, value in scores_final.items()}\\n)\\nresults_to_save.append(df_results)\\n\\nprint_scores(scores_final, METRICS, METRICS_DICT)\\n\\nend = time.time()\\nprint(\\\"Minutes Elapsed: \\\", (end - start) / 60)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()\n",
    "start = time.time()\n",
    "\n",
    "test_size = 0.2\n",
    "repeats = 3\n",
    "scores_final = None\n",
    "\n",
    "print(\"Out of time Cross Val:\")\n",
    "print(f\"Repeats: {repeats}\")\n",
    "print(f\"Train: {80}%\", f\"Test: {20}%\")\n",
    "print()\n",
    "\n",
    "\n",
    "for _ in range(repeats):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=test_size, random_state=SEED, shuffle=False\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"transformer\", StandardScaler()),\n",
    "            (\"estimator\", MLP()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipeline.fit(x_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(x_train)\n",
    "    y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "    scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\n",
    "\n",
    "    if scores_final is None:\n",
    "        scores_final = {key: [] for key, _ in scores.items()}\n",
    "\n",
    "    for key, value in scores.items():\n",
    "        scores_final[key] += [value]\n",
    "\n",
    "# Saving the results\n",
    "results_dict_copy = results_dict.copy()\n",
    "results_dict_copy[\"Cross Validation\"] = \"Out of time Split\"\n",
    "results_dict_copy[\"Cross Validation Params\"] = '{\"Test Size\": 0.2}'\n",
    "results_dict_copy[\"Data Shape\"] = x.shape\n",
    "df_results = fill_results_dict(\n",
    "    results_dict_copy, {key: value for key, value in scores_final.items()}\n",
    ")\n",
    "results_to_save.append(df_results)\n",
    "\n",
    "print_scores(scores_final, METRICS, METRICS_DICT)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Minutes Elapsed: \", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "606eb344",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T14:05:45.319053Z",
     "iopub.status.busy": "2024-07-17T14:05:45.318743Z",
     "iopub.status.idle": "2024-07-17T14:05:45.368014Z",
     "shell.execute_reply": "2024-07-17T14:05:45.367087Z"
    },
    "papermill": {
     "duration": 0.060942,
     "end_time": "2024-07-17T14:05:45.370607",
     "exception": false,
     "start_time": "2024-07-17T14:05:45.309665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th>Cross Validation Params</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RMSE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAPE Test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R2 Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chemical + Mineralogical + CS3 + CS7</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Blocking Time Series Split</td>\n",
       "      <td>{\"N_Splits\": 5, \"Repeats\": 3, \"train_size\": 0.8}</td>\n",
       "      <td>9.563569</td>\n",
       "      <td>3.449228</td>\n",
       "      <td>7.111527</td>\n",
       "      <td>2.083870</td>\n",
       "      <td>0.166560</td>\n",
       "      <td>0.052554</td>\n",
       "      <td>-9.432776</td>\n",
       "      <td>6.954767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chemical + Mineralogical + CS3 + CS7</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Out of time Split</td>\n",
       "      <td>{\"Test Size\": 0.2}</td>\n",
       "      <td>2.063016</td>\n",
       "      <td>0.133363</td>\n",
       "      <td>1.652738</td>\n",
       "      <td>0.112220</td>\n",
       "      <td>0.042589</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.448333</td>\n",
       "      <td>0.069447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chemical + Mineralogical + CS3 + CS7</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Repeated KFold</td>\n",
       "      <td>{\"N_Splits\": 5, \"Repeats\": 3}</td>\n",
       "      <td>1.592304</td>\n",
       "      <td>0.090841</td>\n",
       "      <td>1.263278</td>\n",
       "      <td>0.076981</td>\n",
       "      <td>0.029391</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.793708</td>\n",
       "      <td>0.018919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chemical + Mineralogical + CS3 + CS7</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Time Series Split</td>\n",
       "      <td>{\"N_Splits\": 5, \"Repeats\": 3, \"Gap\": 0}</td>\n",
       "      <td>4.483406</td>\n",
       "      <td>3.910333</td>\n",
       "      <td>3.300370</td>\n",
       "      <td>2.836701</td>\n",
       "      <td>0.076624</td>\n",
       "      <td>0.064575</td>\n",
       "      <td>-2.823400</td>\n",
       "      <td>6.191382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Features Model            Cross Validation  \\\n",
       "                                                                            \n",
       "0  Chemical + Mineralogical + CS3 + CS7   MLP  Blocking Time Series Split   \n",
       "1  Chemical + Mineralogical + CS3 + CS7   MLP           Out of time Split   \n",
       "2  Chemical + Mineralogical + CS3 + CS7   MLP              Repeated KFold   \n",
       "3  Chemical + Mineralogical + CS3 + CS7   MLP           Time Series Split   \n",
       "\n",
       "                            Cross Validation Params RMSE Test            \\\n",
       "                                                         mean       std   \n",
       "0  {\"N_Splits\": 5, \"Repeats\": 3, \"train_size\": 0.8}  9.563569  3.449228   \n",
       "1                                {\"Test Size\": 0.2}  2.063016  0.133363   \n",
       "2                     {\"N_Splits\": 5, \"Repeats\": 3}  1.592304  0.090841   \n",
       "3           {\"N_Splits\": 5, \"Repeats\": 3, \"Gap\": 0}  4.483406  3.910333   \n",
       "\n",
       "   MAE Test           MAPE Test             R2 Test            \n",
       "       mean       std      mean       std      mean       std  \n",
       "0  7.111527  2.083870  0.166560  0.052554 -9.432776  6.954767  \n",
       "1  1.652738  0.112220  0.042589  0.003011  0.448333  0.069447  \n",
       "2  1.263278  0.076981  0.029391  0.001791  0.793708  0.018919  \n",
       "3  3.300370  2.836701  0.076624  0.064575 -2.823400  6.191382  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"pd.concat(results_to_save).groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Cross Validation Params\\\"]\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_formatted_code = \"pd.concat(results_to_save).groupby(\\n    [\\\"Features\\\", \\\"Model\\\", \\\"Cross Validation\\\", \\\"Cross Validation Params\\\"]\\n)[[\\\"RMSE Test\\\", \\\"MAE Test\\\", \\\"MAPE Test\\\", \\\"R2 Test\\\"]].agg(\\n    [\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")]\\n).reset_index().rename(\\n    columns={\\\"<lambda_0>\\\": \\\"std\\\"}\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat(results_to_save).groupby(\n",
    "    [\"Features\", \"Model\", \"Cross Validation\", \"Cross Validation Params\"]\n",
    ")[[\"RMSE Test\", \"MAE Test\", \"MAPE Test\", \"R2 Test\"]].agg(\n",
    "    [\"mean\", lambda series: pd.Series(series.std(ddof=0), name=\"std\")]\n",
    ").reset_index().rename(\n",
    "    columns={\"<lambda_0>\": \"std\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd02155",
   "metadata": {
    "papermill": {
     "duration": 0.013696,
     "end_time": "2024-07-17T14:05:45.398372",
     "exception": false,
     "start_time": "2024-07-17T14:05:45.384676",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Saving the results Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f860214",
   "metadata": {
    "papermill": {
     "duration": 0.029867,
     "end_time": "2024-07-17T14:05:45.452117",
     "exception": false,
     "start_time": "2024-07-17T14:05:45.422250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Saving the full dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6639dc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T14:05:45.531292Z",
     "iopub.status.busy": "2024-07-17T14:05:45.530861Z",
     "iopub.status.idle": "2024-07-17T14:05:45.551506Z",
     "shell.execute_reply": "2024-07-17T14:05:45.550188Z"
    },
    "papermill": {
     "duration": 0.070855,
     "end_time": "2024-07-17T14:05:45.554356",
     "exception": false,
     "start_time": "2024-07-17T14:05:45.483501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"path = \\\"../../../../../../reports/results/local_models/partner_ii/all_cements/full/\\\"\\nfilename = \\\"mlp_results_full_15.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"path = \\\"../../../../../../reports/results/local_models/partner_ii/all_cements/full/\\\"\\nfilename = \\\"mlp_results_full_15.csv\\\"\\n\\npd.concat(results_to_save).to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"../../../../../../reports/results/local_models/partner_ii/all_cements/full/\"\n",
    "filename = \"mlp_results_full_15.csv\"\n",
    "\n",
    "pd.concat(results_to_save).to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e32869a",
   "metadata": {
    "papermill": {
     "duration": 0.029316,
     "end_time": "2024-07-17T14:05:45.597292",
     "exception": false,
     "start_time": "2024-07-17T14:05:45.567976",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Saving the grouped dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e26e5c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T14:05:45.656224Z",
     "iopub.status.busy": "2024-07-17T14:05:45.655022Z",
     "iopub.status.idle": "2024-07-17T14:05:45.835209Z",
     "shell.execute_reply": "2024-07-17T14:05:45.833889Z"
    },
    "papermill": {
     "duration": 0.204848,
     "end_time": "2024-07-17T14:05:45.838373",
     "exception": false,
     "start_time": "2024-07-17T14:05:45.633525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"cols_groupby = [\\n    \\\"Category\\\",\\n    \\\"Company\\\",\\n    \\\"Data Shape\\\",\\n    \\\"Timesteps\\\",\\n    \\\"Features\\\",\\n    \\\"Model\\\",\\n    \\\"Cross Validation\\\",\\n    \\\"Cross Validation Params\\\",\\n]\\n\\ncols_agg = [\\\"RMSE Train\\\", \\\"MAE Train\\\", \\\"MAPE Train\\\", \\\"R2 Train\\\"] + [\\n    \\\"RMSE Test\\\",\\n    \\\"MAE Test\\\",\\n    \\\"MAPE Test\\\",\\n    \\\"R2 Test\\\",\\n]\\n\\npath = \\\"../../../../../../reports/results/local_models/partner_ii/all_cements/grouped/\\\"\\nfilename = \\\"mlp_results_grouped_15.csv\\\"\\n\\n\\ndf_results_to_save = (\\n    pd.concat(results_to_save)\\n    .groupby(cols_groupby, dropna=False)[cols_agg]\\n    .agg([\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")])\\n    .reset_index()\\n    .rename(columns={\\\"<lambda_0>\\\": \\\"std\\\"})\\n)\\n\\ndf_results_to_save.to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_formatted_code = \"cols_groupby = [\\n    \\\"Category\\\",\\n    \\\"Company\\\",\\n    \\\"Data Shape\\\",\\n    \\\"Timesteps\\\",\\n    \\\"Features\\\",\\n    \\\"Model\\\",\\n    \\\"Cross Validation\\\",\\n    \\\"Cross Validation Params\\\",\\n]\\n\\ncols_agg = [\\\"RMSE Train\\\", \\\"MAE Train\\\", \\\"MAPE Train\\\", \\\"R2 Train\\\"] + [\\n    \\\"RMSE Test\\\",\\n    \\\"MAE Test\\\",\\n    \\\"MAPE Test\\\",\\n    \\\"R2 Test\\\",\\n]\\n\\npath = \\\"../../../../../../reports/results/local_models/partner_ii/all_cements/grouped/\\\"\\nfilename = \\\"mlp_results_grouped_15.csv\\\"\\n\\n\\ndf_results_to_save = (\\n    pd.concat(results_to_save)\\n    .groupby(cols_groupby, dropna=False)[cols_agg]\\n    .agg([\\\"mean\\\", lambda series: pd.Series(series.std(ddof=0), name=\\\"std\\\")])\\n    .reset_index()\\n    .rename(columns={\\\"<lambda_0>\\\": \\\"std\\\"})\\n)\\n\\ndf_results_to_save.to_csv(\\n    path_or_buf=path + filename,\\n    mode=\\\"w\\\",\\n    index=False,\\n    header=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols_groupby = [\n",
    "    \"Category\",\n",
    "    \"Company\",\n",
    "    \"Data Shape\",\n",
    "    \"Timesteps\",\n",
    "    \"Features\",\n",
    "    \"Model\",\n",
    "    \"Cross Validation\",\n",
    "    \"Cross Validation Params\",\n",
    "]\n",
    "\n",
    "cols_agg = [\"RMSE Train\", \"MAE Train\", \"MAPE Train\", \"R2 Train\"] + [\n",
    "    \"RMSE Test\",\n",
    "    \"MAE Test\",\n",
    "    \"MAPE Test\",\n",
    "    \"R2 Test\",\n",
    "]\n",
    "\n",
    "path = \"../../../../../../reports/results/local_models/partner_ii/all_cements/grouped/\"\n",
    "filename = \"mlp_results_grouped_15.csv\"\n",
    "\n",
    "\n",
    "df_results_to_save = (\n",
    "    pd.concat(results_to_save)\n",
    "    .groupby(cols_groupby, dropna=False)[cols_agg]\n",
    "    .agg([\"mean\", lambda series: pd.Series(series.std(ddof=0), name=\"std\")])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"<lambda_0>\": \"std\"})\n",
    ")\n",
    "\n",
    "df_results_to_save.to_csv(\n",
    "    path_or_buf=path + filename,\n",
    "    mode=\"w\",\n",
    "    index=False,\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ae3b1f",
   "metadata": {
    "papermill": {
     "duration": 0.019584,
     "end_time": "2024-07-17T14:05:45.878753",
     "exception": false,
     "start_time": "2024-07-17T14:05:45.859169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccs28-venv",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1099.106762,
   "end_time": "2024-07-17T14:05:47.126163",
   "environment_variables": {},
   "exception": null,
   "input_path": "/home/peressim/projects/ccs28-ml-modelling/notebooks/modelling/local_models/partner_ii/mlp/all_cements/chemical-mineralogical-cs3-and-cs7-ds.ipynb",
   "output_path": "/home/peressim/projects/ccs28-ml-modelling/notebooks/modelling/local_models/partner_ii/mlp/all_cements/chemical-mineralogical-cs3-and-cs7-ds.ipynb",
   "parameters": {},
   "start_time": "2024-07-17T13:47:28.019401",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}