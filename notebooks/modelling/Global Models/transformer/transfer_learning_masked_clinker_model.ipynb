{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database Reading and Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Linear Algebra\n",
    "import numpy as np\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from src.utils.time_series_procs import split_sequences\n",
    "from src.models.transformer_ts_tf import Transformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, x, y, n_splits=10, n_repeats=10):\n",
    "    scoring = \"neg_root_mean_squared_error\"\n",
    "    cv = RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=SEED)\n",
    "    scores = cross_val_score(model, x, y, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(params):\n",
    "    return Transformer(\n",
    "        num_hid=params[\"num_features\"],\n",
    "        time_steps=params[\"timesteps\"],\n",
    "        num_head=params[\"num_heads\"],\n",
    "        num_layers_enc=params[\"num_layers_enc\"],\n",
    "        num_feed_forward=params[\"num_feed_forward\"],\n",
    "        units_output=params[\"units_output\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler3DShape:\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        X_new = self.scaler.fit_transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)\n",
    "        return X_new\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_new = X.reshape(-1, X.shape[-1])\n",
    "        self.scaler.fit(X_new)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_new = self.scaler.transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1, activation=\"relu\"):\n",
    "        super().__init__()\n",
    "        self.attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(feed_forward_dim, activation=activation),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.attn(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "class Transformer(keras.Model):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_hid=64,  # embed_dim - num of features\n",
    "            time_steps=7,\n",
    "            num_head=2,\n",
    "            num_feed_forward=128,  # pointwise dim\n",
    "            num_layers_enc=4,\n",
    "            dropout_rate=0.1,\n",
    "            activation=\"relu\",\n",
    "            units_output = 1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.numlayers_enc = num_layers_enc\n",
    "        self.enc_input = layers.Input((time_steps, num_hid))\n",
    "        self.encoder = keras.Sequential(\n",
    "            [self.enc_input]\n",
    "            + [\n",
    "                TransformerEncoder(num_hid, num_head, num_feed_forward, dropout_rate, activation)\n",
    "                for _ in range(num_layers_enc)\n",
    "            ]\n",
    "        )\n",
    "        self.GlobalAveragePooling1D = layers.GlobalAveragePooling1D(data_format='channels_last')\n",
    "        self.out = layers.Dense(units=units_output, activation='linear')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        #x =  Time2Vector(x.shape[-1])\n",
    "        x = self.encoder(inputs)\n",
    "        x = self.GlobalAveragePooling1D(x)\n",
    "        y = self.out(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(scores, METRICS, METRICS_DICT):\n",
    "    for phase in [\"train\", \"test\"]:\n",
    "        print(\"******\")\n",
    "        print(f\"[{phase.upper()}]\")\n",
    "        print(\"******\")\n",
    "        for metric in METRICS:\n",
    "            name = METRICS_DICT[metric]           \n",
    "            print(\n",
    "                f\"{name}: %.3f (%.3f)\"\n",
    "                % (\n",
    "                    np.abs(np.mean(scores[f\"{phase}_\" + metric])),\n",
    "                    np.std(scores[f\"{phase}_\" + metric]),\n",
    "                )\n",
    "            )\n",
    "        print(\"\\n======================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred):\n",
    "    TRAIN_RMSE = mean_squared_error(y_true=y_train, y_pred=y_train_pred, squared=False)\n",
    "    TRAIN_MAE = mean_absolute_error(y_true=y_train, y_pred=y_train_pred)\n",
    "    TRAIN_MAPE = mean_absolute_percentage_error(y_true=y_train, y_pred=y_train_pred)\n",
    "    TRAIN_R2 = r2_score(y_true=y_train, y_pred=y_train_pred)\n",
    "\n",
    "    TEST_RMSE = mean_squared_error(y_true=y_test, y_pred=y_test_pred, squared=False)\n",
    "    TEST_MAE = mean_absolute_error(y_true=y_test, y_pred=y_test_pred)\n",
    "    TEST_MAPE = mean_absolute_percentage_error(y_true=y_test, y_pred=y_test_pred)\n",
    "    TEST_R2 = r2_score(y_true=y_test, y_pred=y_test_pred)\n",
    "\n",
    "    scores = {\n",
    "        \"train_neg_root_mean_squared_error\": TRAIN_RMSE,\n",
    "        \"train_neg_mean_absolute_error\": TRAIN_MAE,\n",
    "        \"train_neg_mean_absolute_percentage_error\": TRAIN_MAPE,\n",
    "        \"train_r2\": TRAIN_R2,\n",
    "        \"test_neg_root_mean_squared_error\": TEST_RMSE,\n",
    "        \"test_neg_mean_absolute_error\": TEST_MAE,\n",
    "        \"test_neg_mean_absolute_percentage_error\": TEST_MAPE,\n",
    "        \"test_r2\": TEST_R2,\n",
    "    }\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 47\n",
    "METRICS = (\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_mean_absolute_percentage_error\",\n",
    "    \"r2\",\n",
    ")\n",
    "METRICS_DICT = {\n",
    "    \"neg_root_mean_squared_error\": \"RMSE\",\n",
    "    \"neg_mean_absolute_error\": \"MAE\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"MAPE\",\n",
    "    \"r2\": \"R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clinker = pd.read_csv(\"../../../data/processed/partner_i-Oficial/clinker.csv\")\n",
    "df_cimento = pd.read_csv(\"../../../data/processed/partner_i-Oficial/cement-shipping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AR',\n",
       " 'Aphthitalite',\n",
       " 'C2S',\n",
       " 'C3A cubic',\n",
       " 'C3A ortho',\n",
       " 'C3S M1',\n",
       " 'C3S M3',\n",
       " 'C3S Tot.',\n",
       " 'C4AF',\n",
       " 'Free lime.1',\n",
       " 'LSF',\n",
       " 'Liquid phase 1338',\n",
       " 'Liquid phase 1450',\n",
       " 'SR',\n",
       " 'Sulphur alkali rate',\n",
       " 'TiO2'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_clinker.columns) - set(df_cimento.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'%Clinker',\n",
       " '%Gypsum',\n",
       " '%Limestone',\n",
       " '1 day Compressive strength',\n",
       " '28 day Compressive strength',\n",
       " '3 day Compressive strength',\n",
       " '7 day Compressive strength',\n",
       " 'Alite total',\n",
       " 'Aluminate',\n",
       " 'Aluminate cubic',\n",
       " 'Aluminate orto',\n",
       " 'Anhydrite',\n",
       " 'Aphthalite',\n",
       " 'Bassanite',\n",
       " 'Belite alpha',\n",
       " 'Belite beta',\n",
       " 'Belite gamma',\n",
       " 'Belite total',\n",
       " 'Calcite',\n",
       " 'Dehydration',\n",
       " 'Dolimite',\n",
       " 'Gypsum',\n",
       " 'IR',\n",
       " 'LOI',\n",
       " 'Quartz',\n",
       " 'Remarks_CPIIF40 Expedido',\n",
       " 'Remarks_CPVARI Expedido',\n",
       " 'Total alkali as Na2O'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_cimento.columns) - set(df_clinker.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLINKER_TO_DROP = [\n",
    "    'AR',\n",
    "     'Aphthitalite',\n",
    "     'C2S',\n",
    "     'C3A cubic',\n",
    "     'C3A ortho',\n",
    "     'C3S M1',\n",
    "     'C3S M3',\n",
    "     'C3S Tot.',\n",
    "     'C4AF',\n",
    "     'Free lime.1',\n",
    "     'LSF',\n",
    "     'Liquid phase 1338',\n",
    "     'Liquid phase 1450',\n",
    "     'SR',\n",
    "     'Sulphur alkali rate',\n",
    "     'TiO2'\n",
    "]\n",
    "\n",
    "CEMENT_TO_DROP = [\n",
    "    '%Clinker',\n",
    "    '%Gypsum',\n",
    "    '%Limestone',\n",
    "    '1 day Compressive strength',\n",
    "    # '28 day Compressive strength',\n",
    "    '3 day Compressive strength',\n",
    "    '7 day Compressive strength',\n",
    "    'Alite total',\n",
    "    'Aluminate',\n",
    "    'Aluminate cubic',\n",
    "    'Aluminate orto',\n",
    "    'Anhydrite',\n",
    "    'Aphthalite',\n",
    "    'Bassanite',\n",
    "    'Belite alpha',\n",
    "    'Belite beta',\n",
    "    'Belite gamma',\n",
    "    'Belite total',\n",
    "    'Calcite',\n",
    "    'Dehydration',\n",
    "    'Dolimite',\n",
    "    'Gypsum',\n",
    "    'IR',\n",
    "    'LOI',\n",
    "    'Quartz',\n",
    "    'Remarks_CPIIF40 Expedido',\n",
    "    'Remarks_CPVARI Expedido',\n",
    "    'Total alkali as Na2O'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clinker = df_clinker.drop(CLINKER_TO_DROP, axis=1)\n",
    "df_cimento = df_cimento.drop(CEMENT_TO_DROP, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>CaO</th>\n",
       "      <th>MgO</th>\n",
       "      <th>Arcanite</th>\n",
       "      <th>Na2O</th>\n",
       "      <th>Al2O3</th>\n",
       "      <th>SiO2</th>\n",
       "      <th>SO3</th>\n",
       "      <th>K2O</th>\n",
       "      <th>Fe2O3</th>\n",
       "      <th>Free lime</th>\n",
       "      <th>Ferrite</th>\n",
       "      <th>Periclase</th>\n",
       "      <th>Portlandite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-11 15:00:00</td>\n",
       "      <td>64.51720</td>\n",
       "      <td>3.53330</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>4.82520</td>\n",
       "      <td>19.86070</td>\n",
       "      <td>2.0278</td>\n",
       "      <td>1.3761</td>\n",
       "      <td>2.90930</td>\n",
       "      <td>6.18</td>\n",
       "      <td>6.730</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-11 17:00:00</td>\n",
       "      <td>65.93120</td>\n",
       "      <td>3.67190</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>4.73900</td>\n",
       "      <td>19.44350</td>\n",
       "      <td>1.5134</td>\n",
       "      <td>1.1837</td>\n",
       "      <td>2.98670</td>\n",
       "      <td>8.50</td>\n",
       "      <td>6.770</td>\n",
       "      <td>2.440</td>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-11 19:00:00</td>\n",
       "      <td>64.76200</td>\n",
       "      <td>3.62370</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.2343</td>\n",
       "      <td>4.81290</td>\n",
       "      <td>20.27340</td>\n",
       "      <td>1.3333</td>\n",
       "      <td>1.1910</td>\n",
       "      <td>3.05860</td>\n",
       "      <td>3.47</td>\n",
       "      <td>7.200</td>\n",
       "      <td>2.620</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-11 21:00:00</td>\n",
       "      <td>64.42930</td>\n",
       "      <td>3.54945</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.2402</td>\n",
       "      <td>4.77185</td>\n",
       "      <td>20.06305</td>\n",
       "      <td>1.6755</td>\n",
       "      <td>1.2726</td>\n",
       "      <td>3.06005</td>\n",
       "      <td>4.42</td>\n",
       "      <td>7.340</td>\n",
       "      <td>2.540</td>\n",
       "      <td>0.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-11 23:00:00</td>\n",
       "      <td>64.09660</td>\n",
       "      <td>3.47520</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.2461</td>\n",
       "      <td>4.73080</td>\n",
       "      <td>19.85270</td>\n",
       "      <td>2.0177</td>\n",
       "      <td>1.3542</td>\n",
       "      <td>3.06150</td>\n",
       "      <td>5.37</td>\n",
       "      <td>7.110</td>\n",
       "      <td>2.640</td>\n",
       "      <td>0.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5150</th>\n",
       "      <td>2022-05-03 05:00:00</td>\n",
       "      <td>63.54070</td>\n",
       "      <td>4.30230</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.2725</td>\n",
       "      <td>4.63760</td>\n",
       "      <td>19.52540</td>\n",
       "      <td>1.6458</td>\n",
       "      <td>1.2908</td>\n",
       "      <td>3.26490</td>\n",
       "      <td>3.10</td>\n",
       "      <td>9.800</td>\n",
       "      <td>3.630</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5151</th>\n",
       "      <td>2022-05-03 09:00:00</td>\n",
       "      <td>63.07030</td>\n",
       "      <td>4.20370</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.3073</td>\n",
       "      <td>4.65580</td>\n",
       "      <td>19.51010</td>\n",
       "      <td>1.8491</td>\n",
       "      <td>1.3412</td>\n",
       "      <td>3.21440</td>\n",
       "      <td>4.55</td>\n",
       "      <td>9.660</td>\n",
       "      <td>3.630</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5152</th>\n",
       "      <td>2022-05-03 13:00:00</td>\n",
       "      <td>62.48160</td>\n",
       "      <td>4.23440</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>4.72230</td>\n",
       "      <td>20.00800</td>\n",
       "      <td>1.5837</td>\n",
       "      <td>1.3319</td>\n",
       "      <td>3.31380</td>\n",
       "      <td>3.48</td>\n",
       "      <td>9.020</td>\n",
       "      <td>3.380</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5153</th>\n",
       "      <td>2022-05-03 17:00:00</td>\n",
       "      <td>62.85425</td>\n",
       "      <td>4.28505</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.2757</td>\n",
       "      <td>4.75515</td>\n",
       "      <td>20.07075</td>\n",
       "      <td>1.6264</td>\n",
       "      <td>1.3342</td>\n",
       "      <td>3.32145</td>\n",
       "      <td>2.92</td>\n",
       "      <td>9.145</td>\n",
       "      <td>3.385</td>\n",
       "      <td>0.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154</th>\n",
       "      <td>2022-05-03 21:00:00</td>\n",
       "      <td>63.22690</td>\n",
       "      <td>4.33570</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.2642</td>\n",
       "      <td>4.78800</td>\n",
       "      <td>20.13350</td>\n",
       "      <td>1.6691</td>\n",
       "      <td>1.3365</td>\n",
       "      <td>3.32910</td>\n",
       "      <td>2.36</td>\n",
       "      <td>9.270</td>\n",
       "      <td>3.390</td>\n",
       "      <td>0.310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5155 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Date       CaO      MgO  Arcanite    Na2O    Al2O3  \\\n",
       "0     2020-01-11 15:00:00  64.51720  3.53330      0.61  0.2625  4.82520   \n",
       "1     2020-01-11 17:00:00  65.93120  3.67190      0.66  0.2414  4.73900   \n",
       "2     2020-01-11 19:00:00  64.76200  3.62370      0.97  0.2343  4.81290   \n",
       "3     2020-01-11 21:00:00  64.42930  3.54945      0.79  0.2402  4.77185   \n",
       "4     2020-01-11 23:00:00  64.09660  3.47520      0.91  0.2461  4.73080   \n",
       "...                   ...       ...      ...       ...     ...      ...   \n",
       "5150  2022-05-03 05:00:00  63.54070  4.30230      0.79  0.2725  4.63760   \n",
       "5151  2022-05-03 09:00:00  63.07030  4.20370      0.80  0.3073  4.65580   \n",
       "5152  2022-05-03 13:00:00  62.48160  4.23440      0.95  0.2872  4.72230   \n",
       "5153  2022-05-03 17:00:00  62.85425  4.28505      1.02  0.2757  4.75515   \n",
       "5154  2022-05-03 21:00:00  63.22690  4.33570      1.09  0.2642  4.78800   \n",
       "\n",
       "          SiO2     SO3     K2O    Fe2O3  Free lime  Ferrite  Periclase  \\\n",
       "0     19.86070  2.0278  1.3761  2.90930       6.18    6.730      2.500   \n",
       "1     19.44350  1.5134  1.1837  2.98670       8.50    6.770      2.440   \n",
       "2     20.27340  1.3333  1.1910  3.05860       3.47    7.200      2.620   \n",
       "3     20.06305  1.6755  1.2726  3.06005       4.42    7.340      2.540   \n",
       "4     19.85270  2.0177  1.3542  3.06150       5.37    7.110      2.640   \n",
       "...        ...     ...     ...      ...        ...      ...        ...   \n",
       "5150  19.52540  1.6458  1.2908  3.26490       3.10    9.800      3.630   \n",
       "5151  19.51010  1.8491  1.3412  3.21440       4.55    9.660      3.630   \n",
       "5152  20.00800  1.5837  1.3319  3.31380       3.48    9.020      3.380   \n",
       "5153  20.07075  1.6264  1.3342  3.32145       2.92    9.145      3.385   \n",
       "5154  20.13350  1.6691  1.3365  3.32910       2.36    9.270      3.390   \n",
       "\n",
       "      Portlandite  \n",
       "0           0.170  \n",
       "1           0.550  \n",
       "2           0.240  \n",
       "3           0.320  \n",
       "4           0.540  \n",
       "...           ...  \n",
       "5150        0.105  \n",
       "5151        0.020  \n",
       "5152        0.250  \n",
       "5153        0.280  \n",
       "5154        0.310  \n",
       "\n",
       "[5155 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clinker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>CaO</th>\n",
       "      <th>MgO</th>\n",
       "      <th>Na2O</th>\n",
       "      <th>Al2O3</th>\n",
       "      <th>SiO2</th>\n",
       "      <th>SO3</th>\n",
       "      <th>K2O</th>\n",
       "      <th>Fe2O3</th>\n",
       "      <th>Ferrite</th>\n",
       "      <th>Free lime</th>\n",
       "      <th>Portlandite</th>\n",
       "      <th>Periclase</th>\n",
       "      <th>Arcanite</th>\n",
       "      <th>28 day Compressive strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>60.007980</td>\n",
       "      <td>3.67285</td>\n",
       "      <td>0.19218</td>\n",
       "      <td>4.27263</td>\n",
       "      <td>18.556379</td>\n",
       "      <td>4.43558</td>\n",
       "      <td>1.21612</td>\n",
       "      <td>2.79746</td>\n",
       "      <td>6.40</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4.62</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>46.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>60.661800</td>\n",
       "      <td>2.53917</td>\n",
       "      <td>0.20305</td>\n",
       "      <td>4.30627</td>\n",
       "      <td>18.414921</td>\n",
       "      <td>2.54332</td>\n",
       "      <td>1.22146</td>\n",
       "      <td>3.03862</td>\n",
       "      <td>6.75</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1.59</td>\n",
       "      <td>37.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>60.755032</td>\n",
       "      <td>2.57985</td>\n",
       "      <td>0.19014</td>\n",
       "      <td>4.15108</td>\n",
       "      <td>18.481070</td>\n",
       "      <td>2.98196</td>\n",
       "      <td>1.12279</td>\n",
       "      <td>3.07343</td>\n",
       "      <td>5.61</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2.79</td>\n",
       "      <td>1.82</td>\n",
       "      <td>1.35</td>\n",
       "      <td>36.099998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>59.827351</td>\n",
       "      <td>3.71899</td>\n",
       "      <td>0.18423</td>\n",
       "      <td>4.25718</td>\n",
       "      <td>18.616140</td>\n",
       "      <td>4.42556</td>\n",
       "      <td>1.19938</td>\n",
       "      <td>2.76630</td>\n",
       "      <td>7.04</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3.77</td>\n",
       "      <td>2.72</td>\n",
       "      <td>1.06</td>\n",
       "      <td>43.900002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>58.848289</td>\n",
       "      <td>2.56056</td>\n",
       "      <td>0.19986</td>\n",
       "      <td>4.18035</td>\n",
       "      <td>17.636169</td>\n",
       "      <td>4.07796</td>\n",
       "      <td>1.20883</td>\n",
       "      <td>3.03309</td>\n",
       "      <td>6.48</td>\n",
       "      <td>0.07</td>\n",
       "      <td>3.41</td>\n",
       "      <td>2.68</td>\n",
       "      <td>1.39</td>\n",
       "      <td>48.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>2022-04-27</td>\n",
       "      <td>59.845181</td>\n",
       "      <td>2.69335</td>\n",
       "      <td>0.19684</td>\n",
       "      <td>4.35530</td>\n",
       "      <td>18.473740</td>\n",
       "      <td>4.19836</td>\n",
       "      <td>1.21207</td>\n",
       "      <td>3.02851</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.48</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.69</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>2022-04-28</td>\n",
       "      <td>58.849140</td>\n",
       "      <td>2.25720</td>\n",
       "      <td>0.18503</td>\n",
       "      <td>4.08649</td>\n",
       "      <td>17.420740</td>\n",
       "      <td>3.76640</td>\n",
       "      <td>1.17111</td>\n",
       "      <td>2.93249</td>\n",
       "      <td>8.98</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.84</td>\n",
       "      <td>47.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>60.535889</td>\n",
       "      <td>2.69857</td>\n",
       "      <td>0.19885</td>\n",
       "      <td>4.42368</td>\n",
       "      <td>18.693199</td>\n",
       "      <td>3.06924</td>\n",
       "      <td>1.21522</td>\n",
       "      <td>3.02881</td>\n",
       "      <td>8.49</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.58</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.82</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>2022-05-02</td>\n",
       "      <td>58.660820</td>\n",
       "      <td>2.58789</td>\n",
       "      <td>0.19424</td>\n",
       "      <td>4.16096</td>\n",
       "      <td>17.674860</td>\n",
       "      <td>4.07574</td>\n",
       "      <td>1.19196</td>\n",
       "      <td>3.04040</td>\n",
       "      <td>8.62</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.34</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.88</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>59.226761</td>\n",
       "      <td>2.34908</td>\n",
       "      <td>0.19578</td>\n",
       "      <td>4.18099</td>\n",
       "      <td>17.683760</td>\n",
       "      <td>3.97979</td>\n",
       "      <td>1.18948</td>\n",
       "      <td>2.92708</td>\n",
       "      <td>8.67</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.63</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.10</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1234 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        CaO      MgO     Na2O    Al2O3       SiO2      SO3  \\\n",
       "0     2020-01-02  60.007980  3.67285  0.19218  4.27263  18.556379  4.43558   \n",
       "1     2020-01-02  60.661800  2.53917  0.20305  4.30627  18.414921  2.54332   \n",
       "2     2020-01-03  60.755032  2.57985  0.19014  4.15108  18.481070  2.98196   \n",
       "3     2020-01-03  59.827351  3.71899  0.18423  4.25718  18.616140  4.42556   \n",
       "4     2020-01-03  58.848289  2.56056  0.19986  4.18035  17.636169  4.07796   \n",
       "...          ...        ...      ...      ...      ...        ...      ...   \n",
       "1229  2022-04-27  59.845181  2.69335  0.19684  4.35530  18.473740  4.19836   \n",
       "1230  2022-04-28  58.849140  2.25720  0.18503  4.08649  17.420740  3.76640   \n",
       "1231  2022-04-29  60.535889  2.69857  0.19885  4.42368  18.693199  3.06924   \n",
       "1232  2022-05-02  58.660820  2.58789  0.19424  4.16096  17.674860  4.07574   \n",
       "1233  2022-05-03  59.226761  2.34908  0.19578  4.18099  17.683760  3.97979   \n",
       "\n",
       "          K2O    Fe2O3  Ferrite  Free lime  Portlandite  Periclase  Arcanite  \\\n",
       "0     1.21612  2.79746     6.40       0.30         4.62       2.95      0.94   \n",
       "1     1.22146  3.03862     6.75       0.27         2.85       2.75      1.59   \n",
       "2     1.12279  3.07343     5.61       0.42         2.79       1.82      1.35   \n",
       "3     1.19938  2.76630     7.04       0.27         3.77       2.72      1.06   \n",
       "4     1.20883  3.03309     6.48       0.07         3.41       2.68      1.39   \n",
       "...       ...      ...      ...        ...          ...        ...       ...   \n",
       "1229  1.21207  3.02851     8.78       0.87         0.48       3.15      0.69   \n",
       "1230  1.17111  2.93249     8.98       1.08         0.32       2.91      0.84   \n",
       "1231  1.21522  3.02881     8.49       0.39         0.58       2.91      0.82   \n",
       "1232  1.19196  3.04040     8.62       0.55         0.34       3.01      0.88   \n",
       "1233  1.18948  2.92708     8.67       0.37         0.63       3.10      1.10   \n",
       "\n",
       "      28 day Compressive strength  \n",
       "0                       46.400002  \n",
       "1                       37.400002  \n",
       "2                       36.099998  \n",
       "3                       43.900002  \n",
       "4                       48.500000  \n",
       "...                           ...  \n",
       "1229                    47.000000  \n",
       "1230                    47.500000  \n",
       "1231                    37.000000  \n",
       "1232                    47.000000  \n",
       "1233                    48.000000  \n",
       "\n",
       "[1234 rows x 15 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_CLINKER = df_cimento.drop(\"28 day Compressive strength\", axis=1).columns\n",
    "COLUMNS_CEMENT  = df_cimento.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'CaO', 'MgO', 'Na2O', 'Al2O3', 'SiO2', 'SO3', 'K2O', 'Fe2O3',\n",
       "       'Ferrite', 'Free lime', 'Portlandite', 'Periclase', 'Arcanite'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMNS_CLINKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'CaO', 'MgO', 'Na2O', 'Al2O3', 'SiO2', 'SO3', 'K2O', 'Fe2O3',\n",
       "       'Ferrite', 'Free lime', 'Portlandite', 'Periclase', 'Arcanite',\n",
       "       '28 day Compressive strength'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMNS_CEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_cimento['28 day Compressive strength']\n",
    "x = df_cimento.drop(['Date', '28 day Compressive strength'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "scores = score_model(model, x, y, n_splits=10, n_repeats=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5345870856333392"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1234, 13)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_cimento['28 day Compressive strength']\n",
    "x = df_cimento.drop(['Date', '28 day Compressive strength'], axis=1)\n",
    "test_size = 0.2\n",
    "x, y = split_sequences(pd.concat([x, y], axis=1).values, 3)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=test_size, random_state=SEED, shuffle=False\n",
    ")\n",
    "sc = StandardScaler3DShape()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[\"num_features\"] = 13\n",
    "params[\"timesteps\"] = 3\n",
    "params[\"num_heads\"] = 2\n",
    "params[\"num_layers_enc\"] = 1\n",
    "params[\"num_feed_forward\"] = 32\n",
    "params[\"units_output\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "31/31 [==============================] - 1s 4ms/step - loss: 1715.2654 - RMSE: 41.4158\n",
      "Epoch 2/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1577.7584 - RMSE: 39.7210\n",
      "Epoch 3/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1505.4209 - RMSE: 38.7998\n",
      "Epoch 4/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1436.4613 - RMSE: 37.9007\n",
      "Epoch 5/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1364.9071 - RMSE: 36.9446\n",
      "Epoch 6/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1289.4106 - RMSE: 35.9084\n",
      "Epoch 7/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1211.4340 - RMSE: 34.8057\n",
      "Epoch 8/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1129.6663 - RMSE: 33.6105\n",
      "Epoch 9/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1044.7505 - RMSE: 32.3226\n",
      "Epoch 10/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 959.4602 - RMSE: 30.9752\n",
      "Epoch 11/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 874.0823 - RMSE: 29.5649\n",
      "Epoch 12/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 789.9489 - RMSE: 28.1060\n",
      "Epoch 13/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 706.6752 - RMSE: 26.5834\n",
      "Epoch 14/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 627.7731 - RMSE: 25.0554\n",
      "Epoch 15/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 551.6249 - RMSE: 23.4867\n",
      "Epoch 16/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 480.1108 - RMSE: 21.9114\n",
      "Epoch 17/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 414.2944 - RMSE: 20.3542\n",
      "Epoch 18/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 353.6922 - RMSE: 18.8067\n",
      "Epoch 19/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 299.7997 - RMSE: 17.3147\n",
      "Epoch 20/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 252.0336 - RMSE: 15.8756\n",
      "Epoch 21/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 209.8806 - RMSE: 14.4873\n",
      "Epoch 22/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 173.5413 - RMSE: 13.1735\n",
      "Epoch 23/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 142.6527 - RMSE: 11.9437\n",
      "Epoch 24/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 117.2124 - RMSE: 10.8265\n",
      "Epoch 25/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 95.6330 - RMSE: 9.7792\n",
      "Epoch 26/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 78.9069 - RMSE: 8.8830\n",
      "Epoch 27/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 65.3725 - RMSE: 8.0853\n",
      "Epoch 28/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 54.8363 - RMSE: 7.4052\n",
      "Epoch 29/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 46.7876 - RMSE: 6.8401\n",
      "Epoch 30/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 40.7173 - RMSE: 6.3810\n",
      "Epoch 31/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 36.1170 - RMSE: 6.0097\n",
      "Epoch 32/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 33.0283 - RMSE: 5.7470\n",
      "Epoch 33/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 30.5191 - RMSE: 5.5244\n",
      "Epoch 34/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 28.9333 - RMSE: 5.3790\n",
      "Epoch 35/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 27.8977 - RMSE: 5.2818\n",
      "Epoch 36/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 26.9590 - RMSE: 5.1922\n",
      "Epoch 37/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 26.4058 - RMSE: 5.1387\n",
      "Epoch 38/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 26.2146 - RMSE: 5.1200\n",
      "Epoch 39/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.8723 - RMSE: 5.0865\n",
      "Epoch 40/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 25.8062 - RMSE: 5.0800\n",
      "Epoch 41/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 25.7545 - RMSE: 5.0749\n",
      "Epoch 42/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.6277 - RMSE: 5.0624\n",
      "Epoch 43/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.6528 - RMSE: 5.0649\n",
      "Epoch 44/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 25.5103 - RMSE: 5.0508\n",
      "Epoch 45/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 25.5972 - RMSE: 5.0594\n",
      "Epoch 46/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.6853 - RMSE: 5.0681\n",
      "Epoch 47/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.6337 - RMSE: 5.0630\n",
      "Epoch 48/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.5131 - RMSE: 5.0510\n",
      "Epoch 49/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.4893 - RMSE: 5.0487\n",
      "Epoch 50/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.6821 - RMSE: 5.0678\n",
      "Epoch 51/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.6268 - RMSE: 5.0623\n",
      "Epoch 52/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.5691 - RMSE: 5.0566\n",
      "Epoch 53/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.4362 - RMSE: 5.0434\n",
      "Epoch 54/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.5484 - RMSE: 5.0545\n",
      "Epoch 55/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.3625 - RMSE: 5.0361\n",
      "Epoch 56/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.5704 - RMSE: 5.0567\n",
      "Epoch 57/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.5617 - RMSE: 5.0559\n",
      "Epoch 58/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.5407 - RMSE: 5.0538\n",
      "Epoch 59/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.3641 - RMSE: 5.0363\n",
      "Epoch 60/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.5054 - RMSE: 5.0503\n",
      "Epoch 61/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.5149 - RMSE: 5.0512\n",
      "Epoch 62/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.6331 - RMSE: 5.0629\n",
      "Epoch 63/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.5074 - RMSE: 5.0505\n",
      "Epoch 64/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.3317 - RMSE: 5.0331\n",
      "Epoch 65/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.3297 - RMSE: 5.0329\n",
      "Epoch 66/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.4521 - RMSE: 5.0450\n",
      "Epoch 67/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.3769 - RMSE: 5.0376\n",
      "Epoch 68/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.5700 - RMSE: 5.0567\n",
      "Epoch 69/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.4674 - RMSE: 5.0465\n",
      "Epoch 70/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.3883 - RMSE: 5.0387\n",
      "Epoch 71/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.3012 - RMSE: 5.0300\n",
      "Epoch 72/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.3697 - RMSE: 5.0368\n",
      "Epoch 73/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.2628 - RMSE: 5.0262\n",
      "Epoch 74/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.2799 - RMSE: 5.0279\n",
      "Epoch 75/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.1470 - RMSE: 5.0147\n",
      "Epoch 76/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 25.1909 - RMSE: 5.0191\n",
      "Epoch 77/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 24.8731 - RMSE: 4.9873\n",
      "Epoch 78/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 24.7786 - RMSE: 4.9778\n",
      "Epoch 79/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 24.8525 - RMSE: 4.9852\n",
      "Epoch 80/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 24.7623 - RMSE: 4.9762\n",
      "Epoch 81/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 24.7303 - RMSE: 4.9730\n",
      "Epoch 82/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 24.4310 - RMSE: 4.9428\n",
      "Epoch 83/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 24.6925 - RMSE: 4.9692\n",
      "Epoch 84/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 25.0097 - RMSE: 5.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 24.2640 - RMSE: 4.9258\n",
      "Epoch 86/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.0952 - RMSE: 4.9087\n",
      "Epoch 87/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.2282 - RMSE: 4.9222\n",
      "Epoch 88/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 24.2545 - RMSE: 4.9249\n",
      "Epoch 89/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 23.9661 - RMSE: 4.8955\n",
      "Epoch 90/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 23.8914 - RMSE: 4.8879\n",
      "Epoch 91/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 24.0132 - RMSE: 4.9003\n",
      "Epoch 92/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 24.7631 - RMSE: 4.9763\n",
      "Epoch 93/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 24.5108 - RMSE: 4.9508\n",
      "Epoch 94/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.1063 - RMSE: 4.9098\n",
      "Epoch 95/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.9275 - RMSE: 4.8916\n",
      "Epoch 96/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 23.9335 - RMSE: 4.8922\n",
      "Epoch 97/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.9673 - RMSE: 4.8956\n",
      "Epoch 98/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.8206 - RMSE: 4.8806\n",
      "Epoch 99/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 23.6181 - RMSE: 4.8598\n",
      "Epoch 100/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.9875 - RMSE: 4.8977\n",
      "Epoch 101/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.6545 - RMSE: 4.8636\n",
      "Epoch 102/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.4821 - RMSE: 4.8458\n",
      "Epoch 103/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 23.5481 - RMSE: 4.8526\n",
      "Epoch 104/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 24.2399 - RMSE: 4.9234\n",
      "Epoch 105/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 23.3022 - RMSE: 4.8272\n",
      "Epoch 106/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.4772 - RMSE: 4.8453\n",
      "Epoch 107/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 23.6002 - RMSE: 4.8580\n",
      "Epoch 108/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 23.2215 - RMSE: 4.8189\n",
      "Epoch 109/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 23.3839 - RMSE: 4.8357\n",
      "Epoch 110/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 24.1437 - RMSE: 4.9136\n",
      "Epoch 111/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 23.0250 - RMSE: 4.7984\n",
      "Epoch 112/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 23.3589 - RMSE: 4.8331\n",
      "Epoch 113/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 23.7839 - RMSE: 4.8769\n",
      "Epoch 114/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 23.6887 - RMSE: 4.8671\n",
      "Epoch 115/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 23.5332 - RMSE: 4.8511\n",
      "Epoch 116/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 23.5280 - RMSE: 4.8506\n",
      "Epoch 117/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 23.2093 - RMSE: 4.8176\n",
      "Epoch 118/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 23.6316 - RMSE: 4.8612\n",
      "Epoch 119/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.5628 - RMSE: 4.8542\n",
      "Epoch 120/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.3215 - RMSE: 4.8292\n",
      "Epoch 121/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 23.4734 - RMSE: 4.8449\n",
      "Epoch 122/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 23.4757 - RMSE: 4.8452\n",
      "Epoch 123/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.3660 - RMSE: 4.8338\n",
      "Epoch 124/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.3326 - RMSE: 4.8304\n",
      "Epoch 125/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 23.4420 - RMSE: 4.8417\n",
      "Epoch 126/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 23.2978 - RMSE: 4.8268\n",
      "Epoch 127/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.9910 - RMSE: 4.7949\n",
      "Epoch 128/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 23.3475 - RMSE: 4.8319\n",
      "Epoch 129/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.2446 - RMSE: 4.8213\n",
      "Epoch 130/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 23.2738 - RMSE: 4.8243\n",
      "Epoch 131/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 23.1245 - RMSE: 4.8088\n",
      "Epoch 132/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.9812 - RMSE: 4.7939\n",
      "Epoch 133/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 23.0474 - RMSE: 4.8008\n",
      "Epoch 134/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 23.6371 - RMSE: 4.8618\n",
      "Epoch 135/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.2009 - RMSE: 4.8167\n",
      "Epoch 136/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 23.2801 - RMSE: 4.8249\n",
      "Epoch 137/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 23.6542 - RMSE: 4.8636\n",
      "Epoch 138/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 23.1517 - RMSE: 4.8116\n",
      "Epoch 139/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 23.3303 - RMSE: 4.8301\n",
      "Epoch 140/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 23.1622 - RMSE: 4.8127\n",
      "Epoch 141/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 23.4614 - RMSE: 4.8437\n",
      "Epoch 142/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.6038 - RMSE: 4.8584\n",
      "Epoch 143/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 22.9051 - RMSE: 4.7859\n",
      "Epoch 144/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 23.2449 - RMSE: 4.8213\n",
      "Epoch 145/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 23.2415 - RMSE: 4.8209\n",
      "Epoch 146/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 23.1740 - RMSE: 4.8139\n",
      "Epoch 147/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.1526 - RMSE: 4.8117\n",
      "Epoch 148/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 23.0519 - RMSE: 4.8012\n",
      "Epoch 149/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 23.0826 - RMSE: 4.8044\n",
      "Epoch 150/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.8729 - RMSE: 4.7826\n",
      "Epoch 151/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 22.8136 - RMSE: 4.7764\n",
      "Epoch 152/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.1063 - RMSE: 4.8069\n",
      "Epoch 153/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.8952 - RMSE: 4.7849\n",
      "Epoch 154/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.2870 - RMSE: 4.8257\n",
      "Epoch 155/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 22.7002 - RMSE: 4.7645\n",
      "Epoch 156/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.6824 - RMSE: 4.7626\n",
      "Epoch 157/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 23.1167 - RMSE: 4.8080\n",
      "Epoch 158/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.7884 - RMSE: 4.7737\n",
      "Epoch 159/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 23.0078 - RMSE: 4.7966\n",
      "Epoch 160/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 22.7424 - RMSE: 4.7689\n",
      "Epoch 161/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 22.7717 - RMSE: 4.7720\n",
      "Epoch 162/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.8981 - RMSE: 4.7852\n",
      "Epoch 163/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 23.0685 - RMSE: 4.8030\n",
      "Epoch 164/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.8760 - RMSE: 4.7829\n",
      "Epoch 165/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 23.0050 - RMSE: 4.7964\n",
      "Epoch 166/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 22.4602 - RMSE: 4.7392\n",
      "Epoch 167/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.9269 - RMSE: 4.7882\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 3ms/step - loss: 23.2153 - RMSE: 4.8182\n",
      "Epoch 169/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 23.0028 - RMSE: 4.7961\n",
      "Epoch 170/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 22.6241 - RMSE: 4.7565\n",
      "Epoch 171/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.4599 - RMSE: 4.7392\n",
      "Epoch 172/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 22.8505 - RMSE: 4.7802\n",
      "Epoch 173/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 23.0071 - RMSE: 4.7966\n",
      "Epoch 174/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.8325 - RMSE: 4.7783\n",
      "Epoch 175/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 23.0637 - RMSE: 4.8025\n",
      "Epoch 176/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.8334 - RMSE: 4.7784\n",
      "Epoch 177/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.9998 - RMSE: 4.7958\n",
      "Epoch 178/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.2080 - RMSE: 4.7125\n",
      "Epoch 179/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 23.8372 - RMSE: 4.8823\n",
      "Epoch 180/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 23.1660 - RMSE: 4.8131\n",
      "Epoch 181/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.9448 - RMSE: 4.7901\n",
      "Epoch 182/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.6675 - RMSE: 4.7610\n",
      "Epoch 183/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.6143 - RMSE: 4.7555\n",
      "Epoch 184/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.7445 - RMSE: 4.7691\n",
      "Epoch 185/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 22.6137 - RMSE: 4.7554\n",
      "Epoch 186/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.6027 - RMSE: 4.7542\n",
      "Epoch 187/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.4034 - RMSE: 4.7332\n",
      "Epoch 188/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.5322 - RMSE: 4.7468\n",
      "Epoch 189/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.6528 - RMSE: 4.7595\n",
      "Epoch 190/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.5473 - RMSE: 4.7484\n",
      "Epoch 191/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.4769 - RMSE: 4.7410\n",
      "Epoch 192/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.6123 - RMSE: 4.7552\n",
      "Epoch 193/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.4202 - RMSE: 4.7350\n",
      "Epoch 194/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.6213 - RMSE: 4.7562\n",
      "Epoch 195/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.4488 - RMSE: 4.7380\n",
      "Epoch 196/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.8713 - RMSE: 4.7824\n",
      "Epoch 197/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.5102 - RMSE: 4.7445\n",
      "Epoch 198/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.4330 - RMSE: 4.7364\n",
      "Epoch 199/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 22.3723 - RMSE: 4.7299\n",
      "Epoch 200/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 22.8078 - RMSE: 4.7758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f79f8bb0c18>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(params)\n",
    "model.compile(\n",
    "    tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"mse\",\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 4.735 (0.000)\n",
      "MAE: 3.991 (0.000)\n",
      "MAPE: 0.098 (0.000)\n",
      "R2: 0.121 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 4.730 (0.000)\n",
      "MAE: 4.157 (0.000)\n",
      "MAPE: 0.098 (0.000)\n",
      "R2: 0.094 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\n",
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 3, 13)             2372      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  14        \n",
      "=================================================================\n",
      "Total params: 2,386\n",
      "Trainable params: 2,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Clinker Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "# https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, samples, batch_size=32, dim=(3,13), shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.samples = samples\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.samples) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        samples_temp = [self.samples[k].copy() for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(samples_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.samples))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, samples_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "        y = np.empty((self.batch_size), dtype=float)        \n",
    "        samples_temp = [array.copy() for array in samples_temp]\n",
    "        \n",
    "        # Generate data\n",
    "        for i, sample in enumerate(samples_temp):\n",
    "            feature = np.random.randint(low=0, high=13, size=None, dtype=int)\n",
    "            # Store sample\n",
    "#             for j, _ in enumerate(sample):\n",
    "#                 y[i] = sample[j][feature]\n",
    "#                 sample[j][feature] = -100\n",
    "            y[i] = sample[0][feature]\n",
    "            sample[0][feature] = -100\n",
    "            X[i,] = sample           \n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generation(samples_temp):\n",
    "    'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "    # Initialization\n",
    "    X = np.empty((32, *(3, 13)))\n",
    "    y = np.empty((32, 13), dtype=float)        \n",
    "    samples_temp_copy = [array.copy() for array in samples_temp]\n",
    "    \n",
    "    # Generate data\n",
    "    for i, sample in enumerate(samples_temp_copy):\n",
    "        feature = np.random.randint(low=0, high=X.shape[1], size=None, dtype=int)\n",
    "        # Store sample\n",
    "        y[i] = sample[feature, :]\n",
    "        sample[feature, :] = -100\n",
    "        X[i,] = sample\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "# https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "\n",
    "class DataGenerator_2(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, samples, batch_size=32, dim=(3,13), shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.samples = samples\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.samples) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        samples_temp = [self.samples[k].copy() for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(samples_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.samples))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, samples_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "        y = np.empty((self.batch_size, X.shape[-1]), dtype=float)        \n",
    "        samples_temp = [array.copy() for array in samples_temp]\n",
    "        \n",
    "        # Generate data\n",
    "        for i, sample in enumerate(samples_temp):\n",
    "            #feature = np.random.randint(low=0, high=X.shape[1], size=None, dtype=int)\n",
    "            feature = X.shape[1] - 1\n",
    "            # Store sample            \n",
    "            y[i] = sample[feature, :]\n",
    "            #if np.random.choice([1, 0], p=[0.3, 0.7]) == 1:\n",
    "            #    sample[feature, :] = -999\n",
    "            sample[feature, :] = -999\n",
    "            X[i,] = sample\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTEPS = 5\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_clinker.drop(\"Date\", axis=1)\n",
    "y = df_clinker.iloc[:, 0]\n",
    "x, _ = split_sequences(pd.concat([x, y], axis=1).values, TIMESTEPS)\n",
    "sc = StandardScaler3DShape()\n",
    "x = sc.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtgen_params = {\n",
    "    'dim': (TIMESTEPS, x.shape[-1]),\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'shuffle': True\n",
    "}\n",
    "\n",
    "training_generator = DataGenerator_2(x, **dtgen_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[\"num_features\"] = x.shape[-1] # 13\n",
    "params[\"timesteps\"] = TIMESTEPS\n",
    "params[\"num_heads\"] = 5\n",
    "params[\"num_layers_enc\"] = 5\n",
    "params[\"num_feed_forward\"] = 128\n",
    "params[\"units_output\"] = x.shape[-1] # 13\n",
    "\n",
    "model = get_model(params)\n",
    "model.compile(\n",
    "    tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"mse\",\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documents/ccs28-venv/lib/python3.6/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "80/80 [==============================] - 8s 24ms/step - loss: 0.8238 - RMSE: 0.9077\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.7305 - RMSE: 0.8547\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.6966 - RMSE: 0.8346\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.6780 - RMSE: 0.8234\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 2s 31ms/step - loss: 0.6621 - RMSE: 0.8137\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 2s 30ms/step - loss: 0.6570 - RMSE: 0.8106\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.6427 - RMSE: 0.8017\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 3s 36ms/step - loss: 0.6427 - RMSE: 0.8017\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 2s 30ms/step - loss: 0.6387 - RMSE: 0.7992\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 3s 34ms/step - loss: 0.6327 - RMSE: 0.7954\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 2s 30ms/step - loss: 0.6415 - RMSE: 0.8009\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 0.6392 - RMSE: 0.7995\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.6353 - RMSE: 0.7971\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.6375 - RMSE: 0.7985\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.6298 - RMSE: 0.7936\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.6297 - RMSE: 0.7936\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.6299 - RMSE: 0.7937\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.6290 - RMSE: 0.7931\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.6272 - RMSE: 0.7920\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.6276 - RMSE: 0.7922\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.6297 - RMSE: 0.7935\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.6298 - RMSE: 0.7936\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.6308 - RMSE: 0.7942\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.6299 - RMSE: 0.7937\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.6266 - RMSE: 0.7916\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 2s 30ms/step - loss: 0.6225 - RMSE: 0.7890\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.6250 - RMSE: 0.7906\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.6225 - RMSE: 0.7890\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.6217 - RMSE: 0.7885\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.6197 - RMSE: 0.7872\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.6161 - RMSE: 0.7849\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.6145 - RMSE: 0.7839\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.6097 - RMSE: 0.7808\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.6162 - RMSE: 0.7850\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.6125 - RMSE: 0.7826\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.6125 - RMSE: 0.7826\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.6138 - RMSE: 0.7835\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.6118 - RMSE: 0.7822\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.6085 - RMSE: 0.7801\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.6054 - RMSE: 0.7781\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.6045 - RMSE: 0.7775\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.6030 - RMSE: 0.7765\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.6012 - RMSE: 0.7754\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.6009 - RMSE: 0.7752\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.6027 - RMSE: 0.7763\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5983 - RMSE: 0.7735\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5983 - RMSE: 0.7735\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5972 - RMSE: 0.7728\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5956 - RMSE: 0.7718\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5935 - RMSE: 0.7704\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5916 - RMSE: 0.7691\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5904 - RMSE: 0.7684\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5908 - RMSE: 0.7686\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5957 - RMSE: 0.7718\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5941 - RMSE: 0.7708\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 3s 32ms/step - loss: 0.5973 - RMSE: 0.7729\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5904 - RMSE: 0.7684\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5855 - RMSE: 0.7652\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5876 - RMSE: 0.7666\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5836 - RMSE: 0.7639\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5884 - RMSE: 0.7671\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5864 - RMSE: 0.7658\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 0.5819 - RMSE: 0.7628\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5809 - RMSE: 0.7622\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5798 - RMSE: 0.7615\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5811 - RMSE: 0.7623\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5759 - RMSE: 0.7589\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5745 - RMSE: 0.7579\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 3s 31ms/step - loss: 0.5732 - RMSE: 0.7571\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5722 - RMSE: 0.7564\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5736 - RMSE: 0.7574\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 3s 36ms/step - loss: 0.5695 - RMSE: 0.7546\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5675 - RMSE: 0.7533\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 0.5697 - RMSE: 0.7548 \n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5685 - RMSE: 0.7540\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5717 - RMSE: 0.7561\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5661 - RMSE: 0.7524\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5634 - RMSE: 0.7506\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5653 - RMSE: 0.7519\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5694 - RMSE: 0.7546\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5694 - RMSE: 0.7546\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5731 - RMSE: 0.7571\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5683 - RMSE: 0.7539\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5668 - RMSE: 0.7528\n",
      "Epoch 85/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5652 - RMSE: 0.7518\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5604 - RMSE: 0.7486\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5603 - RMSE: 0.7486\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5595 - RMSE: 0.7480\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 3s 34ms/step - loss: 0.5593 - RMSE: 0.7479\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5579 - RMSE: 0.7469\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5558 - RMSE: 0.7455\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5542 - RMSE: 0.7444\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.5548 - RMSE: 0.7448\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5525 - RMSE: 0.7433\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5489 - RMSE: 0.7409\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5487 - RMSE: 0.7408\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5474 - RMSE: 0.7399\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5464 - RMSE: 0.7392\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5455 - RMSE: 0.7386\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5463 - RMSE: 0.7392\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5459 - RMSE: 0.7389\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5432 - RMSE: 0.7370\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5413 - RMSE: 0.7357\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5379 - RMSE: 0.7334\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.5368 - RMSE: 0.7327\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5337 - RMSE: 0.7306\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5372 - RMSE: 0.7329\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 2s 31ms/step - loss: 0.5392 - RMSE: 0.7343\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5400 - RMSE: 0.7348\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5421 - RMSE: 0.7362\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5410 - RMSE: 0.7355\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5398 - RMSE: 0.7347\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5389 - RMSE: 0.7341\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5367 - RMSE: 0.7326\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5395 - RMSE: 0.7345\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5375 - RMSE: 0.7331\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5355 - RMSE: 0.7318\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5333 - RMSE: 0.7303\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5390 - RMSE: 0.7342\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5419 - RMSE: 0.7361\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5400 - RMSE: 0.7348\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5409 - RMSE: 0.7355\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5374 - RMSE: 0.7331\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5341 - RMSE: 0.7308\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5367 - RMSE: 0.7326\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5352 - RMSE: 0.7316\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5331 - RMSE: 0.7302\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5308 - RMSE: 0.7286\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5278 - RMSE: 0.7265\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5338 - RMSE: 0.7306\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5329 - RMSE: 0.7300\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.5356 - RMSE: 0.7318\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.5347 - RMSE: 0.7312\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5330 - RMSE: 0.7301\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5366 - RMSE: 0.7325\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5368 - RMSE: 0.7327\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5348 - RMSE: 0.7313\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 0.5414 - RMSE: 0.7358\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5346 - RMSE: 0.7312\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5362 - RMSE: 0.7323\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5333 - RMSE: 0.7302\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5343 - RMSE: 0.7309\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5341 - RMSE: 0.7309\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5309 - RMSE: 0.7286\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 0.5282 - RMSE: 0.7268\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5255 - RMSE: 0.7249\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5268 - RMSE: 0.7258\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.5272 - RMSE: 0.7261\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5251 - RMSE: 0.7247\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5292 - RMSE: 0.7275\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5270 - RMSE: 0.7259\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.5270 - RMSE: 0.7260\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.5282 - RMSE: 0.7267\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5252 - RMSE: 0.7247\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5230 - RMSE: 0.7232\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5274 - RMSE: 0.7262\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5303 - RMSE: 0.7282\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5253 - RMSE: 0.7247\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5247 - RMSE: 0.7243\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5213 - RMSE: 0.7220\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5213 - RMSE: 0.7220\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5208 - RMSE: 0.7217\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5171 - RMSE: 0.7191\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5176 - RMSE: 0.7195\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5227 - RMSE: 0.7230\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5305 - RMSE: 0.7283\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5257 - RMSE: 0.7250\n",
      "Epoch 168/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5226 - RMSE: 0.7229\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5190 - RMSE: 0.7204\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5163 - RMSE: 0.7185\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5155 - RMSE: 0.7180\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5167 - RMSE: 0.7188\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5130 - RMSE: 0.7163\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5116 - RMSE: 0.7153\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5138 - RMSE: 0.7168\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5131 - RMSE: 0.7163\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5128 - RMSE: 0.7161\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5091 - RMSE: 0.7135\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5117 - RMSE: 0.7153\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5135 - RMSE: 0.7166\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5100 - RMSE: 0.7142\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5112 - RMSE: 0.7150\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5192 - RMSE: 0.7206\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5201 - RMSE: 0.7212\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5235 - RMSE: 0.7235\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5214 - RMSE: 0.7221\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 2s 30ms/step - loss: 0.5236 - RMSE: 0.7236\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 3s 36ms/step - loss: 0.5245 - RMSE: 0.7242\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5214 - RMSE: 0.7221\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5210 - RMSE: 0.7218\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5180 - RMSE: 0.7197\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5224 - RMSE: 0.7228\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5279 - RMSE: 0.7266\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5263 - RMSE: 0.7254\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5256 - RMSE: 0.7250\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.5251 - RMSE: 0.7246\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.5241 - RMSE: 0.7239\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5213 - RMSE: 0.7220\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5181 - RMSE: 0.7198\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5149 - RMSE: 0.7176\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5144 - RMSE: 0.7172\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5149 - RMSE: 0.7176\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5130 - RMSE: 0.7162\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 0.5110 - RMSE: 0.7149\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5167 - RMSE: 0.7188\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.5158 - RMSE: 0.7182\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.5127 - RMSE: 0.7160\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.5143 - RMSE: 0.7171\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.5126 - RMSE: 0.7160\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.5114 - RMSE: 0.7151\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.5103 - RMSE: 0.7144\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.5064 - RMSE: 0.7116\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.5072 - RMSE: 0.7122\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.5053 - RMSE: 0.7109\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.5051 - RMSE: 0.7107\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.5041 - RMSE: 0.7100\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.5069 - RMSE: 0.7120\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.5044 - RMSE: 0.7102\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.5055 - RMSE: 0.7110\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.5055 - RMSE: 0.7110\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.5036 - RMSE: 0.7096\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.5038 - RMSE: 0.7098\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4988 - RMSE: 0.7062\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.5017 - RMSE: 0.7083\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4975 - RMSE: 0.7053\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.5037 - RMSE: 0.7097\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.5011 - RMSE: 0.7079\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.5324 - RMSE: 0.7297\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.5252 - RMSE: 0.7247\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.5164 - RMSE: 0.7186\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.5055 - RMSE: 0.7110\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.5016 - RMSE: 0.7083\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.5014 - RMSE: 0.7081\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4990 - RMSE: 0.7064\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.5021 - RMSE: 0.7086\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.5042 - RMSE: 0.7101\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.5016 - RMSE: 0.7082\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.5012 - RMSE: 0.7079\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4986 - RMSE: 0.7061\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4986 - RMSE: 0.7061\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4979 - RMSE: 0.7056\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4967 - RMSE: 0.7048\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4986 - RMSE: 0.7061\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4984 - RMSE: 0.7060\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4960 - RMSE: 0.7043\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4969 - RMSE: 0.7049\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4972 - RMSE: 0.7051\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4979 - RMSE: 0.7057\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.5017 - RMSE: 0.7083\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4999 - RMSE: 0.7070\n",
      "Epoch 251/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4982 - RMSE: 0.7058\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4970 - RMSE: 0.7050\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4938 - RMSE: 0.7027\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4957 - RMSE: 0.7040\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4958 - RMSE: 0.7041\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4917 - RMSE: 0.7012\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4961 - RMSE: 0.7043\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4930 - RMSE: 0.7021\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4993 - RMSE: 0.7066\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4968 - RMSE: 0.7048\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.5001 - RMSE: 0.7072\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.5069 - RMSE: 0.7120\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 1s 19ms/step - loss: 0.5113 - RMSE: 0.7150\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.5056 - RMSE: 0.7111\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.5038 - RMSE: 0.7098\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.5012 - RMSE: 0.7079\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4980 - RMSE: 0.7057\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4982 - RMSE: 0.7058\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4976 - RMSE: 0.7054\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4942 - RMSE: 0.7030\n",
      "Epoch 271/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4949 - RMSE: 0.7035\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4955 - RMSE: 0.7039\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4928 - RMSE: 0.7020\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4927 - RMSE: 0.7019\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4911 - RMSE: 0.7008\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4913 - RMSE: 0.7009\n",
      "Epoch 277/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4932 - RMSE: 0.7022\n",
      "Epoch 278/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4929 - RMSE: 0.7020\n",
      "Epoch 279/500\n",
      "80/80 [==============================] - 1s 19ms/step - loss: 0.4941 - RMSE: 0.7030\n",
      "Epoch 280/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4949 - RMSE: 0.7035\n",
      "Epoch 281/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4873 - RMSE: 0.6981\n",
      "Epoch 282/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4904 - RMSE: 0.7003\n",
      "Epoch 283/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.4870 - RMSE: 0.6978\n",
      "Epoch 284/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4904 - RMSE: 0.7003\n",
      "Epoch 285/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4893 - RMSE: 0.6995\n",
      "Epoch 286/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4941 - RMSE: 0.7029\n",
      "Epoch 287/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4931 - RMSE: 0.7022\n",
      "Epoch 288/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4947 - RMSE: 0.7033\n",
      "Epoch 289/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4918 - RMSE: 0.7013\n",
      "Epoch 290/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4925 - RMSE: 0.7018\n",
      "Epoch 291/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4946 - RMSE: 0.7033\n",
      "Epoch 292/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4923 - RMSE: 0.7016\n",
      "Epoch 293/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4946 - RMSE: 0.7033\n",
      "Epoch 294/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4930 - RMSE: 0.7022\n",
      "Epoch 295/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4978 - RMSE: 0.7055\n",
      "Epoch 296/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4922 - RMSE: 0.7016\n",
      "Epoch 297/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4875 - RMSE: 0.6982\n",
      "Epoch 298/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4840 - RMSE: 0.6957\n",
      "Epoch 299/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4822 - RMSE: 0.6944\n",
      "Epoch 300/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4818 - RMSE: 0.6941\n",
      "Epoch 301/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4857 - RMSE: 0.6969\n",
      "Epoch 302/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4888 - RMSE: 0.6991\n",
      "Epoch 303/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4835 - RMSE: 0.6953\n",
      "Epoch 304/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4842 - RMSE: 0.6958\n",
      "Epoch 305/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4918 - RMSE: 0.7013\n",
      "Epoch 306/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4865 - RMSE: 0.6975\n",
      "Epoch 307/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4873 - RMSE: 0.6981\n",
      "Epoch 308/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4914 - RMSE: 0.7010\n",
      "Epoch 309/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4939 - RMSE: 0.7028\n",
      "Epoch 310/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4905 - RMSE: 0.7003\n",
      "Epoch 311/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.4910 - RMSE: 0.7007\n",
      "Epoch 312/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4854 - RMSE: 0.6967\n",
      "Epoch 313/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4816 - RMSE: 0.6940\n",
      "Epoch 314/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.4877 - RMSE: 0.6984\n",
      "Epoch 315/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4859 - RMSE: 0.6970\n",
      "Epoch 316/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4855 - RMSE: 0.6968\n",
      "Epoch 317/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4820 - RMSE: 0.6943\n",
      "Epoch 318/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4833 - RMSE: 0.6952\n",
      "Epoch 319/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.4835 - RMSE: 0.6954\n",
      "Epoch 320/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4820 - RMSE: 0.6943\n",
      "Epoch 321/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4839 - RMSE: 0.6956\n",
      "Epoch 322/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.4815 - RMSE: 0.6939\n",
      "Epoch 323/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4765 - RMSE: 0.6903\n",
      "Epoch 324/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4903 - RMSE: 0.7002\n",
      "Epoch 325/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4956 - RMSE: 0.7040\n",
      "Epoch 326/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4958 - RMSE: 0.7041\n",
      "Epoch 327/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4896 - RMSE: 0.6997\n",
      "Epoch 328/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4913 - RMSE: 0.7009\n",
      "Epoch 329/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4873 - RMSE: 0.6981\n",
      "Epoch 330/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.4837 - RMSE: 0.6955\n",
      "Epoch 331/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.4876 - RMSE: 0.6983\n",
      "Epoch 332/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4887 - RMSE: 0.6991\n",
      "Epoch 333/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4848 - RMSE: 0.6962\n",
      "Epoch 334/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4830 - RMSE: 0.6950\n",
      "Epoch 335/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4813 - RMSE: 0.6937\n",
      "Epoch 336/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4796 - RMSE: 0.6925\n",
      "Epoch 337/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4796 - RMSE: 0.6925\n",
      "Epoch 338/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4784 - RMSE: 0.6916\n",
      "Epoch 339/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4793 - RMSE: 0.6923\n",
      "Epoch 340/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4808 - RMSE: 0.6934\n",
      "Epoch 341/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4792 - RMSE: 0.6922\n",
      "Epoch 342/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4833 - RMSE: 0.6952\n",
      "Epoch 343/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4821 - RMSE: 0.6943\n",
      "Epoch 344/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4911 - RMSE: 0.7008\n",
      "Epoch 345/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4870 - RMSE: 0.6978\n",
      "Epoch 346/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4884 - RMSE: 0.6988\n",
      "Epoch 347/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4869 - RMSE: 0.6978\n",
      "Epoch 348/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4889 - RMSE: 0.6992\n",
      "Epoch 349/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4888 - RMSE: 0.6992\n",
      "Epoch 350/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4868 - RMSE: 0.6977\n",
      "Epoch 351/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4841 - RMSE: 0.6958\n",
      "Epoch 352/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4856 - RMSE: 0.6969\n",
      "Epoch 353/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4828 - RMSE: 0.6949\n",
      "Epoch 354/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4844 - RMSE: 0.6960\n",
      "Epoch 355/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4813 - RMSE: 0.6937\n",
      "Epoch 356/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4851 - RMSE: 0.6965\n",
      "Epoch 357/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4893 - RMSE: 0.6995\n",
      "Epoch 358/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4853 - RMSE: 0.6967\n",
      "Epoch 359/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4838 - RMSE: 0.6955\n",
      "Epoch 360/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4821 - RMSE: 0.6943\n",
      "Epoch 361/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4825 - RMSE: 0.6946\n",
      "Epoch 362/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4820 - RMSE: 0.6943\n",
      "Epoch 363/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4794 - RMSE: 0.6924\n",
      "Epoch 364/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4788 - RMSE: 0.6920\n",
      "Epoch 365/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4820 - RMSE: 0.6943\n",
      "Epoch 366/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4794 - RMSE: 0.6924\n",
      "Epoch 367/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4788 - RMSE: 0.6919\n",
      "Epoch 368/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4826 - RMSE: 0.6947\n",
      "Epoch 369/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4784 - RMSE: 0.6917\n",
      "Epoch 370/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4723 - RMSE: 0.6873\n",
      "Epoch 371/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.4749 - RMSE: 0.6892\n",
      "Epoch 372/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4742 - RMSE: 0.6886\n",
      "Epoch 373/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4772 - RMSE: 0.6908\n",
      "Epoch 374/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4734 - RMSE: 0.6880\n",
      "Epoch 375/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4724 - RMSE: 0.6873\n",
      "Epoch 376/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4819 - RMSE: 0.6942\n",
      "Epoch 377/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4786 - RMSE: 0.6918\n",
      "Epoch 378/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4788 - RMSE: 0.6920\n",
      "Epoch 379/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4766 - RMSE: 0.6903\n",
      "Epoch 380/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4752 - RMSE: 0.6894\n",
      "Epoch 381/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4675 - RMSE: 0.6837\n",
      "Epoch 382/500\n",
      "80/80 [==============================] - 1s 19ms/step - loss: 0.4726 - RMSE: 0.6875\n",
      "Epoch 383/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4732 - RMSE: 0.6879\n",
      "Epoch 384/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4710 - RMSE: 0.6863\n",
      "Epoch 385/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4715 - RMSE: 0.6867\n",
      "Epoch 386/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4741 - RMSE: 0.6886\n",
      "Epoch 387/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4697 - RMSE: 0.6853\n",
      "Epoch 388/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4716 - RMSE: 0.6867\n",
      "Epoch 389/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4763 - RMSE: 0.6901\n",
      "Epoch 390/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4781 - RMSE: 0.6915\n",
      "Epoch 391/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4772 - RMSE: 0.6908\n",
      "Epoch 392/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4797 - RMSE: 0.6926\n",
      "Epoch 393/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4827 - RMSE: 0.6948\n",
      "Epoch 394/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4793 - RMSE: 0.6923\n",
      "Epoch 395/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4778 - RMSE: 0.6913\n",
      "Epoch 396/500\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.4722 - RMSE: 0.6871\n",
      "Epoch 397/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.4755 - RMSE: 0.6895\n",
      "Epoch 398/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.4685 - RMSE: 0.6845\n",
      "Epoch 399/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.4736 - RMSE: 0.6882\n",
      "Epoch 400/500\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.4688 - RMSE: 0.6847\n",
      "Epoch 401/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.4726 - RMSE: 0.6875\n",
      "Epoch 402/500\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.4700 - RMSE: 0.6856\n",
      "Epoch 403/500\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.4670 - RMSE: 0.6834\n",
      "Epoch 404/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.4679 - RMSE: 0.6840\n",
      "Epoch 405/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4701 - RMSE: 0.6857\n",
      "Epoch 406/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4670 - RMSE: 0.6834\n",
      "Epoch 407/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.4672 - RMSE: 0.6835\n",
      "Epoch 408/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.4670 - RMSE: 0.6833\n",
      "Epoch 409/500\n",
      "80/80 [==============================] - 1s 19ms/step - loss: 0.4680 - RMSE: 0.6841\n",
      "Epoch 410/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.4707 - RMSE: 0.6861\n",
      "Epoch 411/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.4681 - RMSE: 0.6842\n",
      "Epoch 412/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4675 - RMSE: 0.6837\n",
      "Epoch 413/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.4654 - RMSE: 0.6822\n",
      "Epoch 414/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4606 - RMSE: 0.6787\n",
      "Epoch 415/500\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.4665 - RMSE: 0.6830\n",
      "Epoch 416/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4610 - RMSE: 0.6790\n",
      "Epoch 417/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 2s 23ms/step - loss: 0.4623 - RMSE: 0.6799\n",
      "Epoch 418/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.4582 - RMSE: 0.6769\n",
      "Epoch 419/500\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.4612 - RMSE: 0.6791\n",
      "Epoch 420/500\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.4581 - RMSE: 0.6768\n",
      "Epoch 421/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.4622 - RMSE: 0.6798\n",
      "Epoch 422/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4599 - RMSE: 0.6781\n",
      "Epoch 423/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4662 - RMSE: 0.6828\n",
      "Epoch 424/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4679 - RMSE: 0.6840\n",
      "Epoch 425/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.4634 - RMSE: 0.6808\n",
      "Epoch 426/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4625 - RMSE: 0.6801\n",
      "Epoch 427/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4615 - RMSE: 0.6793\n",
      "Epoch 428/500\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.4622 - RMSE: 0.6799\n",
      "Epoch 429/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4614 - RMSE: 0.6793\n",
      "Epoch 430/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.4674 - RMSE: 0.6837\n",
      "Epoch 431/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.4712 - RMSE: 0.6864\n",
      "Epoch 432/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4698 - RMSE: 0.6854\n",
      "Epoch 433/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4639 - RMSE: 0.6811\n",
      "Epoch 434/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.4622 - RMSE: 0.6799\n",
      "Epoch 435/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.4629 - RMSE: 0.6803\n",
      "Epoch 436/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.4647 - RMSE: 0.6817\n",
      "Epoch 437/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.4679 - RMSE: 0.6840\n",
      "Epoch 438/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.4659 - RMSE: 0.6825\n",
      "Epoch 439/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.4679 - RMSE: 0.6841\n",
      "Epoch 440/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.4664 - RMSE: 0.6830\n",
      "Epoch 441/500\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 0.4694 - RMSE: 0.6851\n",
      "Epoch 442/500\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 0.4656 - RMSE: 0.6824\n",
      "Epoch 443/500\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.4633 - RMSE: 0.6807\n",
      "Epoch 444/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.4651 - RMSE: 0.6820\n",
      "Epoch 445/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4679 - RMSE: 0.6840\n",
      "Epoch 446/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4620 - RMSE: 0.6797\n",
      "Epoch 447/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4667 - RMSE: 0.6832\n",
      "Epoch 448/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4652 - RMSE: 0.6821\n",
      "Epoch 449/500\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.4659 - RMSE: 0.6826\n",
      "Epoch 450/500\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.4611 - RMSE: 0.6790\n",
      "Epoch 451/500\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.4618 - RMSE: 0.6796\n",
      "Epoch 452/500\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.4624 - RMSE: 0.6800\n",
      "Epoch 453/500\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.4646 - RMSE: 0.6816\n",
      "Epoch 454/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.4603 - RMSE: 0.6785\n",
      "Epoch 455/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.4637 - RMSE: 0.6810\n",
      "Epoch 456/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4720 - RMSE: 0.6870\n",
      "Epoch 457/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4711 - RMSE: 0.6864\n",
      "Epoch 458/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4702 - RMSE: 0.6857\n",
      "Epoch 459/500\n",
      "80/80 [==============================] - 1s 19ms/step - loss: 0.4659 - RMSE: 0.6826\n",
      "Epoch 460/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4621 - RMSE: 0.6798\n",
      "Epoch 461/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4644 - RMSE: 0.6814\n",
      "Epoch 462/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.4623 - RMSE: 0.6799\n",
      "Epoch 463/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4676 - RMSE: 0.6838\n",
      "Epoch 464/500\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 0.4615 - RMSE: 0.6793\n",
      "Epoch 465/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.4610 - RMSE: 0.6790\n",
      "Epoch 466/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.4649 - RMSE: 0.6819\n",
      "Epoch 467/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4607 - RMSE: 0.6788\n",
      "Epoch 468/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4602 - RMSE: 0.6784\n",
      "Epoch 469/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.4584 - RMSE: 0.6771\n",
      "Epoch 470/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.4599 - RMSE: 0.6781\n",
      "Epoch 471/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4593 - RMSE: 0.6777\n",
      "Epoch 472/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4559 - RMSE: 0.6752\n",
      "Epoch 473/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4601 - RMSE: 0.6783\n",
      "Epoch 474/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4576 - RMSE: 0.6765\n",
      "Epoch 475/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4583 - RMSE: 0.6770\n",
      "Epoch 476/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4620 - RMSE: 0.6797\n",
      "Epoch 477/500\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 0.4615 - RMSE: 0.6794\n",
      "Epoch 478/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4617 - RMSE: 0.6795\n",
      "Epoch 479/500\n",
      "80/80 [==============================] - 1s 19ms/step - loss: 0.4628 - RMSE: 0.6803\n",
      "Epoch 480/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4622 - RMSE: 0.6799\n",
      "Epoch 481/500\n",
      "80/80 [==============================] - 2s 19ms/step - loss: 0.4586 - RMSE: 0.6772\n",
      "Epoch 482/500\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4600 - RMSE: 0.6782\n",
      "Epoch 483/500\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 0.4625 - RMSE: 0.6801\n",
      "Epoch 484/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.4589 - RMSE: 0.6774\n",
      "Epoch 485/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.4549 - RMSE: 0.6744\n",
      "Epoch 486/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.4562 - RMSE: 0.6754\n",
      "Epoch 487/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.4545 - RMSE: 0.6742\n",
      "Epoch 488/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.4506 - RMSE: 0.6713\n",
      "Epoch 489/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.4530 - RMSE: 0.6731\n",
      "Epoch 490/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.4516 - RMSE: 0.6720\n",
      "Epoch 491/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.4514 - RMSE: 0.6719\n",
      "Epoch 492/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.4476 - RMSE: 0.6690\n",
      "Epoch 493/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.4532 - RMSE: 0.6732\n",
      "Epoch 494/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.4477 - RMSE: 0.6691\n",
      "Epoch 495/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.4479 - RMSE: 0.6692\n",
      "Epoch 496/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.4462 - RMSE: 0.6680\n",
      "Epoch 497/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.4481 - RMSE: 0.6694\n",
      "Epoch 498/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.4489 - RMSE: 0.6700\n",
      "Epoch 499/500\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 0.4481 - RMSE: 0.6694\n",
      "Epoch 500/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 17ms/step - loss: 0.4593 - RMSE: 0.6777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f793c9dc898>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=training_generator, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_cimento['28 day Compressive strength']\n",
    "x = df_cimento.drop(['Date', '28 day Compressive strength'], axis=1)\n",
    "test_size = 0.2\n",
    "x, y = split_sequences(pd.concat([x, y], axis=1).values, TIMESTEPS)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=test_size, random_state=SEED, shuffle=False\n",
    ")\n",
    "sc = StandardScaler3DShape()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.Sequential(\n",
    "    model.layers[:-1] +\n",
    "    [\n",
    "        tf.keras.layers.Dense(units=256, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(units=128, activation=\"relu\"),\n",
    "        layers.Dense(units=1, activation='linear')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "31/31 [==============================] - 3s 5ms/step - loss: 1520.4382 - RMSE: 38.9928\n",
      "Epoch 2/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 244.9743 - RMSE: 15.6517\n",
      "Epoch 3/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 40.8714 - RMSE: 6.3931\n",
      "Epoch 4/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 35.7350 - RMSE: 5.9779\n",
      "Epoch 5/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 34.2473 - RMSE: 5.8521\n",
      "Epoch 6/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 34.2381 - RMSE: 5.8513\n",
      "Epoch 7/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 33.2623 - RMSE: 5.7673\n",
      "Epoch 8/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 32.6273 - RMSE: 5.7120\n",
      "Epoch 9/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 30.0668 - RMSE: 5.4833\n",
      "Epoch 10/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 30.5445 - RMSE: 5.5267\n",
      "Epoch 11/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 28.4961 - RMSE: 5.3382\n",
      "Epoch 12/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 29.2334 - RMSE: 5.4068\n",
      "Epoch 13/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 29.3165 - RMSE: 5.4145\n",
      "Epoch 14/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 28.0370 - RMSE: 5.2950\n",
      "Epoch 15/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.8136 - RMSE: 5.2739\n",
      "Epoch 16/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.7768 - RMSE: 5.2704\n",
      "Epoch 17/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 28.1724 - RMSE: 5.3078\n",
      "Epoch 18/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 28.4071 - RMSE: 5.3298\n",
      "Epoch 19/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.8390 - RMSE: 5.2763\n",
      "Epoch 20/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 27.5269 - RMSE: 5.2466\n",
      "Epoch 21/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.9738 - RMSE: 5.1936\n",
      "Epoch 22/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.8305 - RMSE: 5.2755\n",
      "Epoch 23/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.5368 - RMSE: 5.2475\n",
      "Epoch 24/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 28.3825 - RMSE: 5.3275\n",
      "Epoch 25/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 27.7327 - RMSE: 5.2662\n",
      "Epoch 26/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 28.3384 - RMSE: 5.3234\n",
      "Epoch 27/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.2344 - RMSE: 5.2187\n",
      "Epoch 28/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.1413 - RMSE: 5.2097\n",
      "Epoch 29/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 28.3204 - RMSE: 5.3217\n",
      "Epoch 30/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 28.3187 - RMSE: 5.3215\n",
      "Epoch 31/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 26.4477 - RMSE: 5.1427\n",
      "Epoch 32/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.1231 - RMSE: 5.2080\n",
      "Epoch 33/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.7780 - RMSE: 5.2705\n",
      "Epoch 34/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 27.0807 - RMSE: 5.2039\n",
      "Epoch 35/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 26.9386 - RMSE: 5.1902\n",
      "Epoch 36/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.8464 - RMSE: 5.2770\n",
      "Epoch 37/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.9325 - RMSE: 5.2851\n",
      "Epoch 38/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.4675 - RMSE: 5.2409\n",
      "Epoch 39/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 29.2151 - RMSE: 5.4051\n",
      "Epoch 40/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.2922 - RMSE: 5.1276\n",
      "Epoch 41/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.9688 - RMSE: 5.1931\n",
      "Epoch 42/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.6414 - RMSE: 5.2575\n",
      "Epoch 43/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.8618 - RMSE: 5.1828\n",
      "Epoch 44/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.1019 - RMSE: 5.2060\n",
      "Epoch 45/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.3209 - RMSE: 5.2269\n",
      "Epoch 46/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.0036 - RMSE: 5.1965\n",
      "Epoch 47/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.0911 - RMSE: 5.2049\n",
      "Epoch 48/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.6787 - RMSE: 5.2611\n",
      "Epoch 49/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.2051 - RMSE: 5.2158\n",
      "Epoch 50/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.1418 - RMSE: 5.2098\n",
      "Epoch 51/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.8854 - RMSE: 5.1851\n",
      "Epoch 52/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.4070 - RMSE: 5.2352\n",
      "Epoch 53/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.1550 - RMSE: 5.2110\n",
      "Epoch 54/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.2849 - RMSE: 5.2235\n",
      "Epoch 55/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.9252 - RMSE: 5.2844\n",
      "Epoch 56/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.1782 - RMSE: 5.2133\n",
      "Epoch 57/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 29.2561 - RMSE: 5.4089\n",
      "Epoch 58/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.4449 - RMSE: 5.2388\n",
      "Epoch 59/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.2116 - RMSE: 5.2165\n",
      "Epoch 60/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.1624 - RMSE: 5.2118\n",
      "Epoch 61/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.2437 - RMSE: 5.2196\n",
      "Epoch 62/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.2582 - RMSE: 5.2209\n",
      "Epoch 63/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.6742 - RMSE: 5.1647\n",
      "Epoch 64/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 28.2046 - RMSE: 5.3108\n",
      "Epoch 65/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.6105 - RMSE: 5.1585\n",
      "Epoch 66/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.1025 - RMSE: 5.2060\n",
      "Epoch 67/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.5472 - RMSE: 5.2485\n",
      "Epoch 68/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.9881 - RMSE: 5.1950\n",
      "Epoch 69/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.3884 - RMSE: 5.2334\n",
      "Epoch 70/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.9711 - RMSE: 5.1934\n",
      "Epoch 71/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.9554 - RMSE: 5.1919\n",
      "Epoch 72/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.1921 - RMSE: 5.2146\n",
      "Epoch 73/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.7730 - RMSE: 5.1743\n",
      "Epoch 74/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.4827 - RMSE: 5.2424\n",
      "Epoch 75/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.0276 - RMSE: 5.1988\n",
      "Epoch 76/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.5383 - RMSE: 5.2477\n",
      "Epoch 77/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 26.7303 - RMSE: 5.1701\n",
      "Epoch 78/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.9088 - RMSE: 5.1874\n",
      "Epoch 79/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.6571 - RMSE: 5.1631\n",
      "Epoch 80/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.0145 - RMSE: 5.1975\n",
      "Epoch 81/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.0964 - RMSE: 5.2054\n",
      "Epoch 82/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.2771 - RMSE: 5.2227\n",
      "Epoch 83/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.5195 - RMSE: 5.1497\n",
      "Epoch 84/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.2830 - RMSE: 5.1267\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 6ms/step - loss: 26.9680 - RMSE: 5.1931\n",
      "Epoch 86/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.9601 - RMSE: 5.1923\n",
      "Epoch 87/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.3744 - RMSE: 5.1356\n",
      "Epoch 88/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.3143 - RMSE: 5.2263\n",
      "Epoch 89/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.1695 - RMSE: 5.2124\n",
      "Epoch 90/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.5642 - RMSE: 5.1540\n",
      "Epoch 91/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.7146 - RMSE: 5.1686\n",
      "Epoch 92/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.7321 - RMSE: 5.1703\n",
      "Epoch 93/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.2218 - RMSE: 5.1207\n",
      "Epoch 94/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.8506 - RMSE: 5.1818\n",
      "Epoch 95/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.6580 - RMSE: 5.1631\n",
      "Epoch 96/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.9199 - RMSE: 5.1884\n",
      "Epoch 97/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.2223 - RMSE: 5.2175\n",
      "Epoch 98/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.6683 - RMSE: 5.1641\n",
      "Epoch 99/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 25.7912 - RMSE: 5.0785\n",
      "Epoch 100/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.5142 - RMSE: 5.1492\n",
      "Epoch 101/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.0096 - RMSE: 5.1971\n",
      "Epoch 102/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.1699 - RMSE: 5.1157\n",
      "Epoch 103/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.7091 - RMSE: 5.1681\n",
      "Epoch 104/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.9199 - RMSE: 5.1884\n",
      "Epoch 105/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.0399 - RMSE: 5.2000\n",
      "Epoch 106/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.4441 - RMSE: 5.1424\n",
      "Epoch 107/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.4240 - RMSE: 5.2368\n",
      "Epoch 108/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.8141 - RMSE: 5.2739\n",
      "Epoch 109/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 28.6494 - RMSE: 5.3525\n",
      "Epoch 110/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.6152 - RMSE: 5.1590\n",
      "Epoch 111/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.7782 - RMSE: 5.1748\n",
      "Epoch 112/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.7347 - RMSE: 5.1706\n",
      "Epoch 113/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.2998 - RMSE: 5.1283\n",
      "Epoch 114/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.0520 - RMSE: 5.2012\n",
      "Epoch 115/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.2995 - RMSE: 5.1283\n",
      "Epoch 116/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.6143 - RMSE: 5.1589\n",
      "Epoch 117/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.7605 - RMSE: 5.1731\n",
      "Epoch 118/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.0883 - RMSE: 5.2046\n",
      "Epoch 119/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.2655 - RMSE: 5.1250\n",
      "Epoch 120/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.8146 - RMSE: 5.1783\n",
      "Epoch 121/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.1109 - RMSE: 5.2068\n",
      "Epoch 122/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.0000 - RMSE: 5.0990\n",
      "Epoch 123/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.6596 - RMSE: 5.1633\n",
      "Epoch 124/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.4691 - RMSE: 5.1448\n",
      "Epoch 125/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.6852 - RMSE: 5.1658\n",
      "Epoch 126/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.5184 - RMSE: 5.1496\n",
      "Epoch 127/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.9852 - RMSE: 5.1947\n",
      "Epoch 128/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.3667 - RMSE: 5.2313\n",
      "Epoch 129/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.0534 - RMSE: 5.2013\n",
      "Epoch 130/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 25.5841 - RMSE: 5.0581\n",
      "Epoch 131/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.4091 - RMSE: 5.1390\n",
      "Epoch 132/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.1468 - RMSE: 5.1134\n",
      "Epoch 133/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.5835 - RMSE: 5.1559\n",
      "Epoch 134/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.2371 - RMSE: 5.1222\n",
      "Epoch 135/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.1838 - RMSE: 5.1170\n",
      "Epoch 136/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.4372 - RMSE: 5.2380\n",
      "Epoch 137/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.4654 - RMSE: 5.2407\n",
      "Epoch 138/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.3352 - RMSE: 5.1318\n",
      "Epoch 139/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.4826 - RMSE: 5.1461\n",
      "Epoch 140/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.4310 - RMSE: 5.1411\n",
      "Epoch 141/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.2708 - RMSE: 5.1255\n",
      "Epoch 142/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.4537 - RMSE: 5.1433\n",
      "Epoch 143/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.2419 - RMSE: 5.1227\n",
      "Epoch 144/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.3973 - RMSE: 5.1378\n",
      "Epoch 145/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.2662 - RMSE: 5.1251\n",
      "Epoch 146/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.4394 - RMSE: 5.1419\n",
      "Epoch 147/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.9637 - RMSE: 5.1927\n",
      "Epoch 148/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.1896 - RMSE: 5.1176\n",
      "Epoch 149/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.2054 - RMSE: 5.1191\n",
      "Epoch 150/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 25.7972 - RMSE: 5.0791\n",
      "Epoch 151/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.5186 - RMSE: 5.1496\n",
      "Epoch 152/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.0720 - RMSE: 5.2031\n",
      "Epoch 153/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 25.7494 - RMSE: 5.0744\n",
      "Epoch 154/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.3236 - RMSE: 5.1307\n",
      "Epoch 155/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.7936 - RMSE: 5.1763\n",
      "Epoch 156/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.6184 - RMSE: 5.1593\n",
      "Epoch 157/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.4862 - RMSE: 5.1465\n",
      "Epoch 158/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 26.1020 - RMSE: 5.1090\n",
      "Epoch 159/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.4366 - RMSE: 5.1417\n",
      "Epoch 160/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 26.3472 - RMSE: 5.1330\n",
      "Epoch 161/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.4112 - RMSE: 5.2356\n",
      "Epoch 162/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 26.3082 - RMSE: 5.1292\n",
      "Epoch 163/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 26.6721 - RMSE: 5.1645\n",
      "Epoch 164/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 26.9667 - RMSE: 5.1930\n",
      "Epoch 165/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 27.2590 - RMSE: 5.2210\n",
      "Epoch 166/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 26.0707 - RMSE: 5.1059\n",
      "Epoch 167/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 26.7812 - RMSE: 5.1751\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 5ms/step - loss: 28.6636 - RMSE: 5.3538\n",
      "Epoch 169/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.4391 - RMSE: 5.2382\n",
      "Epoch 170/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 26.2882 - RMSE: 5.1272\n",
      "Epoch 171/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 26.3054 - RMSE: 5.1289\n",
      "Epoch 172/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 25.9433 - RMSE: 5.0935\n",
      "Epoch 173/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.2360 - RMSE: 5.2188\n",
      "Epoch 174/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.1417 - RMSE: 5.1129\n",
      "Epoch 175/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.2490 - RMSE: 5.2201\n",
      "Epoch 176/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.5084 - RMSE: 5.1486\n",
      "Epoch 177/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 25.7421 - RMSE: 5.0737\n",
      "Epoch 178/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.2257 - RMSE: 5.1211\n",
      "Epoch 179/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.1457 - RMSE: 5.1133\n",
      "Epoch 180/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 25.9289 - RMSE: 5.0920\n",
      "Epoch 181/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.3243 - RMSE: 5.1307\n",
      "Epoch 182/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.2210 - RMSE: 5.1206\n",
      "Epoch 183/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 25.6987 - RMSE: 5.0694\n",
      "Epoch 184/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.2424 - RMSE: 5.1227\n",
      "Epoch 185/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.0099 - RMSE: 5.1000\n",
      "Epoch 186/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 26.0819 - RMSE: 5.1070\n",
      "Epoch 187/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 28.6139 - RMSE: 5.3492\n",
      "Epoch 188/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 26.1458 - RMSE: 5.1133\n",
      "Epoch 189/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 26.7936 - RMSE: 5.1763\n",
      "Epoch 190/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 27.0437 - RMSE: 5.2004\n",
      "Epoch 191/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 26.6422 - RMSE: 5.1616\n",
      "Epoch 192/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 25.9971 - RMSE: 5.0987\n",
      "Epoch 193/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.1133 - RMSE: 5.1101\n",
      "Epoch 194/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 26.2767 - RMSE: 5.1261\n",
      "Epoch 195/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 27.0711 - RMSE: 5.2030\n",
      "Epoch 196/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 26.3057 - RMSE: 5.1289\n",
      "Epoch 197/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 26.2064 - RMSE: 5.1192\n",
      "Epoch 198/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 26.5733 - RMSE: 5.1549\n",
      "Epoch 199/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 25.9051 - RMSE: 5.0897\n",
      "Epoch 200/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 26.2240 - RMSE: 5.1209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f793c8b29e8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = get_model(params)\n",
    "model2.compile(\n",
    "    tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"mse\",\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    ")\n",
    "\n",
    "model2.fit(x_train, y_train, batch_size=32, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 5.025 (0.000)\n",
      "MAE: 4.587 (0.000)\n",
      "MAPE: 0.111 (0.000)\n",
      "R2: 0.011 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 4.977 (0.000)\n",
      "MAE: 4.735 (0.000)\n",
      "MAPE: 0.112 (0.000)\n",
      "R2: 0.010 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model2.predict(x_train)\n",
    "y_test_pred = model2.predict(x_test)\n",
    "\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\n",
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.sequential.Sequential at 0x7f793f2f2a90>,\n",
       " <keras.layers.pooling.GlobalAveragePooling1D at 0x7f79f890d780>,\n",
       " <keras.layers.core.Dense at 0x7f793f3950f0>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layers = model.layers[0]\n",
    "encoder_layers.trainable = True\n",
    "\n",
    "visible = Input(shape=(TIMESTEPS, 13))\n",
    "enc = encoder_layers(visible)\n",
    "hidden1 = Dense(128, activation='relu')(enc)\n",
    "hidden2 = Dense(64, activation='relu')(hidden1)\n",
    "hidden3 = Dense(32, activation='relu')(hidden2)\n",
    "hidden4 = Flatten()(hidden3)\n",
    "output = Dense(1)(hidden4)\n",
    "model_2 = Model(inputs=visible, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "31/31 [==============================] - 4s 12ms/step - loss: 1307.6304 - RMSE: 36.1612\n",
      "Epoch 2/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 70.6806 - RMSE: 8.4072\n",
      "Epoch 3/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 26.3287 - RMSE: 5.1311\n",
      "Epoch 4/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 26.1464 - RMSE: 5.1134\n",
      "Epoch 5/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 25.4925 - RMSE: 5.0490\n",
      "Epoch 6/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 26.8895 - RMSE: 5.1855\n",
      "Epoch 7/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.8753 - RMSE: 5.0868\n",
      "Epoch 8/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 25.6428 - RMSE: 5.0639\n",
      "Epoch 9/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.7510 - RMSE: 5.0745\n",
      "Epoch 10/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 26.0680 - RMSE: 5.1057\n",
      "Epoch 11/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.0727 - RMSE: 5.1061\n",
      "Epoch 12/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 27.0614 - RMSE: 5.2021\n",
      "Epoch 13/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 27.6509 - RMSE: 5.2584\n",
      "Epoch 14/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 26.3737 - RMSE: 5.1355\n",
      "Epoch 15/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.4741 - RMSE: 5.0472\n",
      "Epoch 16/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 26.5849 - RMSE: 5.1561\n",
      "Epoch 17/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 26.1213 - RMSE: 5.1109\n",
      "Epoch 18/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.2076 - RMSE: 5.1193\n",
      "Epoch 19/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.0433 - RMSE: 5.1033\n",
      "Epoch 20/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.7688 - RMSE: 5.0763\n",
      "Epoch 21/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 26.3745 - RMSE: 5.1356\n",
      "Epoch 22/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 25.9527 - RMSE: 5.0944\n",
      "Epoch 23/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.3887 - RMSE: 5.1370\n",
      "Epoch 24/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 25.7869 - RMSE: 5.0781\n",
      "Epoch 25/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 26.4489 - RMSE: 5.1429\n",
      "Epoch 26/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 27.4551 - RMSE: 5.2398\n",
      "Epoch 27/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 26.0420 - RMSE: 5.1031\n",
      "Epoch 28/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 25.9574 - RMSE: 5.0948\n",
      "Epoch 29/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.0482 - RMSE: 5.1037\n",
      "Epoch 30/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 25.7082 - RMSE: 5.0703\n",
      "Epoch 31/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.1517 - RMSE: 5.1139\n",
      "Epoch 32/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.1046 - RMSE: 5.1093\n",
      "Epoch 33/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.9717 - RMSE: 5.0962\n",
      "Epoch 34/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.8002 - RMSE: 5.0794\n",
      "Epoch 35/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.9896 - RMSE: 5.0980\n",
      "Epoch 36/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 26.0321 - RMSE: 5.1022\n",
      "Epoch 37/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.0489 - RMSE: 5.1038\n",
      "Epoch 38/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 26.4713 - RMSE: 5.1450\n",
      "Epoch 39/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.9555 - RMSE: 5.0947\n",
      "Epoch 40/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.4395 - RMSE: 5.1419\n",
      "Epoch 41/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.0530 - RMSE: 5.1042\n",
      "Epoch 42/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 26.4139 - RMSE: 5.1394\n",
      "Epoch 43/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.0692 - RMSE: 5.1058\n",
      "Epoch 44/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.2678 - RMSE: 5.1252\n",
      "Epoch 45/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 26.1099 - RMSE: 5.1098\n",
      "Epoch 46/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.4775 - RMSE: 5.1456\n",
      "Epoch 47/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.1315 - RMSE: 5.1119\n",
      "Epoch 48/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 26.0454 - RMSE: 5.1035\n",
      "Epoch 49/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.5726 - RMSE: 5.1549\n",
      "Epoch 50/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.3562 - RMSE: 5.1338\n",
      "Epoch 51/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.7680 - RMSE: 5.0762\n",
      "Epoch 52/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 26.4002 - RMSE: 5.1381\n",
      "Epoch 53/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.4771 - RMSE: 5.1456\n",
      "Epoch 54/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.3573 - RMSE: 5.1339\n",
      "Epoch 55/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 27.2330 - RMSE: 5.2185\n",
      "Epoch 56/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.9852 - RMSE: 5.0976\n",
      "Epoch 57/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.7959 - RMSE: 5.0790\n",
      "Epoch 58/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.1706 - RMSE: 5.1157\n",
      "Epoch 59/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.6265 - RMSE: 5.0623\n",
      "Epoch 60/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.5315 - RMSE: 5.1509\n",
      "Epoch 61/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.0884 - RMSE: 5.1077\n",
      "Epoch 62/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.2642 - RMSE: 5.1249\n",
      "Epoch 63/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.6314 - RMSE: 5.0627\n",
      "Epoch 64/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.8448 - RMSE: 5.0838\n",
      "Epoch 65/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.8601 - RMSE: 5.0853\n",
      "Epoch 66/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 26.9855 - RMSE: 5.1948\n",
      "Epoch 67/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 25.8519 - RMSE: 5.0845\n",
      "Epoch 68/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.8664 - RMSE: 5.0859\n",
      "Epoch 69/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.7690 - RMSE: 5.0763\n",
      "Epoch 70/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.2495 - RMSE: 5.1234\n",
      "Epoch 71/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.2875 - RMSE: 5.1271\n",
      "Epoch 72/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.2694 - RMSE: 5.1254\n",
      "Epoch 73/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.8515 - RMSE: 5.0844\n",
      "Epoch 74/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.5625 - RMSE: 5.0559\n",
      "Epoch 75/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.6488 - RMSE: 5.0645\n",
      "Epoch 76/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.5678 - RMSE: 5.0565\n",
      "Epoch 77/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.1650 - RMSE: 5.1152\n",
      "Epoch 78/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 26.7524 - RMSE: 5.1723\n",
      "Epoch 79/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.2290 - RMSE: 5.1214\n",
      "Epoch 80/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.6868 - RMSE: 5.0682\n",
      "Epoch 81/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.5530 - RMSE: 5.0550\n",
      "Epoch 82/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.0167 - RMSE: 5.1007\n",
      "Epoch 83/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.6999 - RMSE: 5.0695\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 13ms/step - loss: 26.3816 - RMSE: 5.1363\n",
      "Epoch 85/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.6457 - RMSE: 5.1620\n",
      "Epoch 86/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.4144 - RMSE: 5.0413\n",
      "Epoch 87/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.6412 - RMSE: 5.1615\n",
      "Epoch 88/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 25.9683 - RMSE: 5.0959\n",
      "Epoch 89/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.6014 - RMSE: 5.1576\n",
      "Epoch 90/500\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 27.3709 - RMSE: 5.2317\n",
      "Epoch 91/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.7822 - RMSE: 5.1752\n",
      "Epoch 92/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.4456 - RMSE: 5.1425\n",
      "Epoch 93/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.4213 - RMSE: 5.1402\n",
      "Epoch 94/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.1363 - RMSE: 5.1124\n",
      "Epoch 95/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.6686 - RMSE: 5.1642\n",
      "Epoch 96/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.3131 - RMSE: 5.0312\n",
      "Epoch 97/500\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 26.6907 - RMSE: 5.1663\n",
      "Epoch 98/500\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 25.6165 - RMSE: 5.0613\n",
      "Epoch 99/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 25.6728 - RMSE: 5.0668\n",
      "Epoch 100/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.0517 - RMSE: 5.1041\n",
      "Epoch 101/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 26.3665 - RMSE: 5.1348\n",
      "Epoch 102/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 25.9980 - RMSE: 5.0988\n",
      "Epoch 103/500\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 25.6543 - RMSE: 5.0650\n",
      "Epoch 104/500\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 26.1093 - RMSE: 5.1097\n",
      "Epoch 105/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 25.5437 - RMSE: 5.0541\n",
      "Epoch 106/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 25.9737 - RMSE: 5.0964\n",
      "Epoch 107/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 25.1212 - RMSE: 5.0121\n",
      "Epoch 108/500\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 25.6645 - RMSE: 5.0660\n",
      "Epoch 109/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 25.1604 - RMSE: 5.0160\n",
      "Epoch 110/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 26.7492 - RMSE: 5.1720\n",
      "Epoch 111/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 25.9754 - RMSE: 5.0966\n",
      "Epoch 112/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 25.5070 - RMSE: 5.0504\n",
      "Epoch 113/500\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 25.8929 - RMSE: 5.0885\n",
      "Epoch 114/500\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 27.6295 - RMSE: 5.2564\n",
      "Epoch 115/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 26.2432 - RMSE: 5.1228\n",
      "Epoch 116/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 25.5008 - RMSE: 5.0498\n",
      "Epoch 117/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 25.7612 - RMSE: 5.0755\n",
      "Epoch 118/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 25.4314 - RMSE: 5.0430\n",
      "Epoch 119/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 25.2419 - RMSE: 5.0241\n",
      "Epoch 120/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 24.9358 - RMSE: 4.9936\n",
      "Epoch 121/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 25.0868 - RMSE: 5.0087\n",
      "Epoch 122/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 25.0785 - RMSE: 5.0078\n",
      "Epoch 123/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 24.9812 - RMSE: 4.9981\n",
      "Epoch 124/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 24.6870 - RMSE: 4.9686\n",
      "Epoch 125/500\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 24.5513 - RMSE: 4.9549\n",
      "Epoch 126/500\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 24.8865 - RMSE: 4.9886\n",
      "Epoch 127/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 25.1148 - RMSE: 5.0115\n",
      "Epoch 128/500\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 24.4460 - RMSE: 4.9443\n",
      "Epoch 129/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 26.1741 - RMSE: 5.1161\n",
      "Epoch 130/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 24.7460 - RMSE: 4.9745\n",
      "Epoch 131/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 24.3008 - RMSE: 4.9296\n",
      "Epoch 132/500\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 24.3296 - RMSE: 4.9325\n",
      "Epoch 133/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 24.9196 - RMSE: 4.9919\n",
      "Epoch 134/500\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 24.3504 - RMSE: 4.9346\n",
      "Epoch 135/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 25.3491 - RMSE: 5.0348\n",
      "Epoch 136/500\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 23.8681 - RMSE: 4.8855\n",
      "Epoch 137/500\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 24.3528 - RMSE: 4.9349\n",
      "Epoch 138/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 24.4405 - RMSE: 4.9437\n",
      "Epoch 139/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.2052 - RMSE: 5.0205\n",
      "Epoch 140/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 25.1902 - RMSE: 5.0190\n",
      "Epoch 141/500\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 25.8058 - RMSE: 5.0799\n",
      "Epoch 142/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 24.2794 - RMSE: 4.9274\n",
      "Epoch 143/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 24.1239 - RMSE: 4.9116\n",
      "Epoch 144/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 23.4090 - RMSE: 4.8383\n",
      "Epoch 145/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 24.8072 - RMSE: 4.9807\n",
      "Epoch 146/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 24.7157 - RMSE: 4.9715\n",
      "Epoch 147/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 23.3612 - RMSE: 4.8333\n",
      "Epoch 148/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 23.1544 - RMSE: 4.8119\n",
      "Epoch 149/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 23.7262 - RMSE: 4.8710\n",
      "Epoch 150/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 23.9392 - RMSE: 4.8928\n",
      "Epoch 151/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 24.0033 - RMSE: 4.8993\n",
      "Epoch 152/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 22.6658 - RMSE: 4.7609\n",
      "Epoch 153/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 23.5549 - RMSE: 4.8533\n",
      "Epoch 154/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 21.8200 - RMSE: 4.6712\n",
      "Epoch 155/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 21.1420 - RMSE: 4.5980\n",
      "Epoch 156/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 20.5888 - RMSE: 4.5375\n",
      "Epoch 157/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 18.9672 - RMSE: 4.3551\n",
      "Epoch 158/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 18.2612 - RMSE: 4.2733\n",
      "Epoch 159/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 16.7916 - RMSE: 4.0978\n",
      "Epoch 160/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 18.3032 - RMSE: 4.2782\n",
      "Epoch 161/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 15.6969 - RMSE: 3.9619\n",
      "Epoch 162/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 14.6884 - RMSE: 3.8325\n",
      "Epoch 163/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 14.4028 - RMSE: 3.7951\n",
      "Epoch 164/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 14.2834 - RMSE: 3.7793\n",
      "Epoch 165/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 13.7228 - RMSE: 3.7044\n",
      "Epoch 166/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 13.6127 - RMSE: 3.6895\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 13ms/step - loss: 13.2043 - RMSE: 3.6338\n",
      "Epoch 168/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 11.4733 - RMSE: 3.3872\n",
      "Epoch 169/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 12.7881 - RMSE: 3.5760\n",
      "Epoch 170/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 12.3039 - RMSE: 3.5077\n",
      "Epoch 171/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 11.3299 - RMSE: 3.3660\n",
      "Epoch 172/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 11.0145 - RMSE: 3.3188\n",
      "Epoch 173/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 11.6992 - RMSE: 3.4204\n",
      "Epoch 174/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 11.4890 - RMSE: 3.3895\n",
      "Epoch 175/500\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 10.3285 - RMSE: 3.2138\n",
      "Epoch 176/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 11.3672 - RMSE: 3.3715\n",
      "Epoch 177/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 10.6302 - RMSE: 3.2604\n",
      "Epoch 178/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 9.3355 - RMSE: 3.0554\n",
      "Epoch 179/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 9.6275 - RMSE: 3.1028\n",
      "Epoch 180/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 11.5162 - RMSE: 3.3935\n",
      "Epoch 181/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 9.7804 - RMSE: 3.1274\n",
      "Epoch 182/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 9.5419 - RMSE: 3.0890\n",
      "Epoch 183/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 9.5752 - RMSE: 3.0944\n",
      "Epoch 184/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 9.0744 - RMSE: 3.0124\n",
      "Epoch 185/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 8.7807 - RMSE: 2.9632\n",
      "Epoch 186/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 8.4896 - RMSE: 2.9137\n",
      "Epoch 187/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 8.5788 - RMSE: 2.9290\n",
      "Epoch 188/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 9.5466 - RMSE: 3.0897\n",
      "Epoch 189/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 9.5809 - RMSE: 3.0953\n",
      "Epoch 190/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 8.0053 - RMSE: 2.8294\n",
      "Epoch 191/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 8.5425 - RMSE: 2.9228\n",
      "Epoch 192/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 8.5403 - RMSE: 2.9224\n",
      "Epoch 193/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 8.1913 - RMSE: 2.8621\n",
      "Epoch 194/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 7.7752 - RMSE: 2.7884\n",
      "Epoch 195/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 8.8170 - RMSE: 2.9694\n",
      "Epoch 196/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 7.6144 - RMSE: 2.7594\n",
      "Epoch 197/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 6.6558 - RMSE: 2.5799\n",
      "Epoch 198/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 6.9665 - RMSE: 2.6394\n",
      "Epoch 199/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 7.8870 - RMSE: 2.8084\n",
      "Epoch 200/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 7.5611 - RMSE: 2.7497\n",
      "Epoch 201/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 7.3822 - RMSE: 2.7170\n",
      "Epoch 202/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 7.6534 - RMSE: 2.7665\n",
      "Epoch 203/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 7.8548 - RMSE: 2.8026\n",
      "Epoch 204/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 7.1993 - RMSE: 2.6831\n",
      "Epoch 205/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 7.1530 - RMSE: 2.6745\n",
      "Epoch 206/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 6.7263 - RMSE: 2.5935\n",
      "Epoch 207/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 6.5845 - RMSE: 2.5660\n",
      "Epoch 208/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 6.3018 - RMSE: 2.5103\n",
      "Epoch 209/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 6.1734 - RMSE: 2.4846\n",
      "Epoch 210/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 7.3668 - RMSE: 2.7142\n",
      "Epoch 211/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 7.1175 - RMSE: 2.6679\n",
      "Epoch 212/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 7.1498 - RMSE: 2.6739\n",
      "Epoch 213/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 6.6067 - RMSE: 2.5704\n",
      "Epoch 214/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.8891 - RMSE: 2.4267\n",
      "Epoch 215/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 6.4739 - RMSE: 2.5444\n",
      "Epoch 216/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 6.4431 - RMSE: 2.5383\n",
      "Epoch 217/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 6.8470 - RMSE: 2.6167\n",
      "Epoch 218/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 6.5209 - RMSE: 2.5536\n",
      "Epoch 219/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 6.9837 - RMSE: 2.6427\n",
      "Epoch 220/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 7.1471 - RMSE: 2.6734\n",
      "Epoch 221/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.8935 - RMSE: 2.4277\n",
      "Epoch 222/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 7.1251 - RMSE: 2.6693\n",
      "Epoch 223/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 8.0552 - RMSE: 2.8382\n",
      "Epoch 224/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 6.0119 - RMSE: 2.4519\n",
      "Epoch 225/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.2614 - RMSE: 2.2938\n",
      "Epoch 226/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 6.1108 - RMSE: 2.4720\n",
      "Epoch 227/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 6.3549 - RMSE: 2.5209\n",
      "Epoch 228/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.4020 - RMSE: 2.3242\n",
      "Epoch 229/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.2954 - RMSE: 2.3012\n",
      "Epoch 230/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.4245 - RMSE: 2.3291\n",
      "Epoch 231/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 6.4039 - RMSE: 2.5306\n",
      "Epoch 232/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.8829 - RMSE: 2.4255\n",
      "Epoch 233/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 6.0627 - RMSE: 2.4622\n",
      "Epoch 234/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 6.4726 - RMSE: 2.5441\n",
      "Epoch 235/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 6.4276 - RMSE: 2.5353\n",
      "Epoch 236/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.8499 - RMSE: 2.4187\n",
      "Epoch 237/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.6773 - RMSE: 2.3827\n",
      "Epoch 238/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.5590 - RMSE: 2.3578\n",
      "Epoch 239/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.3323 - RMSE: 2.3092\n",
      "Epoch 240/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.1962 - RMSE: 2.2795\n",
      "Epoch 241/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.2809 - RMSE: 2.2980\n",
      "Epoch 242/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 4.8923 - RMSE: 2.2119\n",
      "Epoch 243/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.4035 - RMSE: 2.3245\n",
      "Epoch 244/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 4.8216 - RMSE: 2.1958\n",
      "Epoch 245/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 5.9882 - RMSE: 2.4471\n",
      "Epoch 246/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.9521 - RMSE: 2.4397\n",
      "Epoch 247/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.1547 - RMSE: 2.2704\n",
      "Epoch 248/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 5.4786 - RMSE: 2.3406\n",
      "Epoch 249/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 4.7050 - RMSE: 2.1691\n",
      "Epoch 250/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 13ms/step - loss: 4.2504 - RMSE: 2.0616\n",
      "Epoch 251/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.8660 - RMSE: 2.4220\n",
      "Epoch 252/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.6254 - RMSE: 2.3718\n",
      "Epoch 253/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.1916 - RMSE: 2.2785\n",
      "Epoch 254/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.2901 - RMSE: 2.3000\n",
      "Epoch 255/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 4.4087 - RMSE: 2.0997\n",
      "Epoch 256/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 4.0597 - RMSE: 2.0149\n",
      "Epoch 257/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 4.5148 - RMSE: 2.1248\n",
      "Epoch 258/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 4.4408 - RMSE: 2.1073\n",
      "Epoch 259/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 4.6729 - RMSE: 2.1617\n",
      "Epoch 260/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.9929 - RMSE: 2.4480\n",
      "Epoch 261/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.2348 - RMSE: 2.2880\n",
      "Epoch 262/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 4.7096 - RMSE: 2.1702\n",
      "Epoch 263/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 4.5827 - RMSE: 2.1407\n",
      "Epoch 264/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 3.8935 - RMSE: 1.9732\n",
      "Epoch 265/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 4.2224 - RMSE: 2.0548\n",
      "Epoch 266/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.7879 - RMSE: 1.9463\n",
      "Epoch 267/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 4.9562 - RMSE: 2.2262\n",
      "Epoch 268/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 4.7011 - RMSE: 2.1682\n",
      "Epoch 269/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 4.1856 - RMSE: 2.0459\n",
      "Epoch 270/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.9861 - RMSE: 1.9965\n",
      "Epoch 271/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 4.5311 - RMSE: 2.1286\n",
      "Epoch 272/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.2348 - RMSE: 2.2880\n",
      "Epoch 273/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.4892 - RMSE: 1.8679\n",
      "Epoch 274/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.9924 - RMSE: 1.9981\n",
      "Epoch 275/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 3.7909 - RMSE: 1.9470\n",
      "Epoch 276/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 3.8351 - RMSE: 1.9583\n",
      "Epoch 277/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.8689 - RMSE: 1.9669\n",
      "Epoch 278/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 4.1419 - RMSE: 2.0352\n",
      "Epoch 279/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 3.8730 - RMSE: 1.9680\n",
      "Epoch 280/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.5382 - RMSE: 1.8810\n",
      "Epoch 281/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 3.4423 - RMSE: 1.8553\n",
      "Epoch 282/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.4186 - RMSE: 1.8489\n",
      "Epoch 283/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 4.0292 - RMSE: 2.0073\n",
      "Epoch 284/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 4.0981 - RMSE: 2.0244\n",
      "Epoch 285/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 4.0638 - RMSE: 2.0159\n",
      "Epoch 286/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.5228 - RMSE: 1.8769\n",
      "Epoch 287/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.6258 - RMSE: 1.9042\n",
      "Epoch 288/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 4.2689 - RMSE: 2.0661\n",
      "Epoch 289/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 3.8703 - RMSE: 1.9673\n",
      "Epoch 290/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.8296 - RMSE: 1.9569\n",
      "Epoch 291/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 7.0798 - RMSE: 2.6608\n",
      "Epoch 292/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 6.1207 - RMSE: 2.4740\n",
      "Epoch 293/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 3.8854 - RMSE: 1.9711\n",
      "Epoch 294/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.7563 - RMSE: 1.9381\n",
      "Epoch 295/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 4.0522 - RMSE: 2.0130\n",
      "Epoch 296/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.6802 - RMSE: 1.9184\n",
      "Epoch 297/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 4.1403 - RMSE: 2.0348\n",
      "Epoch 298/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.9437 - RMSE: 1.9859\n",
      "Epoch 299/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.1922 - RMSE: 1.7867\n",
      "Epoch 300/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.2362 - RMSE: 1.7989\n",
      "Epoch 301/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.2436 - RMSE: 1.8010\n",
      "Epoch 302/500\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 3.4700 - RMSE: 1.8628\n",
      "Epoch 303/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 3.9024 - RMSE: 1.9754\n",
      "Epoch 304/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 3.7400 - RMSE: 1.9339\n",
      "Epoch 305/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.9652 - RMSE: 1.9913\n",
      "Epoch 306/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 3.7635 - RMSE: 1.9400\n",
      "Epoch 307/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 4.5689 - RMSE: 2.1375\n",
      "Epoch 308/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 3.2444 - RMSE: 1.8012\n",
      "Epoch 309/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 4.3432 - RMSE: 2.0840\n",
      "Epoch 310/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 4.4601 - RMSE: 2.1119\n",
      "Epoch 311/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 5.2460 - RMSE: 2.2904\n",
      "Epoch 312/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 4.3303 - RMSE: 2.0809\n",
      "Epoch 313/500\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 4.7932 - RMSE: 2.1893\n",
      "Epoch 314/500\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 3.4988 - RMSE: 1.8705\n",
      "Epoch 315/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.9624 - RMSE: 1.7212\n",
      "Epoch 316/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 4.2664 - RMSE: 2.0655\n",
      "Epoch 317/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 3.8787 - RMSE: 1.9694\n",
      "Epoch 318/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 3.3026 - RMSE: 1.8173\n",
      "Epoch 319/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.2873 - RMSE: 1.8131\n",
      "Epoch 320/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 3.3962 - RMSE: 1.8429\n",
      "Epoch 321/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 3.0277 - RMSE: 1.7400\n",
      "Epoch 322/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 2.8867 - RMSE: 1.6990\n",
      "Epoch 323/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.0274 - RMSE: 1.7399\n",
      "Epoch 324/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.3978 - RMSE: 1.8433\n",
      "Epoch 325/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.3792 - RMSE: 1.8383\n",
      "Epoch 326/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.9279 - RMSE: 1.7111\n",
      "Epoch 327/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.7456 - RMSE: 1.6570\n",
      "Epoch 328/500\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.4922 - RMSE: 1.5787\n",
      "Epoch 329/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.2716 - RMSE: 1.5072\n",
      "Epoch 330/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.5536 - RMSE: 1.5980\n",
      "Epoch 331/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.0712 - RMSE: 1.7525\n",
      "Epoch 332/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 3.0246 - RMSE: 1.7391\n",
      "Epoch 333/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 13ms/step - loss: 3.4388 - RMSE: 1.8544\n",
      "Epoch 334/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 3.2507 - RMSE: 1.8030\n",
      "Epoch 335/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 4.2054 - RMSE: 2.0507\n",
      "Epoch 336/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 4.5270 - RMSE: 2.1277\n",
      "Epoch 337/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 4.3510 - RMSE: 2.0859\n",
      "Epoch 338/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.5719 - RMSE: 1.8899\n",
      "Epoch 339/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.0019 - RMSE: 1.7326\n",
      "Epoch 340/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.2778 - RMSE: 1.8105\n",
      "Epoch 341/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.5769 - RMSE: 1.8913\n",
      "Epoch 342/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 3.8330 - RMSE: 1.9578\n",
      "Epoch 343/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.2839 - RMSE: 1.8122\n",
      "Epoch 344/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.7407 - RMSE: 1.9341\n",
      "Epoch 345/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 2.9492 - RMSE: 1.7173\n",
      "Epoch 346/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 2.7952 - RMSE: 1.6719\n",
      "Epoch 347/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 2.5365 - RMSE: 1.5926\n",
      "Epoch 348/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.5590 - RMSE: 1.5997\n",
      "Epoch 349/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.9560 - RMSE: 1.7193\n",
      "Epoch 350/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 2.6784 - RMSE: 1.6366\n",
      "Epoch 351/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 4.0754 - RMSE: 2.0188\n",
      "Epoch 352/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.1524 - RMSE: 1.7755\n",
      "Epoch 353/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 3.2744 - RMSE: 1.8095\n",
      "Epoch 354/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 2.7934 - RMSE: 1.6713\n",
      "Epoch 355/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 2.6439 - RMSE: 1.6260\n",
      "Epoch 356/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 2.8551 - RMSE: 1.6897\n",
      "Epoch 357/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 2.8381 - RMSE: 1.6847\n",
      "Epoch 358/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.1607 - RMSE: 1.7778\n",
      "Epoch 359/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 2.7398 - RMSE: 1.6552\n",
      "Epoch 360/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 2.6328 - RMSE: 1.6226\n",
      "Epoch 361/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.7685 - RMSE: 1.6639\n",
      "Epoch 362/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.4837 - RMSE: 1.5760\n",
      "Epoch 363/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 2.1990 - RMSE: 1.4829\n",
      "Epoch 364/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 2.3394 - RMSE: 1.5295\n",
      "Epoch 365/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 2.6524 - RMSE: 1.6286\n",
      "Epoch 366/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 4.7082 - RMSE: 2.1698\n",
      "Epoch 367/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 5.4424 - RMSE: 2.3329\n",
      "Epoch 368/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 3.1874 - RMSE: 1.7853\n",
      "Epoch 369/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.4863 - RMSE: 1.5768\n",
      "Epoch 370/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.9677 - RMSE: 1.7227\n",
      "Epoch 371/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.8612 - RMSE: 1.6915\n",
      "Epoch 372/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.7990 - RMSE: 1.6730\n",
      "Epoch 373/500\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.4932 - RMSE: 1.5790\n",
      "Epoch 374/500\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.8659 - RMSE: 1.6929\n",
      "Epoch 375/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.2649 - RMSE: 1.5050\n",
      "Epoch 376/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.4995 - RMSE: 1.5810\n",
      "Epoch 377/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.0623 - RMSE: 1.7499\n",
      "Epoch 378/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 3.0794 - RMSE: 1.7548\n",
      "Epoch 379/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.4036 - RMSE: 1.5503\n",
      "Epoch 380/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 3.1463 - RMSE: 1.7738\n",
      "Epoch 381/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.0257 - RMSE: 1.7394\n",
      "Epoch 382/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 3.0034 - RMSE: 1.7330\n",
      "Epoch 383/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 2.3583 - RMSE: 1.5357\n",
      "Epoch 384/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.1398 - RMSE: 1.7720\n",
      "Epoch 385/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.1443 - RMSE: 1.7732\n",
      "Epoch 386/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.4088 - RMSE: 1.5520\n",
      "Epoch 387/500\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.1407 - RMSE: 1.4631\n",
      "Epoch 388/500\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.0212 - RMSE: 1.4217\n",
      "Epoch 389/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.2302 - RMSE: 1.4934\n",
      "Epoch 390/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.6827 - RMSE: 1.6379\n",
      "Epoch 391/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.4533 - RMSE: 1.5663\n",
      "Epoch 392/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.8339 - RMSE: 1.6834\n",
      "Epoch 393/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 2.3667 - RMSE: 1.5384\n",
      "Epoch 394/500\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 2.0423 - RMSE: 1.4291\n",
      "Epoch 395/500\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7990 - RMSE: 1.3413\n",
      "Epoch 396/500\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.2909 - RMSE: 1.5136\n",
      "Epoch 397/500\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 2.7450 - RMSE: 1.6568\n",
      "Epoch 398/500\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 2.5396 - RMSE: 1.5936\n",
      "Epoch 399/500\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 2.7858 - RMSE: 1.6691\n",
      "Epoch 400/500\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 2.2331 - RMSE: 1.4944\n",
      "Epoch 401/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.0733 - RMSE: 1.4399\n",
      "Epoch 402/500\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.2454 - RMSE: 1.4985\n",
      "Epoch 403/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.6277 - RMSE: 1.6210\n",
      "Epoch 404/500\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.8339 - RMSE: 1.6834\n",
      "Epoch 405/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.9747 - RMSE: 1.4052\n",
      "Epoch 406/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.8418 - RMSE: 1.3571\n",
      "Epoch 407/500\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.1870 - RMSE: 1.4789\n",
      "Epoch 408/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.3250 - RMSE: 1.5248\n",
      "Epoch 409/500\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.5134 - RMSE: 1.5854\n",
      "Epoch 410/500\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.7435 - RMSE: 1.3204\n",
      "Epoch 411/500\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.7624 - RMSE: 1.3275\n",
      "Epoch 412/500\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 1.8045 - RMSE: 1.3433\n",
      "Epoch 413/500\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 1.9163 - RMSE: 1.3843\n",
      "Epoch 414/500\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 1.9514 - RMSE: 1.3969\n",
      "Epoch 415/500\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.9650 - RMSE: 1.4018\n",
      "Epoch 416/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 20ms/step - loss: 1.8961 - RMSE: 1.3770\n",
      "Epoch 417/500\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.0308 - RMSE: 1.4251\n",
      "Epoch 418/500\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.7001 - RMSE: 1.6432\n",
      "Epoch 419/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 3.0762 - RMSE: 1.7539\n",
      "Epoch 420/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.8237 - RMSE: 1.6804\n",
      "Epoch 421/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.6341 - RMSE: 1.6230\n",
      "Epoch 422/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.7803 - RMSE: 1.6674\n",
      "Epoch 423/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.9432 - RMSE: 1.7156\n",
      "Epoch 424/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.4398 - RMSE: 1.5620\n",
      "Epoch 425/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.3196 - RMSE: 1.5230\n",
      "Epoch 426/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 3.5929 - RMSE: 1.8955\n",
      "Epoch 427/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.2772 - RMSE: 1.5090\n",
      "Epoch 428/500\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.3446 - RMSE: 1.5312\n",
      "Epoch 429/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.7388 - RMSE: 1.6549\n",
      "Epoch 430/500\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.1657 - RMSE: 1.4716\n",
      "Epoch 431/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.8101 - RMSE: 1.3454\n",
      "Epoch 432/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.5684 - RMSE: 1.6026\n",
      "Epoch 433/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.6840 - RMSE: 1.6383\n",
      "Epoch 434/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.1578 - RMSE: 1.4689\n",
      "Epoch 435/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.9465 - RMSE: 1.7165\n",
      "Epoch 436/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.3752 - RMSE: 1.5412\n",
      "Epoch 437/500\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 1.9555 - RMSE: 1.3984\n",
      "Epoch 438/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5916 - RMSE: 1.2616\n",
      "Epoch 439/500\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.6601 - RMSE: 1.2884\n",
      "Epoch 440/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.5511 - RMSE: 1.2454\n",
      "Epoch 441/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.3869 - RMSE: 1.1777\n",
      "Epoch 442/500\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.4448 - RMSE: 1.2020\n",
      "Epoch 443/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.6690 - RMSE: 1.2919\n",
      "Epoch 444/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.7779 - RMSE: 1.3334\n",
      "Epoch 445/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.2445 - RMSE: 1.4982\n",
      "Epoch 446/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.7766 - RMSE: 1.3329\n",
      "Epoch 447/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.3251 - RMSE: 1.1511\n",
      "Epoch 448/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.5482 - RMSE: 1.2443\n",
      "Epoch 449/500\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3086 - RMSE: 1.1439\n",
      "Epoch 450/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.6713 - RMSE: 1.2928\n",
      "Epoch 451/500\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.6355 - RMSE: 1.2789\n",
      "Epoch 452/500\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5661 - RMSE: 1.2514\n",
      "Epoch 453/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.1174 - RMSE: 1.4551\n",
      "Epoch 454/500\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.2527 - RMSE: 1.5009\n",
      "Epoch 455/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.8580 - RMSE: 1.3631\n",
      "Epoch 456/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.0433 - RMSE: 1.4294\n",
      "Epoch 457/500\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 2.9626 - RMSE: 1.7212\n",
      "Epoch 458/500\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.2853 - RMSE: 1.1337\n",
      "Epoch 459/500\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5530 - RMSE: 1.2462\n",
      "Epoch 460/500\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.7321 - RMSE: 1.3161\n",
      "Epoch 461/500\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.3384 - RMSE: 1.1569\n",
      "Epoch 462/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.3230 - RMSE: 1.1502\n",
      "Epoch 463/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.0934 - RMSE: 1.4469\n",
      "Epoch 464/500\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7031 - RMSE: 1.3050\n",
      "Epoch 465/500\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.3289 - RMSE: 1.1528\n",
      "Epoch 466/500\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.6431 - RMSE: 1.2818\n",
      "Epoch 467/500\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 3.6178 - RMSE: 1.9021\n",
      "Epoch 468/500\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 3.2997 - RMSE: 1.8165\n",
      "Epoch 469/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.5560 - RMSE: 1.5988\n",
      "Epoch 470/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.4134 - RMSE: 1.5535\n",
      "Epoch 471/500\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.6511 - RMSE: 1.2850\n",
      "Epoch 472/500\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.6265 - RMSE: 1.2754\n",
      "Epoch 473/500\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.1003 - RMSE: 1.4492\n",
      "Epoch 474/500\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.4757 - RMSE: 1.5735\n",
      "Epoch 475/500\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.5300 - RMSE: 1.5906\n",
      "Epoch 476/500\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.5540 - RMSE: 1.5981\n",
      "Epoch 477/500\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 2.3677 - RMSE: 1.5387\n",
      "Epoch 478/500\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.3250 - RMSE: 1.5248\n",
      "Epoch 479/500\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6884 - RMSE: 1.2994\n",
      "Epoch 480/500\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 1.8219 - RMSE: 1.3498\n",
      "Epoch 481/500\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 1.5409 - RMSE: 1.2413\n",
      "Epoch 482/500\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 1.6886 - RMSE: 1.2995\n",
      "Epoch 483/500\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 1.6744 - RMSE: 1.2940\n",
      "Epoch 484/500\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 1.7217 - RMSE: 1.3121\n",
      "Epoch 485/500\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 1.5585 - RMSE: 1.2484\n",
      "Epoch 486/500\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 1.9773 - RMSE: 1.4062\n",
      "Epoch 487/500\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 1.5600 - RMSE: 1.2490\n",
      "Epoch 488/500\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 1.4706 - RMSE: 1.2127\n",
      "Epoch 489/500\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 1.4638 - RMSE: 1.2099\n",
      "Epoch 490/500\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 1.6496 - RMSE: 1.2844\n",
      "Epoch 491/500\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 1.4349 - RMSE: 1.1979\n",
      "Epoch 492/500\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 1.8010 - RMSE: 1.3420\n",
      "Epoch 493/500\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 1.5055 - RMSE: 1.2270\n",
      "Epoch 494/500\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 1.3387 - RMSE: 1.1570 1s\n",
      "Epoch 495/500\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 1.5684 - RMSE: 1.2524\n",
      "Epoch 496/500\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 1.7392 - RMSE: 1.3188\n",
      "Epoch 497/500\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 1.5694 - RMSE: 1.2528\n",
      "Epoch 498/500\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 1.7461 - RMSE: 1.3214\n",
      "Epoch 499/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 40ms/step - loss: 2.0428 - RMSE: 1.4293\n",
      "Epoch 500/500\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 1.7544 - RMSE: 1.3245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7907ed9940>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.compile(\n",
    "    tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"mse\",\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    ")\n",
    "\n",
    "model_2.fit(x_train, y_train, batch_size=32, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "[TRAIN]\n",
      "******\n",
      "RMSE: 0.893 (0.000)\n",
      "MAE: 0.683 (0.000)\n",
      "MAPE: 0.016 (0.000)\n",
      "R2: 0.969 (0.000)\n",
      "\n",
      "======================\n",
      "\n",
      "******\n",
      "[TEST]\n",
      "******\n",
      "RMSE: 3.821 (0.000)\n",
      "MAE: 2.480 (0.000)\n",
      "MAPE: 0.057 (0.000)\n",
      "R2: 0.405 (0.000)\n",
      "\n",
      "======================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model_2.predict(x_train)\n",
    "y_test_pred = model_2.predict(x_test)\n",
    "\n",
    "scores = score_regression_metrics(y_train, y_train_pred, y_test, y_test_pred)\n",
    "print_scores(scores, METRICS, METRICS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ccs28-venv)",
   "language": "python",
   "name": "ccs28-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
